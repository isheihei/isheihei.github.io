<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>计算机基础 on isheihei&#39;s blog</title>
        <link>https://isheihei.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/</link>
        <description>Recent content in 计算机基础 on isheihei&#39;s blog</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <lastBuildDate>Tue, 26 Jul 2022 15:35:36 +0800</lastBuildDate><atom:link href="https://isheihei.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Reactor模型</title>
        <link>https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/reactor%E6%A8%A1%E5%9E%8B/</link>
        <pubDate>Tue, 26 Jul 2022 15:35:36 +0800</pubDate>
        
        <guid>https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/reactor%E6%A8%A1%E5%9E%8B/</guid>
        <description>&lt;h2 id=&#34;io线程模型&#34;&gt;IO线程模型&lt;/h2&gt;
&lt;p&gt;目前的IO线程处理模型一般可以分为以下三类&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;单线程阻塞I/O服务模型：单线程处理Socket连接和I/O，只能同时处理一个Socket&lt;/li&gt;
&lt;li&gt;多线程阻塞IO服务模型：每建立一个Socket连接就分配一个线程&lt;/li&gt;
&lt;li&gt;Reactor模式：多个连接共用一个阻塞对象，应用程序只需要在一个阻塞对象等待，无需阻塞等待所有连接。当某个连接有新的数据可以处理时，操作系统通知应用程序，线程从阻塞状态返回，开始进行业务处理。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;根据Reactor的数量和处理资源池线程的数量不同，Reactor模式有如下3种典型的实现&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;单Reactor单线程&lt;/li&gt;
&lt;li&gt;单Reactor多线程&lt;/li&gt;
&lt;li&gt;主从Reactor多线程&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;reactor模型&#34;&gt;Reactor模型&lt;/h2&gt;
&lt;p&gt;Reactor模型中有三个角色&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Reactor 对象的作用是监听和分发事件；&lt;/li&gt;
&lt;li&gt;Acceptor 对象的作用是获取连接；&lt;/li&gt;
&lt;li&gt;Handler 对象的作用是处理业务；&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;单线程模型&#34;&gt;单线程模型&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/reactor%E6%A8%A1%E5%9E%8B/%E5%8D%95Reactor%E5%8D%95%E8%BF%9B%E7%A8%8B.png&#34;
	width=&#34;1427&#34;
	height=&#34;834&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/reactor%E6%A8%A1%E5%9E%8B/%E5%8D%95Reactor%E5%8D%95%E8%BF%9B%E7%A8%8B_hu2adaabf63dcb50b8ed74a14558eec4a4_97390_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/reactor%E6%A8%A1%E5%9E%8B/%E5%8D%95Reactor%E5%8D%95%E8%BF%9B%E7%A8%8B_hu2adaabf63dcb50b8ed74a14558eec4a4_97390_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;单Reactor单线程&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;171&#34;
		data-flex-basis=&#34;410px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;对象里的 select、accept、read、send 是系统调用函数，dispatch 和 「业务处理」是需要完成的操作，其中 dispatch 是分发事件操作。&lt;/p&gt;
&lt;p&gt;接下来，介绍下「单 Reactor 单线程」这个方案：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Reactor 对象通过 select （IO 多路复用接口） 监听事件，收到事件后通过 dispatch 进行分发，具体分发给 Acceptor 对象还是 Handler 对象，还要看收到的事件类型；&lt;/li&gt;
&lt;li&gt;如果是连接建立的事件，则交由 Acceptor 对象进行处理，Acceptor 对象会通过 accept 方法 获取连接，并创建一个 Handler 对象来处理后续的响应事件；&lt;/li&gt;
&lt;li&gt;如果不是连接建立事件， 则交由当前连接对应的 Handler 对象来进行响应；&lt;/li&gt;
&lt;li&gt;Handler 对象通过 read -&amp;gt; 业务处理 -&amp;gt; send 的流程来完成完整的业务流程。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;单 Reactor 单线程的方案因为全部工作都在同一个进程内完成，所以实现起来比较简单，不需要考虑进程间通信，也不用担心多进程竞争。&lt;/p&gt;
&lt;p&gt;但是，这种方案存在 2 个缺点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;第一个缺点，因为只有一个进程，&lt;strong&gt;无法充分利用 多核 CPU 的性能&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;第二个缺点，Handler 对象在业务处理时，整个进程是无法处理其他连接的事件的，&lt;strong&gt;如果业务处理耗时比较长，那么就造成响应的延迟&lt;/strong&gt;；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所以，单 Reactor 单进程的方案&lt;strong&gt;不适用计算机密集型的场景，只适用于业务处理非常快速的场景&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;Redis 是由 C 语言实现的，在 Redis 6.0 版本之前采用的正是「单 Reactor 单进程」的方案，因为 Redis 业务处理主要是在内存中完成，操作的速度是很快的，性能瓶颈不在 CPU 上，所以 Redis 对于命令的处理是单进程的方案。&lt;/p&gt;
&lt;h3 id=&#34;多线程模型&#34;&gt;多线程模型&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/reactor%E6%A8%A1%E5%9E%8B/%E5%8D%95Reactor%E5%A4%9A%E7%BA%BF%E7%A8%8B.png&#34;
	width=&#34;1514&#34;
	height=&#34;1277&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/reactor%E6%A8%A1%E5%9E%8B/%E5%8D%95Reactor%E5%A4%9A%E7%BA%BF%E7%A8%8B_hu34f2950544104121fb0752855b411a5e_150874_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/reactor%E6%A8%A1%E5%9E%8B/%E5%8D%95Reactor%E5%A4%9A%E7%BA%BF%E7%A8%8B_hu34f2950544104121fb0752855b411a5e_150874_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;单Reactor多线程&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;118&#34;
		data-flex-basis=&#34;284px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Reactor 对象通过 select （IO 多路复用接口） 监听事件，收到事件后通过 dispatch 进行分发，具体分发给 Acceptor 对象还是 Handler 对象，还要看收到的事件类型；&lt;/li&gt;
&lt;li&gt;如果是连接建立的事件，则交由 Acceptor 对象进行处理，Acceptor 对象会通过 accept 方法 获取连接，并创建一个 Handler 对象来处理后续的响应事件；&lt;/li&gt;
&lt;li&gt;如果不是连接建立事件， 则交由当前连接对应的 Handler 对象来进行响应；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;上面的三个步骤和单 Reactor 单线程方案是一样的，接下来的步骤就开始不一样了：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Handler 对象不再负责业务处理，只负责数据的接收和发送，Handler 对象通过 read 读取到数据后，会将数据发给子线程里的 Processor 对象进行业务处理；&lt;/li&gt;
&lt;li&gt;子线程里的 Processor 对象就进行业务处理，处理完后，将结果发给主线程中的 Handler 对象，接着由 Handler 通过 send 方法将响应结果发送给 client；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;单 Reator 多线程的方案优势在于&lt;strong&gt;能够充分利用多核 CPU 的能&lt;/strong&gt;，那既然引入多线程，那么自然就带来了多线程竞争资源的问题。&lt;/p&gt;
&lt;p&gt;例如，子线程完成业务处理后，要把结果传递给主线程的 Handler 进行发送，这里涉及共享数据的竞争。&lt;/p&gt;
&lt;p&gt;要避免多线程由于竞争共享资源而导致数据错乱的问题，就需要在操作共享资源前加上互斥锁，以保证任意时间里只有一个线程在操作共享资源，待该线程操作完释放互斥锁后，其他线程才有机会操作共享数据。&lt;/p&gt;
&lt;p&gt;另外，「单 Reactor」的模式还有个问题，&lt;strong&gt;因为一个 Reactor 对象承担所有事件的监听和响应，而且只在主线程中运行，在面对瞬间高并发的场景时，容易成为性能的瓶颈的地方&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;主从多线程模型&#34;&gt;主从多线程模型&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/reactor%E6%A8%A1%E5%9E%8B/%E4%B8%BB%E4%BB%8EReactor%E5%A4%9A%E7%BA%BF%E7%A8%8B.png&#34;
	width=&#34;1772&#34;
	height=&#34;1262&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/reactor%E6%A8%A1%E5%9E%8B/%E4%B8%BB%E4%BB%8EReactor%E5%A4%9A%E7%BA%BF%E7%A8%8B_huf6051e633e27963a6945683b5260f969_148611_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/reactor%E6%A8%A1%E5%9E%8B/%E4%B8%BB%E4%BB%8EReactor%E5%A4%9A%E7%BA%BF%E7%A8%8B_huf6051e633e27963a6945683b5260f969_148611_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;主从Reactor多线程&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;140&#34;
		data-flex-basis=&#34;336px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;主线程中的 MainReactor 对象通过 select 监控连接建立事件，收到事件后通过 Acceptor 对象中的 accept 获取连接，将新的连接分配给某个子线程；&lt;/li&gt;
&lt;li&gt;子线程中的 SubReactor 对象将 MainReactor 对象分配的连接加入 select 继续进行监听，并创建一个 Handler 用于处理连接的响应事件。&lt;/li&gt;
&lt;li&gt;如果有新的事件发生时，SubReactor 对象会调用当前连接对应的 Handler 对象来进行响应。&lt;/li&gt;
&lt;li&gt;Handler 对象通过 read -&amp;gt; 业务处理 -&amp;gt; send 的流程来完成完整的业务流程。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;MainReactor 仅监听连接事件，一旦建立了连接就将该连接加入 SubReactor，监听读写事件。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;netty-中的-reactor-模型&#34;&gt;Netty 中的 Reactor 模型&lt;/h2&gt;
&lt;h3 id=&#34;eventloopeventloopgroup-怎么实现reactor线程模型&#34;&gt;EventLoop、EventLoopGroup 怎么实现Reactor线程模型?&lt;/h3&gt;
&lt;p&gt;上面我们已经了解了Reactor线程模型，了解了它的核心就是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Reactor线程模式 = Reactor(I/O多路复用)+ 线程池&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;它的运行模式包括四个步骤：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;连接注册：建立连接后，将channel注册到selector上&lt;/li&gt;
&lt;li&gt;事件轮询：selcetor上轮询(select()函数)获取已经注册的channel的所有I/O事件(多路复用)&lt;/li&gt;
&lt;li&gt;事件分发：把准备就绪的I/O事件分配到对应线程进行处理&lt;/li&gt;
&lt;li&gt;事件处理：每个worker线程执行事件任务&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;那这样的模型在Netty中具体怎么实现呢?&lt;/p&gt;
&lt;p&gt;这就需要我们了解下EventLoop和EventLoopGroup了。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Netty boss 线程池是处理 accept事件的，不管线程池多大，只会使用一个线程，既然只使用一个线程为什么要用线程池呢？主要是异常的情况下，线程die了，可以再创建一个新线程，那什么情况下boss线程池可以使用多个线程呢？那就是当ServerBootstrap bind多个端口时。每个端口都有一个线程eventloop accept事件。&lt;/p&gt;
&lt;p&gt;作者：Rocky
链接：https://www.zhihu.com/question/284788403/answer/1670777098
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;1连接注册&#34;&gt;1)连接注册&lt;/h4&gt;
&lt;p&gt;Boss EventLoopGroup中有一个EventLoop，绑定某个特定端口进行监听。&lt;/p&gt;
&lt;p&gt;一旦有新的连接进来触发accept类型事件，就会在当前EventLoop的I/O事件处理阶段，将这个连接分配给Worker EventLoopGroup中的某一个EventLoop，进行后续 事件的监听。&lt;/p&gt;
&lt;h4 id=&#34;2事件轮询&#34;&gt;2)事件轮询&lt;/h4&gt;
&lt;p&gt;Worker EventLoopGroup中的EventLoop，会通过selcetor对绑定到自身的channel进行轮询，获取已经注册的channel的所有I/O事件(多路复用)。&lt;/p&gt;
&lt;p&gt;当然，EventLoopGroup中会有 多个EventLoop 运行，各自循环处理。具体EventLoop数量是由 用户指定的线程数 或者 默认为核数的2倍。&lt;/p&gt;
&lt;h4 id=&#34;3事件分发&#34;&gt;3)事件分发&lt;/h4&gt;
&lt;p&gt;当Worker EventLoopGroup中的EventLoop获取到I/O事件后，会在EventLoop的 I/O事件处理(processSelectedKeys) 阶段分发给对应ChannelPipeline进行处理。&lt;/p&gt;
&lt;p&gt;注意，仍然在当前线程进行串行处理&lt;/p&gt;
&lt;h4 id=&#34;4事件处理&#34;&gt;4)事件处理&lt;/h4&gt;
&lt;p&gt;在ChannelPipeline中对I/O事件进行处理。&lt;/p&gt;
&lt;p&gt;I/O事件处理完后，EventLoop在 任务处理(runAllTasks) 阶段，对队列中的任务进行消费处理。&lt;/p&gt;
&lt;p&gt;至此，我们就能完全梳理清楚EventLoopGroup/EventLoop 和 Reactor线程模型的关系了。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Boss EventLoopGroup 对应 Reactor 中的 MainReactor，Worker EventLoopGroup 对应 Reactor模型 中的 handler组。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;netty是哪种reactor模型&#34;&gt;Netty是哪种Reactor模型？&lt;/h3&gt;
&lt;p&gt;Netty可以通过简单配置，支持单Reactor单线程模型 、单Reactor多线程模型 、多Reactor多线程模型。&lt;/p&gt;
&lt;h4 id=&#34;单reactor单线程模型&#34;&gt;单Reactor单线程模型&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;new ServerBootstrap()
.group(new NioEventLoopGroup(1))&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;单reactor多线程模型&#34;&gt;单Reactor多线程模型&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;new ServerBootstrap()
.group(new NioEventLoopGroup(1), new NioEventLoopGroup(4))&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;多reactor多线程模型&#34;&gt;多Reactor多线程模型&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;new ServerBootstrap()
.group(new NioEventLoopGroup(4), new NioEventLoopGroup(4))&lt;/p&gt;
&lt;/blockquote&gt;
</description>
        </item>
        <item>
        <title>零拷贝</title>
        <link>https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E9%9B%B6%E6%8B%B7%E8%B4%9D/</link>
        <pubDate>Tue, 26 Jul 2022 10:59:34 +0800</pubDate>
        
        <guid>https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E9%9B%B6%E6%8B%B7%E8%B4%9D/</guid>
        <description>&lt;h2 id=&#34;太长不看系列read--write-一个文件&#34;&gt;太长不看系列：read() &amp;amp; write() 一个文件&lt;/h2&gt;
&lt;h3 id=&#34;没有-dma-技术之前&#34;&gt;没有 DMA 技术之前&lt;/h3&gt;
&lt;p&gt;四次内核态和用户态切换，四次拷贝，且两次拷贝都需要CPU参与&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E9%9B%B6%E6%8B%B7%E8%B4%9D/IO%E4%B8%AD%E6%96%AD.png&#34;
	width=&#34;1337&#34;
	height=&#34;785&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E9%9B%B6%E6%8B%B7%E8%B4%9D/IO%E4%B8%AD%E6%96%AD_hu2a490217fb86f0f2a5249dcee421d1b9_119603_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E9%9B%B6%E6%8B%B7%E8%B4%9D/IO%E4%B8%AD%E6%96%AD_hu2a490217fb86f0f2a5249dcee421d1b9_119603_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;没有DMA技术&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;170&#34;
		data-flex-basis=&#34;408px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;有了dma技术&#34;&gt;有了DMA技术&lt;/h3&gt;
&lt;p&gt;DMA可以控制磁盘到内核缓冲区，所以 CPU 减少了一定的工作量&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E9%9B%B6%E6%8B%B7%E8%B4%9D/%E4%BC%A0%E7%BB%9F%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93.png&#34;
	width=&#34;1100&#34;
	height=&#34;678&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E9%9B%B6%E6%8B%B7%E8%B4%9D/%E4%BC%A0%E7%BB%9F%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93_hua8e3266497881f7d0083c0379c6a4097_87556_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E9%9B%B6%E6%8B%B7%E8%B4%9D/%E4%BC%A0%E7%BB%9F%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93_hua8e3266497881f7d0083c0379c6a4097_87556_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;DMA技术&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;162&#34;
		data-flex-basis=&#34;389px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;零拷贝技术之-mmap&#34;&gt;零拷贝技术之 mmap()&lt;/h3&gt;
&lt;p&gt;mmap() 可以把内核缓冲区数据映射到用户态，所以不再需要内核态和用户态之间拷贝，但是需要在内核的缓冲区和 socket 缓冲区进行拷贝，所以共需要三次拷贝（磁盘 &amp;lt;-&amp;gt; 内核两次、内核PageCache&amp;lt;-&amp;gt; 内核socket缓冲区一次）以及两次系统调用（内核态和用户态四次转换）&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E9%9B%B6%E6%8B%B7%E8%B4%9D/mmap_write.png&#34;
	width=&#34;1100&#34;
	height=&#34;677&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E9%9B%B6%E6%8B%B7%E8%B4%9D/mmap_write_hu991a0cc7cc633bcddc064c5febd47237_90307_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E9%9B%B6%E6%8B%B7%E8%B4%9D/mmap_write_hu991a0cc7cc633bcddc064c5febd47237_90307_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;mmap()&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;162&#34;
		data-flex-basis=&#34;389px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;零拷贝技术之-sendfile&#34;&gt;零拷贝技术之 sendfile()&lt;/h3&gt;
&lt;p&gt;sendfile 可以直接发起一次系统调用进行文件发送，如果网卡支持 SG-DMA（&lt;em&gt;The Scatter-Gather Direct Memory Access&lt;/em&gt;）技术，可以直接从内核PageCache 拷贝到网卡，又减少了一次拷贝。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E9%9B%B6%E6%8B%B7%E8%B4%9D/senfile-3%E6%AC%A1%E6%8B%B7%E8%B4%9D.png&#34;
	width=&#34;1100&#34;
	height=&#34;686&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E9%9B%B6%E6%8B%B7%E8%B4%9D/senfile-3%E6%AC%A1%E6%8B%B7%E8%B4%9D_hu4ccaf8580c03c11a45c20f231e5a5ac8_119322_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E9%9B%B6%E6%8B%B7%E8%B4%9D/senfile-3%E6%AC%A1%E6%8B%B7%E8%B4%9D_hu4ccaf8580c03c11a45c20f231e5a5ac8_119322_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;sendfile无SG-DMA&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;160&#34;
		data-flex-basis=&#34;384px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E9%9B%B6%E6%8B%B7%E8%B4%9D/senfile-%E9%9B%B6%E6%8B%B7%E8%B4%9D.png&#34;
	width=&#34;1160&#34;
	height=&#34;686&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E9%9B%B6%E6%8B%B7%E8%B4%9D/senfile-%E9%9B%B6%E6%8B%B7%E8%B4%9D_hu57149e7fc7cae253fd2388b347179840_126338_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E9%9B%B6%E6%8B%B7%E8%B4%9D/senfile-%E9%9B%B6%E6%8B%B7%E8%B4%9D_hu57149e7fc7cae253fd2388b347179840_126338_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;sendfile有SG-DMA&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;169&#34;
		data-flex-basis=&#34;405px&#34;
	
&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;技术&lt;/th&gt;
&lt;th&gt;系统调用次数&lt;/th&gt;
&lt;th&gt;内核态与用户态切换次数&lt;/th&gt;
&lt;th&gt;数据拷贝次数&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;没有DMA技术之前&lt;/td&gt;
&lt;td&gt;两次&lt;/td&gt;
&lt;td&gt;四次&lt;/td&gt;
&lt;td&gt;四次（都需要CPU）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;DMA技术&lt;/td&gt;
&lt;td&gt;两次&lt;/td&gt;
&lt;td&gt;四次&lt;/td&gt;
&lt;td&gt;四次（两次CPU拷贝、两次DMA拷贝）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;mmap()&lt;/td&gt;
&lt;td&gt;两次&lt;/td&gt;
&lt;td&gt;四次&lt;/td&gt;
&lt;td&gt;三次（两次DMA拷贝、一次CPU拷贝）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;sendfile（）：无SG-DMA&lt;/td&gt;
&lt;td&gt;一次&lt;/td&gt;
&lt;td&gt;两次&lt;/td&gt;
&lt;td&gt;三次（两次DMA拷贝、一次CPU拷贝）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;sendfile（）：有SG-DMA&lt;/td&gt;
&lt;td&gt;一次&lt;/td&gt;
&lt;td&gt;两次&lt;/td&gt;
&lt;td&gt;两次（一次DMA拷贝、一次SG-DMA拷贝）&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;pagecache&#34;&gt;PageCache&lt;/h2&gt;
&lt;p&gt;回顾前面说道文件传输过程，其中第一步都是先需要先把磁盘文件数据拷贝「内核缓冲区」里，这个「内核缓冲区」实际上是&lt;strong&gt;磁盘高速缓存（&lt;em&gt;PageCache&lt;/em&gt;）&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;我们都知道程序运行的时候，具有「局部性」，所以通常，刚被访问的数据在短时间内再次被访问的概率很高，于是我们可以用 &lt;strong&gt;PageCache 来缓存最近被访问的数据&lt;/strong&gt;，当空间不足时淘汰最久未被访问的缓存。&lt;/p&gt;
&lt;p&gt;还有一点，读取磁盘数据的时候，需要找到数据所在的位置，但是对于机械磁盘来说，就是通过磁头旋转到数据所在的扇区，再开始「顺序」读取数据，但是旋转磁头这个物理动作是非常耗时的，为了降低它的影响，&lt;strong&gt;PageCache 使用了「预读功能」&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;比如，假设 read 方法每次只会读 &lt;code&gt;32 KB&lt;/code&gt; 的字节，虽然 read 刚开始只会读 0 ～ 32 KB 的字节，但内核会把其后面的 32～64 KB 也读取到 PageCache，这样后面读取 32～64 KB 的成本就很低，如果在 32～64 KB 淘汰出 PageCache 前，进程读取到它了，收益就非常大。&lt;/p&gt;
&lt;p&gt;所以，PageCache 的优点主要是两个：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;缓存最近被访问的数据；&lt;/li&gt;
&lt;li&gt;预读功能；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这两个做法，将大大提高读写磁盘的性能。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;但是，在传输大文件（GB 级别的文件）的时候，PageCache 会不起作用，那就白白浪费 DMA 多做的一次数据拷贝，造成性能的降低，即使使用了 PageCache 的零拷贝也会损失性能&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这是因为如果你有很多 GB 级别文件需要传输，每当用户访问这些大文件的时候，内核就会把它们载入 PageCache 中，于是 PageCache 空间很快被这些大文件占满。&lt;/p&gt;
&lt;p&gt;另外，由于文件太大，可能某些部分的文件数据被再次访问的概率比较低，这样就会带来 2 个问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PageCache 由于长时间被大文件占据，其他「热点」的小文件可能就无法充分使用到 PageCache，于是这样磁盘读写的性能就会下降了；&lt;/li&gt;
&lt;li&gt;PageCache 中的大文件数据，由于没有享受到缓存带来的好处，但却耗费 DMA 多拷贝到 PageCache 一次；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所以，针对大文件的传输，不应该使用 PageCache，也就是说不应该使用零拷贝技术，因为可能由于 PageCache 被大文件占据，而导致「热点」小文件无法利用到 PageCache，这样在高并发的环境下，会带来严重的性能问题。&lt;/p&gt;
&lt;h2 id=&#34;大文件传输方式异步io--直接io&#34;&gt;大文件传输方式（异步I/O + 直接I/O）&lt;/h2&gt;
&lt;h3 id=&#34;异步io&#34;&gt;异步I/O&lt;/h3&gt;
&lt;p&gt;![异步I/O](异步 IO 的过程.png)&lt;/p&gt;
&lt;p&gt;它把读操作分为两部分：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;前半部分，内核向磁盘发起读请求，但是可以&lt;strong&gt;不等待数据就位就可以返回&lt;/strong&gt;，于是进程此时可以处理其他任务；&lt;/li&gt;
&lt;li&gt;后半部分，当内核将磁盘中的数据拷贝到进程缓冲区后，进程将接收到内核的&lt;strong&gt;通知&lt;/strong&gt;，再去处理数据；&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;直接io&#34;&gt;直接I/O&lt;/h3&gt;
&lt;p&gt;而且，我们可以发现，异步 I/O 并没有涉及到 PageCache，所以使用异步 I/O 就意味着要绕开 PageCache。&lt;/p&gt;
&lt;p&gt;绕开 PageCache 的 I/O 叫直接 I/O，使用 PageCache 的 I/O 则叫缓存 I/O。通常，对于磁盘，异步 I/O 只支持直接 I/O。&lt;/p&gt;
&lt;p&gt;前面也提到，大文件的传输不应该使用 PageCache，因为可能由于 PageCache 被大文件占据，而导致「热点」小文件无法利用到 PageCache。&lt;/p&gt;
&lt;p&gt;于是，&lt;strong&gt;在高并发的场景下，针对大文件的传输的方式，应该使用「异步 I/O + 直接 I/O」来替代零拷贝技术&lt;/strong&gt;。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;参考：&lt;a class=&#34;link&#34; href=&#34;https://xiaolincoding.com/os/8_network_system/zero_copy.html#_9-1-%e4%bb%80%e4%b9%88%e6%98%af%e9%9b%b6%e6%8b%b7%e8%b4%9d&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;9.1 什么是零拷贝？ | 小林coding (xiaolincoding.com)&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>操作系统04-文件管理</title>
        <link>https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/</link>
        <pubDate>Wed, 20 Jul 2022 20:41:40 +0800</pubDate>
        
        <guid>https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/</guid>
        <description>&lt;h2 id=&#34;文件系统的基本组成&#34;&gt;文件系统的基本组成&lt;/h2&gt;
&lt;p&gt;Linux 最经典的一句话是：「&lt;strong&gt;一切皆文件&lt;/strong&gt;」，不仅普通的文件和目录，就连块设备、管道、socket 等，也都是统一交给文件系统管理的。&lt;/p&gt;
&lt;p&gt;Linux 文件系统会为每个文件分配两个数据结构：&lt;strong&gt;索引节点（index node）和目录项（directory entry）&lt;/strong&gt;，它们主要用来记录文件的元信息和目录层次结构。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;索引节点，也就是 &lt;em&gt;inode&lt;/em&gt;，用来记录文件的元信息，比如 inode 编号、文件大小、访问权限、创建时间、修改时间、&lt;strong&gt;数据在磁盘的位置&lt;/strong&gt;等等。索引节点是文件的&lt;strong&gt;唯一&lt;/strong&gt;标识，它们之间一一对应，也同样都会被存储在硬盘中，所以&lt;strong&gt;索引节点同样占用磁盘空间&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;目录项，也就是 &lt;em&gt;dentry&lt;/em&gt;，用来记录文件的名字、&lt;strong&gt;索引节点指针&lt;/strong&gt;以及与其他目录项的层级关联关系。多个目录项关联起来，就会形成目录结构，但它与索引节点不同的是，&lt;strong&gt;目录项是由内核维护的一个数据结构，不存放于磁盘，而是缓存在内存&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由于索引节点唯一标识一个文件，而目录项记录着文件的名，所以目录项和索引节点的关系是多对一，也就是说，一个文件可以有多个别字。比如，硬链接的实现就是多个目录项中的索引节点指向同一个文件。&lt;/p&gt;
&lt;p&gt;注意，目录也是文件，也是用索引节点唯一标识，和普通文件不同的是，普通文件在磁盘里面保存的是文件数据，而目录文件在磁盘里面保存子目录或文件。&lt;/p&gt;
&lt;h3 id=&#34;文件数据是如何存储在磁盘的呢&#34;&gt;文件数据是如何存储在磁盘的呢？&lt;/h3&gt;
&lt;p&gt;磁盘读写的最小单位是&lt;strong&gt;扇区&lt;/strong&gt;，扇区的大小只有 &lt;code&gt;512B&lt;/code&gt; 大小，很明显，如果每次读写都以这么小为单位，那这读写的效率会非常低。&lt;/p&gt;
&lt;p&gt;所以，文件系统把多个扇区组成了一个&lt;strong&gt;逻辑块&lt;/strong&gt;，每次读写的最小单位就是逻辑块（数据块），Linux 中的逻辑块大小为 &lt;code&gt;4KB&lt;/code&gt;，也就是一次性读写 8 个扇区，这将大大提高了磁盘的读写的效率。&lt;/p&gt;
&lt;p&gt;以上就是索引节点、目录项以及文件数据的关系，下面这个图就很好的展示了它们之间的关系：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720220904704.png&#34;
	width=&#34;1172&#34;
	height=&#34;842&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720220904704_hu3cd366e0dcf74c0e534ffb410c2a9a9e_87193_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720220904704_hu3cd366e0dcf74c0e534ffb410c2a9a9e_87193_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;文件系统&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;139&#34;
		data-flex-basis=&#34;334px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;索引节点是存储在硬盘上的数据，那么为了加速文件的访问，通常会把索引节点加载到内存中。&lt;/p&gt;
&lt;p&gt;另外，磁盘进行格式化的时候，会被分成三个存储区域，分别是超级块、索引节点区和数据块区。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;超级块&lt;/em&gt;，用来存储文件系统的详细信息，比如块个数、块大小、空闲块等等。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;索引节点区&lt;/em&gt;，用来存储索引节点；&lt;/li&gt;
&lt;li&gt;&lt;em&gt;数据块区&lt;/em&gt;，用来存储文件或目录数据；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们不可能把超级块和索引节点区全部加载到内存，这样内存肯定撑不住，所以只有当需要使用的时候，才将其加载进内存，它们加载进内存的时机是不同的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;超级块：当文件系统挂载时进入内存；&lt;/li&gt;
&lt;li&gt;索引节点区：当文件被访问时进入内存&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;虚拟文件系统&#34;&gt;虚拟文件系统&lt;/h2&gt;
&lt;p&gt;文件系统的种类众多，而操作系统希望&lt;strong&gt;对用户提供一个统一的接口&lt;/strong&gt;，于是在用户层与文件系统层引入了中间层，这个中间层就称为&lt;strong&gt;虚拟文件系统（Virtual File System，VFS）。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;VFS 定义了一组所有文件系统都支持的数据结构和标准接口，这样程序员不需要了解文件系统的工作原理，只需要了解 VFS 提供的统一接口即可。&lt;/p&gt;
&lt;p&gt;在 Linux 文件系统中，用户空间、系统调用、虚拟机文件系统、缓存、文件系统以及存储之间的关系如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720221037422.png&#34;
	width=&#34;962&#34;
	height=&#34;1262&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720221037422_hu411593b8f87bb7e329570bc5870f5b29_103036_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720221037422_hu411593b8f87bb7e329570bc5870f5b29_103036_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;虚拟文件系统&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;76&#34;
		data-flex-basis=&#34;182px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;文件的使用&#34;&gt;文件的使用&lt;/h2&gt;
&lt;p&gt;我们从用户角度来看文件的话，就是我们要怎么使用文件？首先，我们得通过系统调用来打开一个文件。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720221159824.png&#34;
	width=&#34;1031&#34;
	height=&#34;200&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720221159824_hu00cd86208c69479ee96066c24fb3a012_27261_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720221159824_hu00cd86208c69479ee96066c24fb3a012_27261_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;打开文件&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;515&#34;
		data-flex-basis=&#34;1237px&#34;
	
&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nv&#34;&gt;fd&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; open&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;name, flag&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 打开文件&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;write&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;fd,...&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;         &lt;span class=&#34;c1&#34;&gt;# 写数据&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;close&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;fd&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;             &lt;span class=&#34;c1&#34;&gt;# 关闭文件&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;上面简单的代码是读取一个文件的过程：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;首先用 &lt;code&gt;open&lt;/code&gt; 系统调用打开文件，&lt;code&gt;open&lt;/code&gt; 的参数中包含文件的路径名和文件名。&lt;/li&gt;
&lt;li&gt;使用 &lt;code&gt;write&lt;/code&gt; 写数据，其中 &lt;code&gt;write&lt;/code&gt; 使用 &lt;code&gt;open&lt;/code&gt; 所返回的&lt;strong&gt;文件描述符&lt;/strong&gt;，并不使用文件名作为参数。&lt;/li&gt;
&lt;li&gt;使用完文件后，要用 &lt;code&gt;close&lt;/code&gt; 系统调用关闭文件，避免资源的泄露。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们打开了一个文件后，操作系统会跟踪进程打开的所有文件，所谓的跟踪呢，就是操作系统为每个进程维护一个打开文件表，文件表里的每一项代表「&lt;strong&gt;文件描述符&lt;/strong&gt;」，所以说文件描述符是打开文件的标识。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720221214017.png&#34;
	width=&#34;407&#34;
	height=&#34;332&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720221214017_hu0abec45de03367375af5d364f657894d_8433_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720221214017_hu0abec45de03367375af5d364f657894d_8433_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;打开文件表&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;122&#34;
		data-flex-basis=&#34;294px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;操作系统在打开文件表中维护着打开文件的状态和信息：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;文件指针：系统跟踪上次读写位置作为当前文件位置指针，这种指针对打开文件的某个进程来说是唯一的；&lt;/li&gt;
&lt;li&gt;文件打开计数器：文件关闭时，操作系统必须重用其打开文件表条目，否则表内空间不够用。因为多个进程可能打开同一个文件，所以系统在删除打开文件条目之前，必须等待最后一个进程关闭文件，该计数器跟踪打开和关闭的数量，当该计数为 0 时，系统关闭文件，删除该条目；&lt;/li&gt;
&lt;li&gt;文件磁盘位置：绝大多数文件操作都要求系统修改文件数据，该信息保存在内存中，以免每个操作都从磁盘中读取；&lt;/li&gt;
&lt;li&gt;访问权限：每个进程打开文件都需要有一个访问模式（创建、只读、读写、添加等），该信息保存在进程的打开文件表中，以便操作系统能允许或拒绝之后的 I/O 请求；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;户和操作系统对文件的读写操作是有差异的，用户习惯以字节的方式读写文件，而操作系统则是以数据块来读写文件，那屏蔽掉这种差异的工作就是文件系统了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;文件系统的基本操作单位是数据块&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&#34;文件的存储&#34;&gt;文件的存储&lt;/h2&gt;
&lt;h3 id=&#34;连续空间存放方式&#34;&gt;连续空间存放方式&lt;/h3&gt;
&lt;p&gt;连续空间存放方式顾名思义，&lt;strong&gt;文件存放在磁盘「连续的」物理空间中&lt;/strong&gt;。这种模式下，文件的数据都是紧密相连，&lt;strong&gt;读写效率很高&lt;/strong&gt;，因为一次磁盘寻道就可以读出整个文件。&lt;/p&gt;
&lt;p&gt;使用连续存放的方式有一个前提，必须先知道一个文件的大小，这样文件系统才会根据文件的大小在磁盘上找到一块连续的空间分配给文件。&lt;/p&gt;
&lt;p&gt;所以，&lt;strong&gt;文件头里需要指定「起始块的位置」和「长度」&lt;/strong&gt;，有了这两个信息就可以很好的表示文件存放方式是一块连续的磁盘空间。&lt;/p&gt;
&lt;p&gt;注意，此处说的文件头，就类似于 Linux 的 inode。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720221539944.png&#34;
	width=&#34;602&#34;
	height=&#34;377&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720221539944_hu51650a284614f6843ca9e41e592d496b_17458_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720221539944_hu51650a284614f6843ca9e41e592d496b_17458_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;连续空间存放&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;159&#34;
		data-flex-basis=&#34;383px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;连续空间存放的方式虽然读写效率高，&lt;strong&gt;但是有「磁盘空间碎片」和「文件长度不易扩展」的缺陷。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;非连续空间存放方式&#34;&gt;非连续空间存放方式&lt;/h3&gt;
&lt;h4 id=&#34;链表方式&#34;&gt;链表方式&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;隐式链表方式&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;链表的方式存放是&lt;strong&gt;离散的，不用连续的&lt;/strong&gt;，于是就可以&lt;strong&gt;消除磁盘碎片&lt;/strong&gt;，可大大提高磁盘空间的利用率，同时&lt;strong&gt;文件的长度可以动态扩展&lt;/strong&gt;。根据实现的方式的不同，链表可分为「&lt;strong&gt;隐式链表&lt;/strong&gt;」和「&lt;strong&gt;显式链接&lt;/strong&gt;」两种形式。&lt;/p&gt;
&lt;p&gt;文件要以「&lt;strong&gt;隐式链表&lt;/strong&gt;」的方式存放的话，&lt;strong&gt;实现的方式是文件头要包含「第一块」和「最后一块」的位置，并且每个数据块里面留出一个指针空间，用来存放下一个数据块的位置&lt;/strong&gt;，这样一个数据块连着一个数据块，从链头开是就可以顺着指针找到所有的数据块，所以存放的方式可以是不连续的。&lt;/p&gt;
&lt;p&gt;隐式链表的存放方式的&lt;strong&gt;缺点在于无法直接访问数据块，只能通过指针顺序访问文件，以及数据块指针消耗了一定的存储空间&lt;/strong&gt;。隐式链接分配的&lt;strong&gt;稳定性较差&lt;/strong&gt;，系统在运行过程中由于软件或者硬件错误&lt;strong&gt;导致链表中的指针丢失或损坏，会导致文件数据的丢失。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720221654858.png&#34;
	width=&#34;1067&#34;
	height=&#34;407&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720221654858_hu35b665d951d4b8fabf3aa1c94d9db199_13383_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720221654858_hu35b665d951d4b8fabf3aa1c94d9db199_13383_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;隐式链表方式&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;262&#34;
		data-flex-basis=&#34;629px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;显式链表方式&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;取出每个磁盘块的指针，把它放在内存的一个表中，就可以解决上述隐式链表的两个不足。那么，这种实现方式是「&lt;strong&gt;显式链接&lt;/strong&gt;」，它指&lt;strong&gt;把用于链接文件各数据块的指针，显式地存放在内存的一张链接表中&lt;/strong&gt;，该表在整个磁盘仅设置一张，&lt;strong&gt;每个表项中存放链接指针，指向下一个数据块号&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;内存中的这样一个表格称为&lt;strong&gt;文件分配表（File Allocation Table，FAT）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;由于查找记录的过程是在内存中进行的，因而不仅显著地&lt;strong&gt;提高了检索速度&lt;/strong&gt;，而且&lt;strong&gt;大大减少了访问磁盘的次数&lt;/strong&gt;。但也正是整个表都存放在内存中的关系，它的主要的缺点是&lt;strong&gt;不适用于大磁盘&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720222031787.png&#34;
	width=&#34;489&#34;
	height=&#34;1007&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720222031787_hu242c934c80ff24a5fa59491c5c85b7ac_30819_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720222031787_hu242c934c80ff24a5fa59491c5c85b7ac_30819_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;显式链表方式&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;48&#34;
		data-flex-basis=&#34;116px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;索引方式&#34;&gt;索引方式&lt;/h4&gt;
&lt;p&gt;链表的方式解决了连续分配的磁盘碎片和文件动态扩展的问题，但是不能有效支持直接访问（FAT除外），索引的方式可以解决这个问题。&lt;/p&gt;
&lt;p&gt;索引的实现是为每个文件创建一个「&lt;strong&gt;索引数据块&lt;/strong&gt;」，里面存放的是&lt;strong&gt;指向文件数据块的指针列表&lt;/strong&gt;，说白了就像书的目录一样，要找哪个章节的内容，看目录查就可以。&lt;/p&gt;
&lt;p&gt;另外，&lt;strong&gt;文件头需要包含指向「索引数据块」的指针&lt;/strong&gt;，这样就可以通过文件头知道索引数据块的位置，再通过索引数据块里的索引信息找到对应的数据块。&lt;/p&gt;
&lt;p&gt;创建文件时，索引块的所有指针都设为空。当首次写入第 i 块时，先从空闲空间中取得一个块，再将其地址写到索引块的第 i 个条目。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720222302091.png&#34;
	width=&#34;1067&#34;
	height=&#34;527&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720222302091_hud703d2c88033c5eb38cc293b54670ed1_38769_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720222302091_hud703d2c88033c5eb38cc293b54670ed1_38769_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;索引方式&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;202&#34;
		data-flex-basis=&#34;485px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;索引的方式优点在于：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;文件的创建、增大、缩小很方便；&lt;/li&gt;
&lt;li&gt;不会有碎片的问题；&lt;/li&gt;
&lt;li&gt;支持顺序读写和随机读写；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由于索引数据也是存放在磁盘块的，如果文件很小，明明只需一块就可以存放的下，但还是需要额外分配一块来存放索引数据，所以缺陷之一就是存储索引带来的开销。&lt;/p&gt;
&lt;p&gt;如果文件很大，大到一个索引数据块放不下索引信息，这时又要如何处理大文件的存放呢？我们可以通过组合的方式，来处理大文件的存。&lt;/p&gt;
&lt;p&gt;先来看看链表 + 索引的组合，这种组合称为「&lt;strong&gt;链式索引块&lt;/strong&gt;」，它的实现方式是&lt;strong&gt;在索引数据块留出一个存放下一个索引数据块的指针&lt;/strong&gt;，于是当一个索引数据块的索引信息用完了，就可以通过指针的方式，找到下一个索引数据块的信息。那这种方式也会出现前面提到的链表方式的问题，万一某个指针损坏了，后面的数据也就会无法读取了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720222402714.png&#34;
	width=&#34;1068&#34;
	height=&#34;302&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720222402714_huffaca09dd32077484faf3b7278ea4041_19952_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720222402714_huffaca09dd32077484faf3b7278ea4041_19952_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;链表&amp;#43;索引&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;353&#34;
		data-flex-basis=&#34;848px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;还有另外一种组合方式是索引 + 索引的方式，这种组合称为「&lt;strong&gt;多级索引块&lt;/strong&gt;」，实现方式是&lt;strong&gt;通过一个索引块来存放多个索引数据块&lt;/strong&gt;，一层套一层索引，像极了俄罗斯套娃是吧。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720222413748.png&#34;
	width=&#34;1067&#34;
	height=&#34;332&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720222413748_hu3b5636eec8539623524ab19eca07b6af_29951_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720222413748_hu3b5636eec8539623524ab19eca07b6af_29951_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;多级索引块&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;321&#34;
		data-flex-basis=&#34;771px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;文件存放方式对比&#34;&gt;文件存放方式对比&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720222457865.png&#34;
	width=&#34;977&#34;
	height=&#34;452&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720222457865_huf602c0bf2d28f1bef876403e62420f96_114900_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720222457865_huf602c0bf2d28f1bef876403e62420f96_114900_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;文件存放方式对比&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;216&#34;
		data-flex-basis=&#34;518px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;空闲空间管理&#34;&gt;空闲空间管理&lt;/h2&gt;
&lt;h3 id=&#34;空闲表法&#34;&gt;空闲表法&lt;/h3&gt;
&lt;p&gt;空闲表法就是为所有空闲空间建立一张表，表内容包括空闲区的第一个块号和该空闲区的块个数，注意，这个方式是连续分配的。如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720223722892.png&#34;
	width=&#34;1449&#34;
	height=&#34;557&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720223722892_hu2d1de61b80e241ab581694154a8519a5_122268_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720223722892_hu2d1de61b80e241ab581694154a8519a5_122268_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;空闲表&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;260&#34;
		data-flex-basis=&#34;624px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;当请求分配磁盘空间时，系统依次扫描空闲表里的内容，直到找到一个合适的空闲区域为止。当用户撤销一个文件时，系统回收文件空间。这时，也需顺序扫描空闲表，寻找一个空闲表条目并将释放空间的第一个物理块号及它占用的块数填到这个条目中。&lt;/p&gt;
&lt;p&gt;这种方法仅当有少量的空闲区时才有较好的效果。因为，如果存储空间中有着大量的小的空闲区，则空闲表变得很大，这样查询效率会很低。另外，这种分配技术适用于建立连续文件。&lt;/p&gt;
&lt;h3 id=&#34;空闲链表法&#34;&gt;空闲链表法&lt;/h3&gt;
&lt;p&gt;我们也可以使用「链表」的方式来管理空闲空间，每一个空闲块里有一个指针指向下一个空闲块，这样也能很方便的找到空闲块并管理起来。如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720223908658.png&#34;
	width=&#34;707&#34;
	height=&#34;287&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720223908658_hu3f879d882c5e9252c646af90a1f6569f_21003_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720223908658_hu3f879d882c5e9252c646af90a1f6569f_21003_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;空闲链表&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;246&#34;
		data-flex-basis=&#34;591px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;当创建文件需要一块或几块时，就从链头上依次取下一块或几块。反之，当回收空间时，把这些空闲块依次接到链头上。&lt;/p&gt;
&lt;p&gt;这种技术只要在主存中保存一个指针，令它指向第一个空闲块。其特点是简单，但不能随机访问，工作效率低，因为每当在链上增加或移动空闲块时需要做很多 I/O 操作，同时数据块的指针消耗了一定的存储空间。&lt;/p&gt;
&lt;p&gt;空闲表法和空闲链表法都不适合用于大型文件系统，因为这会使空闲表或空闲链表太大。&lt;/p&gt;
&lt;h3 id=&#34;位图法&#34;&gt;位图法&lt;/h3&gt;
&lt;p&gt;位图是利用二进制的一位来表示磁盘中一个盘块的使用情况，磁盘上所有的盘块都有一个二进制位与之对应。&lt;/p&gt;
&lt;p&gt;当值为 0 时，表示对应的盘块空闲，值为 1 时，表示对应的盘块已分配。它形式如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;1111110011111110001110110111111100111 ...
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;在 Linux 文件系统就采用了位图的方式来管理空闲空间，不仅用于数据空闲块的管理，还用于 inode 空闲块的管理，因为 inode 也是存储在磁盘的，自然也要有对其管理。&lt;/p&gt;
&lt;h2 id=&#34;文件系统的结构&#34;&gt;文件系统的结构&lt;/h2&gt;
&lt;p&gt;数据块的位图是放在磁盘块里的，假设是放在一个块里，一个块 4K，每位表示一个数据块，共可以表示 &lt;code&gt;4 * 1024 * 8 = 2^15&lt;/code&gt;个空闲块，由于 1 个数据块是 4K 大小，那么最大可以表示的空间为 &lt;code&gt;2^15 * 4 * 1024 = 2^27&lt;/code&gt; 个 byte，也就是 128M。&lt;/p&gt;
&lt;p&gt;也就是说按照上面的结构，如果采用「一个块的位图 + 一系列的块」，外加「一个块的 inode 的位图 + 一系列的 inode 的结构」能表示的最大空间也就 128M，这太少了，现在很多文件都比这个大。&lt;/p&gt;
&lt;p&gt;在 Linux 文件系统，把这个结构称为一个&lt;strong&gt;块组&lt;/strong&gt;，那么有 N 多的块组，就能够表示 N 大的文件。&lt;/p&gt;
&lt;p&gt;下图给出了 Linux Ext2 整个文件系统的结构和块组的内容，文件系统都由大量块组组成，在硬盘上相继排布：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720224158302.png&#34;
	width=&#34;1220&#34;
	height=&#34;410&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720224158302_hu72dd70be56a410eb872439a19cc0407c_45774_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720224158302_hu72dd70be56a410eb872439a19cc0407c_45774_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;linux文件系统结构&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;297&#34;
		data-flex-basis=&#34;714px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;最前面的第一个块是引导块，在系统启动时用于启用引导，接着后面就是一个一个连续的块组了，块组的内容如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;超级块&lt;/em&gt;，包含的是文件系统的重要信息，比如 inode 总个数、块总个数、每个块组的 inode 个数、每个块组的块个数等等。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;块组描述符&lt;/em&gt;，包含文件系统中各个块组的状态，比如块组中空闲块和 inode 的数目等，每个块组都包含了文件系统中「所有块组的组描述符信息」。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;数据位图和 inode 位图&lt;/em&gt;， 用于表示对应的数据块或 inode 是空闲的，还是被使用中。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;inode 列表&lt;/em&gt;，包含了块组中所有的 inode，inode 用于保存文件系统中与各个文件和目录相关的所有元数据。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;数据块&lt;/em&gt;，包含文件的有用数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;超级块和块组描述符表，这两个都是全局信息，而且非常的重要&lt;/strong&gt;，这么做是有两个原因：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果系统崩溃破坏了超级块或块组描述符，有关文件系统结构和内容的所有信息都会丢失。如果有冗余的副本，该信息是可能恢复的。&lt;/li&gt;
&lt;li&gt;通过使文件和管理数据尽可能接近，减少了磁头寻道和旋转，这可以提高文件系统的性能。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;目录的存储&#34;&gt;目录的存储&lt;/h2&gt;
&lt;p&gt;基于 Linux 一切皆文件的设计思想，目录其实也是个文件，你甚至可以通过 &lt;code&gt;vim&lt;/code&gt; 打开它，它也有 inode，inode 里面也是指向一些块。&lt;/p&gt;
&lt;p&gt;和普通文件不同的是，&lt;strong&gt;普通文件的块里面保存的是文件数据，而目录文件的块里面保存的是目录里面一项一项的文件信息。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在目录文件的块中，最简单的保存格式就是&lt;strong&gt;列表&lt;/strong&gt;，就是一项一项地将目录下的文件信息（如文件名、文件 inode、文件类型等）列在表里。&lt;/p&gt;
&lt;p&gt;列表中每一项就代表该目录下的文件的文件名和对应的 inode，通过这个 inode，就可以找到真正的文件。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720224351058.png&#34;
	width=&#34;1427&#34;
	height=&#34;882&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720224351058_hu34362f8c3ad42f93da89fcc48e1ad69c_730549_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720224351058_hu34362f8c3ad42f93da89fcc48e1ad69c_730549_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;目录数据块&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;161&#34;
		data-flex-basis=&#34;388px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;通常，第一项是「&lt;code&gt;.&lt;/code&gt;」，表示当前目录，第二项是「&lt;code&gt;..&lt;/code&gt;」，表示上一级目录，接下来就是一项一项的文件名和 inode。&lt;/p&gt;
&lt;p&gt;如果一个目录有超级多的文件，我们要想在这个目录下找文件，按照列表一项一项的找，效率就不高了。&lt;/p&gt;
&lt;p&gt;于是，保存目录的格式改成&lt;strong&gt;哈希表&lt;/strong&gt;，对文件名进行哈希计算，把哈希值保存起来，如果我们要查找一个目录下面的文件名，可以通过名称取哈希。如果哈希能够匹配上，就说明这个文件的信息在相应的块里面。&lt;/p&gt;
&lt;h2 id=&#34;硬链接和软连接&#34;&gt;硬链接和软连接&lt;/h2&gt;
&lt;p&gt;有时候我们希望给某个文件取个别名，那么在 Linux 中可以通过&lt;strong&gt;硬链接（Hard Link）&lt;/strong&gt; 和&lt;strong&gt;软链接（Symbolic Link）&lt;/strong&gt; 的方式来实现，它们都是比较特殊的文件，但是实现方式也是不相同的。&lt;/p&gt;
&lt;h3 id=&#34;硬连接&#34;&gt;硬连接&lt;/h3&gt;
&lt;p&gt;硬链接是&lt;strong&gt;多个目录项中的「索引节点」指向一个文件&lt;/strong&gt;，也就是指向同一个 inode，但是 inode 是不可能跨越文件系统的，每个文件系统都有各自的 inode 数据结构和列表，所以&lt;strong&gt;硬链接是不可用于跨文件系统的&lt;/strong&gt;。由于多个目录项都是指向一个 inode，那么&lt;strong&gt;只有删除文件的所有硬链接以及源文件时，系统才会彻底删除该文件。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720224539724.png&#34;
	width=&#34;1154&#34;
	height=&#34;624&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720224539724_hu9ea82e3b3da66c24ddaa8dc53ecabafa_35447_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720224539724_hu9ea82e3b3da66c24ddaa8dc53ecabafa_35447_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;硬连接&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;184&#34;
		data-flex-basis=&#34;443px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;软连接&#34;&gt;软连接&lt;/h3&gt;
&lt;p&gt;软链接相当于重新创建一个文件，这个文件有&lt;strong&gt;独立的 inode&lt;/strong&gt;，但是这个&lt;strong&gt;文件的内容是另外一个文件的路径&lt;/strong&gt;，所以访问软链接的时候，实际上相当于访问到了另外一个文件，所以&lt;strong&gt;软链接是可以跨文件系统的&lt;/strong&gt;，甚至&lt;strong&gt;目标文件被删除了，链接文件还是在的，只不过指向的文件找不到了而已。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720224624867.png&#34;
	width=&#34;1232&#34;
	height=&#34;642&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720224624867_hu13cf62f41e12c6e2c9e2852121aa4b23_48052_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/image-20220720224624867_hu13cf62f41e12c6e2c9e2852121aa4b23_48052_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;软连接&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;191&#34;
		data-flex-basis=&#34;460px&#34;
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>操作系统02-进程管理</title>
        <link>https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/</link>
        <pubDate>Tue, 19 Jul 2022 19:28:08 +0800</pubDate>
        
        <guid>https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/</guid>
        <description>&lt;h2 id=&#34;进程&#34;&gt;进程&lt;/h2&gt;
&lt;h3 id=&#34;进程的状态&#34;&gt;进程的状态&lt;/h3&gt;
&lt;p&gt;进程共有五个状态&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;创建状态（&lt;em&gt;new&lt;/em&gt;）：进程正在被创建时的状态；&lt;/li&gt;
&lt;li&gt;就绪状态（&lt;em&gt;Ready&lt;/em&gt;）：可运行，由于其他进程处于运行状态而暂时停止运行；&lt;/li&gt;
&lt;li&gt;运行状态（&lt;em&gt;Runing&lt;/em&gt;）：该时刻进程占用 CPU；&lt;/li&gt;
&lt;li&gt;阻塞状态（&lt;em&gt;Blocked&lt;/em&gt;）：该进程正在等待某一事件发生（如等待输入/输出操作的完成）而暂时停止运行，这时，即使给它CPU控制权，它也无法运行；&lt;/li&gt;
&lt;li&gt;阻塞挂起状态：进程在外存（硬盘）并等待某个事件的出现；&lt;/li&gt;
&lt;li&gt;就绪挂起状态：进程在外存（硬盘），但只要进入内存，即刻立刻运行；&lt;/li&gt;
&lt;li&gt;结束状态（&lt;em&gt;Exit&lt;/em&gt;）：进程正在从系统中消失时的状态；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;于是，一个完整的进程状态的变迁如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220719194409025.png&#34;
	width=&#34;1166&#34;
	height=&#34;722&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220719194409025_hu6e34d7aee6d1c15d45f66045adaf77e2_98372_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220719194409025_hu6e34d7aee6d1c15d45f66045adaf77e2_98372_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;进程状态&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;161&#34;
		data-flex-basis=&#34;387px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;再来详细说明一下进程的状态变迁：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;NULL -&amp;gt; 创建状态&lt;/em&gt;：一个新进程被创建时的第一个状态；&lt;/li&gt;
&lt;li&gt;&lt;em&gt;创建状态 -&amp;gt; 就绪状态&lt;/em&gt;：当进程被创建完成并初始化后，一切就绪准备运行时，变为就绪状态，这个过程是很快的；&lt;/li&gt;
&lt;li&gt;&lt;em&gt;就绪态 -&amp;gt; 运行状态&lt;/em&gt;：处于就绪状态的进程被操作系统的进程调度器选中后，就分配给 CPU 正式运行该进程；&lt;/li&gt;
&lt;li&gt;&lt;em&gt;运行状态 -&amp;gt; 结束状态&lt;/em&gt;：当进程已经运行完成或出错时，会被操作系统作结束状态处理；&lt;/li&gt;
&lt;li&gt;&lt;em&gt;运行状态 -&amp;gt; 就绪状态&lt;/em&gt;：处于运行状态的进程在运行过程中，由于分配给它的运行时间片用完，操作系统会把该进程变为就绪态，接着从就绪态选中另外一个进程运行；&lt;/li&gt;
&lt;li&gt;&lt;em&gt;运行状态 -&amp;gt; 阻塞状态&lt;/em&gt;：当进程请求某个事件且必须等待时，例如请求 I/O 事件；&lt;/li&gt;
&lt;li&gt;&lt;em&gt;阻塞状态 -&amp;gt; 就绪状态&lt;/em&gt;：当进程要等待的事件完成时，它从阻塞状态变到就绪状态；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果有大量处于阻塞状态的进程，进程可能会占用着物理内存空间，显然不是我们所希望的，毕竟物理内存空间是有限的，被阻塞状态的进程占用着物理内存就一种浪费物理内存的行为。&lt;/p&gt;
&lt;p&gt;所以，在虚拟内存管理的操作系统中，通常会把阻塞状态的进程的物理内存空间换出到硬盘，等需要再次运行的时候，再从硬盘换入到物理内存。&lt;/p&gt;
&lt;p&gt;那么，就需要一个新的状态，来&lt;strong&gt;描述进程没有占用实际的物理内存空间的情况，这个状态就是挂起状态&lt;/strong&gt;。这跟阻塞状态是不一样，阻塞状态是等待某个事件的返回。&lt;/p&gt;
&lt;h3 id=&#34;pcb进程控制块&#34;&gt;PCB（进程控制块）&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;PCB 是进程存在的唯一标识&lt;/strong&gt;，这意味着一个进程的存在，必然会有一个 PCB，如果进程消失了，那么 PCB 也会随之消失。&lt;/p&gt;
&lt;h4 id=&#34;pcb-具体包含信息&#34;&gt;PCB 具体包含信息&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;进程描述信息：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;进程标识符：标识各个进程，每个进程都有一个并且唯一的标识符；&lt;/li&gt;
&lt;li&gt;用户标识符：进程归属的用户，用户标识符主要为共享和保护服务；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;进程控制和管理信息：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;进程当前状态，如 new、ready、running、waiting 或 blocked 等；&lt;/li&gt;
&lt;li&gt;进程优先级：进程抢占 CPU 时的优先级；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;资源分配清单：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;有关内存地址空间或虚拟地址空间的信息，所打开文件的列表和所使用的 I/O 设备信息。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;CPU 相关信息：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB 中，以便进程重新执行时，能从断点处继续执行。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;pcb-组织结构&#34;&gt;PCB 组织结构&lt;/h4&gt;
&lt;p&gt;通常是通过&lt;strong&gt;链表&lt;/strong&gt;的方式进行组织，把具有&lt;strong&gt;相同状态的进程链在一起，组成各种队列&lt;/strong&gt;。比如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;将所有处于就绪状态的进程链在一起，称为&lt;strong&gt;就绪队列&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;把所有因等待某事件而处于等待状态的进程链在一起就组成各种&lt;strong&gt;阻塞队列&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;另外，对于运行队列在单核 CPU 系统中则只有一个运行指针了，因为单核 CPU 在某个时间，只能运行一个程序。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;那么，就绪队列和阻塞队列链表的组织形式如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220720140749661.png&#34;
	width=&#34;1052&#34;
	height=&#34;572&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220720140749661_hu1f46986af5e8023ed4239022c32dd4fe_23895_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220720140749661_hu1f46986af5e8023ed4239022c32dd4fe_23895_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;就绪队列和阻塞队列&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;183&#34;
		data-flex-basis=&#34;441px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;除了链接的组织方式，还有索引方式，它的工作原理：将同一状态的进程组织在一个索引表中，索引表项指向相应的 PCB，不同状态对应不同的索引表。&lt;/p&gt;
&lt;p&gt;一般会选择链表，因为可能面临进程创建，销毁等调度导致进程状态发生变化，所以链表能够更加灵活的插入和删除。&lt;/p&gt;
&lt;h3 id=&#34;进程的控制&#34;&gt;进程的控制&lt;/h3&gt;
&lt;p&gt;我们熟知了进程的状态变迁和进程的数据结构 PCB 后，再来看看进程的&lt;strong&gt;创建、终止、阻塞、唤醒&lt;/strong&gt;的过程，这些过程也就是进程的控制。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;01 创建进程&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;操作系统允许一个进程创建另一个进程，而且允许子进程继承父进程所拥有的资源，当子进程被终止时，其在父进程处继承的资源应当还给父进程。同时，终止父进程时同时也会终止其所有的子进程。&lt;/p&gt;
&lt;p&gt;注意：Linux 操作系统对于终止有子进程的父进程，会把子进程交给 1 号进程接管。本文所指出的进程终止概念是宏观操作系统的一种观点，最后怎么实现当然是看具体的操作系统。&lt;/p&gt;
&lt;p&gt;创建进程的过程如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;为新进程分配一个唯一的进程标识号，并申请一个空白的 PCB，PCB 是有限的，若申请失败则创建失败；&lt;/li&gt;
&lt;li&gt;为进程分配资源，此处如果资源不足，进程就会进入等待状态，以等待资源；&lt;/li&gt;
&lt;li&gt;初始化 PCB；&lt;/li&gt;
&lt;li&gt;如果进程的调度队列能够接纳新进程，那就将进程插入到就绪队列，等待被调度运行；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;02 终止进程&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;进程可以有 3 种终止方式：正常结束、异常结束以及外界干预（信号 &lt;code&gt;kill&lt;/code&gt; 掉）。&lt;/p&gt;
&lt;p&gt;终止进程的过程如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;查找需要终止的进程的 PCB；&lt;/li&gt;
&lt;li&gt;如果处于执行状态，则立即终止该进程的执行，然后将 CPU 资源分配给其他进程；&lt;/li&gt;
&lt;li&gt;如果其还有子进程，则应将其所有子进程终止；&lt;/li&gt;
&lt;li&gt;将该进程所拥有的全部资源都归还给父进程或操作系统；&lt;/li&gt;
&lt;li&gt;将其从 PCB 所在队列中删除；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;03 阻塞进程&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;当进程需要等待某一事件完成时，它可以调用阻塞语句把自己阻塞等待。而一旦被阻塞等待，它只能由另一个进程唤醒。&lt;/p&gt;
&lt;p&gt;阻塞进程的过程如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;找到将要被阻塞进程标识号对应的 PCB；&lt;/li&gt;
&lt;li&gt;如果该进程为运行状态，则保护其现场，将其状态转为阻塞状态，停止运行；&lt;/li&gt;
&lt;li&gt;将该 PCB 插入到阻塞队列中去；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;04 唤醒进程&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;进程由「运行」转变为「阻塞」状态是由于进程必须等待某一事件的完成，所以处于阻塞状态的进程是绝对不可能叫醒自己的。&lt;/p&gt;
&lt;p&gt;如果某进程正在等待 I/O 事件，需由别的进程发消息给它，则只有当该进程所期待的事件出现时，才由发现者进程用唤醒语句叫醒它。&lt;/p&gt;
&lt;p&gt;唤醒进程的过程如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在&lt;strong&gt;该事件的阻塞队列&lt;/strong&gt;中找到相应进程的 PCB；&lt;/li&gt;
&lt;li&gt;将其从阻塞队列中移出，并置其状态为就绪状态；&lt;/li&gt;
&lt;li&gt;把该 PCB 插入到就绪队列中，等待调度程序调度；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;进程的阻塞和唤醒是一对功能相反的语句，如果某个进程调用了阻塞语句，则必有一个与之对应的唤醒语句。&lt;/p&gt;
&lt;h3 id=&#34;进程的上下文切换&#34;&gt;进程的上下文切换&lt;/h3&gt;
&lt;p&gt;各个进程之间是共享 CPU 资源的，在不同的时候进程之间需要切换，让不同的进程可以在 CPU 执行，那么这个&lt;strong&gt;一个进程切换到另一个进程运行，称为进程的上下文切换&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;CPU 上下文切换就是先把前一个任务的 CPU 上下文（CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。&lt;/p&gt;
&lt;p&gt;系统内核会存储保持下来的上下文信息，当此任务再次被分配给 CPU 运行时，CPU 会重新加载这些上下文，这样就能保证任务原来的状态不受影响，让任务看起来还是连续运行。&lt;/p&gt;
&lt;p&gt;进程是由内核管理和调度的，所以进程的切换只能发生在内核态。&lt;/p&gt;
&lt;p&gt;所以，&lt;strong&gt;进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;通常，会把交换的信息保存在进程的 PCB，当要运行另外一个进程的时候，我们需要从这个进程的 PCB 取出上下文，然后恢复到 CPU 中，这使得这个进程可以继续执行，如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220720144039605.png&#34;
	width=&#34;870&#34;
	height=&#34;191&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220720144039605_huf3946d48492702f2dbca68d54ae7a7f7_22706_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220720144039605_huf3946d48492702f2dbca68d54ae7a7f7_22706_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;进程上下文切换&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;455&#34;
		data-flex-basis=&#34;1093px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;发生进程上下文切换有哪些场景？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。这样，当某个进程的时间片耗尽了，进程就从运行状态变为就绪状态，系统从就绪队列选择另外一个进程运行；&lt;/li&gt;
&lt;li&gt;进程在系统资源不足（比如内存不足）时，要等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行；&lt;/li&gt;
&lt;li&gt;当进程通过睡眠函数 sleep 这样的方法将自己主动挂起时，自然也会重新调度；&lt;/li&gt;
&lt;li&gt;当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行；&lt;/li&gt;
&lt;li&gt;发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序；&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;线程&#34;&gt;线程&lt;/h2&gt;
&lt;h3 id=&#34;什么是线程&#34;&gt;什么是线程？&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;线程是进程当中的一条执行流程。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;同一个进程内多个线程之间可以共享代码段、数据段、打开的文件等资源，但每个线程各自都有一套独立的寄存器和栈，这样可以确保线程的控制流是相对独立的。&lt;/p&gt;
&lt;h3 id=&#34;线程与进程的比较&#34;&gt;线程与进程的比较&lt;/h3&gt;
&lt;p&gt;线程与进程的比较如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;进程是资源（包括内存、打开的文件等）分配的单位，线程是 CPU 调度的单位；&lt;/li&gt;
&lt;li&gt;进程拥有一个完整的资源平台，而线程只独享必不可少的资源，如寄存器和栈；&lt;/li&gt;
&lt;li&gt;线程同样具有就绪、阻塞、执行三种基本状态，同样具有状态之间的转换关系；&lt;/li&gt;
&lt;li&gt;线程能减少并发执行的时间和空间开销；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于，线程相比进程能减少开销，体现在：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;线程的&lt;strong&gt;创建时间&lt;/strong&gt;比进程快，因为进程在创建的过程中，还需要资源管理信息，比如内存管理信息、文件管理信息，而线程在创建的过程中，不会涉及这些资源管理信息，而是共享它们；&lt;/li&gt;
&lt;li&gt;线程的&lt;strong&gt;终止时间&lt;/strong&gt;比进程快，因为线程释放的资源相比进程少很多；&lt;/li&gt;
&lt;li&gt;同一个进程内的线程切换比进程切换快，因为线程具有相同的地址空间（虚拟内存共享），这意味着同一个进程的线程都具有同一个页表，那么在切换的时候&lt;strong&gt;不需要切换页表&lt;/strong&gt;。而对于进程之间的切换，切换的时候要把页表给切换掉，而页表的切换过程开销是比较大的；&lt;/li&gt;
&lt;li&gt;由于同一进程的各线程间共享内存和文件资源，那么在&lt;strong&gt;线程之间数据传递&lt;/strong&gt;的时候，就不需要经过内核了，这就使得线程之间的数据交互效率更高了；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所以，不管是时间效率，还是空间效率线程比进程都要高。&lt;/p&gt;
&lt;h3 id=&#34;线程的上下文切换&#34;&gt;线程的上下文切换&lt;/h3&gt;
&lt;p&gt;线程与进程最大的区别在于：&lt;strong&gt;线程是调度的基本单位，而进程则是资源拥有的基本单位&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;所以，所谓操作系统的任务调度，实际上的调度对象是线程，而进程只是给线程提供了虚拟内存、全局变量等资源。&lt;/p&gt;
&lt;p&gt;对于线程和进程，我们可以这么理解：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;当进程只有一个线程时，可以认为进程就等于线程；&lt;/li&gt;
&lt;li&gt;当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源，这些资源在上下文切换时是不需要修改的；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;另外，线程也有自己的私有数据，比如栈和寄存器等，这些在上下文切换时也是需要保存的。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;线程上下文切换的是什么？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这还得看线程是不是属于同一个进程：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;当两个线程不是属于同一个进程，则切换的过程就跟进程上下文切换一样；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;当两个线程是属于同一个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据&lt;/strong&gt;；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所以，线程的上下文切换相比进程，开销要小很多。&lt;/p&gt;
&lt;h3 id=&#34;线程的实现&#34;&gt;线程的实现&lt;/h3&gt;
&lt;p&gt;主要有三种线程的实现方式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;用户线程（User Thread）&lt;/strong&gt;：在用户空间实现的线程，不是由内核管理的线程，是由用户态的线程库来完成线程的管理；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;内核线程（Kernel Thread）&lt;/strong&gt;：在内核中实现的线程，是由内核管理的线程；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;轻量级进程（LightWeight Process）&lt;/strong&gt;：在内核中来支持用户线程；&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;用户线程&#34;&gt;用户线程&lt;/h4&gt;
&lt;p&gt;用户线程是基于用户态的线程管理库来实现的，那么&lt;strong&gt;线程控制块（Thread Control Block, TCB）&lt;/strong&gt; 也是在库里面来实现的，对于操作系统而言是看不到这个 TCB 的，它只能看到整个进程的 PCB。&lt;/p&gt;
&lt;p&gt;所以，&lt;strong&gt;用户线程的整个线程管理和调度，操作系统是不直接参与的，而是由用户级线程库函数来完成线程的管理，包括线程的创建、终止、同步和调度等。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;用户级线程的模型，是&lt;strong&gt;多对一&lt;/strong&gt;的关系，即&lt;strong&gt;多个用户线程对应同一个内核线程&lt;/strong&gt;，如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220720145706336.png&#34;
	width=&#34;1160&#34;
	height=&#34;749&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220720145706336_huc2a06889ebcd64a5c065f85d5ece94ae_71295_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220720145706336_huc2a06889ebcd64a5c065f85d5ece94ae_71295_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;用户线程&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;154&#34;
		data-flex-basis=&#34;371px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;用户线程的&lt;strong&gt;优点&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每个进程都需要有它私有的线程控制块（TCB）列表，用来跟踪记录它各个线程状态信息（PC、栈指针、寄存器），TCB 由用户级线程库函数来维护，可用于不支持线程技术的操作系统；&lt;/li&gt;
&lt;li&gt;用户线程的切换也是由线程库函数来完成的，无需用户态与内核态的切换，所以速度特别快；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;用户线程的&lt;strong&gt;缺点&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;由于操作系统不参与线程的调度，如果一个线程发起了系统调用而阻塞，那进程所包含的用户线程都不能执行了。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;当一个线程开始运行后，除非它主动地交出 CPU 的使用权，否则它所在的进程当中的其他线程无法运行，因为用户态的线程&lt;strong&gt;没法打断当前运行中的线程&lt;/strong&gt;，它没有这个特权，只有操作系统才有，但是用户线程不是由操作系统管理的。&lt;/li&gt;
&lt;li&gt;由于时间片分配给进程，故与其他进程比，在多线程执行时，每个线程得到的时间片较少，执行会比较慢；&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;内核线程&#34;&gt;内核线程&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;内核线程是由操作系统管理的，线程对应的 TCB 自然是放在操作系统里的，这样线程的创建、终止和管理都是由操作系统负责。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;内核线程的模型，是&lt;strong&gt;一对一&lt;/strong&gt;的关系，即一个用户线程对应一个内核线程，如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220720150008835.png&#34;
	width=&#34;890&#34;
	height=&#34;659&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220720150008835_hu90d29bc0c66e07c04503c342299b9e56_60769_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220720150008835_hu90d29bc0c66e07c04503c342299b9e56_60769_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;内核线程&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;135&#34;
		data-flex-basis=&#34;324px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;内核线程的&lt;strong&gt;优点&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在一个进程当中，如果某个内核线程发起系统调用而被阻塞，并不会影响其他内核线程的运行；&lt;/li&gt;
&lt;li&gt;分配给线程，多线程的进程获得更多的 CPU 运行时间；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;内核线程的&lt;strong&gt;缺点&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在支持内核线程的操作系统中，由内核来维护进程和线程的上下文信息，如 PCB 和 TCB；&lt;/li&gt;
&lt;li&gt;线程的创建、终止和切换都是通过系统调用的方式来进行，因此对于系统来说，系统开销比较大；&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;轻量级进程&#34;&gt;轻量级进程&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;轻量级进程（Light-weight process，LWP）是内核支持的用户线程，一个进程可有一个或多个 LWP，每个 LWP 是跟内核线程一对一映射的，也就是 LWP 都是由一个内核线程支持。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;另外，LWP 只能由内核管理并像普通进程一样被调度，Linux 内核是支持 LWP 的典型例子。&lt;/p&gt;
&lt;p&gt;在大多数系统中，&lt;strong&gt;LWP与普通进程的区别也在于它只有一个最小的执行上下文和调度程序所需的统计信息&lt;/strong&gt;。一般来说，一个进程代表程序的一个实例，而 LWP 代表程序的执行线程，因为一个执行线程不像进程那样需要那么多状态信息，所以 LWP 也不带有这样的信息。&lt;/p&gt;
&lt;h2 id=&#34;调度&#34;&gt;调度&lt;/h2&gt;
&lt;h3 id=&#34;调度时机&#34;&gt;调度时机&lt;/h3&gt;
&lt;p&gt;比如，以下状态的变化都会触发操作系统的调度：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;从就绪态 -&amp;gt; 运行态&lt;/em&gt;：当进程被创建时，会进入到就绪队列，操作系统会从就绪队列选择一个进程运行；&lt;/li&gt;
&lt;li&gt;&lt;em&gt;从运行态 -&amp;gt; 阻塞态&lt;/em&gt;：当进程发生 I/O 事件而阻塞时，操作系统必须另外一个进程运行；&lt;/li&gt;
&lt;li&gt;&lt;em&gt;从运行态 -&amp;gt; 结束态&lt;/em&gt;：当进程退出结束后，操作系统得从就绪队列选择另外一个进程运行；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果硬件时钟提供某个频率的周期性中断，那么可以根据如何处理时钟中断，把调度算法分为两类：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;非抢占式调度算法&lt;/strong&gt;挑选一个进程，然后让该进程运行直到被阻塞，或者直到该进程退出，才会调用另外一个进程，也就是说不会理时钟中断这个事情。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;抢占式调度算法&lt;/strong&gt;挑选一个进程，然后让该进程只运行某段时间，如果在该时段结束时，该进程仍然在运行时，则会把它挂起，接着调度程序从就绪队列挑选另外一个进程。这种抢占式调度处理，需要在时间间隔的末端发生&lt;strong&gt;时钟中断&lt;/strong&gt;，以便把 CPU 控制返回给调度程序进行调度，也就是常说的&lt;strong&gt;时间片机制&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;调度原则&#34;&gt;调度原则&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;CPU 利用率&lt;/strong&gt;：调度程序应确保 CPU 是始终匆忙的状态，这可提高 CPU 的利用率；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;系统吞吐量&lt;/strong&gt;：吞吐量表示的是单位时间内 CPU 完成进程的数量，长作业的进程会占用较长的 CPU 资源，因此会降低吞吐量，相反，短作业的进程会提升系统吞吐量；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;周转时间&lt;/strong&gt;：周转时间是进程运行和阻塞时间总和，一个进程的周转时间越小越好；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;等待时间&lt;/strong&gt;：这个等待时间不是阻塞状态的时间，而是进程处于就绪队列的时间，等待的时间越长，用户越不满意；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;响应时间&lt;/strong&gt;：用户提交请求到系统第一次产生响应所花费的时间，在交互式系统中，响应时间是衡量调度算法好坏的主要标准。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;调度算法单核cpu&#34;&gt;调度算法（单核CPU）&lt;/h3&gt;
&lt;h4 id=&#34;先来先服务调度算法&#34;&gt;先来先服务调度算法&lt;/h4&gt;
&lt;p&gt;最简单的一个调度算法，就是非抢占式的&lt;strong&gt;先来先服务（First Come First Seved, FCFS）算法&lt;/strong&gt;了。&lt;/p&gt;
&lt;p&gt;顾名思义，先来后到，&lt;strong&gt;每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这似乎很公平，但是当一个长作业先运行了，那么后面的短作业等待的时间就会很长，不利于短作业。&lt;/p&gt;
&lt;p&gt;FCFS 对长作业有利，适用于 CPU 繁忙型作业的系统，而不适用于 I/O 繁忙型作业的系统。&lt;/p&gt;
&lt;h4 id=&#34;最短作业优先调度算法&#34;&gt;最短作业优先调度算法&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;最短作业优先（Shortest Job First, SJF）调度算法&lt;/strong&gt;同样也是顾名思义，它会&lt;strong&gt;优先选择运行时间最短的进程来运行&lt;/strong&gt;，这有助于提高系统的吞吐量&lt;/p&gt;
&lt;p&gt;这显然对长作业不利，很容易造成一种极端现象。&lt;/p&gt;
&lt;p&gt;比如，一个长作业在就绪队列等待运行，而这个就绪队列有非常多的短作业，那么就会使得长作业不断的往后推，周转时间变长，致使长作业长期不会被运行。&lt;/p&gt;
&lt;h4 id=&#34;高响应比优先调度算法&#34;&gt;高响应比优先调度算法&lt;/h4&gt;
&lt;p&gt;前面的「先来先服务调度算法」和「最短作业优先调度算法」都没有很好的权衡短作业和长作业。&lt;/p&gt;
&lt;p&gt;那么，&lt;strong&gt;高响应比优先（Highest Response Ratio Next, HRRN）调度算法&lt;/strong&gt;主要是权衡了短作业和长作业。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行&lt;/strong&gt;，「响应比优先级」的计算公式：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220720153850738.png&#34;
	width=&#34;572&#34;
	height=&#34;173&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220720153850738_hu72ccdc27fdf2570721259285a4ca7086_13715_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220720153850738_hu72ccdc27fdf2570721259285a4ca7086_13715_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;响应比&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;330&#34;
		data-flex-basis=&#34;793px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;从上面的公式，可以发现：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果两个进程的「等待时间」相同时，「要求的服务时间」越短，「响应比」就越高，这样短作业的进程容易被选中运行；&lt;/li&gt;
&lt;li&gt;如果两个进程「要求的服务时间」相同时，「等待时间」越长，「响应比」就越高，这就兼顾到了长作业进程，因为进程的响应比可以随时间等待的增加而提高，当其等待时间足够长时，其响应比便可以升到很高，从而获得运行的机会；&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;时间片轮转调度算法&#34;&gt;时间片轮转调度算法&lt;/h4&gt;
&lt;p&gt;最古老、最简单、最公平且使用最广的算法就是&lt;strong&gt;时间片轮转（Round Robin, RR）调度算法&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;每个进程被分配一个时间段，称为时间片（Quantum），即允许该进程在该时间段中运行。&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果时间片用完，进程还在运行，那么将会把此进程从 CPU 释放出来，并把 CPU 分配给另外一个进程；&lt;/li&gt;
&lt;li&gt;如果该进程在时间片结束前阻塞或结束，则 CPU 立即进行切换；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;另外，时间片的长度就是一个很关键的点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果时间片设得太短会导致过多的进程上下文切换，降低了 CPU 效率；&lt;/li&gt;
&lt;li&gt;如果设得太长又可能引起对短作业进程的响应时间变长。将&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一般来说，时间片设为 &lt;code&gt;20ms~50ms&lt;/code&gt; 通常是一个比较合理的折中值。&lt;/p&gt;
&lt;h4 id=&#34;最高优先级调度算法&#34;&gt;最高优先级调度算法&lt;/h4&gt;
&lt;p&gt;前面的「时间片轮转算法」做了个假设，即让所有的进程同等重要，也不偏袒谁，大家的运行时间都一样。&lt;/p&gt;
&lt;p&gt;但是，对于多用户计算机系统就有不同的看法了，它们希望调度是有优先级的，即希望调度程序能&lt;strong&gt;从就绪队列中选择最高优先级的进程进行运行，这称为最高优先级（Highest Priority First，HPF）调度算法&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;进程的优先级可以分为，静态优先级和动态优先级：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;静态优先级：创建进程时候，就已经确定了优先级了，然后整个运行时间优先级都不会变化；&lt;/li&gt;
&lt;li&gt;动态优先级：根据进程的动态变化调整优先级，比如如果进程运行时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则升高其优先级，也就是&lt;strong&gt;随着时间的推移增加等待进程的优先级&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;该算法也有两种处理优先级高的方法，非抢占式和抢占式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;非抢占式：当就绪队列中出现优先级高的进程，运行完当前进程，再选择优先级高的进程。&lt;/li&gt;
&lt;li&gt;抢占式：当就绪队列中出现优先级高的进程，当前进程挂起，调度优先级高的进程运行。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;但是依然有缺点，可能会导致低优先级的进程永远不会运行。&lt;/p&gt;
&lt;h4 id=&#34;多级反馈队列调度算法&#34;&gt;多级反馈队列调度算法&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;多级反馈队列（Multilevel Feedback Queue）调度算法&lt;/strong&gt;是「时间片轮转算法」和「最高优先级算法」的综合和发展。&lt;/p&gt;
&lt;p&gt;顾名思义：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;「多级」表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。&lt;/li&gt;
&lt;li&gt;「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220720155249358.png&#34;
	width=&#34;878&#34;
	height=&#34;650&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220720155249358_hu3bc6ed05eee3a747a8685112f4d8cb8b_47955_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220720155249358_hu3bc6ed05eee3a747a8685112f4d8cb8b_47955_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;多级反馈队列调度算法&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;135&#34;
		data-flex-basis=&#34;324px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;来看看，它是如何工作的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;设置了多个队列，赋予每个队列不同的优先级，每个&lt;strong&gt;队列优先级从高到低&lt;/strong&gt;，同时&lt;strong&gt;优先级越高时间片越短&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成；&lt;/li&gt;
&lt;li&gt;当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;可以发现，对于短作业可能可以在第一级队列很快被处理完。对于长作业，如果在第一级队列处理不完，可以移入下次队列等待被执行，虽然等待的时间变长了，但是运行时间也变更长了，所以该算法很好的&lt;strong&gt;兼顾了长短作业，同时有较好的响应时间。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;进程间通信&#34;&gt;进程间通信&lt;/h2&gt;
&lt;h3 id=&#34;管道&#34;&gt;管道&lt;/h3&gt;
&lt;h4 id=&#34;匿名管道&#34;&gt;匿名管道&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ ps auxf &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; grep mysql
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;上面命令行里的「&lt;code&gt;|&lt;/code&gt;」竖线就是一个&lt;strong&gt;管道&lt;/strong&gt;，它的功能是将前一个命令（&lt;code&gt;ps auxf&lt;/code&gt;）的输出，作为后一个命令（&lt;code&gt;grep mysql&lt;/code&gt;）的输入，从这功能描述，可以看出&lt;strong&gt;管道传输数据是单向的&lt;/strong&gt;，如果想相互通信，我们需要创建两个管道才行。&lt;/p&gt;
&lt;p&gt;匿名管道是特殊的文件，只存在于内存，不存于文件系统中。&lt;/p&gt;
&lt;p&gt;同时，我们得知上面这种管道是没有名字，所以「&lt;code&gt;|&lt;/code&gt;」表示的管道称为&lt;strong&gt;匿名管道&lt;/strong&gt;，用完了就销毁。&lt;/p&gt;
&lt;h4 id=&#34;命名管道&#34;&gt;命名管道&lt;/h4&gt;
&lt;p&gt;管道还有另外一个类型是&lt;strong&gt;命名管道&lt;/strong&gt;，也被叫做 &lt;code&gt;FIFO&lt;/code&gt;，因为数据是先进先出的传输方式。&lt;/p&gt;
&lt;p&gt;在使用命名管道前，先需要通过 &lt;code&gt;mkfifo&lt;/code&gt; 命令来创建，并且指定管道名字：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ mkfifo myPipe
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;myPipe 就是这个管道的名称，基于 Linux 一切皆文件的理念，所以命名管道也是以文件的方式存在，我们可以用 ls 看一下，这个文件的类型是 p，也就是 pipe（管道） 的意思：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ ls -l
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;prw-r--r--. &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; root    root         &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; Jul &lt;span class=&#34;m&#34;&gt;17&lt;/span&gt; 02:45 myPipe
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;接下来，我们往 myPipe 这个管道写入数据：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ &lt;span class=&#34;nb&#34;&gt;echo&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;hello&amp;#34;&lt;/span&gt; &amp;gt; myPipe  // 将数据写进管道
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                         // 停住了 ...
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;你操作了后，你会发现命令执行后就停在这了，这是因为管道里的内容没有被读取，只有当管道里的数据被读完后，命令才可以正常退出。&lt;/p&gt;
&lt;p&gt;于是，我们执行另外一个命令来读取这个管道里的数据：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ cat &amp;lt; myPipe  // 读取管道里的数据
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;hello
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;可以看到，管道里的内容被读取出来了，并打印在了终端上，另外一方面，echo 那个命令也正常退出了。&lt;/p&gt;
&lt;h4 id=&#34;管道创建的原理&#34;&gt;管道创建的原理&lt;/h4&gt;
&lt;p&gt;匿名管道的创建，需要通过下面这个系统调用：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;int pipe&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;int fd&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;2&lt;span class=&#34;o&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;这里表示创建一个&lt;strong&gt;匿名管道&lt;/strong&gt;，并返回了两个描述符，一个是管道的读取端描述符 &lt;code&gt;fd[0]&lt;/code&gt;，另一个是管道的写入端描述符 &lt;code&gt;fd[1]&lt;/code&gt;。注意，这个匿名管道是特殊的文件，只存在于内存，不存于文件系统中。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220720160859304.png&#34;
	width=&#34;602&#34;
	height=&#34;570&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220720160859304_hua610424b2e1543ab7086ce67ee4521f0_28027_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220720160859304_hua610424b2e1543ab7086ce67ee4521f0_28027_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;管道的创建&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;105&#34;
		data-flex-basis=&#34;253px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;其实，&lt;strong&gt;所谓的管道，就是内核里面的一串缓存&lt;/strong&gt;。从管道的一段写入的数据，实际上是缓存在内核中的，另一端读取，也就是从内核中读取这段数据。另外，管道传输的数据是无格式的流且大小受限。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;父子进程&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我们可以使用 &lt;code&gt;fork&lt;/code&gt; 创建子进程，&lt;strong&gt;创建的子进程会复制父进程的文件描述符&lt;/strong&gt;，这样就做到了两个进程各有两个「 &lt;code&gt;fd[0]&lt;/code&gt; 与 &lt;code&gt;fd[1]&lt;/code&gt;」，两个进程就可以通过各自的 fd 写入和读取同一个管道文件实现跨进程通信了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220720160924975.png&#34;
	width=&#34;677&#34;
	height=&#34;977&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220720160924975_hu298c1dec29698f2bfd0720292499a4ac_50054_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220720160924975_hu298c1dec29698f2bfd0720292499a4ac_50054_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;父子进程管道通信&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;69&#34;
		data-flex-basis=&#34;166px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;管道只能一端写入，另一端读出，所以上面这种模式容易造成混乱，因为父进程和子进程都可以同时写入，也都可以读出。那么，为了避免这种情况，通常的做法是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;父进程关闭读取的 fd[0]，只保留写入的 fd[1]；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;子进程关闭写入的 fd[1]，只保留读取的 fd[0]；&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所以说如果需要双向通信，则应该创建两个管道。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;非父子进程&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;到这里，我们仅仅解析了使用管道进行父进程与子进程之间的通信，但是在我们 shell 里面并不是这样的。&lt;/p&gt;
&lt;p&gt;在 shell 里面执行 &lt;code&gt;A | B&lt;/code&gt;命令的时候，A 进程和 B 进程都是 shell 创建出来的子进程，A 和 B 之间不存在父子关系，它俩的父进程都是 shell。&lt;/p&gt;
&lt;p&gt;所以说，在 shell 里通过「&lt;code&gt;|&lt;/code&gt;」匿名管道将多个命令连接在一起，实际上也就是创建了多个子进程，通过关闭某些读端和写端实现两个子进程之间的通信，如图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220720161211719.png&#34;
	width=&#34;1307&#34;
	height=&#34;1037&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220720161211719_hu6cf9614efc6d7225734e7ab452bf2b5d_79576_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220720161211719_hu6cf9614efc6d7225734e7ab452bf2b5d_79576_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;shell里的管道符命令原理&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;126&#34;
		data-flex-basis=&#34;302px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;我们可以得知，&lt;strong&gt;对于匿名管道，它的通信范围是存在父子关系的进程&lt;/strong&gt;。因为管道没有实体，也就是没有管道文件，只能通过 fork 来复制父进程 fd 文件描述符，来达到通信的目的。&lt;/p&gt;
&lt;p&gt;另外，&lt;strong&gt;对于命名管道，它可以在不相关的进程间也能相互通信&lt;/strong&gt;。因为命令管道，提前创建了一个类型为管道的设备文件，在进程里只要使用这个设备文件，就可以相互通信。&lt;/p&gt;
&lt;p&gt;不管是匿名管道还是命名管道，进程写入的数据都是缓存在内核中，另一个进程读取数据时候自然也是从内核中获取，同时通信数据都遵循&lt;strong&gt;先进先出&lt;/strong&gt;原则，不支持 lseek 之类的文件定位操作。&lt;/p&gt;
&lt;h3 id=&#34;消息队列&#34;&gt;消息队列&lt;/h3&gt;
&lt;p&gt;前面说到管道的通信方式是效率低的，因此管道不适合进程间频繁地交换数据。&lt;/p&gt;
&lt;p&gt;对于这个问题，&lt;strong&gt;消息队列&lt;/strong&gt;的通信模式就可以解决。比如，A 进程要给 B 进程发送消息，A 进程把数据放在对应的消息队列后就可以正常返回了，B 进程需要的时候再去读取数据就可以了。同理，B 进程要给 A 进程发送消息也是如此。&lt;/p&gt;
&lt;p&gt;再来，&lt;strong&gt;消息队列是保存在内核中的消息链表&lt;/strong&gt;，在发送数据时，会分成一个一个独立的数据单元，也就是消息体（数据块），消息体是用户自定义的数据类型，消息的发送方和接收方要约定好消息体的数据类型，所以每个消息体都是固定大小的存储块，不像管道是无格式的字节流数据。如果进程从消息队列中读取了消息体，内核就会把这个消息体删除。&lt;/p&gt;
&lt;p&gt;消息队列生命周期随内核，如果没有释放消息队列或者没有关闭操作系统，消息队列会一直存在，而前面提到的&lt;strong&gt;匿名管道&lt;/strong&gt;的生命周期，是随进程的创建而建立，随进程的结束而销毁。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;消息队列不适合比较大数据的传输&lt;/strong&gt;，因为在内核中每个消息体都有一个最大长度的限制，同时所有队列所包含的全部消息体的总长度也是有上限。在 Linux 内核中，会有两个宏定义 &lt;code&gt;MSGMAX&lt;/code&gt; 和 &lt;code&gt;MSGMNB&lt;/code&gt;，它们以字节为单位，分别定义了一条消息的最大长度和一个队列的最大长度。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;消息队列通信过程中，存在用户态与内核态之间的数据拷贝开销&lt;/strong&gt;，因为进程写入数据到内核中的消息队列时，会发生从用户态拷贝数据到内核态的过程，同理另一进程读取内核中的消息数据时，会发生从内核态拷贝数据到用户态的过程。&lt;/p&gt;
&lt;h3 id=&#34;共享内存&#34;&gt;共享内存&lt;/h3&gt;
&lt;p&gt;消息队列的读取和写入的过程，都会有发生用户态与内核态之间的消息拷贝过程。那&lt;strong&gt;共享内存&lt;/strong&gt;的方式，就很好的解决了这一问题。&lt;/p&gt;
&lt;p&gt;现代操作系统，对于内存管理，采用的是虚拟内存技术，也就是每个进程都有自己独立的虚拟内存空间，不同进程的虚拟内存映射到不同的物理内存中。所以，即使进程 A 和 进程 B 的虚拟地址是一样的，其实访问的是不同的物理内存地址，对于数据的增删查改互不影响。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中&lt;/strong&gt;。这样这个进程写入的东西，另外一个进程马上就能看到了，都不需要拷贝来拷贝去，传来传去，大大提高了进程间通信的速度。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220720162544015.png&#34;
	width=&#34;714&#34;
	height=&#34;609&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220720162544015_hu106753bb37647ce4ea03b027cf254138_27525_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220720162544015_hu106753bb37647ce4ea03b027cf254138_27525_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;共享内存&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;117&#34;
		data-flex-basis=&#34;281px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;信号量&#34;&gt;信号量&lt;/h3&gt;
&lt;p&gt;用了共享内存通信方式，带来新的问题，那就是如果多个进程同时修改同一个共享内存，很有可能就冲突了。例如两个进程都同时写一个地址，那先写的那个进程会发现内容被别人覆盖了。&lt;/p&gt;
&lt;p&gt;为了防止多进程竞争共享资源，而造成的数据错乱，所以需要保护机制，使得共享的资源，在任意时刻只能被一个进程访问。正好，&lt;strong&gt;信号量&lt;/strong&gt;就实现了这一保护机制。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;信号量其实是一个整型的计数器，主要用于实现进程间的互斥与同步，而不是用于缓存进程间通信的数据&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;信号量表示资源的数量，控制信号量的方式有两种原子操作：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;一个是 &lt;strong&gt;P 操作&lt;/strong&gt;，这个操作会把信号量减去 1，相减后如果信号量 &amp;lt; 0，则表明资源已被占用，进程需阻塞等待；相减后如果信号量 &amp;gt;= 0，则表明还有资源可使用，进程可正常继续执行。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;另一个是 &lt;strong&gt;V 操作&lt;/strong&gt;，这个操作会把信号量加上 1，相加后如果信号量 &amp;lt;= 0，则表明当前有阻塞中的进程，于是会将该进程唤醒运行；相加后如果信号量 &amp;gt; 0，则表明当前没有阻塞中的进程；&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;P 操作是用在进入共享资源之前，V 操作是用在离开共享资源之后，这两个操作是必须成对出现的。&lt;/p&gt;
&lt;p&gt;接下来，举个例子，如果要使得两个进程互斥访问共享内存，我们可以初始化信号量为 &lt;code&gt;1&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;信号初始化为 &lt;code&gt;1&lt;/code&gt;，就代表着是&lt;strong&gt;互斥信号量&lt;/strong&gt;，它可以保证共享内存在任何时刻只有一个进程在访问，这就很好的保护了共享内存。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220720164142326.png&#34;
	width=&#34;452&#34;
	height=&#34;591&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220720164142326_hucc352da9cd5670822a1a3c3350e27ca2_16487_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220720164142326_hucc352da9cd5670822a1a3c3350e27ca2_16487_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;互斥信号量&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;76&#34;
		data-flex-basis=&#34;183px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;信号初始化为 &lt;code&gt;0&lt;/code&gt;，就代表着是&lt;strong&gt;同步信号量&lt;/strong&gt;，它可以保证进程 A 应在进程 B 之前执行。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220720164152725.png&#34;
	width=&#34;467&#34;
	height=&#34;389&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220720164152725_hu0c037a73a933e4a8d1671e849925169e_15120_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220720164152725_hu0c037a73a933e4a8d1671e849925169e_15120_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;同步信号量&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;120&#34;
		data-flex-basis=&#34;288px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;信号&#34;&gt;信号&lt;/h3&gt;
&lt;p&gt;信号和信号量毫无关系！&lt;/p&gt;
&lt;p&gt;上面说的进程间通信，都是常规状态下的工作模式。&lt;strong&gt;对于异常情况下的工作模式，就需要用「信号」的方式来通知进程。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在 Linux 操作系统中， 为了响应各种各样的事件，提供了几十种信号，分别代表不同的意义。我们可以通过 &lt;code&gt;kill -l&lt;/code&gt; 命令，查看所有的信号：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ kill -l
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; 1) SIGHUP       2) SIGINT       3) SIGQUIT      4) SIGILL       5) SIGTRAP
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; 6) SIGABRT      7) SIGBUS       8) SIGFPE       9) SIGKILL     10) SIGUSR1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;11) SIGSEGV     12) SIGUSR2     13) SIGPIPE     14) SIGALRM     15) SIGTERM
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;16) SIGSTKFLT   17) SIGCHLD     18) SIGCONT     19) SIGSTOP     20) SIGTSTP
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;21) SIGTTIN     22) SIGTTOU     23) SIGURG      24) SIGXCPU     25) SIGXFSZ
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;26) SIGVTALRM   27) SIGPROF     28) SIGWINCH    29) SIGIO       30) SIGPWR
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;31) SIGSYS      34) SIGRTMIN    35) SIGRTMIN+1  36) SIGRTMIN+2  37) SIGRTMIN+3
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;38) SIGRTMIN+4  39) SIGRTMIN+5  40) SIGRTMIN+6  41) SIGRTMIN+7  42) SIGRTMIN+8
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;43) SIGRTMIN+9  44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12 47) SIGRTMIN+13
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;48) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14 51) SIGRTMAX-13 52) SIGRTMAX-12
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;53) SIGRTMAX-11 54) SIGRTMAX-10 55) SIGRTMAX-9  56) SIGRTMAX-8  57) SIGRTMAX-7
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;58) SIGRTMAX-6  59) SIGRTMAX-5  60) SIGRTMAX-4  61) SIGRTMAX-3  62) SIGRTMAX-2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;63) SIGRTMAX-1  64) SIGRTMAX
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;运行在 shell 终端的进程，我们可以通过键盘输入某些组合键的时候，给进程发送信号。例如&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ctrl+C 产生 &lt;code&gt;SIGINT&lt;/code&gt; 信号，表示终止该进程；&lt;/li&gt;
&lt;li&gt;Ctrl+Z 产生 &lt;code&gt;SIGTSTP&lt;/code&gt; 信号，表示停止该进程，但还未结束；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果进程在后台运行，可以通过 &lt;code&gt;kill&lt;/code&gt; 命令的方式给进程发送信号，但前提需要知道运行中的进程 PID 号，例如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;kill -9 1050 ，表示给 PID 为 1050 的进程发送 &lt;code&gt;SIGKILL&lt;/code&gt; 信号，用来立即结束该进程；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所以，信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令）。&lt;/p&gt;
&lt;p&gt;信号是进程间通信机制中&lt;strong&gt;唯一的异步通信机制&lt;/strong&gt;，因为可以在任何时候发送信号给某一进程，一旦有信号产生，我们就有下面这几种，用户进程对信号的处理方式。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;执行默认操作&lt;/strong&gt;。Linux 对每种信号都规定了默认操作，例如，上面列表中的 SIGTERM 信号，就是终止进程的意思。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;捕捉信号&lt;/strong&gt;。我们可以为信号定义一个信号处理函数。当信号发生时，我们就执行相应的信号处理函数。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;忽略信号&lt;/strong&gt;。当我们不希望处理某些信号的时候，就可以忽略该信号，不做任何处理。有两个信号是应用进程无法捕捉和忽略的，即 &lt;code&gt;SIGKILL&lt;/code&gt; 和 &lt;code&gt;SEGSTOP&lt;/code&gt;，它们用于在任何时候中断或结束某一进程。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;socket&#34;&gt;Socket&lt;/h3&gt;
&lt;p&gt;前面提到的管道、消息队列、共享内存、信号量和信号都是在同一台主机上进行进程间通信，那要想&lt;strong&gt;跨网络与不同主机上的进程之间通信，就需要 Socket 通信了。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;实际上，Socket 通信不仅可以跨网络与不同主机的进程间通信，还可以在同主机上进程间通信。&lt;/p&gt;
&lt;p&gt;我们来看看创建 socket 的系统调用：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;int socket&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;int domain, int type, int protocal&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;三个参数分别代表：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;domain 参数用来指定协议族，比如 AF&lt;em&gt;INET 用于 IPV4、AF&lt;/em&gt;INET6 用于 IPV6、AF&lt;em&gt;LOCAL/AF&lt;/em&gt;UNIX 用于本机；&lt;/li&gt;
&lt;li&gt;type 参数用来指定通信特性，比如 SOCK&lt;em&gt;STREAM 表示的是字节流，对应 TCP、SOCK&lt;/em&gt;DGRAM 表示的是数据报，对应 UDP、SOCK_RAW 表示的是原始套接字；&lt;/li&gt;
&lt;li&gt;protocal 参数原本是用来指定通信协议的，但现在基本废弃。因为协议已经通过前面两个参数指定完成，protocol 目前一般写成 0 即可；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;根据创建 socket 类型的不同，通信的方式也就不同：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;实现 TCP 字节流通信： socket 类型是 AF&lt;em&gt;INET 和 SOCK&lt;/em&gt;STREAM；&lt;/li&gt;
&lt;li&gt;实现 UDP 数据报通信：socket 类型是 AF&lt;em&gt;INET 和 SOCK&lt;/em&gt;DGRAM；&lt;/li&gt;
&lt;li&gt;实现本地进程间通信： 「本地字节流 socket 」类型是 AF&lt;em&gt;LOCAL 和 SOCK&lt;/em&gt;STREAM，「本地数据报 socket 」类型是 AF&lt;em&gt;LOCAL 和 SOCK&lt;/em&gt;DGRAM。另外，AF&lt;em&gt;UNIX 和 AF&lt;/em&gt;LOCAL 是等价的，所以 AF_UNIX 也属于本地 socket；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;接下来，简单说一下这三种通信的编程模式。&lt;/p&gt;
&lt;h4 id=&#34;针对-tcp-协议通信的-socket-编程模型&#34;&gt;针对 TCP 协议通信的 socket 编程模型&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220720165415984.png&#34;
	width=&#34;1188&#34;
	height=&#34;1007&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220720165415984_hu8a0c36c9d773cafe1f7be26ff7eda02c_69211_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220720165415984_hu8a0c36c9d773cafe1f7be26ff7eda02c_69211_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;TCP协议的Socket&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;117&#34;
		data-flex-basis=&#34;283px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;针对-udp-协议通信的-socket-编程模型&#34;&gt;针对 UDP 协议通信的 socket 编程模型&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220720165707328.png&#34;
	width=&#34;513&#34;
	height=&#34;671&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220720165707328_hu0fdf2a8a63317f7d6951bf2f5d51a830_29932_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/image-20220720165707328_hu0fdf2a8a63317f7d6951bf2f5d51a830_29932_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;UDP协议的Socket&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;76&#34;
		data-flex-basis=&#34;183px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;UDP 是没有连接的，所以不需要三次握手，也就不需要像 TCP 调用 listen 和 connect，但是 UDP 的交互仍然需要 IP 地址和端口号，因此也需要 bind。&lt;/p&gt;
&lt;p&gt;对于 UDP 来说，不需要要维护连接，那么也就没有所谓的发送方和接收方，甚至都不存在客户端和服务端的概念，只要有一个 socket 多台机器就可以任意通信，因此每一个 UDP 的 socket 都需要 bind。&lt;/p&gt;
&lt;p&gt;另外，每次通信时，调用 sendto 和 recvfrom，都要传入目标主机的 IP 地址和端口。&lt;/p&gt;
&lt;h4 id=&#34;针对本地进程间通信的-socket-编程模型&#34;&gt;针对本地进程间通信的 socket 编程模型&lt;/h4&gt;
&lt;p&gt;本地 socket 被用于在&lt;strong&gt;同一台主机上进程间通信&lt;/strong&gt;的场景：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;本地 socket 的编程接口和 IPv4 、IPv6 套接字编程接口是一致的，可以支持「字节流」和「数据报」两种协议；&lt;/li&gt;
&lt;li&gt;本地 socket 的实现效率大大高于 IPv4 和 IPv6 的字节流、数据报 socket 实现；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;本地字节流 socket 和 本地数据报 socket 在 bind 的时候，不像 TCP 和 UDP 要绑定 IP 地址和端口，而是绑定一个本地文件，这也就是它们之间的最大区别。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;多线程同步&#34;&gt;多线程同步&lt;/h2&gt;
&lt;h3 id=&#34;互斥&#34;&gt;互斥&lt;/h3&gt;
&lt;p&gt;上面展示的情况称为&lt;strong&gt;竞争条件（race condition）&lt;/strong&gt;，当多线程相互竞争操作共享变量时，由于运气不好，即在执行过程中发生了上下文切换，我们得到了错误的结果，事实上，每次运行都可能得到不同的结果，因此输出的结果存在&lt;strong&gt;不确定性（indeterminate）&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;由于多线程执行操作共享变量的这段代码可能会导致竞争状态，因此我们将此段代码称为&lt;strong&gt;临界区（critical section），它是访问共享资源的代码片段，一定不能给多线程同时执行。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我们希望这段代码是&lt;strong&gt;互斥（mutualexclusion）的，也就说保证一个线程在临界区执行时，其他线程应该被阻止进入临界区&lt;/strong&gt;，说白了，就是这段代码执行过程中，最多只能出现一个线程。&lt;/p&gt;
&lt;h3 id=&#34;同步&#34;&gt;同步&lt;/h3&gt;
&lt;p&gt;互斥解决了并发进程/线程对临界区的使用问题。这种基于临界区控制的交互作用是比较简单的，只要一个进程/线程进入了临界区，其他试图想进入临界区的进程/线程都会被阻塞着，直到第一个进程/线程离开了临界区。&lt;/p&gt;
&lt;p&gt;我们都知道在多线程里，每个线程并不一定是顺序执行的，它们基本是以各自独立的、不可预知的速度向前推进，但有时候我们又希望多个线程能密切合作，以实现一个共同的任务。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;所谓同步，就是并发进程/线程在一些关键点上可能需要互相等待与互通消息，这种相互制约的等待与互通信息称为进程/线程同步&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;互斥与同步的实现和使用&#34;&gt;互斥与同步的实现和使用&lt;/h3&gt;
&lt;p&gt;在进程/线程并发执行的过程中，进程/线程之间存在协作的关系，例如有互斥、同步的关系。&lt;/p&gt;
&lt;p&gt;为了实现进程/线程间正确的协作，操作系统必须提供实现进程协作的措施和方法，主要的方法有两种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;锁&lt;/em&gt;：加锁、解锁操作；&lt;/li&gt;
&lt;li&gt;&lt;em&gt;信号量&lt;/em&gt;：P、V 操作；&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;哲学家就餐问题&#34;&gt;哲学家就餐问题&lt;/h4&gt;
&lt;p&gt;解决方案一：限制四个人同时就餐（信号量初始化为4）&lt;/p&gt;
&lt;p&gt;解决方案二：仅当哲学家的左右手筷子都拿起时才允许进餐（拿起左右叉子原子操作）。&lt;/p&gt;
&lt;p&gt;解决方案二：即让偶数编号的哲学家「先拿左边的叉子后拿右边的叉子」，奇数编号的哲学家「先拿右边的叉子后拿左边的叉子」。&lt;/p&gt;
&lt;p&gt;解决方案三：另一个简单的解法是为资源（这里是筷子）分配一个偏序或者分级的关系，并约定所有资源都按照这种顺序获取，按相反顺序释放，而且保证不会有两个无关资源同时被同一项工作所需要。在哲学家就餐问题中，筷子按照某种规则编号为1至5，每一个工作单元（哲学家）总是先拿起左右两边编号较低的筷子，再拿编号较高的。用完筷子后，他总是先放下编号较高的筷子，再放下编号较低的。在这种情况下，当四位哲学家同时拿起他们手边编号较低的筷子时，只有编号最高的筷子留在桌上，从而第五位哲学家就不能使用任何一只筷子了。而且，只有一位哲学家能使用最高编号的筷子，所以他能使用两只筷子用餐。当他吃完后，他会先放下编号最高的筷子，再放下编号较低的筷子，从而让另一位哲学家拿起后边的这只开始吃东西。&lt;/p&gt;
&lt;h2 id=&#34;死锁&#34;&gt;死锁&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;两个线程都在等待对方释放锁&lt;/strong&gt;，在没有外力的作用下，这些线程会一直相互等待，就没办法继续运行，这种情况就是发生了&lt;strong&gt;死锁&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;死锁只有&lt;strong&gt;同时满足&lt;/strong&gt;以下四个条件才会发生：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;互斥条件：互斥条件是指&lt;strong&gt;多个线程不能同时使用同一个资源&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;持有并等待条件：&lt;strong&gt;线程 A 在等待资源 2 的同时并不会释放自己已经持有的资源 1&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;不可剥夺条件：当线程已经持有了资源 ，&lt;strong&gt;在自己使用完之前不能被其他线程获取&lt;/strong&gt;，线程 B 如果也想使用此资源，则只能在线程 A 使用完并释放后才能获取。&lt;/li&gt;
&lt;li&gt;环路等待条件：环路等待条件指都是，在死锁发生的时候，&lt;strong&gt;两个线程获取资源的顺序构成了环形链&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;互斥锁与自旋锁&#34;&gt;互斥锁与自旋锁&lt;/h2&gt;
&lt;h3 id=&#34;互斥锁&#34;&gt;互斥锁&lt;/h3&gt;
&lt;p&gt;加锁失败后，线程会&lt;strong&gt;释放 CPU&lt;/strong&gt; ，给其他线程；&lt;/p&gt;
&lt;p&gt;互斥锁加锁失败时，会从用户态陷入到内核态，让内核帮我们切换线程，虽然简化了使用锁的难度，但是存在一定的性能开销成本。&lt;/p&gt;
&lt;p&gt;那这个开销成本是什么呢？会有&lt;strong&gt;两次线程上下文切换的成本&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;当线程加锁失败时，内核会把线程的状态从「运行」状态设置为「睡眠」状态，然后把 CPU 切换给其他线程运行；&lt;/li&gt;
&lt;li&gt;接着，当锁被释放时，之前「睡眠」状态的线程会变为「就绪」状态，然后内核会在合适的时间，把 CPU 切换给该线程运行。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;自旋锁&#34;&gt;自旋锁&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;加锁失败后，线程会&lt;/strong&gt;忙等待，直到它拿到锁&lt;/p&gt;
&lt;p&gt;自旋锁是通过 CPU 提供的 &lt;code&gt;CAS&lt;/code&gt; 函数（&lt;em&gt;Compare And Swap&lt;/em&gt;），在「用户态」完成加锁和解锁操作，不会主动产生线程上下文切换，所以相比互斥锁来说，会快一些，开销也小一些。&lt;/p&gt;
&lt;p&gt;一般加锁的过程，包含两个步骤：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;第一步，查看锁的状态，如果锁是空闲的，则执行第二步；&lt;/li&gt;
&lt;li&gt;第二步，将锁设置为当前线程持有；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;CAS 函数就把这两个步骤合并成一条硬件级指令，形成&lt;strong&gt;原子指令&lt;/strong&gt;，这样就保证了这两个步骤是不可分割的，要么一次性执行完两个步骤，要么两个步骤都不执行。&lt;/p&gt;
&lt;p&gt;使用自旋锁的时候，当发生多线程竞争锁的情况，加锁失败的线程会「忙等待」，直到它拿到锁。这里的「忙等待」可以用 &lt;code&gt;while&lt;/code&gt; 循环等待实现，不过最好是使用 CPU 提供的 &lt;code&gt;PAUSE&lt;/code&gt; 指令来实现「忙等待」，因为可以减少循环等待时的耗电量。&lt;/p&gt;
&lt;p&gt;自旋锁是最比较简单的一种锁，一直自旋，利用 CPU 周期，直到锁可用。&lt;strong&gt;需要注意，在单核 CPU 上，需要抢占式的调度器（即不断通过时钟中断一个线程，运行其他线程）。否则，自旋锁在单 CPU 上无法使用，因为一个自旋的线程永远不会放弃 CPU。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;自旋锁开销少，在多核系统下一般不会主动产生线程切换，适合异步、协程等在用户态切换请求的编程方式，但如果被锁住的代码执行时间过长，自旋的线程会长时间占用 CPU 资源，所以自旋的时间和被锁住的代码执行的时间是成「正比」的关系，我们需要清楚的知道这一点。&lt;/p&gt;
&lt;p&gt;自旋锁与互斥锁使用层面比较相似，但实现层面上完全不同：&lt;strong&gt;当加锁失败时，互斥锁用「线程切换」来应对，自旋锁则用「忙等待」来应对&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&#34;悲观锁与乐观锁&#34;&gt;悲观锁与乐观锁&lt;/h2&gt;
&lt;p&gt;悲观锁做事比较悲观，它认为&lt;strong&gt;多线程同时修改共享资源的概率比较高，于是很容易出现冲突，所以访问共享资源前，先要上锁&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;那相反的，如果多线程同时修改共享资源的概率比较低，就可以采用乐观锁。&lt;/p&gt;
&lt;p&gt;乐观锁做事比较乐观，它假定冲突的概率很低，它的工作方式是：&lt;strong&gt;先修改完共享资源，再验证这段时间内有没有发生冲突，如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;乐观锁的应用：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;多人在线编辑，先修改，再判断是否发生冲突&lt;/li&gt;
&lt;li&gt;SVG，Git也是提交时才判断冲突&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>操作系统03-内存管理</title>
        <link>https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F03-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</link>
        <pubDate>Tue, 19 Jul 2022 17:05:50 +0800</pubDate>
        
        <guid>https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F03-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</guid>
        <description>&lt;h2 id=&#34;虚拟地址&#34;&gt;虚拟地址&lt;/h2&gt;
&lt;p&gt;我们可以把进程所使用的地址「隔离」开来，即让操作系统为每个进程分配独立的一套「&lt;strong&gt;虚拟地址&lt;/strong&gt;」，人人都有，大家自己玩自己的地址就行，互不干涉。但是有个前提每个进程都不能访问物理地址，至于虚拟地址最终怎么落到物理内存里，对进程来说是透明的，操作系统已经把这些都安排的明明白白了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;操作系统会提供一种机制，将不同进程的虚拟地址和不同内存的物理地址映射起来。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如果程序要访问虚拟地址的时候，由操作系统转换成不同的物理地址，这样不同的进程运行的时候，写入的是不同的物理地址，这样就不会冲突了。&lt;/p&gt;
&lt;p&gt;于是，这里就引出了两种地址的概念：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;我们程序所使用的内存地址叫做&lt;strong&gt;虚拟内存地址&lt;/strong&gt;（&lt;em&gt;Virtual Memory Address&lt;/em&gt;）&lt;/li&gt;
&lt;li&gt;实际存在硬件里面的空间地址叫&lt;strong&gt;物理内存地址&lt;/strong&gt;（&lt;em&gt;Physical Memory Address&lt;/em&gt;）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;操作系统引入了虚拟内存，进程持有的虚拟地址会通过 CPU 芯片中的内存管理单元（MMU）的映射关系，来转换变成物理地址，然后再通过物理地址访问内存，如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F03-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20220719163405369.png&#34;
	width=&#34;831&#34;
	height=&#34;539&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F03-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20220719163405369_hu7771ba620034419cf90013ba5e2f7c80_28128_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F03-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20220719163405369_hu7771ba620034419cf90013ba5e2f7c80_28128_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;虚拟地址转换&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;154&#34;
		data-flex-basis=&#34;370px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;内存分段&#34;&gt;内存分段&lt;/h3&gt;
&lt;p&gt;虚拟地址是通过&lt;strong&gt;段表&lt;/strong&gt;与物理地址进行映射的，分段机制会把程序的虚拟地址分成 4 个段，每个段在段表中有一个项，在这一项找到段的基地址，再加上偏移量，于是就能找到物理内存中的地址，如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F03-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20220719163644039.png&#34;
	width=&#34;1055&#34;
	height=&#34;651&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F03-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20220719163644039_hu7d2dfa21e90472fda57e4fc2927f0621_73250_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F03-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20220719163644039_hu7d2dfa21e90472fda57e4fc2927f0621_73250_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;段地址转换&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;162&#34;
		data-flex-basis=&#34;388px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;分段的办法很好，解决了程序本身不需要关心具体的物理内存地址的问题，但它也有一些不足之处：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;第一个就是&lt;strong&gt;内存碎片&lt;/strong&gt;的问题。&lt;/li&gt;
&lt;li&gt;第二个就是&lt;strong&gt;内存交换的效率低&lt;/strong&gt;的问题（内存交换粒度太大）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;内存分页&#34;&gt;内存分页&lt;/h3&gt;
&lt;p&gt;分段的好处就是能产生连续的内存空间，但是会出现内存碎片和内存交换的空间太大的问题。&lt;/p&gt;
&lt;p&gt;要解决这些问题，那么就要想出能少出现一些内存碎片的办法。另外，当需要进行内存交换的时候，让需要交换写入或者从磁盘装载的数据更少一点，这样就可以解决问题了。这个办法，也就是&lt;strong&gt;内存分页&lt;/strong&gt;（&lt;em&gt;Paging&lt;/em&gt;）。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小&lt;/strong&gt;。这样一个连续并且尺寸固定的内存空间，我们叫&lt;strong&gt;页&lt;/strong&gt;（&lt;em&gt;Page&lt;/em&gt;）。在 Linux 下，每一页的大小为 &lt;code&gt;4KB&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;虚拟地址与物理地址之间通过&lt;strong&gt;页表&lt;/strong&gt;来映射，如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F03-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20220719164053124.png&#34;
	width=&#34;935&#34;
	height=&#34;561&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F03-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20220719164053124_hu331ef90abbb4fa0ddd009260d43d66c3_50154_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F03-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20220719164053124_hu331ef90abbb4fa0ddd009260d43d66c3_50154_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;内存分页&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;166&#34;
		data-flex-basis=&#34;400px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;缺页中断：而当进程访问的虚拟地址在页表中查不到时，系统会产生一个&lt;strong&gt;缺页异常&lt;/strong&gt;，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;分页是怎么解决分段的内存碎片、内存交换效率低的问题？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;由于内存空间都是预先划分好的，也就不会像分段会产生间隙非常小的内存，这正是分段会产生内存碎片的原因。而&lt;strong&gt;采用了分页，那么释放的内存都是以页为单位释放的，也就不会产生无法给进程使用的小内存。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如果内存空间不够，操作系统会把其他正在运行的进程中的「最近没被使用」的内存页面给释放掉，也就是暂时写在硬盘上，称为&lt;strong&gt;换出&lt;/strong&gt;（&lt;em&gt;Swap Out&lt;/em&gt;）。一旦需要的时候，再加载进来，称为&lt;strong&gt;换入&lt;/strong&gt;（&lt;em&gt;Swap In&lt;/em&gt;）。所以，一次性写入磁盘的也只有少数的一个页或者几个页，不会花太多时间，&lt;strong&gt;内存交换的效率就相对比较高。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F03-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20220719170234253.png&#34;
	width=&#34;1406&#34;
	height=&#34;857&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F03-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20220719170234253_hube0ae2631e29792aa932e471333f94e7_64247_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F03-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20220719170234253_hube0ae2631e29792aa932e471333f94e7_64247_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;内存分页换入换出&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;164&#34;
		data-flex-basis=&#34;393px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;在分页机制下，虚拟地址分为两部分，&lt;strong&gt;页号&lt;/strong&gt;和&lt;strong&gt;页内偏移&lt;/strong&gt;。页号作为页表的索引，&lt;strong&gt;页表&lt;/strong&gt;包含物理页每页所在&lt;strong&gt;物理内存的基地址&lt;/strong&gt;，这个基地址与页内偏移的组合就形成了物理内存地址，见下图。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F03-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20220719170308722.png&#34;
	width=&#34;1067&#34;
	height=&#34;797&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F03-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20220719170308722_huf423f7529ea661758fee94eee70e2892_41014_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F03-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20220719170308722_huf423f7529ea661758fee94eee70e2892_41014_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;分页地址映射&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;133&#34;
		data-flex-basis=&#34;321px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;总结一下，对于一个内存地址转换，其实就是这样三个步骤：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;把虚拟内存地址，切分成页号和偏移量；&lt;/li&gt;
&lt;li&gt;根据页号，从页表里面，查询对应的物理页号；&lt;/li&gt;
&lt;li&gt;直接拿物理页号，加上前面的偏移量，就得到了物理内存地址。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;多级页表&#34;&gt;多级页表&lt;/h4&gt;
&lt;p&gt;因为操作系统是可以同时运行非常多的进程的，那这不就意味着页表会非常的庞大。&lt;/p&gt;
&lt;p&gt;在 32 位的环境下，虚拟地址空间共有 4GB，假设一个页的大小是 4KB（2^12），那么就需要大约 100 万 （2^20） 个页，每个「页表项」需要 4 个字节大小来存储，那么整个 4GB 空间的映射就需要有 &lt;code&gt;4MB&lt;/code&gt; 的内存来存储页表。&lt;/p&gt;
&lt;p&gt;这 4MB 大小的页表，看起来也不是很大。但是要知道每个进程都是有自己的虚拟地址空间的，也就说都有自己的页表。&lt;/p&gt;
&lt;p&gt;那么，&lt;code&gt;100&lt;/code&gt; 个进程的话，就需要 &lt;code&gt;400MB&lt;/code&gt; 的内存来存储页表，这是非常大的内存了，更别说 64 位的环境了&lt;/p&gt;
&lt;p&gt;要解决上面的问题，就需要采用一种叫作&lt;strong&gt;多级页表&lt;/strong&gt;（&lt;em&gt;Multi-Level Page Table&lt;/em&gt;）的解决方案。&lt;/p&gt;
&lt;p&gt;在前面我们知道了，对于单页表的实现方式，在 32 位和页大小 &lt;code&gt;4KB&lt;/code&gt; 的环境下，一个进程的页表需要装下 100 多万个「页表项」，并且每个页表项是占用 4 字节大小的，于是相当于每个页表需占用 4MB 大小的空间。&lt;/p&gt;
&lt;p&gt;我们把这个 100 多万个「页表项」的单级页表再分页，将页表（一级页表）分为 &lt;code&gt;1024&lt;/code&gt; 个页表（二级页表），每个表（二级页表）中包含 &lt;code&gt;1024&lt;/code&gt; 个「页表项」，形成&lt;strong&gt;二级分页&lt;/strong&gt;。如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F03-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20220719170441463.png&#34;
	width=&#34;1686&#34;
	height=&#34;1146&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F03-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20220719170441463_hu3a57298840d906de5d656e76c57869dd_154508_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F03-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20220719170441463_hu3a57298840d906de5d656e76c57869dd_154508_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;多级页表&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;147&#34;
		data-flex-basis=&#34;353px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;你可能会问，分了二级表，映射 4GB 地址空间就需要 4KB（一级页表）+ 4MB（二级页表）的内存，这样占用空间不是更大了吗？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;当然如果 4GB 的虚拟地址全部都映射到了物理内存上的话，二级分页占用空间确实是更大了，但是，我们往往不会为一个进程分配那么多内存。&lt;/p&gt;
&lt;p&gt;其实我们应该换个角度来看问题，还记得计算机组成原理里面无处不在的&lt;strong&gt;局部性原理&lt;/strong&gt;么？&lt;/p&gt;
&lt;p&gt;每个进程都有 4GB 的虚拟地址空间，而显然对于大多数程序来说，其使用到的空间远未达到 4GB，因为会存在部分对应的页表项都是空的，根本没有分配，对于已分配的页表项，如果存在最近一定时间未访问的页表，在物理内存紧张的情况下，操作系统会将页面换出到硬盘，也就是说不会占用物理内存。&lt;/p&gt;
&lt;p&gt;如果使用了二级分页，一级页表就可以覆盖整个 4GB 虚拟地址空间，但&lt;strong&gt;如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表了，即可以在需要时才创建二级页表&lt;/strong&gt;。做个简单的计算，假设只有 20% 的一级页表项被用到了，那么页表占用的内存空间就只有 4KB（一级页表） + 20% * 4MB（二级页表）= &lt;code&gt;0.804MB&lt;/code&gt;，这对比单级页表的 &lt;code&gt;4MB&lt;/code&gt; 是不是一个巨大的节约？&lt;/p&gt;
&lt;p&gt;那么为什么不分级的页表就做不到这样节约内存呢？我们从页表的性质来看，保存在内存中的页表承担的职责是将虚拟地址翻译成物理地址。假如虚拟地址在页表中找不到对应的页表项，计算机系统就不能工作了。所以&lt;strong&gt;页表一定要覆盖全部虚拟地址空间，不分级的页表就需要有 100 多万个页表项来映射，而二级分页则只需要 1024 个页表项&lt;/strong&gt;（此时一级页表覆盖到了全部虚拟地址空间，二级页表在需要时创建）。&lt;/p&gt;
&lt;h4 id=&#34;tlb快表&#34;&gt;TLB（快表）&lt;/h4&gt;
&lt;p&gt;多级页表虽然解决了空间上的问题，但是虚拟地址到物理地址的转换就多了几道转换的工序，这显然就降低了这俩地址转换的速度，也就是带来了时间上的开销。&lt;/p&gt;
&lt;p&gt;程序是有局部性的，即在一段时间内，整个程序的执行仅限于程序中的某一部分。相应地，执行所访问的存储空间也局限于某个内存区域。&lt;/p&gt;
&lt;p&gt;我们就可以利用这一特性，把最常访问的几个页表项存储到访问速度更快的硬件，于是计算机科学家们，就在 CPU 芯片中，加入了一个专门存放程序最常访问的页表项的 Cache，这个 Cache 就是 &lt;strong&gt;TLB（&lt;em&gt;Translation Lookaside Buffer&lt;/em&gt;）&lt;/strong&gt; ，通常称为页表缓存、转址旁路缓存、快表等。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F03-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20220719170955312.png&#34;
	width=&#34;1008&#34;
	height=&#34;509&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F03-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20220719170955312_hu74f27f6e3fd7010e7fa9f8b67f1ea605_31693_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F03-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20220719170955312_hu74f27f6e3fd7010e7fa9f8b67f1ea605_31693_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;TLB&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;198&#34;
		data-flex-basis=&#34;475px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;在 CPU 芯片里面，封装了内存管理单元（&lt;em&gt;Memory Management Unit&lt;/em&gt;）芯片，它用来完成地址转换和 TLB 的访问与交互。&lt;/p&gt;
&lt;p&gt;有了 TLB 后，那么 CPU 在寻址时，会先查 TLB，如果没找到，才会继续查常规的页表。&lt;/p&gt;
&lt;p&gt;TLB 的命中率其实是很高的，因为程序最常访问的页就那么几个。&lt;/p&gt;
&lt;h3 id=&#34;段页式内存管理&#34;&gt;段页式内存管理&lt;/h3&gt;
&lt;p&gt;内存分段和内存分页并不是对立的，它们是可以组合起来在同一个系统中使用的，那么组合起来后，通常称为&lt;strong&gt;段页式内存管理&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;段页式内存管理实现的方式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;先将程序划分为多个有逻辑意义的段，也就是前面提到的分段机制；&lt;/li&gt;
&lt;li&gt;接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这样，地址结构就由&lt;strong&gt;段号、段内页号和页内位移&lt;/strong&gt;三部分组成。&lt;/p&gt;
&lt;p&gt;用于段页式地址变换的数据结构是每一个程序一张段表，每个段又建立一张页表，段表中的地址是页表的起始地址，而页表中的地址则为某页的物理页号，如图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F03-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20220719171112512.png&#34;
	width=&#34;1452&#34;
	height=&#34;699&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F03-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20220719171112512_hub1a9609121469a957ca2d95b1f9e49ab_84793_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F03-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20220719171112512_hub1a9609121469a957ca2d95b1f9e49ab_84793_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;段页式内存管理&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;207&#34;
		data-flex-basis=&#34;498px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;段页式地址变换中要得到物理地址须经过三次内存访问：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;第一次访问段表，得到页表起始地址；&lt;/li&gt;
&lt;li&gt;第二次访问页表，得到物理页号；&lt;/li&gt;
&lt;li&gt;第三次将物理页号与页内位移组合，得到物理地址。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;可用软、硬件相结合的方法实现段页式地址变换，这样虽然增加了硬件成本和系统开销，但提高了内存的利用率。&lt;/p&gt;
&lt;h2 id=&#34;内存页面置换算法&#34;&gt;内存页面置换算法&lt;/h2&gt;
&lt;p&gt;在了解内存页面置换算法前，我们得先谈一下&lt;strong&gt;缺页异常（缺页中断）&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;当 CPU 访问的页面不在物理内存时，便会产生一个缺页中断，请求操作系统将所缺页调入到物理内存。那它与一般中断的主要区别在于：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;缺页中断在指令执行「期间」产生和处理中断信号，而一般中断在一条指令执行「完成」后检查和处理中断信号。&lt;/li&gt;
&lt;li&gt;缺页中断返回到该指令的开始重新执行「该指令」，而一般中断返回回到该指令的「下一个指令」执行。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们来看一下缺页中断的处理流程，如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F03-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20220720203505314.png&#34;
	width=&#34;1112&#34;
	height=&#34;950&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F03-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20220720203505314_hu64cfc6ff8f575c07b3f0cdce31679c47_86419_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F03-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20220720203505314_hu64cfc6ff8f575c07b3f0cdce31679c47_86419_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;缺页中断&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;117&#34;
		data-flex-basis=&#34;280px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;找不到空闲页的话，就说明此时内存已满了，这时候，就需要「页面置换算法」选择一个物理页，如果该物理页有被修改过（脏页），则把它换出到磁盘，然后把该被置换出去的页表项的状态改成「无效的」，最后把正在访问的页面装入到这个物理页中。&lt;/p&gt;
&lt;p&gt;页表项通常有如下图的字段：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F03-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20220720203551692.png&#34;
	width=&#34;1083&#34;
	height=&#34;93&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F03-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20220720203551692_hu6387822acf02b2c8592fbe00b633377d_23018_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F03-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20220720203551692_hu6387822acf02b2c8592fbe00b633377d_23018_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;页表项字段&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;1164&#34;
		data-flex-basis=&#34;2794px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;状态位&lt;/em&gt;：用于表示该页是否有效，也就是说是否在物理内存中，供程序访问时参考。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;访问字段&lt;/em&gt;：用于记录该页在一段时间被访问的次数，供页面置换算法选择出页面时参考。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;修改位&lt;/em&gt;：表示该页在调入内存后是否有被修改过，由于内存中的每一页都在磁盘上保留一份副本，因此，如果没有修改，在置换该页时就不需要将该页写回到磁盘上，以减少系统的开销；如果已经被修改，则将该页重写到磁盘上，以保证磁盘中所保留的始终是最新的副本。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;硬盘地址&lt;/em&gt;：用于指出该页在硬盘上的地址，通常是物理块号，供调入该页时使用。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F03-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20220720203620516.png&#34;
	width=&#34;1190&#34;
	height=&#34;1980&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F03-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20220720203620516_hu0bbd89a7992cbfdcb694c6a62682495e_205180_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F03-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20220720203620516_hu0bbd89a7992cbfdcb694c6a62682495e_205180_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;虚拟内存管理流程&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;60&#34;
		data-flex-basis=&#34;144px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;最佳页面置换算法&#34;&gt;最佳页面置换算法&lt;/h3&gt;
&lt;p&gt;最佳页面置换算法基本思路是，&lt;strong&gt;置换在「未来」最长时间不访问的页面&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;这很理想，但是实际系统中无法实现，因为程序访问页面时是动态的，我们是无法预知每个页面在「下一次」访问前的等待时间。&lt;/p&gt;
&lt;p&gt;所以，最佳页面置换算法作用是为了衡量你的算法的效率，你的算法效率越接近该算法的效率，那么说明你的算法是高效的。&lt;/p&gt;
&lt;h3 id=&#34;先进先出置换算法&#34;&gt;先进先出置换算法&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;选择在内存驻留时间很长的页面进行中置换&lt;/strong&gt;，这个就是「先进先出置换」算法的思想&lt;/p&gt;
&lt;h3 id=&#34;最近最久未使用的置换算法&#34;&gt;最近最久未使用的置换算法&lt;/h3&gt;
&lt;p&gt;最近最久未使用（&lt;em&gt;LRU&lt;/em&gt;）的置换算法的基本思路是，发生缺页时，&lt;strong&gt;选择最长时间没有被访问的页面进行置换&lt;/strong&gt;，也就是说，该算法假设已经很久没有使用的页面很有可能在未来较长的一段时间内仍然不会被使用。&lt;/p&gt;
&lt;p&gt;这种算法近似最优置换算法，最优置换算法是通过「未来」的使用情况来推测要淘汰的页面，而 LRU 则是通过「历史」的使用情况来推测要淘汰的页面。&lt;/p&gt;
&lt;p&gt;虽然 LRU 在理论上是可以实现的，但代价很高。为了完全实现 LRU，需要在内存中维护一个所有页面的链表，最近最多使用的页面在表头，最近最少使用的页面在表尾。&lt;/p&gt;
&lt;p&gt;困难的是，在每次访问内存时都必须要更新「整个链表」。在链表中找到一个页面，删除它，然后把它移动到表头是一个非常费时的操作。&lt;/p&gt;
&lt;p&gt;所以，LRU 虽然看上去不错，但是由于开销比较大，实际应用中比较少使用。&lt;/p&gt;
&lt;h3 id=&#34;时钟页面置换算法&#34;&gt;时钟页面置换算法&lt;/h3&gt;
&lt;p&gt;那有没有一种即能优化置换的次数，也能方便实现的算法呢？&lt;/p&gt;
&lt;p&gt;时钟页面置换算法就可以两者兼得，它跟 LRU 近似，又是对 FIFO 的一种改进。&lt;/p&gt;
&lt;p&gt;该算法的思路是，把所有的页面都保存在一个类似钟面的「环形链表」中，一个表针指向最老的页面。&lt;/p&gt;
&lt;p&gt;当发生缺页中断时，算法首先检查表针指向的页面：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果它的访问位是 0 就淘汰该页面，并把新的页面插入这个位置，然后把表针前移一个位置；&lt;/li&gt;
&lt;li&gt;如果访问位是 1 就清除访问位，并把表针前移一个位置，重复这个过程直到找到了一个访问位为 0 的页面为止；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F03-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20220720203922297.png&#34;
	width=&#34;1166&#34;
	height=&#34;1352&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F03-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20220720203922297_hu5c4777e07b0c5cf530eb644218ab2f1a_135280_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F03-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/image-20220720203922297_hu5c4777e07b0c5cf530eb644218ab2f1a_135280_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;时钟页面置换算法&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;86&#34;
		data-flex-basis=&#34;206px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;最不常用算法&#34;&gt;最不常用算法&lt;/h3&gt;
&lt;p&gt;最不常用（&lt;em&gt;LFU&lt;/em&gt;）算法，这名字听起来很调皮，但是它的意思不是指这个算法不常用，而是&lt;strong&gt;当发生缺页中断时，选择「访问次数」最少的那个页面，并将其淘汰&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;它的实现方式是，对每个页面设置一个「访问计数器」，每当一个页面被访问时，该页面的访问计数器就累加 1。在发生缺页中断时，淘汰计数器值最小的那个页面。&lt;/p&gt;
&lt;p&gt;看起来很简单，每个页面加一个计数器就可以实现了，但是在操作系统中实现的时候，我们需要考虑效率和硬件成本的。&lt;/p&gt;
&lt;p&gt;要增加一个计数器来实现，这个硬件成本是比较高的，另外如果要对这个计数器查找哪个页面访问次数最小，查找链表本身，如果链表长度很大，是非常耗时的，效率不高。&lt;/p&gt;
&lt;p&gt;但还有个问题，LFU 算法只考虑了频率问题，没考虑时间的问题，比如有些页面在过去时间里访问的频率很高，但是现在已经没有访问了，而当前频繁访问的页面由于没有这些页面访问的次数高，在发生缺页中断时，就会可能会误伤当前刚开始频繁访问，但访问次数还不高的页面。&lt;/p&gt;
&lt;p&gt;那这个问题的解决的办法还是有的，可以定期减少访问的次数，比如当发生时间中断时，把过去时间访问的页面的访问次数除以 2，也就说，随着时间的流失，以前的高访问次数的页面会慢慢减少，相当于加大了被置换的概率。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>操作系统01-硬件原理</title>
        <link>https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F01-%E7%A1%AC%E4%BB%B6%E5%8E%9F%E7%90%86/</link>
        <pubDate>Tue, 19 Jul 2022 15:05:03 +0800</pubDate>
        
        <guid>https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F01-%E7%A1%AC%E4%BB%B6%E5%8E%9F%E7%90%86/</guid>
        <description>&lt;h2 id=&#34;冯诺伊曼模型&#34;&gt;冯诺伊曼模型&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F01-%E7%A1%AC%E4%BB%B6%E5%8E%9F%E7%90%86/image-20220719150904126.png&#34;
	width=&#34;920&#34;
	height=&#34;407&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F01-%E7%A1%AC%E4%BB%B6%E5%8E%9F%E7%90%86/image-20220719150904126_hu22670e02696e25176fb6f555a18fe966_42048_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F01-%E7%A1%AC%E4%BB%B6%E5%8E%9F%E7%90%86/image-20220719150904126_hu22670e02696e25176fb6f555a18fe966_42048_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;冯诺依曼模型&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;226&#34;
		data-flex-basis=&#34;542px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;线路位宽与cpu位宽&#34;&gt;线路位宽与CPU位宽&lt;/h2&gt;
&lt;p&gt;数据是如何通过线路传输的呢？其实是通过操作电压，低电压表示 0，高压电压则表示 1。如果构造了高低高这样的信号，其实就是 101 二进制数据，十进制则表示 5，如果只有⼀条线路，就意味着每次只能传递 1 bit 的数据，即 0 或 1，那么传输 101 这个数据，就需要 3 次才能传输完成，这样的效率非常低。&lt;/p&gt;
&lt;p&gt;这样⼀位⼀位传输的方式，称为串行，下⼀个 bit 必须等待上⼀个 bit 传输完成才能进行传输。当然，想⼀次多传⼀些数据，增加线路即可，这时数据就可以并行传输。
为了避免低效率的串行传输的⽅式，线路的位宽最好⼀次就能访问到所有的内存地址。 CPU 要想操作的内存地址就需要地址总线，如果地址总线只有 1 条，那每次只能表示 「0 或 1」这两种情况，所以 CPU ⼀次只能操作 2 个内存地址，如果想要 CPU 操作 4G 的内存，那么就需要 32 条地址总线，因为 2 ^ 32 =4G 。&lt;/p&gt;
&lt;p&gt;知道了线路位宽的意义后，我们再来看看 CPU 位宽。&lt;/p&gt;
&lt;p&gt;CPU 的位宽最好不要小于线路位宽，比如 32 位 CPU 控制 40 位宽的地址总线和数据总线的话，工作起来就会非常复杂且麻烦，所以 32 位的 CPU 最好和 32 位宽的线路搭配，因为 32 位 CPU ⼀次最多只能操作32 位宽的地址总线和数据总线。&lt;/p&gt;
&lt;p&gt;但是并不代表 64 位 CPU 性能比32 位 CPU 高很多，很少应用需要算超过 32 位的数字，所以如果计算的数额不超过 32 位数字的情况下，32 位和 64 位 CPU 之间没什么区别的，只有当计算超过 32 位数字的情况下，64 位的优势才能体现出来。&lt;/p&gt;
&lt;p&gt;另外，32 位 CPU 最大只能操作 4GB 内存，就算你装了 8 GB 内存条，也没用。而 64 位 CPU 寻址范围则很大，理论最大的寻址空间为 2^64 。&lt;/p&gt;
&lt;h2 id=&#34;存储器的层次&#34;&gt;存储器的层次&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F01-%E7%A1%AC%E4%BB%B6%E5%8E%9F%E7%90%86/image-20220719153300329.png&#34;
	width=&#34;1007&#34;
	height=&#34;485&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F01-%E7%A1%AC%E4%BB%B6%E5%8E%9F%E7%90%86/image-20220719153300329_hu8bb09d7dcf0aa5190db316bc507ae8b8_62691_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F01-%E7%A1%AC%E4%BB%B6%E5%8E%9F%E7%90%86/image-20220719153300329_hu8bb09d7dcf0aa5190db316bc507ae8b8_62691_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;存储金字塔&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;207&#34;
		data-flex-basis=&#34;498px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;CPU Cache 用的是⼀种叫 SRAM（Static Random-Access Memory，静态随机存储器） 的芯片。SRAM 之所以叫「静态」存储器，是因为只要有电，数据就可以保持存在，而⼀旦断电，数据就会丢失了。&lt;/p&gt;
&lt;p&gt;在 SRAM 里面，⼀个 bit 的数据，通常需要 6 个晶体管，所以 SRAM 的存储密度不高，同样的物理空间下，能存储的数据是有限的，不过也因为 SRAM 的电路简单，所以访问速度非常快。&lt;/p&gt;
&lt;p&gt;内存用的芯片和 CPU Cache 有所不同，它使用的是⼀种叫作 DRAM （Dynamic Random AccessMemory，动态随机存取存储器） 的芯片。&lt;/p&gt;
&lt;p&gt;相比 SRAM，DRAM 的密度更高，功耗更低，有更大的容量，而且造价比 SRAM 芯片便宜很多。DRAM 存储⼀个 bit 数据，只需要⼀个晶体管和⼀个电容就能存储，但是因为数据会被存储在电容里，电容会不断漏电，所以需要「定时刷新」电容，才能保证数据不会被丢失，这就是 DRAM 之所以被称为「动态」存储器的原因，只有不断刷新，数据才能被存储起来。&lt;/p&gt;
&lt;h2 id=&#34;cache伪共享&#34;&gt;Cache伪共享&lt;/h2&gt;
&lt;p&gt;相邻的数据可能会被两个线程同时访问，这样每个线程都会将这个两个数据加入cache，但是这两个数据又相邻很近，会被记载进同一个cache Line中，这样另一个线程修改一个数据会造成cache的刷新，这样就失去了cache的意义，叫做伪共享。&lt;/p&gt;
&lt;p&gt;避免伪共享：数据对齐，每个cache Line大约为64字节，填充一个不足64字节的数据，就可以独占一个 cache Line。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>网络01-HTTP协议</title>
        <link>https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C01-http%E5%8D%8F%E8%AE%AE/</link>
        <pubDate>Mon, 18 Jul 2022 15:15:33 +0800</pubDate>
        
        <guid>https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C01-http%E5%8D%8F%E8%AE%AE/</guid>
        <description>&lt;h2 id=&#34;状态码&#34;&gt;状态码&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C01-http%E5%8D%8F%E8%AE%AE/HTTP%E7%8A%B6%E6%80%81%E7%A0%81.png&#34;
	width=&#34;913&#34;
	height=&#34;456&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C01-http%E5%8D%8F%E8%AE%AE/HTTP%E7%8A%B6%E6%80%81%E7%A0%81_hue8d9df02a05fa4118ed1a59593f7ba78_201118_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C01-http%E5%8D%8F%E8%AE%AE/HTTP%E7%8A%B6%E6%80%81%E7%A0%81_hue8d9df02a05fa4118ed1a59593f7ba78_201118_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;HTTP状态码&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;200&#34;
		data-flex-basis=&#34;480px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;1xx&#34;&gt;1xx&lt;/h3&gt;
&lt;p&gt;1xx 类状态码属于提示信息，是协议处理中的⼀种中间状态，实际用到的比较少。&lt;/p&gt;
&lt;h3 id=&#34;2xx&#34;&gt;2xx&lt;/h3&gt;
&lt;p&gt;2xx 类状态码表示服务器成功处理了客户端的请求，也是我们最愿意看到的状态。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;200 OK：是最常⻅的成功状态码，表示⼀切正常。如果是⾮ HEAD 请求，服务器返回的响应头都会有 body数据。&lt;/li&gt;
&lt;li&gt;204 No Content：也是常⻅的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。&lt;/li&gt;
&lt;li&gt;206 Partial Content：是应用于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，⽽是其中的⼀部分，也是服务器处理成功的状态。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;3xx&#34;&gt;3xx&lt;/h3&gt;
&lt;p&gt;3xx 类状态码表示客户端请求的资源发送了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是重定向。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;301 Moved Permanently：表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。&lt;/li&gt;
&lt;li&gt;302 Found：表示临时重定向，说明请求的资源还在，但暂时需要用另⼀个 URL 来访问。301 和 302 都会在响应头⾥使用字段 Location ，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。&lt;/li&gt;
&lt;li&gt;304 Not Modified：不具有跳转的含义，表示资源未修改，重定向已存在的缓冲⽂件，也称缓存重定向，用于缓存控制。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;4xx&#34;&gt;4xx&lt;/h3&gt;
&lt;p&gt;4xx 类状态码表示客户端发送的报⽂有误，服务器无法处理，也就是错误码的含义。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;400 Bad Request：表示客户端请求的报⽂有错误，但只是个笼统的错误。&lt;/li&gt;
&lt;li&gt;403 Forbidden：表示服务器禁⽌访问资源，并不是客户端的请求出错。&lt;/li&gt;
&lt;li&gt;404 Not Found：表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;5xx&#34;&gt;5xx&lt;/h3&gt;
&lt;p&gt;5xx 类状态码表示客户端请求报⽂正确，但是服务器处理时内部发生了错误，属于服务器端的错误码。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;500 Internal Server Error：与 400 类型，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。&lt;/li&gt;
&lt;li&gt;501 Not Implemented：表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。&lt;/li&gt;
&lt;li&gt;502 Bad Gateway：通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。&lt;/li&gt;
&lt;li&gt;503 Service Unavailable：表示服务器当前很忙，暂时无法响应服务器，类似“网络服务正忙，请稍后重试”的意思。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;http常见字段&#34;&gt;HTTP常见字段&lt;/h2&gt;
&lt;p&gt;Host：客户端发送请求时，用来指定服务器的域名&lt;/p&gt;
&lt;p&gt;Content-Length：服务器在返回数据时，表明本次回应的数据长度。&lt;/p&gt;
&lt;p&gt;Connection：Connection 字段最常用于客户端要求服务器使用 TCP 持久连接，以便其他请求复用。HTTP/1.1 版本的默认连接都是持久连接，但为了兼容老版本的 HTTP，需要指定 Connection ⾸部字段的值为Keep-Alive 。⼀个可以复用的 TCP 连接就建⽴了，直到客户端或服务器主动关闭连接。但是，这不是标准字段&lt;/p&gt;
&lt;p&gt;Content-Type：用于服务器回应时，告诉客户端，本次数据是什么格式。&lt;/p&gt;
&lt;p&gt;Content-Encoding：说明数据的压缩方法。表示服务器返回的数据使用了什么压缩格式；客户端在请求时，用 Accept-Encoding 字段说明自⼰可以接受哪些压缩方法。&lt;/p&gt;
&lt;h2 id=&#34;get-与-post&#34;&gt;GET 与 POST&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;GET 是安全且幂等的，因为他是只读操作，无论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。&lt;/li&gt;
&lt;li&gt;POST 因为是新增或提交数据的操作，会修改服务器上的资源，所以是不安全的，且多次提交就会创建多个资源，所以不是幂等的&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;http-与-https&#34;&gt;HTTP 与 HTTPS&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;HTTP 是超⽂本传输协议，信息是明文传输，存在安全⻛险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。&lt;/li&gt;
&lt;li&gt;HTTP 连接建立相对简单， TCP 三次握手之后便可进⾏ HTTP 的报⽂传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。&lt;/li&gt;
&lt;li&gt;HTTP 的端口号是 80，HTTPS 的端口号是 443。&lt;/li&gt;
&lt;li&gt;HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;消息摘要消息认证码与数字签名的区别&#34;&gt;消息摘要、消息认证码与数字签名的区别&lt;/h2&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.51cto.com/u_3078781/3292004&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;加解密算法+消息摘要+消息认证技术+数字签名+公钥证书_&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;ssltls握手&#34;&gt;SSL/TLS握手&lt;/h2&gt;
&lt;p&gt;SSL/TLS 协议建⽴的详细流程：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;ClientHello：首先，由客户端向服务器发起加密通信请求，也就是 ClientHello 请求。在这⼀步，客户端主要向服务器发送以下信息：
&lt;ul&gt;
&lt;li&gt;客户端支持的 SSL/TLS 协议版本，如 TLS 1.2 版本。&lt;/li&gt;
&lt;li&gt;客户端生产的随机数（ Client Random ），后面用于生产「会话秘钥」。&lt;/li&gt;
&lt;li&gt;客户端⽀持的密码套件列表，如 RSA 加密算法。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;SeverHello：服务器收到客户端请求后，向客户端发出响应，也就是 SeverHello 。服务器回应的内容有如下内容：
&lt;ul&gt;
&lt;li&gt;确认 SSL/ TLS 协议版本，如果浏览器不支持，则关闭加密通信。&lt;/li&gt;
&lt;li&gt;服务器生产的随机数（ Server Random ），后面用于生产「会话秘钥」。&lt;/li&gt;
&lt;li&gt;确认的密码套件列表，如 RSA 加密算法。&lt;/li&gt;
&lt;li&gt;服务器的数字证书。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;客户端回应：客户端收到服务器的回应之后，⾸先通过浏览器或者操作系统中的 CA 公钥，确认服务器的数字证书的真实性。如果证书没有问题，客户端会从数字证书中取出服务器的公钥，然后使用它加密报文，向服务器发送如下信息：
&lt;ul&gt;
&lt;li&gt;⼀个随机数（ pre-master key ）。该随机数会被服务器公钥加密。&lt;/li&gt;
&lt;li&gt;加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。&lt;/li&gt;
&lt;li&gt;客户端握手结束通知，表示客户端的握手阶段已经结束。这⼀项同时把之前所有内容的发生的数据做个摘要，用来供服务端校验。上面第⼀项的随机数是整个握手阶段的第三个随机数，这样服务器和客户端就同时有三个随机数，接着就用双方协商的加密算法，各自生成本次通信的「会话秘钥」。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;服务器的最后回应：服务器收到客户端的第三个随机数（ pre-master key ）之后，通过协商的加密算法，计算出本次通信的「会话秘钥」。然后，向客户端发出最后的信息：
&lt;ul&gt;
&lt;li&gt;加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。&lt;/li&gt;
&lt;li&gt;服务器握手结束通知，表示服务器的握手阶段已经结束。这⼀项同时把之前所有内容的发生的数据做个摘要，用来供客户端校验。&lt;/li&gt;
&lt;li&gt;至此，整个 SSL/TLS 的握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的 HTTP协议，只不过用「会话秘钥」加密内容。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C01-http%E5%8D%8F%E8%AE%AE/image-20220718225002147.png&#34;
	width=&#34;1545&#34;
	height=&#34;2807&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C01-http%E5%8D%8F%E8%AE%AE/image-20220718225002147_hu51dd03d806d8dfdbf68b6d43e682b388_1055339_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C01-http%E5%8D%8F%E8%AE%AE/image-20220718225002147_hu51dd03d806d8dfdbf68b6d43e682b388_1055339_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;SSL/TSL握手&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;55&#34;
		data-flex-basis=&#34;132px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;http10http11http2http3演变&#34;&gt;HTTP/1.0、HTTP/1.1、HTTP/2、HTTP/3演变&lt;/h2&gt;
&lt;h3 id=&#34;http11-相比-http10-的改进&#34;&gt;HTTP/1.1 相比 HTTP/1.0 的改进&lt;/h3&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://javaguide.cn/cs-basics/network/http1.0&amp;amp;http1.1.html#%e5%93%8d%e5%ba%94%e7%8a%b6%e6%80%81%e7%a0%81&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;HTTP 1.0 vs HTTP 1.1（应用层） | JavaGuide&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;连接方式&lt;/strong&gt; : HTTP 1.0 为短连接，HTTP 1.1 支持长连接。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;状态响应码&lt;/strong&gt; : HTTP/1.1中新加入了大量的状态码，光是错误响应状态码就新增了24种。比如说，&lt;code&gt;100 (Continue)&lt;/code&gt;——在请求大资源前的预热请求，&lt;code&gt;206 (Partial Content)&lt;/code&gt;——范围请求的标识码，&lt;code&gt;409 (Conflict)&lt;/code&gt;——请求与当前资源的规定冲突，&lt;code&gt;410 (Gone)&lt;/code&gt;——资源已被永久转移，而且没有任何已知的转发地址。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;缓存处理&lt;/strong&gt; : 在 HTTP1.0 中主要使用 header 里的 If-Modified-Since,Expires 来做为缓存判断的标准，HTTP1.1 则引入了更多的缓存控制策略例如 Entity tag，If-Unmodified-Since, If-Match, If-None-Match 等更多可供选择的缓存头来控制缓存策略。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;带宽优化及网络连接的使用&lt;/strong&gt; :HTTP1.0 中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1 则在请求头引入了 range 头域，它允许只请求资源的某个部分，即返回码是 206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Host头处理&lt;/strong&gt; : HTTP/1.1在请求头中加入了&lt;code&gt;Host&lt;/code&gt;字段。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;使用TCP 长连接的方式改善了 HTTP/1.0  短链接造成的性能开销&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;支持管道网络传输，只要第一个请求发出去了，不必等期回来，就可以发第二个请求出去，可以减少整体的响应时间&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;http2-针对-http11-优化&#34;&gt;HTTP/2 针对 HTTP/1.1 优化&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;头部压缩，如果同时发出多个请求，他们的头是一样的或是相似的，那么下一会帮你消除重复部分。这就是 &lt;code&gt;HPACK&lt;/code&gt; 算法：客户端和服务端同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后不发送同样字段了，只发送索引号，这样就提高速度。&lt;/li&gt;
&lt;li&gt;HTTP/2 不再像 HTTP/1.1 里的纯文本形式的报文，而是全面采用了二进制格式，头和数据体都是二进制。收到报文后无需再将铭文的报文转成二进制，而是直接解析二进制报文，这增加了数据传输的效率。&lt;/li&gt;
&lt;li&gt;数据流：&lt;strong&gt;HTTP/2 的数据包不是按顺序发送的，同⼀个连接⾥⾯连续的数据包，可能属于不同的回应&lt;/strong&gt;。因此，必须要对数据包做标记，指出它属于哪个回应。每个请求或回应的所有数据包，称为⼀个数据流（ Stream ）。每个数据流都标记着⼀个独一无二的编号，其中规定客户端发出的数据流编号为奇数， 服务器发出的数据流编号为偶数。&lt;/li&gt;
&lt;li&gt;多路复用：HTTP/2 是可以在⼀个连接中并发多个请求或回应，而不用按照顺序⼀⼀对应。移除了 HTTP/1.1 中的串⾏请求，不需要排队等待，也就不会再出现「队头阻塞」问题，降低了延迟，⼤幅度提高了连接的利⽤率。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;http3&#34;&gt;HTTP/3&lt;/h3&gt;
&lt;p&gt;HTTP/2 主要的问题在于，多个 HTTP 请求在复⽤⼀个 TCP 连接，下层的 TCP 协议是不知道有多少个 HTTP 请求的。所以⼀旦发生了丢包现象，就会触发 TCP 的重传机制，这样在⼀个 TCP 连接中的所有的 HTTP 请求都必须等待这个丢了的包被重传回来。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;HTTP/1.1 中的管道（ pipeline）传输中如果有⼀个请求阻塞了，那么队列后请求也统统被阻塞住了&lt;/li&gt;
&lt;li&gt;HTTP/2 多个请求复用⼀个TCP连接，⼀旦发生丢包，就会阻塞住所有的 HTTP 请求。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这都是基于 TCP 传输层的问题，所以 HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP！&lt;/p&gt;
&lt;p&gt;UDP 是不可靠传输的，但基于 UDP 的 QUIC 协议 可以实现类似 TCP 的可靠性传输。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;QUIC 有自己的⼀套机制可以保证传输的可靠性的。当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响。&lt;/li&gt;
&lt;li&gt;TLS3 升级成了最新的 1.3 版本，头部压缩算法也升级成了 QPack 。&lt;/li&gt;
&lt;li&gt;HTTPS 要建⽴⼀个连接，要花费 6 次交互，先是建⽴三次握⼿，然后是 TLS/1.3 的三次握⼿。QUIC 直接把以往的 TCP 和 TLS/1.3 的 6 次交互合并成了 3 次，减少了交互次数。&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>网络02-TCP协议</title>
        <link>https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/</link>
        <pubDate>Mon, 18 Jul 2022 00:04:43 +0800</pubDate>
        
        <guid>https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/</guid>
        <description>&lt;h2 id=&#34;什么是tcp&#34;&gt;什么是TCP&lt;/h2&gt;
&lt;p&gt;IP 层是「不可靠」的，它不保证网络包的交付、不保证网络包的按序交付、也不保证网络包中的数据的完整性。&lt;/p&gt;
&lt;p&gt;如果需要保障网络数据包的可靠性，那么就需要由上层（传输层）的 TCP 协议来负责。因为 TCP 是⼀个⼯作在传输层的可靠数据传输的服务，它能确保接收端接收的网络包是无损坏、无间隔、非冗余和按序的。&lt;/p&gt;
&lt;p&gt;TCP 是面向连接的、可靠的、基于字节流的传输层通信协议。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;面向连接：⼀定是「⼀对⼀」才能连接，不能像 UDP 协议可以⼀个主机同时向多个主机发送消息，也就是⼀对多是无法做到的；&lt;/li&gt;
&lt;li&gt;可靠的：无论的网络链路中出现了怎样的链路变化，TCP 都可以保证⼀个报文⼀定能够到达接收端；&lt;/li&gt;
&lt;li&gt;字节流：消息是「没有边界」的，所以无论我们消息有多大都可以进⾏传输。并且消息是「有序的」，当「前⼀个」消息没有收到的时候，即使它先收到了后面的字节，那么也不能扔给应用层去处理，同时对「重复」的报文会⾃动丢弃。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;TCP 四元组可以唯⼀的确定⼀个连接，四元组包括如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;源地址&lt;/li&gt;
&lt;li&gt;源端口&lt;/li&gt;
&lt;li&gt;目的地址&lt;/li&gt;
&lt;li&gt;目的端口&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718202454871.png&#34;
	width=&#34;821&#34;
	height=&#34;228&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718202454871_hu5382c26f3f67254d930af289186624bc_24142_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718202454871_hu5382c26f3f67254d930af289186624bc_24142_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;TCP四元组&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;360&#34;
		data-flex-basis=&#34;864px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;源地址和⽬的地址的字段（32位）是在 &lt;strong&gt;IP 头部&lt;/strong&gt; 中，作用是通过 IP 协议发送报文给对方主机。&lt;/p&gt;
&lt;p&gt;源端口和⽬的端口的字段（16位）是在 &lt;strong&gt;TCP 头部&lt;/strong&gt; 中，作用是告诉 TCP 协议应该把报文发给哪个进程。&lt;/p&gt;
&lt;h2 id=&#34;什么是tcp连接&#34;&gt;什么是TCP连接&lt;/h2&gt;
&lt;p&gt;简单来说就是，用于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，包括Socket、序列号和窗口大小称为连接。&lt;/p&gt;
&lt;p&gt;所以我们可以知道，建⽴⼀个 TCP 连接是需要客户端与服务器端达成上述三个信息的共识。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Socket：由 IP 地址和端口号组成&lt;/li&gt;
&lt;li&gt;序列号：用来解决乱序问题等&lt;/li&gt;
&lt;li&gt;窗口大小：用来做流量控制&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tcp-格式&#34;&gt;TCP 格式&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718201052747.png&#34;
	width=&#34;1053&#34;
	height=&#34;828&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718201052747_hu143c1bfee3267be99575a2a0ea300bb4_85927_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718201052747_hu143c1bfee3267be99575a2a0ea300bb4_85927_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;TCP头部格式&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;127&#34;
		data-flex-basis=&#34;305px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;序列号：在建⽴连接时由计算机生成的随机数作为其初始值，通过 SYN 包传给接收端主机，每发送⼀次数据，就「累加」⼀次该「数据字节数」的大小。用来解决网络包乱序问题。&lt;/p&gt;
&lt;p&gt;确认应答号：指下⼀次「期望」收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。用来解决不丢包的问题。&lt;/p&gt;
&lt;p&gt;控制位：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ACK：该位为 1 时，「确认应答」的字段变为有效，TCP 规定除了最初建⽴连接时的 SYN 包之外该位必须设置为 1 。&lt;/li&gt;
&lt;li&gt;RST：该位为 1 时，表示 TCP 连接中出现异常必须强制断开连接。&lt;/li&gt;
&lt;li&gt;SYN：该位为 1 时，表示希望建⽴连接，并在其「序列号」的字段进⾏序列号初始值的设定。&lt;/li&gt;
&lt;li&gt;FIN：该位为 1 时，表示今后不会再有数据发送，希望断开连接。当通信结束希望断开连接时，通信双方的主机之间就可以相互交换 FIN 位为 1 的 TCP 段。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tcp-和-udp-区别&#34;&gt;TCP 和 UDP 区别&lt;/h2&gt;
&lt;p&gt;UDP 不提供复杂的控制机制，利用 IP 提供面向「无连接」的通信服务。UDP 协议真的非常简，头部只有 8 个字节（ 64 位），UDP 的头部格式如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718203033417.png&#34;
	width=&#34;783&#34;
	height=&#34;468&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718203033417_hub871f519644e7be8a66c647c49d6b24b_35126_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718203033417_hub871f519644e7be8a66c647c49d6b24b_35126_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;UDP头部&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;167&#34;
		data-flex-basis=&#34;401px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;⽬标和源端口：主要是告诉 UDP 协议应该把报文发给哪个进程。&lt;/li&gt;
&lt;li&gt;包长度：该字段保存了 UDP 首部的长度跟数据的长度之和。&lt;/li&gt;
&lt;li&gt;校验和：校验和是为了提供可靠的 UDP 首部和数据而设计。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;区别&#34;&gt;区别&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;连接：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;TCP 是面向连接的传输层协议，传输数据前先要建⽴连接。&lt;/li&gt;
&lt;li&gt;UDP 是不需要连接，即刻传输数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;服务对象&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;TCP 是⼀对⼀的两点服务，即⼀条连接只有两个端点。&lt;/li&gt;
&lt;li&gt;UDP ⽀持⼀对⼀、⼀对多、多对多的交互通信&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;可靠性&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按需到达。&lt;/li&gt;
&lt;li&gt;UDP 是尽最大努⼒交付，不保证可靠交付数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;拥塞控制、流量控制&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。&lt;/li&gt;
&lt;li&gt;UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;首部开销&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;TCP 首部长度较长，会有⼀定的开销，首部在没有使用「选项」字段时是 20 个字节，如果使用了「选项」字段则会变长的。&lt;/li&gt;
&lt;li&gt;UDP 首部只有 8 个字节，并且是固定不变的，开销较小。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;传输方式&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;TCP 是流式传输，没有边界，但保证顺序和可靠。&lt;/li&gt;
&lt;li&gt;UDP 是⼀个包⼀个包的发送，是有边界的，但可能会丢包和乱序。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;分片不同&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;TCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP数据包，如果中途丢失了⼀个分片，只需要传输丢失的这个分片。&lt;/li&gt;
&lt;li&gt;UDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层，但是如果中途丢了⼀个分片，在实现可靠传输的 UDP 时则就需要重传所有的数据包，这样传输效率非常差，所以通常 UDP 的报文应该小于 MTU。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;tcp-和-udp-应用场景&#34;&gt;TCP 和 UDP 应用场景：&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;FTP 文件传输&lt;/li&gt;
&lt;li&gt;HTTP / HTTPS&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由于 UDP 面向无连接，它可以随时发送数据，再加上UDP本身的处理既简单又高效，因此经常用于：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;包总量较少的通信，如 DNS 、 SNMP 等&lt;/li&gt;
&lt;li&gt;视频、音频等多媒体通信&lt;/li&gt;
&lt;li&gt;广播通信&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;为什么 UDP 头部没有「首部长度」字段，而TCP 头部有「首部长度」字段呢？&lt;/p&gt;
&lt;p&gt;原因是 TCP 有可变长的「选项」字段，而UDP 头部长度则是不会变化的，无需多⼀个字段去记录 UDP 的首部长度。&lt;/p&gt;
&lt;p&gt;为什么 UDP 头部有「包长度」字段，而 TCP 头部则没有「包长度」字段呢？&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718205054689.png&#34;
	width=&#34;1007&#34;
	height=&#34;62&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718205054689_hua2ef8e70df4b2dd128cdf2480b61936e_18068_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718205054689_hua2ef8e70df4b2dd128cdf2480b61936e_18068_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;TCP数据长度计算公式&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;1624&#34;
		data-flex-basis=&#34;3898px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;其中 IP 总长度 和 IP 首部长度，在 IP 首部格式是已知的。TCP 首部长度，则是在 TCP 首部格式已知的，所以就可以求得 TCP 数据的长度。&lt;/p&gt;
&lt;p&gt;因为为了网络设备硬件设计和处理方便，首部长度需要是 4 字节的整数倍。&lt;/p&gt;
&lt;h2 id=&#34;tcp连接&#34;&gt;TCP连接&lt;/h2&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/qzcsu/article/details/72861891&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;两张动图-彻底明白TCP的三次握手与四次挥手&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718205302134.png&#34;
	width=&#34;813&#34;
	height=&#34;678&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718205302134_hu11f676b8277e0c8c3fcdd8bc60b2f4ee_63124_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718205302134_hu11f676b8277e0c8c3fcdd8bc60b2f4ee_63124_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;三次握手&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;119&#34;
		data-flex-basis=&#34;287px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;⼀开始，客户端和服务端都处于 CLOSED 状态。先是服务端主动监听某个端口，处于 LISTEN 状态&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718205347523.png&#34;
	width=&#34;1173&#34;
	height=&#34;708&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718205347523_huce689b0c8b97dd2dfea4e38658c95ca7_109592_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718205347523_huce689b0c8b97dd2dfea4e38658c95ca7_109592_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;三次握手-1&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;165&#34;
		data-flex-basis=&#34;397px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;客户端会随机初始化序号（ client_isn ），将此序号置于 TCP 首部的「序号」字段中，同时把 SYN 标志位置为 1 ，表示 SYN 报文。接着把第⼀个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于 SYN-SENT 状态。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718205410356.png&#34;
	width=&#34;1188&#34;
	height=&#34;708&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718205410356_hu4cc1a77cd489dbcd6ce93358ba072968_134235_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718205410356_hu4cc1a77cd489dbcd6ce93358ba072968_134235_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;三次握手-2&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;167&#34;
		data-flex-basis=&#34;402px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;服务端收到客户端的 SYN 报文后，首先服务端也随机初始化⾃⼰的序号（ server_isn ），将此序号填入TCP 首部的「序号」字段中，其次把 TCP 首部的「确认应答号」字段填入 client_isn + 1 , 接着把 SYN和 ACK 标志位置为 1 。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 SYN-RCVD 状态。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718205435389.png&#34;
	width=&#34;1188&#34;
	height=&#34;708&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718205435389_huf2b5cad342f679d42319469f44c59b63_114934_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718205435389_huf2b5cad342f679d42319469f44c59b63_114934_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;三次握手-3&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;167&#34;
		data-flex-basis=&#34;402px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;客户端收到服务端报文后，还要向服务端回应最后⼀个应答报文，首先该应答报文 TCP 首部 ACK 标志位置为 1 ，其次「确认应答号」字段填入 server_isn + 1 ，最后把报文发送给服务端，这次报文可以携带客户到服务器的数据，之后客户端处于 ESTABLISHED 状态。&lt;/li&gt;
&lt;li&gt;服务器收到客户端的应答报文后，也进入 ESTABLISHED 状态。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;如何在-linux-系统中查看-tcp-状态&#34;&gt;如何在 Linux 系统中查看 TCP 状态？&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;netstat -napt&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718210055179.png&#34;
	width=&#34;1563&#34;
	height=&#34;327&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718210055179_hu1cd9efad8a5ad1fba906c8b4f73860e1_54379_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718210055179_hu1cd9efad8a5ad1fba906c8b4f73860e1_54379_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;netstat命令&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;477&#34;
		data-flex-basis=&#34;1147px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;为什么是三次握手不是两次四次&#34;&gt;为什么是三次握手？不是两次、四次？&lt;/h3&gt;
&lt;p&gt;以三个方面分析三次握手的原因&lt;/p&gt;
&lt;h4 id=&#34;三次握手才可以阻止重复历史连接的初始化-避免资源浪费主要原因&#34;&gt;三次握手才可以阻止重复历史连接的初始化 避免资源浪费（主要原因）&lt;/h4&gt;
&lt;p&gt;如果只有「两次握手」，当客户端的 SYN 请求连接在网络中阻塞，客户端没有接收到 ACK 报文，就会重新发送 SYN ，由于没有第三次握手，服务器不清楚客户端是否收到了自己发送的建⽴连接的 ACK 确认信号，所以每收到⼀个 SYN 就只能先主动建立⼀个连接，这会造成什么情况呢？&lt;/p&gt;
&lt;p&gt;如果客户端的 SYN 阻塞了，重复发送多次 SYN 报文，那么服务器在收到请求后就会建立多个冗余的无效链接，造成不必要的资源浪费。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;⼀个「旧 SYN 报文」比「最新的 SYN 」 报文早到达了服务端；&lt;/li&gt;
&lt;li&gt;那么此时服务端就会回⼀个 SYN + ACK 报文给客户端；&lt;/li&gt;
&lt;li&gt;客户端收到后可以根据自身的上下文，判断这是⼀个历史连接（序列号过期或超时），那么客户端就会发送RST 报文给服务端，表示中止这⼀次连接。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;三次握手才可以同步双方的初始序列号&#34;&gt;三次握手才可以同步双方的初始序列号&lt;/h4&gt;
&lt;p&gt;互相发送序列号并互相得到对方的确认，至少需要三次握手。如果两次握手那么服务端无法得到客户端的确认信息。&lt;/p&gt;
&lt;h2 id=&#34;tcp连接断开&#34;&gt;TCP连接断开&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718213708230.png&#34;
	width=&#34;753&#34;
	height=&#34;794&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718213708230_hu59227d121b74d6a5ef23fdc8d02accce_67564_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718213708230_hu59227d121b74d6a5ef23fdc8d02accce_67564_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;四次挥手&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;94&#34;
		data-flex-basis=&#34;227px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;客户端打算关闭连接，此时会发送⼀个 TCP 首部 FIN 标志位被置为 1 的报文，也即 FIN 报文，之后客户端进入 FIN_WAIT_1 状态。&lt;/li&gt;
&lt;li&gt;服务端收到该报文后，就向客户端发送 ACK 应答报文，接着服务端进入 CLOSED_WAIT 状态。&lt;/li&gt;
&lt;li&gt;客户端收到服务端的 ACK 应答报文后，之后进入 FIN_WAIT_2 状态。&lt;/li&gt;
&lt;li&gt;等待服务端处理完数据后，也向客户端发送 FIN 报文，之后服务端进入 LAST_ACK 状态。&lt;/li&gt;
&lt;li&gt;客户端收到服务端的 FIN 报文后，回⼀个 ACK 应答报文，之后进入 TIME_WAIT 状态&lt;/li&gt;
&lt;li&gt;服务器收到了 ACK 应答报文后，就进入了 CLOSED 状态，⾄此服务端已经完成连接的关闭。&lt;/li&gt;
&lt;li&gt;客户端在经过 2MSL ⼀段时间后，⾃动进入 CLOSED 状态，⾄此客户端也完成连接的关闭。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;每个方向都需要⼀个 FIN 和⼀个 ACK，因此通常被称为四次挥手。这⾥⼀点需要注意是：主动关闭连接的，才有 TIME_WAIT 状态。&lt;/p&gt;
&lt;h3 id=&#34;为什么需要四次挥手&#34;&gt;为什么需要四次挥手&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;关闭连接时，客户端向服务端发送 FIN 时，仅仅表示客户端不再发送数据了但是还能接收数据。&lt;/li&gt;
&lt;li&gt;服务器收到客户端的 FIN 报文时，先回⼀个 ACK 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 FIN 报文给客户端来表示同意现在关闭连接。&lt;/li&gt;
&lt;li&gt;从上面过程可知，服务端通常需要等待完成数据的发送和处理，所以服务端的 ACK 和 FIN ⼀般都会分开发送，从而比三次握手导致多了⼀次。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;为什么-time_wait-等待的时间是-2msl&#34;&gt;为什么 TIME_WAIT 等待的时间是 2MSL？&lt;/h3&gt;
&lt;p&gt;MSL 是 Maximum Segment Lifetime，报文最大生存时间，它是任何报文在网络上存在的最⻓时间，超过这个时间报文将被丢弃。因为 TCP 报文基于是 IP 协议的，而 IP 头中有⼀个 TTL 字段，是 IP 数据报可以经过的最大路由数，每经过⼀个处理他的路由器此值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。&lt;/p&gt;
&lt;p&gt;MSL 与 TTL 的区别： MSL 的单位是时间，而 TTL 是经过路由跳数。所以 MSL 应该要大于等于 TTL 消耗为 0 的时间，以确保报文已被⾃然消亡。TIME_WAIT 等待 2 倍的 MSL，比较合理的解释是： 网络中可能存在来⾃发送方的数据包，当这些发送方的数据包被接收方处理后⼜会向对方发送响应，所以⼀来⼀回需要等待 2倍的时间。&lt;/p&gt;
&lt;p&gt;比如如果被动关闭方没有收到断开连接的最后的 ACK 报文，就会触发超时重发 Fin 报文，另⼀方接收到 FIN 后，会重发 ACK 给被动关闭方， ⼀来⼀去正好 2 个MSL。&lt;/p&gt;
&lt;p&gt;2MSL 的时间是从客户端接收到 FIN 后发送 ACK 开始计时的。如果在 TIME-WAIT 时间内，因为客户端的 ACK没有传输到服务端，客户端⼜接收到了服务端重发的 FIN 报文，那么 2MSL 时间将重新计时。&lt;/p&gt;
&lt;p&gt;在 Linux 系统⾥ 2MSL 默认是 60 秒，那么⼀个 MSL 也就是 30 秒。Linux 系统停留在 TIME_WAIT 的时间为固定的 60 秒。&lt;/p&gt;
&lt;h3 id=&#34;为什么需要-time_wait-状态&#34;&gt;为什么需要 TIME_WAIT 状态？&lt;/h3&gt;
&lt;h4 id=&#34;防止旧连接的数据包&#34;&gt;防止旧连接的数据包&lt;/h4&gt;
&lt;p&gt;经过 2MSL 这个时间，⾜以让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都⾃然消失，再出现的数据包⼀定都是新建⽴连接所产生的。&lt;/p&gt;
&lt;h4 id=&#34;保证连接正确关闭&#34;&gt;保证连接正确关闭&lt;/h4&gt;
&lt;p&gt;TIME-WAIT 作用是等待⾜够的时间以确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭。&lt;/p&gt;
&lt;h3 id=&#34;time_wait-过多有什么危害&#34;&gt;TIME_WAIT 过多有什么危害？&lt;/h3&gt;
&lt;p&gt;过多的 TIME-WAIT 状态主要的危害有两种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;第⼀是内存资源占用；&lt;/li&gt;
&lt;li&gt;第⼆是对端口资源的占用，⼀个 TCP 连接⾄少消耗⼀个本地端口；如果发起连接⼀方的 TIME_WAIT 状态过多，占满了所有端口资源，则会导致无法创建新连接。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;如何优化-time_wait&#34;&gt;如何优化 TIME_WAIT？&lt;/h4&gt;
&lt;p&gt;Linux 内核参数开启后，则可以复用处于 TIME_WAIT 的 socket 为新的连接所用。tcp_tw_reuse 功能只能用客户端（连接发起方），因为开启了该功能，在调用 connect()函数时，内核会随机找⼀个 time_wait 状态超过 1 秒的连接给新的连接复用。&lt;/p&gt;
&lt;h3 id=&#34;tcp保活机制&#34;&gt;TCP保活机制&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;TCP短连接:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;TCP短连接的情况，client向server发起连接请求，server接到请求，然后双方建立连接。client向server发送消息，server回应client，然后一次读写就完成了，这时候双方任何一个都可以发起close操作，不过一般都是client先发起close操作。&lt;/p&gt;
&lt;p&gt;为什么呢，一般的server不会回复完client后立即关闭连接的，当然不排除有特殊的情况。从上面的描述看，短连接一般只会在client/server间传递一次读写操作&lt;/p&gt;
&lt;p&gt;短连接的优点是：管理起来比较简单，存在的连接都是有用的连接，不需要额外的控制手段。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TCP长连接：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;长连接的情况，client向server发起连接，server接受client连接，双方建立连接。Client与server完成一次读写之后，它们之间的连接并不会主动关闭，后续的读写操作会继续使用这个连接。&lt;/p&gt;
&lt;p&gt;首先说一下TCP/IP详解上讲到的TCP保活功能，保活功能主要为服务器应用提供，服务器应用希望知道客户主机是否崩溃，从而可以代表客户使用资源。如果客户已经消失，使得服务器上保留一个半开放的连接，而服务器又在等待来自客户端的数据，则服务器将应远等待客户端的数据，保证功能就是试图在服务器端检测到这种半开放的连接。&lt;/p&gt;
&lt;p&gt;如果一个给定的连接在两小时内没有任何的动作，则服务器就向客户发一个探测报文段，客户主机必须处于以下4个状态之一：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;客户主机依然正常运行，并从服务器可达。客户的TCP响应正常，而服务器也知道对方是正常的，服务器在两小时后将保证定时器复位。&lt;/li&gt;
&lt;li&gt;客户主机已经崩溃，并且关闭或者正在重新启动。在任何一种情况下，客户的TCP都没有响应。服务端将不能收到对探测的响应，并在75秒后超时。服务器总共发送10个这样的探测 ，每个间隔75秒。如果服务器没有收到一个响应，它就认为客户主机已经关闭并终止连接。&lt;/li&gt;
&lt;li&gt;客户主机崩溃并已经重新启动。服务器将收到一个对其保证探测的响应，这个响应是一个复位，使得服务器终止这个连接。&lt;/li&gt;
&lt;li&gt;客户机正常运行，但是服务器不可达，这种情况与2类似，TCP能发现的就是没有收到探查的响应。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;从上面可以看出，TCP保活功能主要为探测长连接的存活状况，不过这里存在一个问题，存活功能的探测周期太长，还有就是它只是探测TCP连接的存活，属于比较斯文的做法，遇到恶意的连接时，保活功能就不够使了。&lt;/p&gt;
&lt;h2 id=&#34;既然-ip-层会分片为什么-tcp-层还需要-mss-呢&#34;&gt;既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718212310101.png&#34;
	width=&#34;1067&#34;
	height=&#34;422&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718212310101_hu1e526c0b4a2f8d3152247bc5add70829_64608_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718212310101_hu1e526c0b4a2f8d3152247bc5add70829_64608_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;MTU和MSS&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;252&#34;
		data-flex-basis=&#34;606px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MTU ：⼀个网络包的最大长度，以太网中⼀般为 1500 字节；&lt;/li&gt;
&lt;li&gt;MSS ：除去 IP 和 TCP 头部之后，⼀个网络包所能容纳的 TCP 数据的最大度；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当 IP 层有⼀个超过 MTU 大小的数据（TCP 头部 + TCP 数据）要发送，那么 IP 层就要进⾏分片，把数据分片成若⼲片，保证每⼀个分片都小于 MTU。把⼀份 IP 数据报进⾏分片以后，由⽬标主机的 IP 层来进⾏重新组装后，再交给上⼀层 TCP 传输层。&lt;/p&gt;
&lt;p&gt;这看起来井然有序，但这存在隐患的，那么当如果⼀个 IP 分片丢失，整个 IP 报文的所有分片都得重传。&lt;/p&gt;
&lt;p&gt;因为 IP 层本身没有超时重传机制，它由传输层的 TCP 来负责超时和重传。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;当接收方发现 TCP 报文（头部 + 数据）的某⼀片丢失后，则不会响应 ACK 给对方，那么发送方的 TCP 在超时后，就会重发「整个 TCP 报文（头部 + 数据）」。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;因此，可以得知由 IP 层进⾏分片传输，是非常没有效率的。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;所以，为了达到最佳的传输效能 TCP 协议在建⽴连接的时候通常要协商双方的 MSS 值，当 TCP 层发现数据超过MSS 时，则就先会进⾏分片，当然由它形成的 IP 包的⻓度也就不会大于 MTU ，⾃然也就不用 IP 分片了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;经过 TCP 层分片后，如果⼀个 TCP 分片丢失后，进⾏重发时也是以 MSS 为单位，而不用重传所有的分片，大大增加了重传的效率。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;什么是-syn-攻击如何避免-syn-攻击&#34;&gt;什么是 SYN 攻击？如何避免 SYN 攻击？&lt;/h2&gt;
&lt;h3 id=&#34;syn攻击&#34;&gt;SYN攻击&lt;/h3&gt;
&lt;p&gt;我们都知道 TCP 连接建⽴是需要三次握手，假设攻击者短时间伪造不同 IP 地址的 SYN 报文，服务端每接收到⼀个 SYN 报文，就进入 SYN_RCVD 状态，但服务端发送出去的 ACK + SYN 报文，无法得到未知 IP 主机的ACK 应答，久而久之就会占满服务端的 SYN 接收队列（未连接队列），使得服务器不能为正常用户服务。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718212721706.png&#34;
	width=&#34;500&#34;
	height=&#34;348&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718212721706_hue4f8755de0cf2894d775595508aba5a7_101239_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718212721706_hue4f8755de0cf2894d775595508aba5a7_101239_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;SYN攻击&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;143&#34;
		data-flex-basis=&#34;344px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;解决方法&#34;&gt;解决方法&lt;/h3&gt;
&lt;p&gt;方法一：&lt;/p&gt;
&lt;p&gt;其中⼀种解决方式是通过修改 Linux 内核参数，控制队列大小和当队列满时应做什么处理。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;当网卡接收数据包的速度大于内核处理的速度时，会有⼀个队列保存这些数据包。控制该队列的最大值如下参数：&lt;code&gt;net.core.netdev_max_backlog&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;SYN_RCVD 状态连接的最大个数：&lt;code&gt;net.ipv4.tcp_max_syn_backlog&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;超出处理能时，对新的 SYN 直接回报 RST，丢弃连接：&lt;code&gt;net.ipv4.tcp_abort_on_overflow&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;方法二：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718212953083.png&#34;
	width=&#34;737&#34;
	height=&#34;519&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718212953083_hu7c65eb8fdeda67b3846fc3fa95f9b0b3_61732_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718212953083_hu7c65eb8fdeda67b3846fc3fa95f9b0b3_61732_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;SYN队列&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;142&#34;
		data-flex-basis=&#34;340px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;当 「 SYN 队列」满之后，后续服务器收到 SYN 包，不进入「 SYN 队列」；&lt;/li&gt;
&lt;li&gt;计算出⼀个 cookie 值，再以 SYN + ACK 中的「序列号」返回客户端，（cookie 的作用是验证之后可能到达的&lt;code&gt;ACK&lt;/code&gt;的有效性，保证这是一次完整的握手获得&lt;code&gt;SYN&lt;/code&gt;报文中携带的&lt;code&gt;TCP&lt;/code&gt;选项信息）&lt;/li&gt;
&lt;li&gt;服务端接收到客户端的应答报文时，服务器会检查这个 ACK 包的合法性。如果合法，直接放入到「 Accept队列」。&lt;/li&gt;
&lt;li&gt;最后应用通过调用 accpet() socket 接口，从「 Accept 队列」取出的连接。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718213041933.png&#34;
	width=&#34;762&#34;
	height=&#34;564&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718213041933_hu09417038a9a317da07526dbff59acc00_73260_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718213041933_hu09417038a9a317da07526dbff59acc00_73260_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;SYN攻击解决&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;135&#34;
		data-flex-basis=&#34;324px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;tcp重传机制&#34;&gt;TCP重传机制&lt;/h2&gt;
&lt;h3 id=&#34;超时重传&#34;&gt;超时重传&lt;/h3&gt;
&lt;p&gt;重传机制的其中⼀个方式，就是在发送数据时，设定⼀个定时器，当超过指定的时间后，没有收到对方的 ACK确认应答报文，就会重发该数据，也就是我们常说的超时重传。
TCP 会在以下两种情况发生超时重传：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;数据包丢失&lt;/li&gt;
&lt;li&gt;确认应答丢失&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;超时时间&#34;&gt;超时时间&lt;/h4&gt;
&lt;p&gt;RTT 就是数据从网络⼀端传送到另⼀端所需的时间，也就是包的往返时间。超时重传时间是以 RTO （Retransmission Timeout 超时重传时间）表示。&lt;/p&gt;
&lt;p&gt;超时重传时间 RTO 的值应该略大于报文往返 RTT 的值。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;当超时时间 RTO 较大时，重发就慢，丢了老半天才重发，没有效率，性能差；&lt;/li&gt;
&lt;li&gt;当超时时间 RTO 较小时，会导致可能并没有丢就重发，于是重发的就快，会增加网络拥塞，导致更多的超时，更多的超时导致更多的重发。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;快速重传&#34;&gt;快速重传&lt;/h3&gt;
&lt;p&gt;TCP 还有另外⼀种快速重传（Fast Retransmit）机制，它不以时间为驱动，而是以数据驱动重传&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718220814102.png&#34;
	width=&#34;647&#34;
	height=&#34;602&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718220814102_hu6e48694c64f8a588a8190d7e30d521e5_53429_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/image-20220718220814102_hu6e48694c64f8a588a8190d7e30d521e5_53429_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;快速重传&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;107&#34;
		data-flex-basis=&#34;257px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;快速重传的⼯作方式是当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。&lt;/p&gt;
&lt;p&gt;快速重传机制只解决了⼀个问题，就是超时时间的问题，但是它依然面临着另外⼀个问题。就是重传的时候，是重传之前的⼀个，还是重传所有的问题。&lt;/p&gt;
&lt;h3 id=&#34;sack&#34;&gt;SACK&lt;/h3&gt;
&lt;p&gt;还有一种实现重传机制的方式叫：SACK（ Selective Acknowledgment 选择性确认）。
这种方式需要在 TCP 头部「选项」字段里加一个 SACK 的东西，它&lt;strong&gt;可以将缓存的地图发送给发送方&lt;/strong&gt;，这样发送方就可以知道哪些数据收到了，哪些数据没收到知道了这些信息，就可以&lt;strong&gt;只重传丢失的数据&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;dsack&#34;&gt;DSACK&lt;/h3&gt;
&lt;p&gt;Duplicate SACK ⼜称 D-SACK ，其主要使用了 SACK 来告诉「发送方」有哪些数据被重复接收了。&lt;/p&gt;
&lt;h2 id=&#34;滑动窗口&#34;&gt;滑动窗口&lt;/h2&gt;
&lt;p&gt;累计确认不怕ACK信息丢失&lt;/p&gt;
&lt;p&gt;累计确认：只要发送方收到了 ACK700 确认应答，就意味着 700 之前的所有数据「接收方」都收到了。这个模式就叫累计确认或者累计应答。&lt;/p&gt;
&lt;h3 id=&#34;窗口大小如何确定&#34;&gt;窗口大小如何确定&lt;/h3&gt;
&lt;p&gt;这个字段是接收端告诉发送端 还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能⼒来发送数据，而不会导致接收端处理不过来。所以，通常窗口的大小是由接收方的窗口大小来决定的。&lt;/p&gt;
&lt;p&gt;发送方发送的数据大小不能超过接收方的窗口大小，否则接收方就无法正常接收到数据。&lt;/p&gt;
&lt;h2 id=&#34;流量控制&#34;&gt;流量控制&lt;/h2&gt;
&lt;p&gt;发送方不能无脑的发数据给接收方，要考虑接收方处理能⼒。&lt;/p&gt;
&lt;p&gt;如果⼀直无脑的发数据给对方，但对方处理不过来，那么就会导致触发重发机制，从而导致网络流量的无端的浪费。&lt;/p&gt;
&lt;p&gt;为了解决这种现象发生，TCP 提供⼀种机制可以让「发送方」根据「接收方」的实际接收能⼒控制发送的数据量，这就是所谓的流量控制。&lt;/p&gt;
&lt;p&gt;根据调整窗口的大小来控制发送方与接收方的流量&lt;/p&gt;
&lt;h2 id=&#34;拥塞控制&#34;&gt;拥塞控制&lt;/h2&gt;
&lt;h3 id=&#34;流量控制与拥塞控制对比&#34;&gt;流量控制与拥塞控制对比&lt;/h3&gt;
&lt;p&gt;前面的流量控制是避免「发送方」的数据填满「接收方」的缓存，但是并不知道网络的中发生了什么。⼀般来说，计算机网络都处在⼀个共享的环境。因此也有可能会因为其他主机之间的通信使得网络拥堵。&lt;/p&gt;
&lt;p&gt;在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是⼀重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放大&amp;hellip;.&lt;/p&gt;
&lt;p&gt;于是，就有了拥塞控制，控制的⽬的就是避免「发送方」的数据填满整个网络。为了在「发送方」调节所要发送数据的量，定义了⼀个叫做「拥塞窗口」的概念。&lt;/p&gt;
&lt;p&gt;拥塞窗口 cwnd是发送方维护的⼀个的状态变量，它会根据网络的拥塞程度动态变化的。&lt;/p&gt;
&lt;p&gt;我们在前面提到过发送窗口 swnd 和接收窗口 rwnd 是约等于的关系，那么由于加入了拥塞窗口的概念后，此时发送窗口的值是swnd = min(cwnd, rwnd)，也就是&lt;strong&gt;拥塞窗口和接收窗口中的最小值&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;拥塞窗口 cwnd 变化的规则：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;只要网络中没有出现拥塞， cwnd 就会增大；&lt;/li&gt;
&lt;li&gt;但网络中出现了拥塞， cwnd 就减少；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;传输轮次：每一个窗口为一轮，例如当前轮次窗口为4，那么传输完4个TCP报文后，开始下一轮。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/14.jpg&#34;
	width=&#34;621&#34;
	height=&#34;313&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/14_hu672fe8e890b96438a399c64b3e32e88a_46530_480x0_resize_q75_box.jpg 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/14_hu672fe8e890b96438a399c64b3e32e88a_46530_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;拥塞控制&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;198&#34;
		data-flex-basis=&#34;476px&#34;
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>网络03-IP协议</title>
        <link>https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C03-ip%E5%8D%8F%E8%AE%AE/</link>
        <pubDate>Mon, 18 Jul 2022 00:04:34 +0800</pubDate>
        
        <guid>https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C03-ip%E5%8D%8F%E8%AE%AE/</guid>
        <description>&lt;h2 id=&#34;数据链路层&#34;&gt;数据链路层&lt;/h2&gt;
&lt;p&gt;[计算机网络 - 链路层 | CS-Notes (cyc2018.xyz)](&lt;a class=&#34;link&#34; href=&#34;http://www.cyc2018.xyz/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;http://www.cyc2018.xyz/&lt;/a&gt;计算机基础/网络基础/计算机网络 - 链路层.html)&lt;/p&gt;
&lt;h2 id=&#34;网络层和数据链路层的关系&#34;&gt;网络层和数据链路层的关系&lt;/h2&gt;
&lt;p&gt;IP 的作用是主机之间通信用的，而 MAC 的作用则是实现「直连」的两个设备之间通信，而 IP 则负责在「没有直连」的两个网络之间进行通信传输。&lt;/p&gt;
&lt;h2 id=&#34;ip地址分类&#34;&gt;IP地址分类&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C03-ip%E5%8D%8F%E8%AE%AE/image-20220718165201221.png&#34;
	width=&#34;965&#34;
	height=&#34;645&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C03-ip%E5%8D%8F%E8%AE%AE/image-20220718165201221_huab3169f209f237fe3b95a91e12da8a16_125241_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C03-ip%E5%8D%8F%E8%AE%AE/image-20220718165201221_huab3169f209f237fe3b95a91e12da8a16_125241_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;IP地址分类&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;149&#34;
		data-flex-basis=&#34;359px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;D类地址用于组播（多播用于将包发送给特定组内的所有主机。）、E类地址为保留用&lt;/p&gt;
&lt;h3 id=&#34;主机个数&#34;&gt;主机个数&lt;/h3&gt;
&lt;p&gt;每类地址的最大主机个数要看主机号的位数，例如C类地址的主机号占8位，那么C类地址的最大主机个数位：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C03-ip%E5%8D%8F%E8%AE%AE/image-20220718165417407.png&#34;
	width=&#34;482&#34;
	height=&#34;119&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C03-ip%E5%8D%8F%E8%AE%AE/image-20220718165417407_hub91a98ade6dc23db785b6bbe6f396d29_11287_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C03-ip%E5%8D%8F%E8%AE%AE/image-20220718165417407_hub91a98ade6dc23db785b6bbe6f396d29_11287_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;C类地址的主机数&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;405&#34;
		data-flex-basis=&#34;972px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;为什么要减2呢？因为在 IP 地址中，有两个 IP 是特殊的，分别是主机号全为 1 和 全为 0 地址。&lt;/p&gt;
&lt;p&gt;广播地址可以分为本地广播和直接广播两种。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在本网络内广播的叫做本地广播。例如网络地址为 192.168.0.0/24 的情况下，广播地址是 192.168.0.255 。因为这个广播地址的 IP 包会被路由器屏蔽，所以不会到达 192.168.0.0/24 以外的其他链路上。&lt;/li&gt;
&lt;li&gt;在不同网络之间的广播叫做直接广播。例如网络地址为 192.168.0.0/24 的主机向 192.168.1.255/24 的目标地址发送 IP 包。收到这个包的路由器，将数据转发给 192.168.1.0/24，从而使得所有192.168.1.1~192.168.1.254 的主机都能收到这个包（由于直接广播有⼀定的安全问题，多数情况下会在路由器上设置为不转发）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ip分类的优缺点&#34;&gt;IP分类的优缺点&lt;/h3&gt;
&lt;h4 id=&#34;优点&#34;&gt;优点&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;不管是路由器还是主机解析到⼀个 IP 地址时候，我们判断其 IP 地址的首位是否为 0，为 0 则为 A 类地址，那么就能很快的找出网络地址和主机地址。优点就是简单明了、选路（基于网络地址）简单。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;缺点&#34;&gt;缺点&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;同⼀网络下没有地址层次，比如⼀个公司⾥用了 B 类地址，但是可能需要根据⽣产环境、测试环境、开发环境来划分地址层次，而这种 IP 分类是没有地址层次划分的功能，所以这就缺少地址的灵活性。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A、B、C类有个尴尬处境，就是不能很好的与现实网络匹配。C 类地址能包含的最大主机数量实在太少了，只有 254 个，估计⼀个网吧都不够用。而 B 类地址能包含的最大主机数量⼜太多了，6 万多台机器放在⼀个网络下面，⼀般的企业基本达不到这个规模，闲着的地址就是浪费。这两个缺点，都可以在 CIDR ⽆分类地址解决。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;无分类地址-cidr&#34;&gt;无分类地址 CIDR&lt;/h3&gt;
&lt;p&gt;⼦网掩码，掩码的意思就是掩盖掉主机号，剩余的就是网络号。将⼦网掩码和 IP 地址按位计算 AND，就可得到网络号。&lt;/p&gt;
&lt;p&gt;子网划分：从主机号中借几位作为子网号，同时搭配对应的子网掩码。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C03-ip%E5%8D%8F%E8%AE%AE/image-20220718165954778.png&#34;
	width=&#34;710&#34;
	height=&#34;897&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C03-ip%E5%8D%8F%E8%AE%AE/image-20220718165954778_hu5db76a85da64ed758b895fc2aee977cf_130816_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C03-ip%E5%8D%8F%E8%AE%AE/image-20220718165954778_hu5db76a85da64ed758b895fc2aee977cf_130816_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;CIDR&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;79&#34;
		data-flex-basis=&#34;189px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;ip地址与路由控制&#34;&gt;IP地址与路由控制&lt;/h2&gt;
&lt;p&gt;IP地址的网络地址这⼀部分是用于进行路由控制。&lt;/p&gt;
&lt;p&gt;路由控制表中记录着网络地址与下⼀步应该发送至路由器的地址。在主机和路由器上都会有各自的路由器控制表。&lt;/p&gt;
&lt;p&gt;在发送 IP 包时，首先要确定 IP 包首部中的目标地址，再从路由控制表中找到与该地址具有相同网络地址的记录，根据该记录将 IP 包转发给相应的下⼀个路由器。如果路由控制表中存在多条相同网络地址的记录，就选择相同位数最多的网络地址，也就是最长匹配。&lt;/p&gt;
&lt;p&gt;下面以下图的网络链路作为例⼦说明&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C03-ip%E5%8D%8F%E8%AE%AE/image-20220718170355355.png&#34;
	width=&#34;1416&#34;
	height=&#34;902&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C03-ip%E5%8D%8F%E8%AE%AE/image-20220718170355355_hub4f69c90462582ff85546b9caf48a3ba_146717_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C03-ip%E5%8D%8F%E8%AE%AE/image-20220718170355355_hub4f69c90462582ff85546b9caf48a3ba_146717_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;IP路由过程&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;156&#34;
		data-flex-basis=&#34;376px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;环回地址&#34;&gt;环回地址&lt;/h3&gt;
&lt;p&gt;环回地址是在同⼀台计算机上的程序之间进行网络通信时所使用的⼀个默认地址。计算机使用⼀个特殊的 IP 地址 127.0.0.1 作为环回地址。与该地址具有相同意义的是⼀个叫做 localhost 的主机名。使用这个 IP 或主机名时，数据包不会流向网络。&lt;/p&gt;
&lt;h2 id=&#34;ip分片与重组&#34;&gt;IP分片与重组&lt;/h2&gt;
&lt;p&gt;每种数据链路的最大传输单元 MTU 都是不相同的，如 FDDI 数据链路 MTU 4352、以太网的 MTU 是 1500 字节等。&lt;/p&gt;
&lt;p&gt;每种数据链路的 MTU 之所以不同，是因为每个不同类型的数据链路的使用目的不同。使用目的不同，可承载的MTU 也就不同。&lt;/p&gt;
&lt;p&gt;其中，我们最常见数据链路是以太网，它的 MTU 是 1500 字节。&lt;/p&gt;
&lt;p&gt;那么当 IP 数据包大小大于 MTU 时， IP 数据包就会被分片。&lt;/p&gt;
&lt;p&gt;经过分片之后的 IP 数据报在被重组的时候，只能由目标主机进行，路由器是不会进行重组的。&lt;/p&gt;
&lt;p&gt;假设发送⽅发送⼀个 4000 字节的大数据报，若要传输在以太网链路，则需要把数据报分片成 3 个小数据报进行传输，再交由接收⽅重组成大数据报。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C03-ip%E5%8D%8F%E8%AE%AE/image-20220718170803277.png&#34;
	width=&#34;1154&#34;
	height=&#34;285&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C03-ip%E5%8D%8F%E8%AE%AE/image-20220718170803277_hue4850b2b9bd1125e429178351e028c6e_49201_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C03-ip%E5%8D%8F%E8%AE%AE/image-20220718170803277_hue4850b2b9bd1125e429178351e028c6e_49201_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;IP分组&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;404&#34;
		data-flex-basis=&#34;971px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;ipv6&#34;&gt;IPV6&lt;/h2&gt;
&lt;p&gt;IPv4 地址长度共 32 位，是以每 8 位作为⼀组，并用点分⼗进制的表示⽅式。&lt;/p&gt;
&lt;p&gt;IPv6 地址长度是 128 位，是以每 16 位作为⼀组，每组用冒号 「:」 隔开。&lt;/p&gt;
&lt;p&gt;IPv6 相比 IPv4 的首部改进：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;取消了首部校验和字段。 因为在数据链路层和传输层都会校验，因此 IPv6 直接取消了 IP 的校验。&lt;/li&gt;
&lt;li&gt;取消了分片/重新组装相关字段。 分片与重组是耗时的过程，IPv6 不允许在中间路由器进行分片与重组，这种操作只能在源与目标主机，这将大大提⾼了路由器转发的速度。&lt;/li&gt;
&lt;li&gt;取消选项字段。 选项字段不再是标准 IP 首部的⼀部分了，但它并没有消失，而是可能出现在 IPv6 首部中的「下⼀个首部」指出的位置上。删除该选项字段使的 IPv6 的首部成为固定长度的 40 字节。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C03-ip%E5%8D%8F%E8%AE%AE/image-20220718171251585.png&#34;
	width=&#34;1517&#34;
	height=&#34;497&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C03-ip%E5%8D%8F%E8%AE%AE/image-20220718171251585_huf3841a1c6187d16241175a67e11c902b_108207_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C03-ip%E5%8D%8F%E8%AE%AE/image-20220718171251585_huf3841a1c6187d16241175a67e11c902b_108207_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;IPV6 与 IPV4 首部对比&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;305&#34;
		data-flex-basis=&#34;732px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;ip协议相关技术&#34;&gt;IP协议相关技术&lt;/h2&gt;
&lt;h3 id=&#34;dns&#34;&gt;DNS&lt;/h3&gt;
&lt;p&gt;根域是在最顶层，它的下⼀层就是 com 顶级域，再下面是 server.com。&lt;/p&gt;
&lt;p&gt;所以域名的层级关系类似⼀个树状结构：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;根 DNS 服务器&lt;/li&gt;
&lt;li&gt;顶级域 DNS 服务器（com）&lt;/li&gt;
&lt;li&gt;权威 DNS 服务器（server.com）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C03-ip%E5%8D%8F%E8%AE%AE/image-20220718172004203.png&#34;
	width=&#34;1505&#34;
	height=&#34;1095&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C03-ip%E5%8D%8F%E8%AE%AE/image-20220718172004203_hu24d2fbe6b2573423461fd745ec56deac_268308_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C03-ip%E5%8D%8F%E8%AE%AE/image-20220718172004203_hu24d2fbe6b2573423461fd745ec56deac_268308_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;DNS解析过程&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;137&#34;
		data-flex-basis=&#34;329px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;arp&#34;&gt;ARP&lt;/h3&gt;
&lt;p&gt;在传输⼀个 IP 数据报的时候，确定了源 IP 地址和目标 IP 地址后，就会通过主机「路由表」确定 IP 数据包下⼀跳。然而，网络层的下⼀层是数据链路层，所以我们还要知道「下⼀跳」的 MAC 地址。&lt;/p&gt;
&lt;p&gt;由于主机的路由表中可以找到下⼀跳的 IP 地址，所以可以通过 ARP 协议，求得下⼀跳的 MAC 地址。&lt;/p&gt;
&lt;p&gt;那么 ARP ⼜是如何知道对⽅ MAC 地址的呢？&lt;/p&gt;
&lt;p&gt;简单地说，ARP 是借助 ARP 请求与 ARP 响应两种类型的包确定 MAC 地址的。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;主机会通过广播发送 ARP 请求，这个包中包含了想要知道的 MAC 地址的主机 IP 地址。&lt;/li&gt;
&lt;li&gt;当同个链路中的所有设备收到 ARP 请求时，会去拆开 ARP 请求包⾥的内容，如果 ARP 请求包中的目标 IP地址与自己的 IP 地址⼀致，那么这个设备就将自己的 MAC 地址塞入 ARP 响应包返回给主机。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C03-ip%E5%8D%8F%E8%AE%AE/image-20220718191154055.png&#34;
	width=&#34;594&#34;
	height=&#34;498&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C03-ip%E5%8D%8F%E8%AE%AE/image-20220718191154055_hucf92c20f33913cb3a5706a65679b1d50_71116_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C03-ip%E5%8D%8F%E8%AE%AE/image-20220718191154055_hucf92c20f33913cb3a5706a65679b1d50_71116_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;ARP请求&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;119&#34;
		data-flex-basis=&#34;286px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;操作系统通常会把第⼀次通过 ARP 获取的 MAC 地址缓存起来，以便下次直接从缓存中找到对应 IP 地址的 MAC地址。不过，MAC 地址的缓存是有⼀定期限的，超过这个期限，缓存的内容将被清除。&lt;/p&gt;
&lt;h3 id=&#34;rarp&#34;&gt;RARP&lt;/h3&gt;
&lt;p&gt;ARP 协议是已知 IP 地址求 MAC 地址，那 RARP 协议正好相反，它是已知 MAC 地址求 IP 地址。例如将打印机服务器等小型嵌入式设备接入到网络时就经常会用得到。&lt;/p&gt;
&lt;p&gt;通常这需要架设⼀台 RARP 服务器，在这个服务器上注册设备的 MAC 地址及其 IP 地址。然后再将这个设备接入到网络，接着：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;该设备会发送⼀条「我的 MAC 地址是XXXX，请告诉我，我的IP地址应该是什么」的请求信息。&lt;/li&gt;
&lt;li&gt;RARP 服务器接到这个消息后返回「MAC地址为 XXXX 的设备，IP地址为 XXXX」的信息给这个设备。&lt;/li&gt;
&lt;li&gt;最后，设备就根据从 RARP 服务器所收到的应答信息设置自己的 IP 地址。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;dhcp&#34;&gt;DHCP&lt;/h3&gt;
&lt;p&gt;DHCP 在⽣活中我们是很常见的了，我们的电脑通常都是通过 DHCP 动态获取 IP 地址，大大省去了配 IP 信息繁琐的过程&lt;/p&gt;
&lt;p&gt;DHCP 交互中，全程都是使用 &lt;strong&gt;UDP 广播通信&lt;/strong&gt; 。&lt;/p&gt;
&lt;p&gt;先说明⼀点，DHCP 客户端进程监听的是 68 端口号，DHCP 服务端进程监听的是 67 端口号。&lt;/p&gt;
&lt;p&gt;这 4 个步骤：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;客户端首先发起 DHCP 发现报文（DHCP DISCOVER） 的 IP 数据报，由于客户端没有 IP 地址，也不知道DHCP 服务器的地址，所以使用的是 UDP 广播通信，其使用的广播目的地址是 255.255.255.255（端口67） 并且使用 0.0.0.0（端口 68） 作为源 IP 地址。DHCP 客户端将该 IP 数据报传递给链路层，链路层然后将帧广播到所有的网络中设备。&lt;/li&gt;
&lt;li&gt;DHCP 服务器收到 DHCP 发现报文时，用 DHCP 提供报文（DHCP OFFER） 向客户端做出响应。该报文仍然使用 IP 广播地址 255.255.255.255，该报文信息携带服务器提供可租约的 IP 地址、⼦网掩码、默认网关、DNS 服务器以及 IP 地址租用期。&lt;/li&gt;
&lt;li&gt;客户端收到⼀个或多个服务器的 DHCP 提供报文后，从中选择⼀个服务器，并向选中的服务器发送 DHCP 请求报文（DHCP REQUEST进行响应，回显配置的参数。&lt;/li&gt;
&lt;li&gt;最后，服务端用 DHCP ACK 报文对 DHCP 请求报文进行响应，应答所要求的参数。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;⼀旦客户端收到 DHCP ACK 后，交互便完成了，并且客户端能够在租用期内使用 DHCP 服务器分配的 IP 地址。如果租约的 DHCP IP 地址快期后，客户端会向服务器发送 DHCP 请求报文：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;服务器如果同意继续租用，则用 DHCP ACK 报文进行应答，客户端就会延长租期。&lt;/li&gt;
&lt;li&gt;服务器如果不同意继续租用，则用 DHCP NACK 报文，客户端就要停⽌使用租约的 IP 地址。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;nat&#34;&gt;NAT&lt;/h3&gt;
&lt;p&gt;IPv4 的地址是非常紧缺的，在前面我们也提到可以通过⽆分类地址来减缓 IPv4 地址耗尽的速度，但是互联网的用户增速是非常惊⼈的，所以 IPv4 地址依然有被耗尽的危险。于是，提出了⼀种网络地址转换 NAT 的⽅法，再次缓解了 IPv4 地址耗尽的问题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;简单的来说 NAT 就是同个公司、家庭、教室内的主机对外部通信时，把私有 IP 地址转换成公有 IP 地址。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C03-ip%E5%8D%8F%E8%AE%AE/image-20220718192020671.png&#34;
	width=&#34;1562&#34;
	height=&#34;617&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C03-ip%E5%8D%8F%E8%AE%AE/image-20220718192020671_hu0f7672e1f9a3dd3928a10546c47aa9f6_100412_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C03-ip%E5%8D%8F%E8%AE%AE/image-20220718192020671_hu0f7672e1f9a3dd3928a10546c47aa9f6_100412_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;NAT协议&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;253&#34;
		data-flex-basis=&#34;607px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;那不是 N 个私有 IP 地址，你就要 N 个公有 IP 地址？这怎么就缓解了 IPv4 地址耗尽的问题？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;由于绝大多数的网络应用都是使用传输层协议 TCP 或 UDP 来传输数据的。因此，可以把 IP 地址 + 端口号⼀起进行转换。这样，就用⼀个全球 IP 地址就可以了，这种转换技术就叫网络地址与端口转换 NAPT。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C03-ip%E5%8D%8F%E8%AE%AE/image-20220718192418804.png&#34;
	width=&#34;1541&#34;
	height=&#34;834&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C03-ip%E5%8D%8F%E8%AE%AE/image-20220718192418804_hudadf5ac9a1ccbea3e104eb07b6c831d3_140429_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C03-ip%E5%8D%8F%E8%AE%AE/image-20220718192418804_hudadf5ac9a1ccbea3e104eb07b6c831d3_140429_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;NAPT协议&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;184&#34;
		data-flex-basis=&#34;443px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;图中有两个客户端 192.168.1.10 和 192.168.1.11 同时与服务器 183.232.231.172 进行通信，并且这两个客户端的本地端口都是 1025。&lt;/p&gt;
&lt;p&gt;此时，两个私有 IP 地址都转换 IP 地址为公有地址 120.229.175.121，但是以不同的端口号作为区分。&lt;/p&gt;
&lt;p&gt;于是，⽣成⼀个 NAPT 路由器的转换表，就可以正确地转换地址跟端口的组合，令客户端 A、B 能同时与服务器之间进行通信。&lt;/p&gt;
&lt;p&gt;这种转换表在 NAT 路由器上自动⽣成。例如，在 TCP 的情况下，建⽴ TCP 连接首次握⼿时的 SYN 包⼀经发出，就会⽣成这个表。而后⼜随着收到关闭连接时发出 FIN 包的确认应答从表中被删除。&lt;/p&gt;
&lt;h4 id=&#34;nat-的缺点&#34;&gt;NAT 的缺点&lt;/h4&gt;
&lt;p&gt;由于 NAT/NAPT 都依赖于自己的转换表，因此会有以下的问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;外部⽆法主动与 NAT 内部服务器建⽴连接，因为 NAPT 转换表没有转换记录。&lt;/li&gt;
&lt;li&gt;转换表的⽣成与转换操作都会产⽣性能开销。&lt;/li&gt;
&lt;li&gt;通信过程中，如果 NAT 路由器重启了，所有的 TCP 连接都将被重置。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;解决&#34;&gt;解决&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;改用IPV6，每台机器一个公网IP&lt;/li&gt;
&lt;li&gt;NAT穿透技术：&lt;/li&gt;
&lt;li&gt;客户端主动从 NAT 设备获取公有 IP 地址，然后自己建⽴端口映射条目，然后用这个条目对外通信，就不需要 NAT 设备来进行转换了&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;icmp&#34;&gt;ICMP&lt;/h3&gt;
&lt;p&gt;ICMP 全称是 Internet Control Message Protocol，也就是互联网控制报文协议。&lt;/p&gt;
&lt;p&gt;ICMP 主要的功能包括：确认 IP 包是否成功送达目标地址、报告发送过程中 IP 包被废弃的原因和改善网络设置等。&lt;/p&gt;
&lt;p&gt;在 IP 通信中如果某个 IP 包因为某种原因未能达到目标地址，那么这个具体的原因将由 ICMP 负责通知。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C03-ip%E5%8D%8F%E8%AE%AE/image-20220718195953248.png&#34;
	width=&#34;966&#34;
	height=&#34;705&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C03-ip%E5%8D%8F%E8%AE%AE/image-20220718195953248_hu91e7a1518b7f78f09235a8e58079c93f_83828_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C03-ip%E5%8D%8F%E8%AE%AE/image-20220718195953248_hu91e7a1518b7f78f09235a8e58079c93f_83828_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;ICMP报文类型&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;137&#34;
		data-flex-basis=&#34;328px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C03-ip%E5%8D%8F%E8%AE%AE/image-20220718200110669.png&#34;
	width=&#34;1472&#34;
	height=&#34;1388&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C03-ip%E5%8D%8F%E8%AE%AE/image-20220718200110669_hu505635c5b7bb1109541094f54ae41f26_193821_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C03-ip%E5%8D%8F%E8%AE%AE/image-20220718200110669_hu505635c5b7bb1109541094f54ae41f26_193821_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;ICM报文&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;106&#34;
		data-flex-basis=&#34;254px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;ping工作原理&#34;&gt;Ping工作原理&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C03-ip%E5%8D%8F%E8%AE%AE/image-20220718200252435.png&#34;
	width=&#34;2840&#34;
	height=&#34;1544&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C03-ip%E5%8D%8F%E8%AE%AE/image-20220718200252435_hu885992200f332d4cef4a175edc4f7c5c_355748_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C03-ip%E5%8D%8F%E8%AE%AE/image-20220718200252435_hu885992200f332d4cef4a175edc4f7c5c_355748_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Ping工作流程&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;183&#34;
		data-flex-basis=&#34;441px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;traceroute命令&#34;&gt;traceroute命令&lt;/h3&gt;
&lt;p&gt;有⼀款充分利用 ICMP 差错报文类型的应用叫做 traceroute （在UNIX、MacOS中是这个命令，而在Windows中对等的命令叫做 tracert ）&lt;/p&gt;
&lt;h4 id=&#34;作用&#34;&gt;作用&lt;/h4&gt;
&lt;p&gt;traceroute 的第⼀个作用就是故意设置特殊的 TTL，来追踪去往目的地时沿途经过的路由器。&lt;/p&gt;
&lt;p&gt;traceroute 的参数指向某个目的 IP 地址：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;traceout 192.168.1.100
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h4 id=&#34;原理&#34;&gt;原理&lt;/h4&gt;
&lt;p&gt;它的原理就是利用 IP 包的⽣存期限 从 1 开始按照顺序递增的同时发送 UDP 包，强制接收 ICMP 超时消息的⼀种⽅法。&lt;/p&gt;
&lt;p&gt;比如，将 TTL 设置 为 1 ，则遇到第⼀个路由器，就牺牲了，接着返回 ICMP 差错报文网络包，类型是时间超时。&lt;/p&gt;
&lt;p&gt;接下来将 TTL 设置为 2 ，第⼀个路由器过了，遇到第⼆个路由器也牺牲了，也同时返回了 ICMP 差错报文数据包，如此往复，直到到达目的主机。&lt;/p&gt;
&lt;p&gt;这样的过程，traceroute 就可以拿到了所有的路由器 IP。当然有的路由器根本就不会返回这个 ICMP，所以对于有的公网地址，是看不到中间经过的路由的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;发送⽅如何知道发出的 UDP 包是否到达了目的主机呢？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;traceroute 在发送 UDP 包时，会填入⼀个不可能的端口号值作为 UDP 目标端口号（大于 3000 ）。当目的主机，收到 UDP 包后，会返回 ICMP 差错报文消息，但这个差错报文消息的类型是「端口不可达」。所以，当差错报文类型是端口不可达时，说明发送⽅发出的 UDP 包到达了目的主机。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>IO模型分析与对比</title>
        <link>https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/io%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90%E4%B8%8E%E5%AF%B9%E6%AF%94/</link>
        <pubDate>Fri, 24 Jun 2022 13:45:35 +0800</pubDate>
        
        <guid>https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/io%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90%E4%B8%8E%E5%AF%B9%E6%AF%94/</guid>
        <description>&lt;p&gt;参考：&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://segmentfault.com/a/1190000003063859#articleHeader17&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Linux IO模式及 select、poll、epoll详解 - SegmentFault 思否&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/272891398&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;一文搞懂select、poll和epoll区别 - 知乎 (zhihu.com)&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;一些前置概念&#34;&gt;一些前置概念&lt;/h2&gt;
&lt;h3 id=&#34;用户空间与内核空间&#34;&gt;用户空间与内核空间&lt;/h3&gt;
&lt;p&gt;现在操作系统都是采用虚拟存储器，那么对32位操作系统而言，它的寻址空间（虚拟存储空间）为4G（2的32次方）。操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。为了保证用户进程不能直接操作内核（kernel），保证内核的安全，操心系统将虚拟空间划分为两部分，一部分为内核空间，一部分为用户空间。&lt;/p&gt;
&lt;h3 id=&#34;进程阻塞&#34;&gt;进程阻塞&lt;/h3&gt;
&lt;p&gt;正在执行的进程，由于期待的某些事件未发生，如请求系统资源失败、等待某种操作的完成、新数据尚未到达或无新工作做等，则由系统自动执行阻塞原语(Block)，使自己由运行状态变为阻塞状态。可见，进程的阻塞是进程自身的一种主动行为，也因此只有处于运行态的进程（获得CPU），才可能将其转为阻塞状态。&lt;code&gt;当进程进入阻塞状态，是不占用CPU资源的&lt;/code&gt;。&lt;/p&gt;
&lt;h3 id=&#34;文件描述符-fd&#34;&gt;文件描述符 fd&lt;/h3&gt;
&lt;p&gt;文件描述符（File descriptor）是计算机科学中的一个术语，是一个用于表述指向文件的引用的抽象化概念。&lt;/p&gt;
&lt;p&gt;文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展开。但是文件描述符这一概念往往只适用于UNIX、Linux这样的操作系统。&lt;/p&gt;
&lt;h3 id=&#34;缓存-io&#34;&gt;缓存 I/O&lt;/h3&gt;
&lt;p&gt;缓存 I/O 又被称作标准 I/O，大多数文件系统的默认 I/O 操作都是缓存 I/O。在 Linux 的缓存 I/O 机制中，操作系统会将 I/O 的数据缓存在文件系统的页缓存（ page cache ）中，也就是说，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;缓存 I/O 的缺点：&lt;/strong&gt;
数据在传输过程中需要在应用程序地址空间和内核进行多次数据拷贝操作，这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的&lt;/p&gt;
&lt;h2 id=&#34;io-模式&#34;&gt;I/O 模式&lt;/h2&gt;
&lt;p&gt;对于一次IO访问（以read举例），数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。所以说，当一个read操作发生时，它会经历两个阶段：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;等待数据准备 (Waiting for the data to be ready)&lt;/li&gt;
&lt;li&gt;将数据从内核拷贝到进程中 (Copying the data from the kernel to the process)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;正是因为这两个阶段，linux系统产生了下面五种网络模式的方案。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;阻塞 I/O（blocking IO）&lt;/li&gt;
&lt;li&gt;非阻塞 I/O（nonblocking IO）&lt;/li&gt;
&lt;li&gt;I/O 多路复用（ IO multiplexing）&lt;/li&gt;
&lt;li&gt;信号驱动 I/O（ signal driven IO）&lt;/li&gt;
&lt;li&gt;异步 I/O（asynchronous IO）&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;阻塞-ioblocking-io&#34;&gt;阻塞 I/O（blocking IO）&lt;/h3&gt;
&lt;p&gt;在linux中，默认情况下所有的socket都是blocking，一个典型的读操作流程大概是这样：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/io%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90%E4%B8%8E%E5%AF%B9%E6%AF%94/bio.png&#34;
	width=&#34;552&#34;
	height=&#34;331&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/io%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90%E4%B8%8E%E5%AF%B9%E6%AF%94/bio_huc5d37df4b38ee3db2ba7c889e6af7011_57429_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/io%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90%E4%B8%8E%E5%AF%B9%E6%AF%94/bio_huc5d37df4b38ee3db2ba7c889e6af7011_57429_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;blocking IO&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;166&#34;
		data-flex-basis=&#34;400px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;当用户进程调用了recvfrom这个系统调用，kernel就开始了IO的第一个阶段：准备数据（对于网络IO来说，很多时候数据在一开始还没有到达。比如，还没有收到一个完整的UDP包。这个时候kernel就要等待足够的数据到来）。这个过程需要等待，也就是说数据被拷贝到操作系统内核的缓冲区中是需要一个过程的。而在用户进程这边，整个进程会被阻塞（当然，是进程自己选择的阻塞）。当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;所以，blocking IO的特点就是在IO执行的两个阶段都被block了。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;非阻塞-iononblocking-io&#34;&gt;非阻塞 I/O（nonblocking IO）&lt;/h3&gt;
&lt;p&gt;linux下，可以通过设置socket使其变为non-blocking。当对一个non-blocking socket执行读操作时，流程是这个样子：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/io%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90%E4%B8%8E%E5%AF%B9%E6%AF%94/nio.png&#34;
	width=&#34;603&#34;
	height=&#34;333&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/io%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90%E4%B8%8E%E5%AF%B9%E6%AF%94/nio_hu95f0bfd8ac579c5e5f7fba016d9afeb7_84999_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/io%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90%E4%B8%8E%E5%AF%B9%E6%AF%94/nio_hu95f0bfd8ac579c5e5f7fba016d9afeb7_84999_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;nonblocking IO&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;181&#34;
		data-flex-basis=&#34;434px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;当用户进程发出read操作时，如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error。从用户进程角度讲 ，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的system call，那么它马上就将数据拷贝到了用户内存，然后返回。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;所以，nonblocking IO的特点是用户进程需要&lt;strong&gt;不断的主动询问&lt;/strong&gt;kernel数据好了没有。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;io-多路复用-io-multiplexing&#34;&gt;I/O 多路复用（ IO multiplexing）&lt;/h3&gt;
&lt;p&gt;IO multiplexing就是我们说的select，poll，epoll，有些地方也称这种IO方式为event driven IO。select/epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基本原理就是select，poll，epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/io%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90%E4%B8%8E%E5%AF%B9%E6%AF%94/io-multi.png&#34;
	width=&#34;609&#34;
	height=&#34;326&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/io%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90%E4%B8%8E%E5%AF%B9%E6%AF%94/io-multi_huf8e7078d51edfb1acbaeb5699c79fdf4_77265_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/io%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90%E4%B8%8E%E5%AF%B9%E6%AF%94/io-multi_huf8e7078d51edfb1acbaeb5699c79fdf4_77265_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;IO multiplexing&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;186&#34;
		data-flex-basis=&#34;448px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;当用户进程调用了select，那么整个进程会被block&lt;/code&gt;，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;所以，I/O 多路复用的特点是通过一种机制一个进程能同时等待多个文件描述符，而这些文件描述符（套接字描述符）其中的任意一个进入读就绪状态，select()函数就可以返回。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这个图和blocking IO的图其实并没有太大的不同，事实上，还更差一些。因为这里需要使用两个system call (select 和 recvfrom)，而blocking IO只调用了一个system call (recvfrom)。但是，用select的优势在于它可以同时处理多个connection。&lt;/p&gt;
&lt;p&gt;所以，如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好，可能延迟还更大。select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。）&lt;/p&gt;
&lt;p&gt;在IO multiplexing Model中，实际中，对于每一个socket，一般都设置成为non-blocking，但是，如上图所示，整个用户的process其实是一直被block的。只不过process是被select这个函数block，而不是被socket IO给block。&lt;/p&gt;
&lt;h3 id=&#34;异步-ioasynchronous-io&#34;&gt;异步 I/O（asynchronous IO）&lt;/h3&gt;
&lt;p&gt;inux下的asynchronous IO其实用得很少。先看一下它的流程：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/io%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90%E4%B8%8E%E5%AF%B9%E6%AF%94/async-io.png&#34;
	width=&#34;572&#34;
	height=&#34;324&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/io%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90%E4%B8%8E%E5%AF%B9%E6%AF%94/async-io_huc529fa909bb0db7279e58b28456e00fe_62560_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/io%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90%E4%B8%8E%E5%AF%B9%E6%AF%94/async-io_huc529fa909bb0db7279e58b28456e00fe_62560_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;asynchronous IO&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;176&#34;
		data-flex-basis=&#34;423px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;用户进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。&lt;/p&gt;
&lt;h3 id=&#34;信号驱动-io-signal-driven-io&#34;&gt;信号驱动 I/O（ signal driven IO）&lt;/h3&gt;
&lt;p&gt;在信号驱动式I/O模型中，应用程序使用套接口进行信号驱动I/O，并安装一个信号处理函数，进程继续运行并不阻塞。当数据准备好时，进程会收到一个SIGIO信号，可以在信号处理函数中调用I/O操作函数处理数据&lt;/p&gt;
&lt;p&gt;异步 I/O与信号驱动 I/O的主要区别在于：&lt;strong&gt;信号驱动I/O是由内核通知应用程序何时启动一个I/O操作，而异步I/O模型是由内核通知应用程序I/O操作何时完成&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;优点：线程并没有在等待数据时被阻塞，可以提高资源的利用率&lt;/p&gt;
&lt;p&gt;缺点：信号I/O在大量IO操作时可能会因为信号队列溢出导致没法通知。&lt;/p&gt;
&lt;p&gt;信号驱动I/O尽管对于处理UDP套接字来说有用，即这种信号通知意味着到达一个数据报，或者返回一个异步错误。但是，对于TCP而言，信号驱动的I/O方式近乎无用，因为导致这种通知的条件为数众多，每一个来进行判别会消耗很大资源。&lt;/p&gt;
&lt;h3 id=&#34;io模式总结&#34;&gt;IO模式总结&lt;/h3&gt;
&lt;h4 id=&#34;blocking和non-blocking的区别&#34;&gt;blocking和non-blocking的区别&lt;/h4&gt;
&lt;p&gt;调用blocking IO会一直block住对应的进程直到操作完成，而 non-blocking IO在 kernel 还未准备好数据的情况下会立刻返回。&lt;/p&gt;
&lt;h4 id=&#34;synchronous-io和asynchronous-io的区别&#34;&gt;synchronous IO和asynchronous IO的区别&lt;/h4&gt;
&lt;p&gt;在说明synchronous IO和asynchronous IO的区别之前，需要先给出两者的定义。POSIX的定义是这样子的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A synchronous I/O operation causes the requesting process to be blocked until that I/O operation completes;&lt;/li&gt;
&lt;li&gt;An asynchronous I/O operation does not cause the requesting process to be blocked;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;两者的区别就在于synchronous IO做”IO operation”的时候会将process阻塞。按照这个定义，之前所述的blocking IO，non-blocking IO，IO multiplexing都属于synchronous IO。&lt;/p&gt;
&lt;p&gt;这里有个非常“狡猾”的地方，定义中所指的”IO operation”是指真实的IO操作，就是例子中的recvfrom这个system call。non-blocking IO在执行recvfrom这个system call的时候，如果kernel的数据没有准备好，这时候不会block进程。但是，当kernel中数据准备好的时候，recvfrom会将数据从kernel拷贝到用户内存中，这个时候进程是被block了，在这段时间内，进程是被block的。&lt;/p&gt;
&lt;p&gt;而asynchronous IO则不一样，当进程发起IO 操作之后，就直接返回再也不理睬了，直到kernel发送一个信号，告诉进程说IO完成。在这整个过程中，进程完全没有被block。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;同步IO和异步IO的区别就在于：数据拷贝的时候进程是否阻塞！&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;阻塞IO和非阻塞IO的区别就在于：应用程序的调用是否立即返回！&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;各个IO Model的比较如图所示：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/io%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90%E4%B8%8E%E5%AF%B9%E6%AF%94/comparison.png&#34;
	width=&#34;614&#34;
	height=&#34;327&#34;
	srcset=&#34;https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/io%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90%E4%B8%8E%E5%AF%B9%E6%AF%94/comparison_hu9340ee179b4f5f73a447f871db282220_91658_480x0_resize_box_3.png 480w, https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/io%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90%E4%B8%8E%E5%AF%B9%E6%AF%94/comparison_hu9340ee179b4f5f73a447f871db282220_91658_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;IO Model 对比&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;187&#34;
		data-flex-basis=&#34;450px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;通过上面的图片，可以发现non-blocking IO和asynchronous IO的区别还是很明显的。在non-blocking IO中，虽然进程大部分时间都不会被block，但是它仍然要求进程去主动的check，并且当数据准备完成以后，也需要进程主动的再次调用recvfrom来将数据拷贝到用户内存。而asynchronous IO则完全不同。它就像是用户进程将整个IO操作交给了他人（kernel）完成，然后他人做完后发信号通知。在此期间，用户进程不需要去检查IO操作的状态，也不需要主动的去拷贝数据。&lt;/p&gt;
&lt;h2 id=&#34;io-多路复用之selectpollepollkqueue详解&#34;&gt;I/O 多路复用之select、poll、epoll、kqueue详解&lt;/h2&gt;
&lt;p&gt;select，poll，epoll，kqueue都是IO多路复用的机制。I/O多路复用就是通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。（这里啰嗦下）&lt;/p&gt;
&lt;h3 id=&#34;select&#34;&gt;select&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;select&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fd_set&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;readfds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fd_set&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;writefds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fd_set&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;exceptfds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;timeval&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;timeout&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;//	writefds、readfds、和exceptfds　是三个指针，分别记录了读、写和 except 事件描述符
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;//	进程调用select的时候会把这三个指针传递进函数并阻塞直到有就绪事件
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;//	如果有就绪的事件对应的描述符，会对其设置就绪，select 返回后进程可以遍历所有的描述符，找到就绪的进行处理。
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;select 函数监视的文件描述符分3类，分别是writefds、readfds、和exceptfds。调用后select函数会阻塞，直到有描述副就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以 通过遍历fdset，来找到就绪的描述符。&lt;/p&gt;
&lt;p&gt;select目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点。select的一 个缺点在于单个进程能够监视的文件描述符的数量&lt;strong&gt;存在最大限制&lt;/strong&gt;，在Linux上一般为1024，可以通过修改宏定义甚至重新编译内核的方式提升这一限制，但 是这样也会造成效率的降低。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;调用过程&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;使用copy_from_user从用户空间拷贝fd_set到内核空间&lt;/li&gt;
&lt;li&gt;注册回调函数&lt;code&gt;__pollwait&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;遍历所有fd，调用其对应的poll方法（对于socket，这个poll方法是sock_poll，sock_poll根据情况会调用到tcp_poll，udp_poll或datagram_poll），以tcp_poll为例，核心实现就是&lt;code&gt;__pollwait&lt;/code&gt;，即上面注册的回调函数。&lt;code&gt;__pollwait&lt;/code&gt;，就是把current（当前进程）挂到设备的等待队列，不同设备有不同等待队列，如tcp_poll的等待队列是sk-&amp;gt;sk_sleep（把进程挂到等待队列中并不代表进程已睡眠）。在设备收到一条消息（网络设备）或填写完文件数据（磁盘设备）后，会唤醒设备等待队列上睡眠的进程，这时current便被唤醒。&lt;/li&gt;
&lt;li&gt;poll方法返回时会返回一个描述读写操作是否就绪的mask掩码，根据这个mask掩码给fd_set赋值&lt;/li&gt;
&lt;li&gt;若遍历完所有fd，还没返回一个可读写的mask掩码，则调schedule_timeout是调用select的进程（也就是current）进入睡眠。当设备驱动发生自身资源可读写后，会唤醒其等待队列上睡眠的进程。若超过一定超时时间（schedule_timeout指定），还没人唤醒，则调用select的进程会重新被唤醒获得CPU，进而重新遍历fd，判断有无就绪的fd&lt;/li&gt;
&lt;li&gt;把fd_set从内核空间拷贝到用户空间&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;缺点&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;内核需要将消息传递到用户空间，都需要内核拷贝动作。需要维护一个用来存放大量fd的数据结构，使得用户空间和内核空间在传递该结构时复制开销大。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每次调用select，都需把fd集合从用户态拷贝到内核态，fd很多时开销就很大&lt;/li&gt;
&lt;li&gt;同时每次调用select都需在内核遍历传递进来的所有fd，fd很多时开销就很大&lt;/li&gt;
&lt;li&gt;select支持的文件描述符数量太小了，默认最大支持1024个&lt;/li&gt;
&lt;li&gt;主动轮询效率很低&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;poll&#34;&gt;poll&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;poll&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;pollfd&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;unsigned&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nfds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;timeout&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;不同与select使用三个位图来表示三个fdset的方式，poll使用一个 pollfd的指针实现。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;pollfd&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fd&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;cm&#34;&gt;/* 文件描述符 */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kt&#34;&gt;short&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;events&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;cm&#34;&gt;/* 要监视的事件 */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kt&#34;&gt;short&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;revents&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;cm&#34;&gt;/* 发生的事件 */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;};&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;pollfd结构包含了要监视的event和发生的event，不再使用select“参数-值”传递的方式。同时，pollfd并没有最大数量限制（但是数量过大后性能也是会下降）。 和select函数一样，poll返回后，需要轮询pollfd来获取就绪的描述符。&lt;/p&gt;
&lt;p&gt;poll和select同样存在一个缺点就是，包含大量文件描述符的数组被整体复制于用户态和内核的地址空间之间，而不论这些文件描述符是否就绪，它的开销随着文件描述符数量的增加而线性增大。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;它将用户传入的数组拷贝到内核空间&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;然后查询每个fd对应的设备状态：&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;如果设备就绪 在设备等待队列中加入一项继续遍历&lt;/li&gt;
&lt;li&gt;若遍历完所有fd后，都没发现就绪的设备 挂起当前进程，直到设备就绪或主动超时，被唤醒后它又再次遍历fd。这个过程经历多次无意义的遍历。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;从上面看，select和poll都需要在返回后，&lt;code&gt;通过遍历文件描述符来获取已经就绪的socket&lt;/code&gt;。事实上，同时连接的大量客户端在一时刻可能只有很少的处于就绪状态，因此随着监视的描述符数量的增长，其效率也会线性下降。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;epoll&#34;&gt;epoll&lt;/h3&gt;
&lt;p&gt;epoll是在2.6内核中提出的，是之前的select和poll的增强版本。相对于select和poll来说，epoll更加灵活，没有描述符限制。epoll使用一个文件描述符管理多个描述符，&lt;strong&gt;将用户关心的文件描述符的事件存放到内核的一个事件表中&lt;/strong&gt;，用户每次新增和删除监听事件都通过内核中的这个事件表，这样在用户空间和内核空间的copy只需一次。&lt;strong&gt;select 和 poll 都需要把fd表或者数据结构拷贝到内核态再从内核态取出。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;epoll模型修改主动轮询为被动通知，当有事件发生时，被动接收通知。所以epoll模型注册套接字后，主程序可做其他事情，当事件发生时，接收到通知后再去处理。可理解为&lt;strong&gt;event poll&lt;/strong&gt;，epoll会把哪个流发生哪种I/O事件通知我们。所以epoll是事件驱动（每个事件关联fd），此时我们对这些流的操作都是有意义的。复杂度也降到O(1)。&lt;/p&gt;
&lt;h4 id=&#34;epoll操作过程&#34;&gt;epoll操作过程&lt;/h4&gt;
&lt;p&gt;epoll操作过程需要三个接口，分别如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;epoll_create&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;；&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//创建一个epoll的句柄（epfd），size用来告诉内核这个监听的数目一共有多大
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;epoll_ctl&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;epfd&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;op&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fd&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;epoll_event&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;event&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;；&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;// 增删改某个fd的某个事件
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;epoll_wait&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;epfd&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;epoll_event&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;events&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;maxevents&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;timeout&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;	&lt;span class=&#34;c1&#34;&gt;// 等待 epfd 上的事件
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;1. int epoll_create(int size);&lt;/strong&gt;
创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大，这个参数不同于select()中的第一个参数，给出最大监听的fd+1的值，&lt;code&gt;参数size并不是限制了epoll所能监听的描述符最大个数，只是对内核初始分配内部数据结构的一个建议&lt;/code&gt;。
当创建好epoll句柄后，它就会占用一个fd值，在linux下如果查看/proc/进程id/fd/，是能够看到这个fd的，所以在使用完epoll后，必须调用close()关闭，否则可能导致fd被耗尽。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2. int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；&lt;/strong&gt;
函数是对指定描述符fd执行op操作。
- epfd：是epoll_create()的返回值。
- op：表示op操作，用三个宏来表示：添加EPOLL_CTL_ADD，删除EPOLL_CTL_DEL，修改EPOLL_CTL_MOD。分别添加、删除和修改对fd的监听事件。
- fd：是需要监听的fd（文件描述符）
- epoll_event：是告诉内核需要监听什么事，struct epoll_event结构如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;epoll_event&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;__uint32_t&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;events&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;  &lt;span class=&#34;cm&#34;&gt;/* Epoll events */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;epoll_data_t&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;  &lt;span class=&#34;cm&#34;&gt;/* User data variable */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;};&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;//events可以是以下几个宏的集合：
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;EPOLLIN&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;：表示对应的文件描述符可以读（包括对端&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;SOCKET正常关闭&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;）；&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;EPOLLOUT&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;：表示对应的文件描述符可以写；&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;EPOLLPRI&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）；&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;EPOLLERR&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;：表示对应的文件描述符发生错误；&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;EPOLLHUP&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;：表示对应的文件描述符被挂断；&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;EPOLLET&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;：&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;将&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;EPOLL设为边缘触发&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Edge&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Triggered&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;模式，这是相对于水平触发&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Level&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Triggered&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;来说的。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;EPOLLONESHOT&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;socket的话&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;，需要再次把这个&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;socket加入到EPOLL队列里&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;3. int epoll_wait(int epfd,  struct epoll_event  * events,  int maxevents,  int timeout);&lt;/strong&gt;
等待epfd上的io事件，最多返回maxevents个事件。
参数events用来从内核得到事件的集合，maxevents告知内核这个events有多大，这个maxevents的值不能大于创建epoll_create()时的size，参数timeout是超时时间（毫秒，0会立即返回，-1将不确定，也有说法说是永久阻塞）。该函数返回需要处理的事件数目，如返回0表示已超时。&lt;/p&gt;
&lt;h4 id=&#34;工作模式&#34;&gt;工作模式&lt;/h4&gt;
&lt;p&gt;epoll对文件描述符的操作有两种模式：&lt;strong&gt;LT（level trigger）&lt;strong&gt;和&lt;/strong&gt;ET（edge trigger）&lt;/strong&gt;。LT模式是默认模式，LT模式与ET模式的区别如下：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;LT模式，默认的模式（水平触发）&lt;/strong&gt;：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，&lt;code&gt;应用程序可以不立即处理该事件&lt;/code&gt;。下次调用epoll_wait时，会再次响应应用程序并通知此事件。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ET模式，“高速”模式（边缘触发）&lt;/strong&gt;：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，&lt;code&gt;应用程序必须立即处理该事件&lt;/code&gt;。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;LT模式&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;LT(level triggered)是缺省的工作方式，并且同时支持block和no-block socket.在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ET模式&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;ET(edge-triggered)是高速工作方式，只支持no-block socket。在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知，直到你做了某些操作导致那个文件描述符不再为就绪状态了(比如，你在发送，接收或者接收请求，或者发送接收的数据少于一定量时导致了一个EWOULDBLOCK 错误）。但是请注意，如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核不会发送更多的通知(only once)&lt;/p&gt;
&lt;p&gt;ET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。epoll工作在ET模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;假如有这样一个例子：&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;我们已经把一个用来从管道中读取数据的文件句柄(RFD)添加到epoll描述符&lt;/li&gt;
&lt;li&gt;这个时候从管道的另一端被写入了2KB的数据&lt;/li&gt;
&lt;li&gt;调用epoll_wait(2)，并且它会返回RFD，说明它已经准备好读取操作&lt;/li&gt;
&lt;li&gt;然后我们读取了1KB的数据&lt;/li&gt;
&lt;li&gt;调用epoll_wait(2)&amp;hellip;&amp;hellip;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;LT模式：&lt;/strong&gt;
如果是LT模式，那么在第5步调用epoll_wait(2)之后，仍然能受到通知。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ET模式：&lt;/strong&gt;
如果我们在第1步将RFD添加到epoll描述符的时候使用了EPOLLET标志，那么在第5步调用epoll_wait(2)之后将有可能会挂起，因为剩余的数据还存在于文件的输入缓冲区内，而且数据发出端还在等待一个针对已经发出数据的反馈信息。只有在监视的文件句柄上发生了某个事件的时候 ET 工作模式才会汇报事件。因此在第5步的时候，调用者可能会放弃等待仍在存在于文件输入缓冲区内的剩余数据。&lt;/p&gt;
&lt;p&gt;当使用epoll的ET模型来工作时，当产生了一个EPOLLIN事件后，
读数据的时候需要考虑的是当recv()返回的大小如果等于请求的大小，那么很有可能是缓冲区还有数据未读完，也意味着该次事件还没有处理完，所以还需要再次读取：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;while&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;){&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;buflen&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;recv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;activeevents&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;].&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fd&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;buf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;sizeof&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;buf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;buflen&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;){&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;// 由于是非阻塞的模式,所以当errno为EAGAIN时,表示当前缓冲区已无数据可读
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;// 在这里就当作是该次事件已处理处.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;errno&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;EAGAIN&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;){&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;break&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;buflen&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;){&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;     &lt;span class=&#34;c1&#34;&gt;// 这里表示对端的socket已正常关闭.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;  &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;buflen&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;sizeof&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;buf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;){&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;n&#34;&gt;rs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;   &lt;span class=&#34;c1&#34;&gt;// 需要再次读取
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;n&#34;&gt;rs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Linux中的EAGAIN含义&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Linux环境下开发经常会碰到很多错误(设置errno)，其中EAGAIN是其中比较常见的一个错误(比如用在非阻塞操作中)。
从字面上来看，是提示再试一次。这个错误经常出现在当应用程序进行一些非阻塞(non-blocking)操作(对文件或socket)的时候。&lt;/p&gt;
&lt;p&gt;例如，以 O_NONBLOCK的标志打开文件/socket/FIFO，如果你连续做read操作而没有数据可读。此时程序不会阻塞起来等待数据准备就绪返回，read函数会返回一个错误EAGAIN，提示你的应用程序现在没有数据可读请稍后再试。
又例如，当一个系统调用(比如fork)因为没有足够的资源(比如虚拟内存)而执行失败，返回EAGAIN提示其再调用一次(也许下次就能成功)。&lt;/p&gt;
&lt;h4 id=&#34;优点&#34;&gt;优点&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;没有最大并发连接的限制，能打开的FD的上限远大于1024（1G的内存上能监听约10万个端口）&lt;/li&gt;
&lt;li&gt;效率提升，不是轮询，不会随着FD数目的增加效率下降。只有活跃可用的FD才会调用callback函数 即Epoll最大的优点就在于它只关心“活跃”的连接，而跟连接总数无关，因此在实际的网络环境中，Epoll的效率就会远远高于select和poll&lt;/li&gt;
&lt;li&gt;内存拷贝，利用mmap()文件映射内存加速与内核空间的消息传递；即epoll使用mmap减少复制开销。&lt;/li&gt;
&lt;li&gt;epoll通过内核和用户空间共享一块内存来实现的&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;kqueue&#34;&gt;kqueue&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;kqueue和epoll一样，都是用来替换select和poll的。不同的是kqueue被用在FreeBSD,NetBSD, OpenBSD, DragonFly BSD, 和 macOS中。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;kqueue 不仅能够处理文件描述符事件，还可以用于各种其他通知，例如文件修改监视、信号、异步 I/O 事件 (AIO)、子进程状态更改监视和支持纳秒级分辨率的计时器，此外kqueue提供了一种方式除了内核提供的事件之外，还可以使用用户定义的事件。&lt;/p&gt;
&lt;p&gt;kqueue提供了两个API，第一个是构建kqueue：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;kqueue&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;第二个是创建kevent:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;kevent&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;kq&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;const&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;kevent&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;changelist&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nchanges&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;kevent&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;eventlist&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nevents&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;const&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;timespec&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;timeout&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;kevent中的第一个参数是要注册的kqueue，changelist是要监视的事件列表，nchanges表示要监听事件的长度，eventlist是kevent返回的事件列表,nevents表示要返回事件列表的长度，最后一个参数是timeout。&lt;/p&gt;
&lt;p&gt;除此之外，kqueue还有一个用来初始化kevent结构体的EV_SET宏：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;EV_SET&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kev&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ident&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;filter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;flags&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fflags&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;udata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;
&lt;p&gt;在 select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，而&lt;strong&gt;epoll事先通过epoll_ctl()来注册一 个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait() 时便得到通知&lt;/strong&gt;。(&lt;code&gt;此处去掉了遍历文件描述符，而是通过监听回调的的机制&lt;/code&gt;。这正是epoll的魅力所在。)&lt;/p&gt;
&lt;p&gt;select，poll，epoll都是IO多路复用机制，即可以监视多个描述符，一旦某个描述符就绪（读或写就绪），能够通知程序进行相应读写操作。 但select，poll，epoll本质上都是&lt;strong&gt;同步I/O&lt;/strong&gt;，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;select，poll实现需要自己不断轮询所有fd集合，直到设备就绪，期间可能要睡眠和唤醒多次交替。而epoll其实也需要调用epoll_wait不断轮询就绪链表，期间也可能多次睡眠和唤醒交替，但是它是设备就绪时，调用回调函数，把就绪fd放入就绪链表中，并唤醒在epoll_wait中进入睡眠的进程。虽然都要睡眠和交替，但是select和poll在“醒着”的时候要遍历整个fd集合，而epoll在“醒着”的时候只要判断一下就绪链表是否为空就行了，这节省了大量的CPU时间。这就是回调机制带来的性能提升。&lt;/li&gt;
&lt;li&gt;select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把current往设备等待队列中挂一次，而epoll只要一次拷贝，而且把current往等待队列上挂也只挂一次（在epoll_wait的开始，注意这里的等待队列并不是设备等待队列，只是一个epoll内部定义的等待队列）。这也能节省不少的开销。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;如果没有大量的idle -connection或者dead-connection，epoll的效率并不会比select/poll高很多，但是当遇到大量的idle- connection，就会发现epoll的效率大大高于select/poll。&lt;/p&gt;
&lt;/blockquote&gt;
</description>
        </item>
        
    </channel>
</rss>
