[{"content":"hugo 安装 参考官方文档：Hugo Documentation | Hugo (gohugo.io)\ngithub仓库：Releases · gohugoio/hugo (github.com)\n由于我使用的主题是 stack [CaiJimmy/hugo-theme-stack: Card-style Hugo theme designed for bloggers (github.com)]，主题要求下载 hugo-extended 版本\nstack中文文档：介绍 | Hugo 主题 Stack (jimmycai.com)\n下载完成后解压并配置环境变量\nhugo 基本命令 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  # 新建 site-name：quickstart hugo new site \u0026#34;quickstart\u0026#34; # 添加或者修改主题  cd quickstart git init git submodule add https://github.com/CaiJimmy/hugo-theme-stack.git # 方法1： echo theme = \\\u0026#34;stack\\\u0026#34; \u0026gt;\u0026gt; config.toml #方法2（建议）： #使用主题的 \\themes\\hugo-theme-stack\\exampleSite\\config.yaml 文件覆盖 site 的配置文件，这样做是因为主题自带的样例配置已经做了很多默认配置，自己只需要进行简单的定制化即可 # 添加一篇文章 hugo new posts/my-first-post.md # 启动 hugoserver hugo server -D # 访问 http://localhost:1313/   部署 方式1：使用 github 托管  新建仓库：仓库名必须为 {github-username}.github.io 将 hugo 生成的 public 目录作为 git仓库 push 到新建的远程仓库即可  为了避免每次更新都要重新更新仓库，我使用了shell脚本自动化完成，可参考如下脚本：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  #!/bin/sh  # If a command fails then the deploy stops set -e printf \u0026#34;\\033[0;32mDeploying updates to GitHub...\\033[0m\\n\u0026#34; # push meta files git add . msg=\u0026#34;update site $(date)\u0026#34; if [ -n \u0026#34;$*\u0026#34; ]; then msg=\u0026#34;$*\u0026#34; fi git commit -m \u0026#34;$msg\u0026#34; git push -u origin main # Build the project. hugo -D --cleanDestinationDir # if using a theme, replace with `hugo -t \u0026lt;YOURTHEME\u0026gt;` # Go To Public folder cd public # Add changes to git. git add . # Commit changes. msg=\u0026#34;rebuilding site $(date)\u0026#34; if [ -n \u0026#34;$*\u0026#34; ]; then msg=\u0026#34;$*\u0026#34; fi git commit -m \u0026#34;$msg\u0026#34; # Push source and build repos. git push -u origin main   方式2：部署到服务器 服务器安装nginx\n1  yum install nginx -y   配置\n1  vim /etc/nginx/nginx.conf   1 2 3 4 5 6 7 8 9 10 11 12  server { listen 80; listen [::]:80; server_name isheihei.cn; root /root/isheihei.github.io; //网站目录 # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; error_page 404 /404.html; location = /404.html { }   启动\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  // 启动 nginx // 重启 nginx -s reload // 设置开机自启动 systemcel enable nginx.service // 查看nginx状态 systemctl status nginx.service // 杀死nginx重启nginx pkill -9 nginx ps aux | grep nginx systemctl start nginx   遇到的一些问题及解决方案 问题1：插入图片问题 如果需要在博文中插入图片的话，可以使用同图床，但是我自身习惯是所有的博客和资源统一静态管理，那么就需要在生成站点的时候将一些静态图片文件也一起打包。好在 hugo 也提供了这样一种机制。参考：Content Organization | Hugo (gohugo.io)\n遗憾的是我并没有完全搞懂官方的组织管理的方法，这里提供我自己的实现方案供参考\n默认情况下，我们的文章都是在 content/posts/ 目录下，官方提供了一种打包方案：一个文件夹下命名为 index.md 的文档可以访问本文件夹下的静态资源。那么我们只需要给每篇文章使用单独的文件夹目录，该文档包含的图片一并放在该目录下即可。\n为了方便，使用 shell 脚本自动化创建目录和文档\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  #!/bin/sh blog_path=\u0026#34;./content/posts/$2\u0026#34; category_path=\u0026#34;./content/categories/$2\u0026#34; # new blog if [ $1 == \u0026#34;-b\u0026#34; ] then mkdir ${blog_path} hugo new ${blog_path}/index.md # new category elif [ $1 == \u0026#34;-c\u0026#34; ] then mkdir ${category_path} hugo new ${category_path}/_index.md elif [ $1 == \u0026#34;help\u0026#34; -o $1 == \u0026#34;-h\u0026#34; ] then echo \u0026#34;var1\u0026#34; echo \u0026#34;-b:new blog, -c:new category, -h/help:help\u0026#34; echo \u0026#34;var2\u0026#34; echo \u0026#34;path:base is ./content/posts or ./content/categories\u0026#34; # new tag fi   问题2：网页favcoin无法显示 stack 主题提供了配置文件自定义配置 favcoin ，但是我实测后好像一直无法使用静态相对路径访问到。最终的解决方案是修改主题网页模板代码\n文件目录为：\\themes\\hugo-theme-stack\\layouts\\partials\\head.html\n参考作者对于 avator 的处理方法，先对图标进行裁剪，再引入。\n以下是参考对象 \\themes\\hugo-theme-stack\\layouts\\partials\\sidebar\\left.html\n效果：\n","date":"2022-05-19T14:11:07+08:00","image":"https://isheihei.github.io/posts/tips/hugo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E9%83%A8%E7%BD%B2%E4%BB%A5%E5%8F%8A%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/hugo-logo-wide.svg","permalink":"https://isheihei.github.io/posts/tips/hugo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E9%83%A8%E7%BD%B2%E4%BB%A5%E5%8F%8A%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/","title":"Hugo博客搭建部署以及问题解决"},{"content":"为什么需要索引    优势 劣势     提高数据检索的效率，降低数据库的IO成本 索引列也是要占空间的   通过索引列对数据进行排序，，降低数据排序的成本，降低CPU的消耗 索引大大提高了查询效率，同时却也降低了更新表的速度    索引结构 二叉树 如果选择二叉树作为索引结构，会存在以下缺点：\n 顺序插入时，会形成一个链表，查询性能大大降低。 大数据量情况下，层级较深，检索速度慢。  即使选择红黑树，红黑树是一颗自平衡二叉树，那这样即使是顺序插入数据，最终形成的数据结构也是一颗平衡的二叉树，大数据量情况下，层级依然较深，检索速度慢。\nB树（B-树） B-Tree，B树是一种多叉路衡查找树，相对于二叉树，B树每个节点可以有多个分支，即多叉。以一颗最大度数（max-degree，树的度数指的是一个节点的子节点个数）为5(5阶)的b-tree为例，那这个B树每个节点最多存储4个key，5个指针：\n特点：\n 5阶的B树，每一个节点最多存储4个key，对应5个指针。 一旦节点存储的key数量到达5，就会裂变，中间元素向上分裂。 在B树中，非叶子节点和叶子节点都会存放数据。  B+树 B+Tree是B-Tree的变种，我们以一颗最大度数（max-degree）为4（4阶）的b+tree为例，来看一下其结构示意图：\n我们可以看到，两部分：\n 绿色框框起来的部分，是索引部分，仅仅起到索引数据的作用，不存储数据。 红色框框起来的部分，是数据存储部分，在其叶子节点中要存储具体的数据。  最终我们看到，B+Tree 与 B-Tree相比，主要有以下三点区别：\n B- 树的所有节点既存放键(key) 也存放 数据(data)，而 B+树只有叶子节点存放 key 和 data，其他内节点只存放 key。 B- 树的叶子节点都是独立的；B+树的叶子节点有一条引用链指向与它相邻的叶子节点。 B- 树的检索的过程相当于对范围内的每个节点的关键字做二分查找，可能还没有到达叶子节点，检索就结束了。而 B+树的检索效率就很稳定了，任何查找都是从根节点到叶子节点的过程，叶子节点的顺序检索很明显。  hash MySQL中除了支持B+Tree索引，还支持一种索引类型\u0026mdash;Hash索引。\n特点\n Hash索引只能用于对等比较(=，in)，不支持范围查询（between，\u0026gt;，\u0026lt; ，\u0026hellip;） 无法利用索引完成排序操作 查询效率高，通常(不存在hash冲突的情况)只需要一次检索就可以了，效率通常要高于B+tree索引  存储引擎支持\n在MySQL中，支持hash索引的是Memory存储引擎。 而InnoDB中具有自适应hash功能，hash索引是InnoDB存储引擎根据B+Tree索引在指定条件下自动构建的。\n索引类型 主键索引 数据表的主键列使用的就是主键索引。\n一张数据表有只能有一个主键，并且主键不能为 null，不能重复。\n在 MySQL 的 InnoDB 的表中，当没有显示的指定表的主键时，InnoDB 会自动先检查表中是否有唯一索引且不允许存在null值的字段，如果有，则选择该字段为默认的主键，否则 InnoDB 将会自动创建一个 6Byte 的自增主键（rowid）。\n辅助索引 二级索引又称为辅助索引，是因为二级索引的叶子节点存储的数据是主键。也就是说，通过二级索引，可以定位主键的位置。\n唯一索引，普通索引，前缀索引等索引属于二级索引。\n 唯一索引(Unique Key) ：唯一索引也是一种约束。唯一索引的属性列不能出现重复的数据，但是允许数据为 NULL，一张表允许创建多个唯一索引。 建立唯一索引的目的大部分时候都是为了该属性列的数据的唯一性，而不是为了查询效率。 普通索引(Index) ：普通索引的唯一作用就是为了快速查询数据，一张表允许创建多个普通索引，并允许数据重复和 NULL。 前缀索引(Prefix) ：前缀索引只适用于字符串类型的数据。前缀索引是对文本的前几个字符创建索引，相比普通索引建立的数据更小， 因为只取前几个字符。 全文索引(Full Text) ：全文索引主要是为了检索大文本数据中的关键字的信息，是目前搜索引擎数据库使用的一种技术。Mysql5.6 之前只有 MYISAM 引擎支持全文索引，5.6 之后 InnoDB 也支持了全文索引。  聚集索引与非聚集索引 聚集索引 聚集索引即索引结构和数据一起存放的索引。主键索引属于聚集索引。\n在 MySQL 中，InnoDB 引擎的表的 .ibd文件就包含了该表的索引和数据，对于 InnoDB 引擎表来说，该表的索引(B+树)的每个非叶子节点存储索引，叶子节点存储索引和索引对应的数据。\n聚集索引的优点 聚集索引的查询速度非常的快，因为整个 B+树本身就是一颗多叉平衡树，叶子节点也都是有序的，定位到索引的节点，就相当于定位到了数据。\n聚集索引的缺点  依赖于有序的数据 ：因为 B+树是多路平衡树，如果索引的数据不是有序的，那么就需要在插入时排序，如果数据是整型还好，否则类似于字符串或 UUID 这种又长又难比较的数据，插入或查找的速度肯定比较慢。 更新代价大 ： 如果对索引列的数据被修改时，那么对应的索引也将会被修改，而且聚集索引的叶子节点还存放着数据，修改代价肯定是较大的，所以对于主键索引来说，主键一般都是不可被修改的。  非聚集索引 非聚集索引即索引结构和数据分开存放的索引。\n二级索引属于非聚集索引。\n非聚集索引的叶子节点并不一定存放数据的指针，因为二级索引的叶子节点就存放的是主键，根据主键再回表查数据。\n非聚集索引的优点 更新代价比聚集索引要小 。非聚集索引的更新代价就没有聚集索引那么大了，非聚集索引的叶子节点是不存放数据的\n非聚集索引的缺点  跟聚集索引一样，非聚集索引也依赖于有序的数据 可能会二次查询(回表) :这应该是非聚集索引最大的缺点了。 当查到索引对应的指针或主键后，可能还需要根据指针或主键再到数据文件或表中查询。  InnoDB主键索引的B+Tree高度 索引B+树的组织方式是：主键索引树是按照聚簇索引的方式，即叶子节点存数据，非叶子节点存线索，也就是说，一张Innodb表一定会有一棵主键索引树。并且非叶子节点的大小保持相等等于16K**(为了IO方便，一次IO从磁盘读取一个page的大小，写入的时候也是一次IO写入一个page的大小)**。所以有了这个，B+树上的节点的大小就是确定的，就是16K了，而B+树是一个m-n排序树，所以一个节点就是主键ID+指针(指向孩子节点的指针)构成的。\n 非叶子节点：存的就是主键索引的线索。 叶子节点：注意并不是所有的行数据都在叶子节点上，只是父节点中线索指向的那些节点在树上，如上图，两个灰色的其实就不再树上。  所以，叶子节点是个链表，理论上可以无限大，但是非叶子节点就是一个16k大小的page，所以对于一棵树能存多少数据，主要就看非叶节点能存下多少个[主键ID+指针]了。\n计算 一行数据大小为1k，一页中可以存储16行这样的数据。InnoDB的指针占用6个字节的空间，主键即使为bigint，占用字节数为8。\n高度为2：\nn * 8 + (n + 1) * 6 = 16 * 1024 , 算出n约为 1170\n1171 * 16 = 18736\n也就是说，如果树的高度为2，则可以存储 18000 多条记录。\n高度为3：\n1171 * 1171 * 16 = 21939856\n也就是说，如果树的高度为3，则可以存储 2200w 左右的记录。\n自增主键的优点 如果表使用自增主键，那么每次插入新的记录，记录就会顺序添加到当前索引节点的后续位置，当一页写满，就会自动开辟一个新的页。如果不是自增主键，那么可能会在中间插入，学过数据结构的同学都知道，在中间插入，B+树为了维持平衡，引起B+树的节点分裂。总的来说用自增主键是可以提高查询和插入的性能。\n索引语法 创建索引 1  CREATE[UNIQUE|FULLTEXT]INDEXindex_nameONtable_name(index_col_name,...);  查看索引 1  SHOWINDEXFROMtable_name;  删除索引 1  DROPINDEXindex_nameONtable_name;  创建联合索引 1  CREATEINDEXidx_user_pro_age_staONtb_user(profession,age,status);  数据库性能分析 SQL执行频率 MySQL 客户端连接成功后，通过 show [session|global] status 命令可以提供服务器状态信息。通过如下指令，可以查看当前数据库的INSERT、UPDATE、DELETE、SELECT的访问频次：\n1 2 3  -- session 是查看当前会话 ; -- global 是查询全局数据 ; SHOWGLOBALSTATUSLIKE\u0026#39;Com_______\u0026#39;;   Com_delete: 删除次数 Com_insert: 插入次数 Com_select: 查询次数 Com_update: 更新次数  通过上述指令，我们可以查看到当前数据库到底是以查询为主，还是以增删改为主，从而为数据库优化提供参考依据。 如果是以增删改为主，我们可以考虑不对其进行索引的优化。 如果是以查询为主，那么就要考虑对数据库的索引进行优化了。\n慢日志查询 慢查询日志记录了所有执行时间超过指定参数（long_query_time，单位：秒，默认10秒）的所有SQL语句的日志。\nMySQL的慢查询日志默认没有开启，我们可以查看一下系统变量 slow_query_log。\n如果要开启慢查询日志，需要在MySQL的配置文件（/etc/my.cnf）中配置如下信息：\n1 2 3 4  #开启MySQL慢日志查询开关slow_query_log=1#设置慢日志的时间为2秒，SQL语句执行时间超过2秒，就会视为慢查询，记录慢查询日志long_query_time=2  配置完毕之后，通过以下指令重新启动MySQL服务器进行测试，查看慢日志文件中记录的信息/var/lib/mysql/localhost-slow.log。\n那这样，通过慢查询日志，就可以定位出执行效率比较低的SQL，从而有针对性的进行优化。\nprofile详情 show profiles 能够在做SQL优化时帮助我们了解时间都耗费到哪里去了。通过have_profiling参数，能够看到当前MySQL是否支持profile操作：\n1  SELECT@@have_profiling;  可以看到，当前MySQL是支持 profile操作的，但是开关是关闭的。可以通过set语句在session/global级别开启profiling：\n1  SETprofiling=1;  执行一系列的业务SQL的操作，然后通过如下指令查看指令的执行耗时：\n1 2 3 4 5 6  -- 查看每一条SQL的耗时基本情况 showprofiles;-- 查看指定query_id的SQL语句各个阶段的耗时情况 showprofileforqueryquery_id;-- 查看指定query_id的SQL语句CPU的使用情况 showprofilecpuforqueryquery_id;  查看每一条SQL的耗时情况\n查看指定SQL各个阶段的耗时情况 :\nexplain EXPLAIN 或者 DESC命令获取 MySQL 如何执行 SELECT 语句的信息，包括在 SELECT 语句执行过程中表如何连接和连接的顺序。\n语法：\n1 2  -- 直接在select语句之前加上关键字 explain / desc EXPLAINSELECT字段列表FROM表名WHERE条件;  Explain 执行计划中各个字段的含义：\n   字段 含义     id select查询的序列号，表示查询中执行select子句或者是操作表的顺序(id相同，执行顺序从上到下；id不同，值越大，越先执行)。   select_type 表示 SELECT 的类型，常见的取值有 SIMPLE（简单表，即不使用表连接或者子查询）、PRIMARY（主查询，即外层的查询）、UNION（UNION 中的第二个或者后面的查询语句）、SUBQUERY（SELECT/WHERE之后包含了子查询）等   type 表示连接类型，性能由好到差的连接类型为NULL、system、const、eq_ref、ref、range、 index、all 。   possible_key 显示可能应用在这张表上的索引，一个或多个。   key 实际使用的索引，如果为NULL，则没有使用索引。   key_len 表示索引中使用的字节数， 该值为索引字段最大可能长度，并非实际使用长度，在不损失精确性的前提下， 长度越短越好 。   rows MySQL认为必须要执行查询的行数，在innodb引擎的表中，是一个估计值，可能并不总是准确的。   filtered 表示返回结果的行数占需读取行数的百分比， filtered 的值越大越好。    最左前缀法则 如果索引了多列（联合索引），要遵守最左前缀法则。最左前缀法则指的是查询从索引的最左列开始，并且不跳过索引中的列。如果跳跃某一列，索引将会部分失效(后面的字段索引失效)。\n最左前缀法则中指的最左边的列，是指在查询时，联合索引的最左边的字段(即是第一个字段)必须存在，与我们编写SQL时，条件编写的先后顺序无关。例如用and链接起来的where条件不分顺序，只要存在就可以命中索引\n索引失效 范围查询 联合索引中，出现范围查询(\u0026gt;,\u0026lt;)，范围查询右侧的列索引失效。当范围查询使用\u0026gt;= 或 \u0026lt;= 时，走联合索引了，就说明所有的字段都是走索引的。\n尽可能的使用类似于 \u0026gt;= 或 \u0026lt;= 这类的范围查询，而避免使用 \u0026gt; 或 \u0026lt;\n索引列运算 不要在索引列上进行运算操作， 索引将失效。\n例如：\n1  explainselect*fromtb_userwheresubstring(phone,10,2)=\u0026#39;15\u0026#39;;  字符串不加引号 字符串类型字段使用时，不加引号，索引将失效。\n如果字符串不加单引号，对于查询结果，没什么影响，但是数据库存在隐式类型转换，索引将失效。\n模糊查询 如果仅仅是尾部模糊匹配，索引不会失效。如果是头部模糊匹配，索引失效。\n1 2 3  explainselect*fromtb_userwhereprofessionlike\u0026#39;软件%\u0026#39;;#索引生效explainselect*fromtb_userwhereprofessionlike\u0026#39;%工程\u0026#39;;#索引失效explainselect*fromtb_userwhereprofessionlike\u0026#39;%工%\u0026#39;;#索引失效  or连接条件 用or分割开的条件， 如果or前的条件中的列有索引，而后面的列中没有索引，那么涉及的索引都不会被用到。\n当or连接的条件，左右两侧字段都有索引时，索引才会生效。\n数据分布影响 如果MySQL评估使用索引比全表更慢，则不使用索引\n覆盖索引 尽量使用覆盖索引，减少 select *。 那么什么是覆盖索引呢？ 覆盖索引是指 查询使用了索引，并且需要返回的列，在该索引中已经全部能够找到 。\n从上述的执行计划我们可以看到，这四条SQL语句的执行计划前面所有的指标都是一样的，看不出来差异。但是此时，我们主要关注的是后面的Extra，前面两天SQL的结果为 Using where; UsingIndex ; 而后面两条SQL的结果为: Using index condition 。\n   Extra 含义     using where；Using Index 查找使用了索引，但是需要的数据都在索引列中能找到，所以不需要回表查询数据   Using index condition 查找使用了索引，但是需要徽标查询数据    索引下推（MySQL5.6及以上版本） 当使用联合索引，查询条件满足最左匹配原则，但是因为注入模糊匹配之类的条件导致后面的索引字段匹配不上，只能使用部分索引进行查询，这时候就需要大量的回表，来匹配出最终的结果。\n索引下推就是在引擎层面会先筛选出匹配条件再回表，减少回表次数。提高查询效率。\nMySQL索引下推，原来这么简单！ - 墨天轮 (modb.pro)\n","date":"2022-07-22T20:30:17+08:00","permalink":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%8602-%E7%B4%A2%E5%BC%95/","title":"MySQL底层原理02 索引"},{"content":"MySQL架构 MySQL架构图：\n一条 SQL 语句在 MySQL 中如何被执行的? | JavaGuide\n存储引擎 存储引擎就是存储数据、建立索引、更新/查询数据等技术的实现方式 。存储引擎是基于表的，而不是基于库的，所以存储引擎也可被称为表类型。我们可以在创建表的时候，来指定选择的存储引擎，如果没有指定将自动选择默认的存储引擎。\n 建表时指定存储引擎  1 2 3 4 5  CREATETABLE表名(字段1字段1类型[COMMENT字段1注释],......字段n字段n类型[COMMENT字段n注释])ENGINE=INNODB[COMMENT表注释];  查询当前数据库支持的存储引擎  1  showengines;  InnoDB 介绍 InnoDB是一种兼顾高可靠性和高性能的通用存储引擎，在 MySQL 5.5 之后，InnoDB是默认的MySQL 存储引擎\n特点  DML操作遵循ACID模型，支持事务； 行级锁，提高并发访问性能； 支持外键FOREIGN KEY约束，保证数据的完整性和正确性；  文件 xxx.ibd：xxx代表的是表名，innoDB引擎的每张表都会对应这样一个表空间文件，存储该表的表结构（frm-早期的 、sdi-新版的）、数据和索引。\n参数：innodb_file_per_table\n如果该参数开启，代表对于InnoDB引擎的表，每一张表都对应一个ibd文件。 我们直接打开MySQL的数据存放目录： C:\\ProgramData\\MySQL\\MySQL Server 8.0\\Data ， 这个目录下有很多文件夹，不同的文件夹代表不同的数据库，我们直接打开对应数据库的文件夹。\n可以看到里面有很多的ibd文件，每一个ibd文件就对应一张表，比如：我们有一张表 account，就有这样的一个account.ibd文件，而在这个ibd文件中不仅存放表结构、数据，还会存放该表对应的索引信息。 而该文件是基于二进制存储的，不能直接基于记事本打开，我们可以使用mysql提供的一个指令 ibd2sdi ，通过该指令就可以从ibd文件中提取sdi信息，而sdi数据字典信息中就包含该表的表结构。\n逻辑存储结构  表空间 : InnoDB存储引擎逻辑结构的最高层，ibd文件其实就是表空间文件，在表空间中可以包含多个Segment段。 段 : 表空间是由各个段组成的， 常见的段有数据段、索引段、回滚段等。InnoDB中对于段的管理，都是引擎自身完成，不需要人为对其控制，一个段中包含多个区。 区 : 区是表空间的单元结构，每个区的大小为1M。 默认情况下， InnoDB存储引擎页大小为16K， 即一个区中一共有64个连续的页。 页 : 页是组成区的最小单元，页也是InnoDB 存储引擎磁盘管理的最小单元，每个页的大小默认为 16KB。为了保证页的连续性，InnoDB 存储引擎每次从磁盘申请 4-5 个区。 行 : InnoDB 存储引擎是面向行的，也就是说数据是按行进行存放的，在每一行中除了定义表时所指定的字段以外，还包含两个隐藏字段(MVCC中用到)。  MyISAM 介绍 MyISAM是MySQL早期的默认存储引擎。\n特点  不支持事务，不支持外键 支持表锁，不支持行锁 访问速度快  文件  xxx.sdi：存储表结构信息 xxx.MYD: 存储数据 xxx.MYI: 存储索引  Memory 介绍 Memory引擎的表数据时存储在内存中的，由于受到硬件问题、或断电问题的影响，只能将这些表作为临时表或缓存使用。\n特点 内存存放，hash索引（默认）\n文件 xxx.sdi：存储表结构信息\nInnoDB引擎与MyISAM引擎的区别 ?  InnoDB引擎, 支持事务, 而MyISAM不支持。 InnoDB引擎, 支持行锁和表锁, 而MyISAM仅支持表锁, 不支持行锁（自然也不支持MVCC）。 InnoDB引擎, 支持外键, 而MyISAM是不支持的。 是否支持数据库异常崩溃后的安全恢复：MyISAM 不支持，而 InnoDB 支持。使用 InnoDB 的数据库在异常崩溃后，数据库重新启动的时候会保证数据库恢复到崩溃前的状态。这个恢复的过程依赖于 redo log 。  存储引擎选择 在选择存储引擎时，应该根据应用系统的特点选择合适的存储引擎。对于复杂的应用系统，还可以根据实际情况选择多种存储引擎进行组合。\n InnoDB: 是Mysql的默认存储引擎，支持事务、外键。如果应用对事务的完整性有比较高的要求，在并发条件下要求数据的一致性，数据操作除了插入和查询之外，还包含很多的更新、删除操作，那么InnoDB存储引擎是比较合适的选择。 MyISAM ： 如果应用是以读操作和插入操作为主，只有很少的更新和删除操作，并且对事务的完整性、并发性要求不是很高，那么选择这个存储引擎是非常合适的。 MEMORY：将所有数据保存在内存中，访问速度快，通常用于临时表及缓存。MEMORY的缺陷就是对表的大小有限制，太大的表无法缓存在内存中，而且无法保障数据的安全性。  ","date":"2022-07-22T19:33:47+08:00","permalink":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%8601-%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/","title":"MySQL底层原理01-存储引擎"},{"content":"SQL分类    分类 全称 说明     DDL Data Definition Language 数据定义语言，用来定义数据库对象（数据库，表，字段）   DML Data Manipulation Language 数据操作语言，用来对数据库表中的数据进行增删改   DQL Data Query Language 数据查询语言，用来查询数据库中表的记录   DCL Data Control Language 数据控制语言，用来创建数据库用户、控制数据库的范围权限    创建和操纵表 创建表 1 2 3 4 5 6 7 8 9 10 11  CREATETABLEmytable(#int类型，不为空，自增idINTNOTNULLAUTO_INCREMENT,#int类型，不可为空，默认值为1，不为空col1INTNOTNULLDEFAULT1,#变长字符串类型，最长为45个字符，可以为空col2VARCHAR(45)NULL,#日期类型，可为空col3DATENULL,#设置主键为idPRIMARYKEY(`id`));  修改表 添加列\n1 2  ALTERTABLEmytableADDcolCHAR(20);  删除列\n1 2  ALTERTABLEmytableDROPCOLUMNcol;  删除表\n1  DROPTABLEmytable;  表的增删改 插入 普通插入\n1 2  INSERTINTOmytable(col1,col2)VALUES(val1,val2);  插入检索出来的数据\n1 2 3  INSERTINTOmytable1(col1,col2)SELECTcol1,col2FROMmytable2;  将一个表的内容插入到一个新表\n1 2  CREATETABLEnewtableASSELECT*FROMmytable;  更新 1 2 3  UPDATEmytableSETcol=valWHEREid=1;  删除 1 2  DELETEFROMmytableWHEREid=1;  TRUNCATE TABLE 可以清空表，也就是删除所有行。\n1  TRUNCATETABLEmytable;   truncate 是删除表再创建，delete 是逐条删除 truncate 重置auto_increment的值。而delete不会 runcate 不知道删除了几条，而delete知道。  使用更新和删除操作时一定要用 WHERE 子句，不然会把整张表的数据都破坏。可以先用 SELECT 语句进行测试，防止错误删除。\n检索：SELECT 检索单个列：DISTINCT 相同值只会出现一次。它作用于所有列，也就是说所有列的值都相同才算相同。\n1 2  SELECTDISTINCTcol1,col2FROMmytable;  限制结果：LIMIT 限制返回的行数。可以有两个参数，第一个参数为起始行，从 0 开始；第二个参数为返回的总行数。\n返回前 5 行：\n1 2 3 4 5 6  SELECT*FROMmytableLIMIT5;SELECT*FROMmytableLIMIT0,5;  返回第 3 ~ 5 行：\n1 2 3  SELECT*FROMmytableLIMIT2,3;  MySQL 5支持LIMIT的另一种替代语法。LIMIT 4 OFFSET 3 意为从行3开始取4行，就像 LIMIT 3, 4 一样。\n排序检索数据：ORDER BY 检索出的数据并不是以纯粹的随机顺序显示的。如果不排序，数据一般将以它在底层表中出现的顺序显示\n ASC ：升序（默认） DESC ：降序  可以按多个列进行排序，并且为每个列指定不同的排序方式：\n1 2 3  SELECT*FROMmytableORDERBYcol1DESC,col2ASC;  通过非选择列进行排序 ：通常，ORDER BY子句中使用的列将是为显示所选择的列。但是，实际上并不一定要这样，用非检索的列排序数据是完全合法的。\nRDER BY子句的位置 ：在给出ORDER BY子句时，应该保证它位于 FROM 子句和 WHERE 子句之后。如果使用LIMIT，它必须位于ORDER BY之后。使用子句的次序不对将产生错误消息。\n按照多个列排序 经常需要按不止一个列进行数据排序。例如，如果要显示雇员清单，可能希望按姓和名排序（首先按姓排序，然后在每个姓中再按名排序）。如果多个雇员具有相同的姓，这样做很有用。\n为了按多个列排序，只要指定列名，列名之间用逗号分开即可（就像选择多个列时所做的那样）。\n1 2 3  SELECTprod_id,prod_price,prod_nameFROmproductsORDERBYprod_price,prod_name  在多个列上降序排序 ：DESC关键字只应用到直接位于其前面的列名，如果想在多个列上进行降序排序，必须对每个列指定DESC关键字。\n区分大小写和排序顺序 ：在对文本性的数据进行排序时，A与a相同吗？a位于B之前还是位于Z之后？这些问题不是理论问题，其答案取决于数据库如何设置。在字典（dictionary）排序顺序中，A被视为与a相同，这是MySQL（和大多数数据库管理系统）的默认行为。但是，许多数据库管理员能够在需要时改变这种行为（如果你的数据库包含大量外语字符，可能必须这样做）。\n过滤数据：WHERE 不进行过滤的数据非常大，导致通过网络传输了多余的数据，从而浪费了网络带宽。因此尽量使用 SQL 语句来过滤不必要的数据，而不是传输所有的数据到客户端中然后由客户端进行过滤。\n1 2 3  SELECT*FROMmytableWHEREcolISNULL;  下表显示了 WHERE 子句可用的操作符\n   操作符 说明     = 等于   \u0026lt; 小于   \u0026gt; 大于   \u0026lt;\u0026gt; 不等于   != 不等于   \u0026lt;= 小于等于   \u0026gt;= 大于等于   BETWEEN AND 在两个值之间   IS NULL 为 NULL 值    应该注意到，NULL 与 0、空字符串都不同。\nMySQL在执行匹配时默认不区分大小写\nAND 和 OR 用于连接多个过滤条件。优先处理 AND，当一个过滤表达式涉及到多个 AND 和 OR 时，可以使用 () 来决定优先级，使得优先级关系更清晰。\nIN 操作符用于匹配一组值，其后也可以接一个 SELECT 子句，从而匹配子查询得到的一组值。\nNOT 操作符用于否定一个条件：NOT IN，NOT BETWEEN， NOT EXISTS。\n何时使用引号 有的值括在单引号内，而有的值未括起来。单引号用来限定字符串。如果将值与串类型的列进行比较，则需要限定引号。用来与数值列进行比较的值不用引号。\n通配符（区分大小写 ） 通配符也是用在过滤语句中，但它只能用于文本字段。\n % 匹配 \u0026gt;=0 个任意字符； _ 匹配 ==1 个任意字符；  可以匹配集合内的字符，例如 [ab] 将匹配字符 a 或者 b。用脱字符 ^ 可以对其进行否定，也就是不匹配集合内的字符。  使用 Like 来进行通配符匹配。\n1 2 3  SELECT*FROMmytableWHEREcolLIKE\u0026#39;[^AB]%\u0026#39;;-- 不以 A 和 B 开头的任意文本   虽然似乎%通配符可以匹配任何东西，但有一个例外，即NULL。即使是WHERE prod_name LIKE \u0026lsquo;%\u0026lsquo;也不能匹配用值NULL作为产品名的行。\n不要滥用通配符，通配符位于开头处匹配会非常慢。\n正则表达式匹配 除关键字LIKE被REGEXP替代外，语句看上去非常像使用LIKE\n在LIKE和REGEXP之间有一个重要的差别：\n LIKE匹配整个列。如果被匹配的文本在列值中出现（值不相等，只是包含关系），LIKE将不会找到它，相应的行也不被返回（除非使用通配符）。 而REGEXP在列值内进行匹配，如果被匹配的文本在列值中出现，REGEXP将会找到它，相应的行将被返回。这是一个非常重要的差别。  不区分大小写\nMySQL中的正则表达式匹配（自版本3.23.4后）不区分大小写（即，大写和小写都匹配）。为区分大小写，可使用BINARY关键字，如\nWHERE prod_name REGEXP BINARY 'JetPack .000'\nOR匹配 1000 | 2000：匹配1000或者2000\n匹配几个字符之一 [123]：与 1|2|3 功能相同\n匹配范围 [0-9] = [0123456789]：匹配任意数字\n[a-z]匹配任意字母字符\n匹配特殊字符 要用 \\\\ 来转义特殊字符\n匹配多个实例    元字符 说明     * 0个或多个匹配   + 1个或多个匹配（等于{1,}）   ？ 0个或1个匹配（等于{0,1}）   {n} 指定数目的匹配   {n,} 不少于指定数目的匹配   {n,m} 匹配i数目的范围（m不超过255）    定位符    元字符 说明     ^ 文本的开始   $ 文本的结尾   [[:\u0026lt;:]] 词的开始   [[:\u0026gt;:]] 词的结尾    使REGEXP起类似LIKE的作用\n本章前面说过，LIKE和REGEXP的不同在于，LIKE匹配整个串而REGEXP匹配子串。利用定位符，通过用^开始每个表达式，用$结束每个表达式，可以使REGEXP的作用与LIKE一样。\n测试正则表达式 简单的正则表达式测试 可以在不使用数据库表的情况下用SELECT来测试正则表达式。REGEXP检查总是返回0（没有匹配）或1（匹配）。可以用带文字串的REGEXP来测试表达式，并试验它们。相应的语法如下：\n1  SELECT\u0026#39;hello\u0026#39;REGEXP\u0026#39;[0-9]\u0026#39;;  这个例子显然将返回0（因为文本hello中没有数字）。\n计算字段 拼接字段 在数据库服务器上完成数据的转换和格式化的工作往往比客户端上快得多，并且转换和格式化后的数据量更少的话可以减少网络通信量。\n计算字段通常需要使用 AS 来取别名，否则输出的时候字段名为计算表达式。\n1 2  SELECTcol1*col2ASaliasFROMmytable;  CONCAT() 用于连接两个字段。许多数据库会使用空格把一个值填充为列宽，因此连接的结果会出现一些不必要的空格，使用 TRIM() 可以去除首尾空格。\n1 2  SELECTCONCAT(TRIM(col1),\u0026#39;(\u0026#39;,TRIM(col2),\u0026#39;)\u0026#39;)ASconcat_colFROMmytable;  执行算术计算 1 2  SELECTcol1*col2AScompute_colFROMmytable;  支持：+、-、 *、 /\n各个 DBMS 的函数都是不相同的，因此不可移植，以下主要是 MySQL 的函数。\n函数 聚集函数 各个 DBMS 的函数都是不相同的，因此不可移植，以下主要是 MySQL 的函数。\n   函 数 说 明 补充     AVG() 返回某列的平均值 AVG()只能用来确定特定数值列的平均值，而且列名必须作为函数参数给出，忽略列值为NULL的行   COUNT() 返回某列的行数 如果指定列名，则指定列的值为空的行被COUNT()函数忽略，但如果COUNT()函数中用的是星号（*），则不忽略。   MAX() 返回某列的最大值 MAX()函数忽略列值为NULL的行。   MIN() 返回某列的最小值 MIN()函数忽略列值为NULL的行。   SUM() 返回某列值之和 SUM()函数忽略列值为NULL的行；利用标准的算术操作符，所有聚集函数都可用来执行多个列上的计算，例如：SELECT SUM(item_price*item_quantity)    AVG() 会忽略 NULL 行。\n使用 DISTINCT 可以汇总不同的值。\n1 2  SELECTAVG(DISTINCTcol1)ASavg_colFROMmytable;  文本处理    函数 说明     LEFT() 左边的字符   RIGHT() 右边的字符   LOWER() 转换为小写字符   UPPER() 转换为大写字符   LTRIM() 去除左边的空格   RTRIM() 去除右边的空格   LENGTH() 长度   SOUNDEX() 转换为语音值    其中， SOUNDEX() 可以将一个字符串转换为描述其语音表示的字母数字模式。\n1 2 3  SELECT*FROMmytableWHERESOUNDEX(col1)=SOUNDEX(\u0026#39;apple\u0026#39;)  日期和时间处理  日期格式：YYYY-MM-DD 时间格式：HH:MM:SS     函 数 说 明     ADDDATE() 增加一个日期（天、周等）   ADDTIME() 增加一个时间（时、分等）   CURDATE() 返回当前日期   CURTIME() 返回当前时间   DATE() 返回日期时间的日期部分   DATEDIFF() 计算两个日期之差   DATE_ADD() 高度灵活的日期运算函数   DATE_FORMAT() 返回一个格式化的日期或时间串   DAY() 返回一个日期的天数部分   DAYOFWEEK() 对于一个日期，返回对应的星期几   HOUR() 返回一个时间的小时部分   MINUTE() 返回一个时间的分钟部分   MONTH() 返回一个日期的月份部分   NOW() 返回当前日期和时间   SECOND() 返回一个时间的秒部分   TIME() 返回一个日期时间的时间部分   YEAR() 返回一个日期的年份部分    1 2  mysql\u0026gt;SELECTNOW();2018-4-1420:25:11  数值处理    函数 说明     SIN() 正弦   COS() 余弦   TAN() 正切   ABS() 绝对值   SQRT() 平方根   MOD() 余数   EXP() 指数   PI() 圆周率   RAND() 随机数    分组：GROUP BY 把具有相同的数据值的行放在同一组中。\n可以对同一分组数据使用汇总函数进行处理，例如求分组数据的平均值等。\n指定的分组字段除了能按该字段进行分组，也会自动按该字段进行排序。\n1 2 3  SELECTcol,COUNT(*)ASnumFROMmytableGROUPBYcol;  GROUP BY 自动按分组字段进行排序，ORDER BY 也可以按汇总字段来进行排序。\n1 2 3 4  SELECTcol,COUNT(*)ASnumFROMmytableGROUPBYcolORDERBYnum;  WHERE 过滤行，HAVING 过滤分组，行过滤应当先于分组过滤。\n1 2 3 4 5  SELECTcol,COUNT(*)ASnumFROMmytableWHEREcol\u0026gt;2GROUPBYcolHAVINGnum\u0026gt;=2;  分组规定：\n GROUP BY 子句出现在 WHERE 子句之后，ORDER BY 子句之前； 除了聚集字段外，SELECT 语句中的每一字段都必须在 GROUP BY 子句中给出（因为查询结果是按照分组来展示的，每个分组作为一行，那么如果SELECT有非聚集字段，那么查询结果怎么展示？展示的是某一条？还是？所以所有查询字段都要聚集） NULL 的行会单独分为一组； 大多数 SQL 实现不支持 GROUP BY 列具有可变长度的数据类型。  SELECT子句顺序  SELECT FROM WHERE GROUP BY HAVING ORDER BY LIMIT  子查询 子查询中只能返回一个字段的数据。\n可以将子查询的结果作为 WHRER 语句的过滤条件：\n1 2 3 4  SELECT*FROMmytable1WHEREcol1IN(SELECTcol2FROMmytable2);  下面的语句可以检索出客户的订单数量，子查询语句会对第一个查询检索出的每个客户执行一次：\n1 2 3 4 5 6  SELECTcust_name,(SELECTCOUNT(*)FROMOrdersWHEREOrders.cust_id=Customers.cust_id)ASorders_numFROMCustomersORDERBYcust_name;  连接 连接用于连接多个表，使用 JOIN 关键字，并且条件语句使用 ON 而不是 WHERE。\n连接可以替换子查询，并且比子查询的效率一般会更快。\n可以用 AS 给列名、计算字段和表名取别名，给表名取别名是为了简化 SQL 语句以及连接相同表。\n内连接 内连接又称等值连接，使用 INNER JOIN 关键字。\n1 2 3  SELECTA.value,B.valueFROMtableaASAINNERJOINtablebASBONA.key=B.key;  可以不明确使用 INNER JOIN，而使用普通查询并在 WHERE 中将两个表中要连接的列用等值方法连接起来。\n1 2 3  SELECTA.value,B.valueFROMtableaASA,tablebASBWHEREA.key=B.key;  自连接 自连接可以看成内连接的一种，只是连接的表是自身而已。\n一张员工表，包含员工姓名和员工所属部门，要找出与 Jim 处在同一部门的所有员工姓名。\n子查询版本\n1 2 3 4 5 6  SELECTnameFROMemployeeWHEREdepartment=(SELECTdepartmentFROMemployeeWHEREname=\u0026#34;Jim\u0026#34;);  自连接版本（性能高，推荐！）\n1 2 3 4  SELECTe1.nameFROMemployeeASe1INNERJOINemployeeASe2ONe1.department=e2.departmentANDe2.name=\u0026#34;Jim\u0026#34;;  自然连接 自然连接是把同名列通过等值测试连接起来的，同名列可以有多个。\n内连接和自然连接的区别：内连接提供连接的列，而自然连接自动连接所有同名列。\n1 2  SELECTA.value,B.valueFROMtableaASANATURALJOINtablebASB;  外连接 外连接保留了没有关联的那些行。分为左外连接，右外连接以及全外连接，左外连接就是保留左表没有关联的行。\n检索所有顾客的订单信息，包括还没有订单信息的顾客。\n1 2 3  SELECTCustomers.cust_id,Customer.cust_name,Orders.order_idFROMCustomersLEFTOUTERJOINOrdersONCustomers.cust_id=Orders.cust_id;  customers 表：\n   cust_id cust_name     1 a   2 b   3 c    orders 表：\n   order_id cust_id     1 1   2 1   3 3   4 3    结果：\n   cust_id cust_name order_id     1 a 1   1 a 2   3 c 3   3 c 4   2 b Null    组合查询 使用 UNION 来组合两个查询，如果第一个查询返回 M 行，第二个查询返回 N 行，那么组合查询的结果一般为 M+N 行。\n每个查询必须包含相同的列、表达式和聚集函数。\n默认会去除相同行，如果需要保留相同行，使用 UNION ALL。\n只能包含一个 ORDER BY 子句，并且必须位于语句的最后。\n1 2 3 4 5 6 7  SELECTcolFROMmytableWHEREcol=1UNIONSELECTcolFROMmytableWHEREcol=2;  ","date":"2022-07-21T14:15:38+08:00","permalink":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql%E8%AF%AD%E6%B3%95/","title":"MySQL语法"},{"content":"","date":"2022-07-20T23:06:44+08:00","permalink":"https://isheihei.github.io/posts/tips/linux%E5%B8%B8%E8%A7%81%E5%91%BD%E4%BB%A4/","title":"Linux常见命令"},{"content":"文件系统的基本组成 Linux 最经典的一句话是：「一切皆文件」，不仅普通的文件和目录，就连块设备、管道、socket 等，也都是统一交给文件系统管理的。\nLinux 文件系统会为每个文件分配两个数据结构：索引节点（index node）和目录项（directory entry），它们主要用来记录文件的元信息和目录层次结构。\n 索引节点，也就是 inode，用来记录文件的元信息，比如 inode 编号、文件大小、访问权限、创建时间、修改时间、数据在磁盘的位置等等。索引节点是文件的唯一标识，它们之间一一对应，也同样都会被存储在硬盘中，所以索引节点同样占用磁盘空间。 目录项，也就是 dentry，用来记录文件的名字、索引节点指针以及与其他目录项的层级关联关系。多个目录项关联起来，就会形成目录结构，但它与索引节点不同的是，目录项是由内核维护的一个数据结构，不存放于磁盘，而是缓存在内存。  由于索引节点唯一标识一个文件，而目录项记录着文件的名，所以目录项和索引节点的关系是多对一，也就是说，一个文件可以有多个别字。比如，硬链接的实现就是多个目录项中的索引节点指向同一个文件。\n注意，目录也是文件，也是用索引节点唯一标识，和普通文件不同的是，普通文件在磁盘里面保存的是文件数据，而目录文件在磁盘里面保存子目录或文件。\n文件数据是如何存储在磁盘的呢？ 磁盘读写的最小单位是扇区，扇区的大小只有 512B 大小，很明显，如果每次读写都以这么小为单位，那这读写的效率会非常低。\n所以，文件系统把多个扇区组成了一个逻辑块，每次读写的最小单位就是逻辑块（数据块），Linux 中的逻辑块大小为 4KB，也就是一次性读写 8 个扇区，这将大大提高了磁盘的读写的效率。\n以上就是索引节点、目录项以及文件数据的关系，下面这个图就很好的展示了它们之间的关系：\n索引节点是存储在硬盘上的数据，那么为了加速文件的访问，通常会把索引节点加载到内存中。\n另外，磁盘进行格式化的时候，会被分成三个存储区域，分别是超级块、索引节点区和数据块区。\n 超级块，用来存储文件系统的详细信息，比如块个数、块大小、空闲块等等。 索引节点区，用来存储索引节点； 数据块区，用来存储文件或目录数据；  我们不可能把超级块和索引节点区全部加载到内存，这样内存肯定撑不住，所以只有当需要使用的时候，才将其加载进内存，它们加载进内存的时机是不同的：\n 超级块：当文件系统挂载时进入内存； 索引节点区：当文件被访问时进入内存  虚拟文件系统 文件系统的种类众多，而操作系统希望对用户提供一个统一的接口，于是在用户层与文件系统层引入了中间层，这个中间层就称为虚拟文件系统（Virtual File System，VFS）。\nVFS 定义了一组所有文件系统都支持的数据结构和标准接口，这样程序员不需要了解文件系统的工作原理，只需要了解 VFS 提供的统一接口即可。\n在 Linux 文件系统中，用户空间、系统调用、虚拟机文件系统、缓存、文件系统以及存储之间的关系如下图：\n文件的使用 我们从用户角度来看文件的话，就是我们要怎么使用文件？首先，我们得通过系统调用来打开一个文件。\n1 2 3 4 5  fd = open(name, flag); # 打开文件 ... write(fd,...); # 写数据 ... close(fd); # 关闭文件   上面简单的代码是读取一个文件的过程：\n 首先用 open 系统调用打开文件，open 的参数中包含文件的路径名和文件名。 使用 write 写数据，其中 write 使用 open 所返回的文件描述符，并不使用文件名作为参数。 使用完文件后，要用 close 系统调用关闭文件，避免资源的泄露。  我们打开了一个文件后，操作系统会跟踪进程打开的所有文件，所谓的跟踪呢，就是操作系统为每个进程维护一个打开文件表，文件表里的每一项代表「文件描述符」，所以说文件描述符是打开文件的标识。\n操作系统在打开文件表中维护着打开文件的状态和信息：\n 文件指针：系统跟踪上次读写位置作为当前文件位置指针，这种指针对打开文件的某个进程来说是唯一的； 文件打开计数器：文件关闭时，操作系统必须重用其打开文件表条目，否则表内空间不够用。因为多个进程可能打开同一个文件，所以系统在删除打开文件条目之前，必须等待最后一个进程关闭文件，该计数器跟踪打开和关闭的数量，当该计数为 0 时，系统关闭文件，删除该条目； 文件磁盘位置：绝大多数文件操作都要求系统修改文件数据，该信息保存在内存中，以免每个操作都从磁盘中读取； 访问权限：每个进程打开文件都需要有一个访问模式（创建、只读、读写、添加等），该信息保存在进程的打开文件表中，以便操作系统能允许或拒绝之后的 I/O 请求；  户和操作系统对文件的读写操作是有差异的，用户习惯以字节的方式读写文件，而操作系统则是以数据块来读写文件，那屏蔽掉这种差异的工作就是文件系统了。\n文件系统的基本操作单位是数据块。\n文件的存储 连续空间存放方式 连续空间存放方式顾名思义，文件存放在磁盘「连续的」物理空间中。这种模式下，文件的数据都是紧密相连，读写效率很高，因为一次磁盘寻道就可以读出整个文件。\n使用连续存放的方式有一个前提，必须先知道一个文件的大小，这样文件系统才会根据文件的大小在磁盘上找到一块连续的空间分配给文件。\n所以，文件头里需要指定「起始块的位置」和「长度」，有了这两个信息就可以很好的表示文件存放方式是一块连续的磁盘空间。\n注意，此处说的文件头，就类似于 Linux 的 inode。\n连续空间存放的方式虽然读写效率高，但是有「磁盘空间碎片」和「文件长度不易扩展」的缺陷。\n非连续空间存放方式 链表方式 隐式链表方式\n链表的方式存放是离散的，不用连续的，于是就可以消除磁盘碎片，可大大提高磁盘空间的利用率，同时文件的长度可以动态扩展。根据实现的方式的不同，链表可分为「隐式链表」和「显式链接」两种形式。\n文件要以「隐式链表」的方式存放的话，实现的方式是文件头要包含「第一块」和「最后一块」的位置，并且每个数据块里面留出一个指针空间，用来存放下一个数据块的位置，这样一个数据块连着一个数据块，从链头开是就可以顺着指针找到所有的数据块，所以存放的方式可以是不连续的。\n隐式链表的存放方式的缺点在于无法直接访问数据块，只能通过指针顺序访问文件，以及数据块指针消耗了一定的存储空间。隐式链接分配的稳定性较差，系统在运行过程中由于软件或者硬件错误导致链表中的指针丢失或损坏，会导致文件数据的丢失。\n显式链表方式\n取出每个磁盘块的指针，把它放在内存的一个表中，就可以解决上述隐式链表的两个不足。那么，这种实现方式是「显式链接」，它指把用于链接文件各数据块的指针，显式地存放在内存的一张链接表中，该表在整个磁盘仅设置一张，每个表项中存放链接指针，指向下一个数据块号。\n内存中的这样一个表格称为文件分配表（File Allocation Table，FAT）\n由于查找记录的过程是在内存中进行的，因而不仅显著地提高了检索速度，而且大大减少了访问磁盘的次数。但也正是整个表都存放在内存中的关系，它的主要的缺点是不适用于大磁盘。\n索引方式 链表的方式解决了连续分配的磁盘碎片和文件动态扩展的问题，但是不能有效支持直接访问（FAT除外），索引的方式可以解决这个问题。\n索引的实现是为每个文件创建一个「索引数据块」，里面存放的是指向文件数据块的指针列表，说白了就像书的目录一样，要找哪个章节的内容，看目录查就可以。\n另外，文件头需要包含指向「索引数据块」的指针，这样就可以通过文件头知道索引数据块的位置，再通过索引数据块里的索引信息找到对应的数据块。\n创建文件时，索引块的所有指针都设为空。当首次写入第 i 块时，先从空闲空间中取得一个块，再将其地址写到索引块的第 i 个条目。\n索引的方式优点在于：\n 文件的创建、增大、缩小很方便； 不会有碎片的问题； 支持顺序读写和随机读写；  由于索引数据也是存放在磁盘块的，如果文件很小，明明只需一块就可以存放的下，但还是需要额外分配一块来存放索引数据，所以缺陷之一就是存储索引带来的开销。\n如果文件很大，大到一个索引数据块放不下索引信息，这时又要如何处理大文件的存放呢？我们可以通过组合的方式，来处理大文件的存。\n先来看看链表 + 索引的组合，这种组合称为「链式索引块」，它的实现方式是在索引数据块留出一个存放下一个索引数据块的指针，于是当一个索引数据块的索引信息用完了，就可以通过指针的方式，找到下一个索引数据块的信息。那这种方式也会出现前面提到的链表方式的问题，万一某个指针损坏了，后面的数据也就会无法读取了。\n还有另外一种组合方式是索引 + 索引的方式，这种组合称为「多级索引块」，实现方式是通过一个索引块来存放多个索引数据块，一层套一层索引，像极了俄罗斯套娃是吧。\n文件存放方式对比 空闲空间管理 空闲表法 空闲表法就是为所有空闲空间建立一张表，表内容包括空闲区的第一个块号和该空闲区的块个数，注意，这个方式是连续分配的。如下图：\n当请求分配磁盘空间时，系统依次扫描空闲表里的内容，直到找到一个合适的空闲区域为止。当用户撤销一个文件时，系统回收文件空间。这时，也需顺序扫描空闲表，寻找一个空闲表条目并将释放空间的第一个物理块号及它占用的块数填到这个条目中。\n这种方法仅当有少量的空闲区时才有较好的效果。因为，如果存储空间中有着大量的小的空闲区，则空闲表变得很大，这样查询效率会很低。另外，这种分配技术适用于建立连续文件。\n空闲链表法 我们也可以使用「链表」的方式来管理空闲空间，每一个空闲块里有一个指针指向下一个空闲块，这样也能很方便的找到空闲块并管理起来。如下图：\n当创建文件需要一块或几块时，就从链头上依次取下一块或几块。反之，当回收空间时，把这些空闲块依次接到链头上。\n这种技术只要在主存中保存一个指针，令它指向第一个空闲块。其特点是简单，但不能随机访问，工作效率低，因为每当在链上增加或移动空闲块时需要做很多 I/O 操作，同时数据块的指针消耗了一定的存储空间。\n空闲表法和空闲链表法都不适合用于大型文件系统，因为这会使空闲表或空闲链表太大。\n位图法 位图是利用二进制的一位来表示磁盘中一个盘块的使用情况，磁盘上所有的盘块都有一个二进制位与之对应。\n当值为 0 时，表示对应的盘块空闲，值为 1 时，表示对应的盘块已分配。它形式如下：\n1  1111110011111110001110110111111100111 ...   在 Linux 文件系统就采用了位图的方式来管理空闲空间，不仅用于数据空闲块的管理，还用于 inode 空闲块的管理，因为 inode 也是存储在磁盘的，自然也要有对其管理。\n文件系统的结构 数据块的位图是放在磁盘块里的，假设是放在一个块里，一个块 4K，每位表示一个数据块，共可以表示 4 * 1024 * 8 = 2^15个空闲块，由于 1 个数据块是 4K 大小，那么最大可以表示的空间为 2^15 * 4 * 1024 = 2^27 个 byte，也就是 128M。\n也就是说按照上面的结构，如果采用「一个块的位图 + 一系列的块」，外加「一个块的 inode 的位图 + 一系列的 inode 的结构」能表示的最大空间也就 128M，这太少了，现在很多文件都比这个大。\n在 Linux 文件系统，把这个结构称为一个块组，那么有 N 多的块组，就能够表示 N 大的文件。\n下图给出了 Linux Ext2 整个文件系统的结构和块组的内容，文件系统都由大量块组组成，在硬盘上相继排布：\n最前面的第一个块是引导块，在系统启动时用于启用引导，接着后面就是一个一个连续的块组了，块组的内容如下：\n 超级块，包含的是文件系统的重要信息，比如 inode 总个数、块总个数、每个块组的 inode 个数、每个块组的块个数等等。 块组描述符，包含文件系统中各个块组的状态，比如块组中空闲块和 inode 的数目等，每个块组都包含了文件系统中「所有块组的组描述符信息」。 数据位图和 inode 位图， 用于表示对应的数据块或 inode 是空闲的，还是被使用中。 inode 列表，包含了块组中所有的 inode，inode 用于保存文件系统中与各个文件和目录相关的所有元数据。 数据块，包含文件的有用数据。  超级块和块组描述符表，这两个都是全局信息，而且非常的重要，这么做是有两个原因：\n 如果系统崩溃破坏了超级块或块组描述符，有关文件系统结构和内容的所有信息都会丢失。如果有冗余的副本，该信息是可能恢复的。 通过使文件和管理数据尽可能接近，减少了磁头寻道和旋转，这可以提高文件系统的性能。  目录的存储 基于 Linux 一切皆文件的设计思想，目录其实也是个文件，你甚至可以通过 vim 打开它，它也有 inode，inode 里面也是指向一些块。\n和普通文件不同的是，普通文件的块里面保存的是文件数据，而目录文件的块里面保存的是目录里面一项一项的文件信息。\n在目录文件的块中，最简单的保存格式就是列表，就是一项一项地将目录下的文件信息（如文件名、文件 inode、文件类型等）列在表里。\n列表中每一项就代表该目录下的文件的文件名和对应的 inode，通过这个 inode，就可以找到真正的文件。\n通常，第一项是「.」，表示当前目录，第二项是「..」，表示上一级目录，接下来就是一项一项的文件名和 inode。\n如果一个目录有超级多的文件，我们要想在这个目录下找文件，按照列表一项一项的找，效率就不高了。\n于是，保存目录的格式改成哈希表，对文件名进行哈希计算，把哈希值保存起来，如果我们要查找一个目录下面的文件名，可以通过名称取哈希。如果哈希能够匹配上，就说明这个文件的信息在相应的块里面。\n硬链接和软连接 有时候我们希望给某个文件取个别名，那么在 Linux 中可以通过硬链接（Hard Link） 和软链接（Symbolic Link） 的方式来实现，它们都是比较特殊的文件，但是实现方式也是不相同的。\n硬连接 硬链接是多个目录项中的「索引节点」指向一个文件，也就是指向同一个 inode，但是 inode 是不可能跨越文件系统的，每个文件系统都有各自的 inode 数据结构和列表，所以硬链接是不可用于跨文件系统的。由于多个目录项都是指向一个 inode，那么只有删除文件的所有硬链接以及源文件时，系统才会彻底删除该文件。\n软连接 软链接相当于重新创建一个文件，这个文件有独立的 inode，但是这个文件的内容是另外一个文件的路径，所以访问软链接的时候，实际上相当于访问到了另外一个文件，所以软链接是可以跨文件系统的，甚至目标文件被删除了，链接文件还是在的，只不过指向的文件找不到了而已。\n","date":"2022-07-20T20:41:40+08:00","permalink":"https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F04-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/","title":"操作系统04-文件管理"},{"content":"参考：「源码分析」— 为什么枚举是单例模式的最佳方法 \n单例模式分类  饿汉式：类加载就会导致该单实例对象被创建 懒汉式：类加载不会导致该单实例对象被创建，而是首次使用该对象时才会创建  饿汉单例 1 2 3 4 5 6 7 8 9 10  public final class Singleton { // 类加载过程的初始化阶段：clinit 在jvm层面保证了线程安全  private static final Singleton INSTANCE = new Singleton(); private Singleton() {} public static Singleton getInstance() { return INSTANCE; } }   双重检验锁懒汉单例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  public final class Singleton { private Singleton() { } private static volatileSingleton INSTANCE = null; public static Singleton getInstance() { if(INSTANCE == null) { // 这里的判断不是线程安全的  // 首次访问会同步，而之后的使用没有 synchronized  synchronized(Singleton.class) { // 这里是线程安全的判断，防止其他线程在当前线程等待锁的期间完成了初始化  if (INSTANCE == null) { INSTANCE = new Singleton(); } } } return INSTANCE; } }   静态内部类懒汉单例 1 2 3 4 5 6 7 8 9 10 11 12 13  public final class Singleton { // 静态内部类：使用时才会加载，所以是懒汉式  private static class SingletonHolder { private static final Singleton INSTANCE = new Singleton(); } private Singleton() {} public static final Singleton getInstance() { return SingletonHolder.INSTANCE; } }   破坏单例 反射破坏单例 反射攻击（非枚举类型） 1 2 3 4 5 6 7 8 9 10 11 12 13  public class ReflectAttack { public static void main(String[] args) throws Exception { Singleton instance = Singleton.getInstance(); // 获取无参的构造函数  Constructor\u0026lt;Singleton\u0026gt; constructor = Singleton.class.getDeclaredConstructor(); // 使用构造函数创建对象  constructor.setAccessible(true); Singleton reflectInstance = constructor.newInstance(); System.out.println(instance == reflectInstance); } } // output: // false   防止反射攻击 增加一个标志变量，在构造函数中检查是否已被调用过，若已被调用过，将抛出异常，保证构造函数只被调用一次：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  public class Singleton { private static Singleton instance; private static boolean isInstance = false; private Singleton() { synchronized (Singleton.class) { if (!isInstance) { isInstance = true; } else { throw new RuntimeException(\u0026#34;单例模式受到反射攻击！已成功阻止！\u0026#34;); } } } public static Singleton getInstance() { if (instance == null) { instance = new Singleton(); } return instance; } }   反序列化破坏单例 反序列化攻击（非枚举类型） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  public class DeserializeAttack { public static void main(String[] args) throws Exception { Singleton instance = Singleton.getInstance(); byte[] bytes = serialize(instance); Object deserializeInstance = deserialize(bytes); System.out.println(instance == deserializeInstance); } private static byte[] serialize(Object object) throws Exception { ByteArrayOutputStream baos = new ByteArrayOutputStream(); ObjectOutputStream oos = new ObjectOutputStream(baos); oos.writeObject(object); byte[] bytes = baos.toByteArray(); return bytes; } private static Object deserialize(byte[] bytes) throws Exception { ByteArrayInputStream bais = new ByteArrayInputStream(bytes); ObjectInputStream ois = new ObjectInputStream(bais); return ois.readObject(); } } // output: // false   防止反序列化攻击 增加一个 readResolve 方法并返回 instance 对象。当 ObjectInputStream类反序列化时，如果对象存在 readResolve 方法，则会调用该方法返回对象。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  public class Singleton implements Serializable { private static Singleton instance; private Singleton() {} public static Singleton getInstance() { if (instance == null) { instance = new Singleton(); } return instance; } private Object readResolve() { return instance; } }   枚举单例（最推荐） 不能使用反射和反序列化攻击\n1 2 3  enum Singleton { INSTANCE; }   枚举类型防止反射破坏单例的原理 1 2 3 4 5 6 7 8 9 10 11 12 13  public class ReflectAttack { public static void main(String[] args) throws Exception { EnumSingleton instance = EnumSingleton.INSTANCE; Constructor\u0026lt;EnumSingleton\u0026gt; constructor = EnumSingleton.class.getDeclaredConstructor(String.class, int.class); constructor.setAccessible(true); EnumSingleton reflectInstance = constructor.newInstance(\u0026#34;REFLECT_INSTANCE\u0026#34;, 1); System.out.println(instance == reflectInstance); } } // output: // Exception in thread \u0026#34;main\u0026#34; java.lang.IllegalArgumentException: Cannot reflectively create enum objects // at java.lang.reflect.Constructor.newInstance(Constructor.java:417) // at com.chaycao.java.ReflectAttack.main(ReflectAttack.java:16)   报错，并提示我们不能反射创建枚举对象。错误位于 Constructor的 newInstance方法，第 417 行，代码如下：\n1 2  if ((clazz.getModifiers() \u0026amp; Modifier.ENUM) != 0) throw new IllegalArgumentException(\u0026#34;Cannot reflectively create enum objects\u0026#34;);   如果该类是 ENUM 类型，则会抛出 IllegalArgumentException异常，便也阻止了反射攻击。\n枚举类型防止反序列化破坏单例的原理 序列化过程\nObjectOutputStream 的序列化方法看下 Enum 类型的序列化内容，顺着 writeobject方法找到 writeObject0方法。对于Enum 类型会执行专门的writeEnum方法进行序列化，只会序列化\n1 2 3 4 5 6 7 8 9 10 11 12 13  private void writeEnum(Enum\u0026lt;?\u0026gt; en, ObjectStreamClass desc, boolean unshared) throws IOException { // 1. ENUM类型标志（常量）：“126”  bout.writeByte(TC_ENUM); ObjectStreamClass sdesc = desc.getSuperDesc(); // 2. 完整类名：“com.chaycao.java.EnumSingleton: static final long serialVersionUID = 0L;”  writeClassDesc((sdesc.forClass() == Enum.class) ? desc : sdesc, false); handles.assign(unshared ? null : en); // 3. Enum对象的名称：“INSTANCE”  writeString(en.name(), false); }   反序列化过程\nObjectInputStream 与 ObjectOutputStream 类似，对于 Enum 类型也使用专用的 readEnum 方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  private Enum\u0026lt;?\u0026gt; readEnum(boolean unshared) throws IOException { // 1. 检查标志位  if (bin.readByte() != TC_ENUM) { throw new InternalError(); } // 2. 检查类名是否是Enum类型  ObjectStreamClass desc = readClassDesc(false); if (!desc.isEnum()) { throw new InvalidClassException(\u0026#34;non-enum class: \u0026#34; + desc); } int enumHandle = handles.assign(unshared ? unsharedMarker : null); ClassNotFoundException resolveEx = desc.getResolveException(); if (resolveEx != null) { handles.markException(enumHandle, resolveEx); } String name = readString(false); Enum\u0026lt;?\u0026gt; result = null; // 3. 加载类，并使用类的valueOf方法获取Enum对象  Class\u0026lt;?\u0026gt; cl = desc.forClass(); if (cl != null) { try { @SuppressWarnings(\u0026#34;unchecked\u0026#34;) Enum\u0026lt;?\u0026gt; en = Enum.valueOf((Class)cl, name); result = en; } catch (IllegalArgumentException ex) { throw (IOException) new InvalidObjectException( \u0026#34;enum constant \u0026#34; + name + \u0026#34; does not exist in \u0026#34; + cl).initCause(ex); } if (!unshared) { handles.setObject(enumHandle, result); } } handles.finish(enumHandle); passHandle = enumHandle; return result; }   其过程对应了之前的序列化过程，而其中最重要的便是 Enum.valueOf方法：\n1 2 3 4 5 6 7 8 9 10 11 12  public static \u0026lt;T extends Enum\u0026lt;T\u0026gt;\u0026gt; T valueOf(Class\u0026lt;T\u0026gt; enumType, String name) { // name = \u0026#34;INSTANCE\u0026#34;  // 根据名称查找  T result = enumType.enumConstantDirectory().get(name); if (result != null) return result; if (name == null) throw new NullPointerException(\u0026#34;Name is null\u0026#34;); // 没有找到，抛出异常  throw new IllegalArgumentException( \u0026#34;No enum constant \u0026#34; + enumType.getCanonicalName() + \u0026#34;.\u0026#34; + name); }   根据名称查找对象，再返回，所以仍会返回 EnumSingleton中的 INSTANCE，不会存在反序列化的危险。\n","date":"2022-07-19T21:10:02+08:00","permalink":"https://isheihei.github.io/posts/java/%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E7%9A%84%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/","title":"线程安全的单例模式"},{"content":"进程 进程的状态 进程共有五个状态\n 创建状态（new）：进程正在被创建时的状态； 就绪状态（Ready）：可运行，由于其他进程处于运行状态而暂时停止运行； 运行状态（Runing）：该时刻进程占用 CPU； 阻塞状态（Blocked）：该进程正在等待某一事件发生（如等待输入/输出操作的完成）而暂时停止运行，这时，即使给它CPU控制权，它也无法运行； 阻塞挂起状态：进程在外存（硬盘）并等待某个事件的出现； 就绪挂起状态：进程在外存（硬盘），但只要进入内存，即刻立刻运行； 结束状态（Exit）：进程正在从系统中消失时的状态；  于是，一个完整的进程状态的变迁如下图：\n再来详细说明一下进程的状态变迁：\n NULL -\u0026gt; 创建状态：一个新进程被创建时的第一个状态； 创建状态 -\u0026gt; 就绪状态：当进程被创建完成并初始化后，一切就绪准备运行时，变为就绪状态，这个过程是很快的； 就绪态 -\u0026gt; 运行状态：处于就绪状态的进程被操作系统的进程调度器选中后，就分配给 CPU 正式运行该进程； 运行状态 -\u0026gt; 结束状态：当进程已经运行完成或出错时，会被操作系统作结束状态处理； 运行状态 -\u0026gt; 就绪状态：处于运行状态的进程在运行过程中，由于分配给它的运行时间片用完，操作系统会把该进程变为就绪态，接着从就绪态选中另外一个进程运行； 运行状态 -\u0026gt; 阻塞状态：当进程请求某个事件且必须等待时，例如请求 I/O 事件； 阻塞状态 -\u0026gt; 就绪状态：当进程要等待的事件完成时，它从阻塞状态变到就绪状态；  如果有大量处于阻塞状态的进程，进程可能会占用着物理内存空间，显然不是我们所希望的，毕竟物理内存空间是有限的，被阻塞状态的进程占用着物理内存就一种浪费物理内存的行为。\n所以，在虚拟内存管理的操作系统中，通常会把阻塞状态的进程的物理内存空间换出到硬盘，等需要再次运行的时候，再从硬盘换入到物理内存。\n那么，就需要一个新的状态，来描述进程没有占用实际的物理内存空间的情况，这个状态就是挂起状态。这跟阻塞状态是不一样，阻塞状态是等待某个事件的返回。\nPCB（进程控制块） PCB 是进程存在的唯一标识，这意味着一个进程的存在，必然会有一个 PCB，如果进程消失了，那么 PCB 也会随之消失。\nPCB 具体包含信息 进程描述信息：\n 进程标识符：标识各个进程，每个进程都有一个并且唯一的标识符； 用户标识符：进程归属的用户，用户标识符主要为共享和保护服务；  进程控制和管理信息：\n 进程当前状态，如 new、ready、running、waiting 或 blocked 等； 进程优先级：进程抢占 CPU 时的优先级；  资源分配清单：\n 有关内存地址空间或虚拟地址空间的信息，所打开文件的列表和所使用的 I/O 设备信息。  CPU 相关信息：\n CPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB 中，以便进程重新执行时，能从断点处继续执行。  PCB 组织结构 通常是通过链表的方式进行组织，把具有相同状态的进程链在一起，组成各种队列。比如：\n 将所有处于就绪状态的进程链在一起，称为就绪队列； 把所有因等待某事件而处于等待状态的进程链在一起就组成各种阻塞队列； 另外，对于运行队列在单核 CPU 系统中则只有一个运行指针了，因为单核 CPU 在某个时间，只能运行一个程序。  那么，就绪队列和阻塞队列链表的组织形式如下图：\n除了链接的组织方式，还有索引方式，它的工作原理：将同一状态的进程组织在一个索引表中，索引表项指向相应的 PCB，不同状态对应不同的索引表。\n一般会选择链表，因为可能面临进程创建，销毁等调度导致进程状态发生变化，所以链表能够更加灵活的插入和删除。\n进程的控制 我们熟知了进程的状态变迁和进程的数据结构 PCB 后，再来看看进程的创建、终止、阻塞、唤醒的过程，这些过程也就是进程的控制。\n01 创建进程\n操作系统允许一个进程创建另一个进程，而且允许子进程继承父进程所拥有的资源，当子进程被终止时，其在父进程处继承的资源应当还给父进程。同时，终止父进程时同时也会终止其所有的子进程。\n注意：Linux 操作系统对于终止有子进程的父进程，会把子进程交给 1 号进程接管。本文所指出的进程终止概念是宏观操作系统的一种观点，最后怎么实现当然是看具体的操作系统。\n创建进程的过程如下：\n 为新进程分配一个唯一的进程标识号，并申请一个空白的 PCB，PCB 是有限的，若申请失败则创建失败； 为进程分配资源，此处如果资源不足，进程就会进入等待状态，以等待资源； 初始化 PCB； 如果进程的调度队列能够接纳新进程，那就将进程插入到就绪队列，等待被调度运行；  02 终止进程\n进程可以有 3 种终止方式：正常结束、异常结束以及外界干预（信号 kill 掉）。\n终止进程的过程如下：\n 查找需要终止的进程的 PCB； 如果处于执行状态，则立即终止该进程的执行，然后将 CPU 资源分配给其他进程； 如果其还有子进程，则应将其所有子进程终止； 将该进程所拥有的全部资源都归还给父进程或操作系统； 将其从 PCB 所在队列中删除；  03 阻塞进程\n当进程需要等待某一事件完成时，它可以调用阻塞语句把自己阻塞等待。而一旦被阻塞等待，它只能由另一个进程唤醒。\n阻塞进程的过程如下：\n 找到将要被阻塞进程标识号对应的 PCB； 如果该进程为运行状态，则保护其现场，将其状态转为阻塞状态，停止运行； 将该 PCB 插入到阻塞队列中去；  04 唤醒进程\n进程由「运行」转变为「阻塞」状态是由于进程必须等待某一事件的完成，所以处于阻塞状态的进程是绝对不可能叫醒自己的。\n如果某进程正在等待 I/O 事件，需由别的进程发消息给它，则只有当该进程所期待的事件出现时，才由发现者进程用唤醒语句叫醒它。\n唤醒进程的过程如下：\n 在该事件的阻塞队列中找到相应进程的 PCB； 将其从阻塞队列中移出，并置其状态为就绪状态； 把该 PCB 插入到就绪队列中，等待调度程序调度；  进程的阻塞和唤醒是一对功能相反的语句，如果某个进程调用了阻塞语句，则必有一个与之对应的唤醒语句。\n进程的上下文切换 各个进程之间是共享 CPU 资源的，在不同的时候进程之间需要切换，让不同的进程可以在 CPU 执行，那么这个一个进程切换到另一个进程运行，称为进程的上下文切换。\nCPU 上下文切换就是先把前一个任务的 CPU 上下文（CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。\n系统内核会存储保持下来的上下文信息，当此任务再次被分配给 CPU 运行时，CPU 会重新加载这些上下文，这样就能保证任务原来的状态不受影响，让任务看起来还是连续运行。\n进程是由内核管理和调度的，所以进程的切换只能发生在内核态。\n所以，进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。\n通常，会把交换的信息保存在进程的 PCB，当要运行另外一个进程的时候，我们需要从这个进程的 PCB 取出上下文，然后恢复到 CPU 中，这使得这个进程可以继续执行，如下图所示：\n 发生进程上下文切换有哪些场景？\n  为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。这样，当某个进程的时间片耗尽了，进程就从运行状态变为就绪状态，系统从就绪队列选择另外一个进程运行； 进程在系统资源不足（比如内存不足）时，要等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行； 当进程通过睡眠函数 sleep 这样的方法将自己主动挂起时，自然也会重新调度； 当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行； 发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序；  线程 什么是线程？ 线程是进程当中的一条执行流程。\n同一个进程内多个线程之间可以共享代码段、数据段、打开的文件等资源，但每个线程各自都有一套独立的寄存器和栈，这样可以确保线程的控制流是相对独立的。\n线程与进程的比较 线程与进程的比较如下：\n 进程是资源（包括内存、打开的文件等）分配的单位，线程是 CPU 调度的单位； 进程拥有一个完整的资源平台，而线程只独享必不可少的资源，如寄存器和栈； 线程同样具有就绪、阻塞、执行三种基本状态，同样具有状态之间的转换关系； 线程能减少并发执行的时间和空间开销；  对于，线程相比进程能减少开销，体现在：\n 线程的创建时间比进程快，因为进程在创建的过程中，还需要资源管理信息，比如内存管理信息、文件管理信息，而线程在创建的过程中，不会涉及这些资源管理信息，而是共享它们； 线程的终止时间比进程快，因为线程释放的资源相比进程少很多； 同一个进程内的线程切换比进程切换快，因为线程具有相同的地址空间（虚拟内存共享），这意味着同一个进程的线程都具有同一个页表，那么在切换的时候不需要切换页表。而对于进程之间的切换，切换的时候要把页表给切换掉，而页表的切换过程开销是比较大的； 由于同一进程的各线程间共享内存和文件资源，那么在线程之间数据传递的时候，就不需要经过内核了，这就使得线程之间的数据交互效率更高了；  所以，不管是时间效率，还是空间效率线程比进程都要高。\n线程的上下文切换 线程与进程最大的区别在于：线程是调度的基本单位，而进程则是资源拥有的基本单位。\n所以，所谓操作系统的任务调度，实际上的调度对象是线程，而进程只是给线程提供了虚拟内存、全局变量等资源。\n对于线程和进程，我们可以这么理解：\n 当进程只有一个线程时，可以认为进程就等于线程； 当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源，这些资源在上下文切换时是不需要修改的；  另外，线程也有自己的私有数据，比如栈和寄存器等，这些在上下文切换时也是需要保存的。\n 线程上下文切换的是什么？\n 这还得看线程是不是属于同一个进程：\n 当两个线程不是属于同一个进程，则切换的过程就跟进程上下文切换一样； 当两个线程是属于同一个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据；  所以，线程的上下文切换相比进程，开销要小很多。\n线程的实现 主要有三种线程的实现方式：\n 用户线程（User Thread）：在用户空间实现的线程，不是由内核管理的线程，是由用户态的线程库来完成线程的管理； 内核线程（Kernel Thread）：在内核中实现的线程，是由内核管理的线程； 轻量级进程（LightWeight Process）：在内核中来支持用户线程；  用户线程 用户线程是基于用户态的线程管理库来实现的，那么线程控制块（Thread Control Block, TCB） 也是在库里面来实现的，对于操作系统而言是看不到这个 TCB 的，它只能看到整个进程的 PCB。\n所以，用户线程的整个线程管理和调度，操作系统是不直接参与的，而是由用户级线程库函数来完成线程的管理，包括线程的创建、终止、同步和调度等。\n用户级线程的模型，是多对一的关系，即多个用户线程对应同一个内核线程，如下图所示：\n用户线程的优点：\n 每个进程都需要有它私有的线程控制块（TCB）列表，用来跟踪记录它各个线程状态信息（PC、栈指针、寄存器），TCB 由用户级线程库函数来维护，可用于不支持线程技术的操作系统； 用户线程的切换也是由线程库函数来完成的，无需用户态与内核态的切换，所以速度特别快；  用户线程的缺点：\n 由于操作系统不参与线程的调度，如果一个线程发起了系统调用而阻塞，那进程所包含的用户线程都不能执行了。 当一个线程开始运行后，除非它主动地交出 CPU 的使用权，否则它所在的进程当中的其他线程无法运行，因为用户态的线程没法打断当前运行中的线程，它没有这个特权，只有操作系统才有，但是用户线程不是由操作系统管理的。 由于时间片分配给进程，故与其他进程比，在多线程执行时，每个线程得到的时间片较少，执行会比较慢；  内核线程 内核线程是由操作系统管理的，线程对应的 TCB 自然是放在操作系统里的，这样线程的创建、终止和管理都是由操作系统负责。\n内核线程的模型，是一对一的关系，即一个用户线程对应一个内核线程，如下图所示：\n内核线程的优点：\n 在一个进程当中，如果某个内核线程发起系统调用而被阻塞，并不会影响其他内核线程的运行； 分配给线程，多线程的进程获得更多的 CPU 运行时间；  内核线程的缺点：\n 在支持内核线程的操作系统中，由内核来维护进程和线程的上下文信息，如 PCB 和 TCB； 线程的创建、终止和切换都是通过系统调用的方式来进行，因此对于系统来说，系统开销比较大；  轻量级进程 轻量级进程（Light-weight process，LWP）是内核支持的用户线程，一个进程可有一个或多个 LWP，每个 LWP 是跟内核线程一对一映射的，也就是 LWP 都是由一个内核线程支持。\n另外，LWP 只能由内核管理并像普通进程一样被调度，Linux 内核是支持 LWP 的典型例子。\n在大多数系统中，LWP与普通进程的区别也在于它只有一个最小的执行上下文和调度程序所需的统计信息。一般来说，一个进程代表程序的一个实例，而 LWP 代表程序的执行线程，因为一个执行线程不像进程那样需要那么多状态信息，所以 LWP 也不带有这样的信息。\n调度 调度时机 比如，以下状态的变化都会触发操作系统的调度：\n 从就绪态 -\u0026gt; 运行态：当进程被创建时，会进入到就绪队列，操作系统会从就绪队列选择一个进程运行； 从运行态 -\u0026gt; 阻塞态：当进程发生 I/O 事件而阻塞时，操作系统必须另外一个进程运行； 从运行态 -\u0026gt; 结束态：当进程退出结束后，操作系统得从就绪队列选择另外一个进程运行；  如果硬件时钟提供某个频率的周期性中断，那么可以根据如何处理时钟中断，把调度算法分为两类：\n 非抢占式调度算法挑选一个进程，然后让该进程运行直到被阻塞，或者直到该进程退出，才会调用另外一个进程，也就是说不会理时钟中断这个事情。 抢占式调度算法挑选一个进程，然后让该进程只运行某段时间，如果在该时段结束时，该进程仍然在运行时，则会把它挂起，接着调度程序从就绪队列挑选另外一个进程。这种抢占式调度处理，需要在时间间隔的末端发生时钟中断，以便把 CPU 控制返回给调度程序进行调度，也就是常说的时间片机制。  调度原则  CPU 利用率：调度程序应确保 CPU 是始终匆忙的状态，这可提高 CPU 的利用率； 系统吞吐量：吞吐量表示的是单位时间内 CPU 完成进程的数量，长作业的进程会占用较长的 CPU 资源，因此会降低吞吐量，相反，短作业的进程会提升系统吞吐量； 周转时间：周转时间是进程运行和阻塞时间总和，一个进程的周转时间越小越好； 等待时间：这个等待时间不是阻塞状态的时间，而是进程处于就绪队列的时间，等待的时间越长，用户越不满意； 响应时间：用户提交请求到系统第一次产生响应所花费的时间，在交互式系统中，响应时间是衡量调度算法好坏的主要标准。  调度算法（单核CPU） 先来先服务调度算法 最简单的一个调度算法，就是非抢占式的先来先服务（First Come First Seved, FCFS）算法了。\n顾名思义，先来后到，每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。\n这似乎很公平，但是当一个长作业先运行了，那么后面的短作业等待的时间就会很长，不利于短作业。\nFCFS 对长作业有利，适用于 CPU 繁忙型作业的系统，而不适用于 I/O 繁忙型作业的系统。\n最短作业优先调度算法 最短作业优先（Shortest Job First, SJF）调度算法同样也是顾名思义，它会优先选择运行时间最短的进程来运行，这有助于提高系统的吞吐量\n这显然对长作业不利，很容易造成一种极端现象。\n比如，一个长作业在就绪队列等待运行，而这个就绪队列有非常多的短作业，那么就会使得长作业不断的往后推，周转时间变长，致使长作业长期不会被运行。\n高响应比优先调度算法 前面的「先来先服务调度算法」和「最短作业优先调度算法」都没有很好的权衡短作业和长作业。\n那么，高响应比优先（Highest Response Ratio Next, HRRN）调度算法主要是权衡了短作业和长作业。\n每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行，「响应比优先级」的计算公式：\n从上面的公式，可以发现：\n 如果两个进程的「等待时间」相同时，「要求的服务时间」越短，「响应比」就越高，这样短作业的进程容易被选中运行； 如果两个进程「要求的服务时间」相同时，「等待时间」越长，「响应比」就越高，这就兼顾到了长作业进程，因为进程的响应比可以随时间等待的增加而提高，当其等待时间足够长时，其响应比便可以升到很高，从而获得运行的机会；  时间片轮转调度算法 最古老、最简单、最公平且使用最广的算法就是时间片轮转（Round Robin, RR）调度算法。\n每个进程被分配一个时间段，称为时间片（Quantum），即允许该进程在该时间段中运行。\n 如果时间片用完，进程还在运行，那么将会把此进程从 CPU 释放出来，并把 CPU 分配给另外一个进程； 如果该进程在时间片结束前阻塞或结束，则 CPU 立即进行切换；  另外，时间片的长度就是一个很关键的点：\n 如果时间片设得太短会导致过多的进程上下文切换，降低了 CPU 效率； 如果设得太长又可能引起对短作业进程的响应时间变长。将  一般来说，时间片设为 20ms~50ms 通常是一个比较合理的折中值。\n最高优先级调度算法 前面的「时间片轮转算法」做了个假设，即让所有的进程同等重要，也不偏袒谁，大家的运行时间都一样。\n但是，对于多用户计算机系统就有不同的看法了，它们希望调度是有优先级的，即希望调度程序能从就绪队列中选择最高优先级的进程进行运行，这称为最高优先级（Highest Priority First，HPF）调度算法。\n进程的优先级可以分为，静态优先级和动态优先级：\n 静态优先级：创建进程时候，就已经确定了优先级了，然后整个运行时间优先级都不会变化； 动态优先级：根据进程的动态变化调整优先级，比如如果进程运行时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则升高其优先级，也就是随着时间的推移增加等待进程的优先级。  该算法也有两种处理优先级高的方法，非抢占式和抢占式：\n 非抢占式：当就绪队列中出现优先级高的进程，运行完当前进程，再选择优先级高的进程。 抢占式：当就绪队列中出现优先级高的进程，当前进程挂起，调度优先级高的进程运行。  但是依然有缺点，可能会导致低优先级的进程永远不会运行。\n多级反馈队列调度算法 多级反馈队列（Multilevel Feedback Queue）调度算法是「时间片轮转算法」和「最高优先级算法」的综合和发展。\n顾名思义：\n 「多级」表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。 「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队  来看看，它是如何工作的：\n 设置了多个队列，赋予每个队列不同的优先级，每个队列优先级从高到低，同时优先级越高时间片越短； 新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成； 当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行；  可以发现，对于短作业可能可以在第一级队列很快被处理完。对于长作业，如果在第一级队列处理不完，可以移入下次队列等待被执行，虽然等待的时间变长了，但是运行时间也变更长了，所以该算法很好的兼顾了长短作业，同时有较好的响应时间。\n进程间通信 管道 匿名管道 1  $ ps auxf | grep mysql   上面命令行里的「|」竖线就是一个管道，它的功能是将前一个命令（ps auxf）的输出，作为后一个命令（grep mysql）的输入，从这功能描述，可以看出管道传输数据是单向的，如果想相互通信，我们需要创建两个管道才行。\n匿名管道是特殊的文件，只存在于内存，不存于文件系统中。\n同时，我们得知上面这种管道是没有名字，所以「|」表示的管道称为匿名管道，用完了就销毁。\n命名管道 管道还有另外一个类型是命名管道，也被叫做 FIFO，因为数据是先进先出的传输方式。\n在使用命名管道前，先需要通过 mkfifo 命令来创建，并且指定管道名字：\n1  $ mkfifo myPipe   myPipe 就是这个管道的名称，基于 Linux 一切皆文件的理念，所以命名管道也是以文件的方式存在，我们可以用 ls 看一下，这个文件的类型是 p，也就是 pipe（管道） 的意思：\n1 2  $ ls -l prw-r--r--. 1 root root 0 Jul 17 02:45 myPipe   接下来，我们往 myPipe 这个管道写入数据：\n1 2  $ echo \u0026#34;hello\u0026#34; \u0026gt; myPipe // 将数据写进管道 // 停住了 ...   你操作了后，你会发现命令执行后就停在这了，这是因为管道里的内容没有被读取，只有当管道里的数据被读完后，命令才可以正常退出。\n于是，我们执行另外一个命令来读取这个管道里的数据：\n1 2  $ cat \u0026lt; myPipe // 读取管道里的数据 hello   可以看到，管道里的内容被读取出来了，并打印在了终端上，另外一方面，echo 那个命令也正常退出了。\n管道创建的原理 匿名管道的创建，需要通过下面这个系统调用：\n1  int pipe(int fd[2])   这里表示创建一个匿名管道，并返回了两个描述符，一个是管道的读取端描述符 fd[0]，另一个是管道的写入端描述符 fd[1]。注意，这个匿名管道是特殊的文件，只存在于内存，不存于文件系统中。\n其实，所谓的管道，就是内核里面的一串缓存。从管道的一段写入的数据，实际上是缓存在内核中的，另一端读取，也就是从内核中读取这段数据。另外，管道传输的数据是无格式的流且大小受限。\n父子进程\n我们可以使用 fork 创建子进程，创建的子进程会复制父进程的文件描述符，这样就做到了两个进程各有两个「 fd[0] 与 fd[1]」，两个进程就可以通过各自的 fd 写入和读取同一个管道文件实现跨进程通信了。\n管道只能一端写入，另一端读出，所以上面这种模式容易造成混乱，因为父进程和子进程都可以同时写入，也都可以读出。那么，为了避免这种情况，通常的做法是：\n  父进程关闭读取的 fd[0]，只保留写入的 fd[1]；\n  子进程关闭写入的 fd[1]，只保留读取的 fd[0]；\n  所以说如果需要双向通信，则应该创建两个管道。\n非父子进程\n到这里，我们仅仅解析了使用管道进行父进程与子进程之间的通信，但是在我们 shell 里面并不是这样的。\n在 shell 里面执行 A | B命令的时候，A 进程和 B 进程都是 shell 创建出来的子进程，A 和 B 之间不存在父子关系，它俩的父进程都是 shell。\n所以说，在 shell 里通过「|」匿名管道将多个命令连接在一起，实际上也就是创建了多个子进程，通过关闭某些读端和写端实现两个子进程之间的通信，如图：\n我们可以得知，对于匿名管道，它的通信范围是存在父子关系的进程。因为管道没有实体，也就是没有管道文件，只能通过 fork 来复制父进程 fd 文件描述符，来达到通信的目的。\n另外，对于命名管道，它可以在不相关的进程间也能相互通信。因为命令管道，提前创建了一个类型为管道的设备文件，在进程里只要使用这个设备文件，就可以相互通信。\n不管是匿名管道还是命名管道，进程写入的数据都是缓存在内核中，另一个进程读取数据时候自然也是从内核中获取，同时通信数据都遵循先进先出原则，不支持 lseek 之类的文件定位操作。\n消息队列 前面说到管道的通信方式是效率低的，因此管道不适合进程间频繁地交换数据。\n对于这个问题，消息队列的通信模式就可以解决。比如，A 进程要给 B 进程发送消息，A 进程把数据放在对应的消息队列后就可以正常返回了，B 进程需要的时候再去读取数据就可以了。同理，B 进程要给 A 进程发送消息也是如此。\n再来，消息队列是保存在内核中的消息链表，在发送数据时，会分成一个一个独立的数据单元，也就是消息体（数据块），消息体是用户自定义的数据类型，消息的发送方和接收方要约定好消息体的数据类型，所以每个消息体都是固定大小的存储块，不像管道是无格式的字节流数据。如果进程从消息队列中读取了消息体，内核就会把这个消息体删除。\n消息队列生命周期随内核，如果没有释放消息队列或者没有关闭操作系统，消息队列会一直存在，而前面提到的匿名管道的生命周期，是随进程的创建而建立，随进程的结束而销毁。\n消息队列不适合比较大数据的传输，因为在内核中每个消息体都有一个最大长度的限制，同时所有队列所包含的全部消息体的总长度也是有上限。在 Linux 内核中，会有两个宏定义 MSGMAX 和 MSGMNB，它们以字节为单位，分别定义了一条消息的最大长度和一个队列的最大长度。\n消息队列通信过程中，存在用户态与内核态之间的数据拷贝开销，因为进程写入数据到内核中的消息队列时，会发生从用户态拷贝数据到内核态的过程，同理另一进程读取内核中的消息数据时，会发生从内核态拷贝数据到用户态的过程。\n共享内存 消息队列的读取和写入的过程，都会有发生用户态与内核态之间的消息拷贝过程。那共享内存的方式，就很好的解决了这一问题。\n现代操作系统，对于内存管理，采用的是虚拟内存技术，也就是每个进程都有自己独立的虚拟内存空间，不同进程的虚拟内存映射到不同的物理内存中。所以，即使进程 A 和 进程 B 的虚拟地址是一样的，其实访问的是不同的物理内存地址，对于数据的增删查改互不影响。\n共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中。这样这个进程写入的东西，另外一个进程马上就能看到了，都不需要拷贝来拷贝去，传来传去，大大提高了进程间通信的速度。\n信号量 用了共享内存通信方式，带来新的问题，那就是如果多个进程同时修改同一个共享内存，很有可能就冲突了。例如两个进程都同时写一个地址，那先写的那个进程会发现内容被别人覆盖了。\n为了防止多进程竞争共享资源，而造成的数据错乱，所以需要保护机制，使得共享的资源，在任意时刻只能被一个进程访问。正好，信号量就实现了这一保护机制。\n信号量其实是一个整型的计数器，主要用于实现进程间的互斥与同步，而不是用于缓存进程间通信的数据。\n信号量表示资源的数量，控制信号量的方式有两种原子操作：\n  一个是 P 操作，这个操作会把信号量减去 1，相减后如果信号量 \u0026lt; 0，则表明资源已被占用，进程需阻塞等待；相减后如果信号量 \u0026gt;= 0，则表明还有资源可使用，进程可正常继续执行。\n  另一个是 V 操作，这个操作会把信号量加上 1，相加后如果信号量 \u0026lt;= 0，则表明当前有阻塞中的进程，于是会将该进程唤醒运行；相加后如果信号量 \u0026gt; 0，则表明当前没有阻塞中的进程；\n  P 操作是用在进入共享资源之前，V 操作是用在离开共享资源之后，这两个操作是必须成对出现的。\n接下来，举个例子，如果要使得两个进程互斥访问共享内存，我们可以初始化信号量为 1。\n信号初始化为 1，就代表着是互斥信号量，它可以保证共享内存在任何时刻只有一个进程在访问，这就很好的保护了共享内存。\n信号初始化为 0，就代表着是同步信号量，它可以保证进程 A 应在进程 B 之前执行。\n信号 信号和信号量毫无关系！\n上面说的进程间通信，都是常规状态下的工作模式。对于异常情况下的工作模式，就需要用「信号」的方式来通知进程。\n在 Linux 操作系统中， 为了响应各种各样的事件，提供了几十种信号，分别代表不同的意义。我们可以通过 kill -l 命令，查看所有的信号：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  $ kill -l 1) SIGHUP 2) SIGINT 3) SIGQUIT 4) SIGILL 5) SIGTRAP 6) SIGABRT 7) SIGBUS 8) SIGFPE 9) SIGKILL 10) SIGUSR1 11) SIGSEGV 12) SIGUSR2 13) SIGPIPE 14) SIGALRM 15) SIGTERM 16) SIGSTKFLT 17) SIGCHLD 18) SIGCONT 19) SIGSTOP 20) SIGTSTP 21) SIGTTIN 22) SIGTTOU 23) SIGURG 24) SIGXCPU 25) SIGXFSZ 26) SIGVTALRM 27) SIGPROF 28) SIGWINCH 29) SIGIO 30) SIGPWR 31) SIGSYS 34) SIGRTMIN 35) SIGRTMIN+1 36) SIGRTMIN+2 37) SIGRTMIN+3 38) SIGRTMIN+4 39) SIGRTMIN+5 40) SIGRTMIN+6 41) SIGRTMIN+7 42) SIGRTMIN+8 43) SIGRTMIN+9 44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12 47) SIGRTMIN+13 48) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14 51) SIGRTMAX-13 52) SIGRTMAX-12 53) SIGRTMAX-11 54) SIGRTMAX-10 55) SIGRTMAX-9 56) SIGRTMAX-8 57) SIGRTMAX-7 58) SIGRTMAX-6 59) SIGRTMAX-5 60) SIGRTMAX-4 61) SIGRTMAX-3 62) SIGRTMAX-2 63) SIGRTMAX-1 64) SIGRTMAX   运行在 shell 终端的进程，我们可以通过键盘输入某些组合键的时候，给进程发送信号。例如\n Ctrl+C 产生 SIGINT 信号，表示终止该进程； Ctrl+Z 产生 SIGTSTP 信号，表示停止该进程，但还未结束；  如果进程在后台运行，可以通过 kill 命令的方式给进程发送信号，但前提需要知道运行中的进程 PID 号，例如：\n kill -9 1050 ，表示给 PID 为 1050 的进程发送 SIGKILL 信号，用来立即结束该进程；  所以，信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令）。\n信号是进程间通信机制中唯一的异步通信机制，因为可以在任何时候发送信号给某一进程，一旦有信号产生，我们就有下面这几种，用户进程对信号的处理方式。\n 执行默认操作。Linux 对每种信号都规定了默认操作，例如，上面列表中的 SIGTERM 信号，就是终止进程的意思。 捕捉信号。我们可以为信号定义一个信号处理函数。当信号发生时，我们就执行相应的信号处理函数。 忽略信号。当我们不希望处理某些信号的时候，就可以忽略该信号，不做任何处理。有两个信号是应用进程无法捕捉和忽略的，即 SIGKILL 和 SEGSTOP，它们用于在任何时候中断或结束某一进程。  Socket 前面提到的管道、消息队列、共享内存、信号量和信号都是在同一台主机上进行进程间通信，那要想跨网络与不同主机上的进程之间通信，就需要 Socket 通信了。\n实际上，Socket 通信不仅可以跨网络与不同主机的进程间通信，还可以在同主机上进程间通信。\n我们来看看创建 socket 的系统调用：\n1  int socket(int domain, int type, int protocal)   三个参数分别代表：\n domain 参数用来指定协议族，比如 AFINET 用于 IPV4、AFINET6 用于 IPV6、AFLOCAL/AFUNIX 用于本机； type 参数用来指定通信特性，比如 SOCKSTREAM 表示的是字节流，对应 TCP、SOCKDGRAM 表示的是数据报，对应 UDP、SOCK_RAW 表示的是原始套接字； protocal 参数原本是用来指定通信协议的，但现在基本废弃。因为协议已经通过前面两个参数指定完成，protocol 目前一般写成 0 即可；  根据创建 socket 类型的不同，通信的方式也就不同：\n 实现 TCP 字节流通信： socket 类型是 AFINET 和 SOCKSTREAM； 实现 UDP 数据报通信：socket 类型是 AFINET 和 SOCKDGRAM； 实现本地进程间通信： 「本地字节流 socket 」类型是 AFLOCAL 和 SOCKSTREAM，「本地数据报 socket 」类型是 AFLOCAL 和 SOCKDGRAM。另外，AFUNIX 和 AFLOCAL 是等价的，所以 AF_UNIX 也属于本地 socket；  接下来，简单说一下这三种通信的编程模式。\n针对 TCP 协议通信的 socket 编程模型 针对 UDP 协议通信的 socket 编程模型 UDP 是没有连接的，所以不需要三次握手，也就不需要像 TCP 调用 listen 和 connect，但是 UDP 的交互仍然需要 IP 地址和端口号，因此也需要 bind。\n对于 UDP 来说，不需要要维护连接，那么也就没有所谓的发送方和接收方，甚至都不存在客户端和服务端的概念，只要有一个 socket 多台机器就可以任意通信，因此每一个 UDP 的 socket 都需要 bind。\n另外，每次通信时，调用 sendto 和 recvfrom，都要传入目标主机的 IP 地址和端口。\n针对本地进程间通信的 socket 编程模型 本地 socket 被用于在同一台主机上进程间通信的场景：\n 本地 socket 的编程接口和 IPv4 、IPv6 套接字编程接口是一致的，可以支持「字节流」和「数据报」两种协议； 本地 socket 的实现效率大大高于 IPv4 和 IPv6 的字节流、数据报 socket 实现；  本地字节流 socket 和 本地数据报 socket 在 bind 的时候，不像 TCP 和 UDP 要绑定 IP 地址和端口，而是绑定一个本地文件，这也就是它们之间的最大区别。\n多线程同步 互斥 上面展示的情况称为竞争条件（race condition），当多线程相互竞争操作共享变量时，由于运气不好，即在执行过程中发生了上下文切换，我们得到了错误的结果，事实上，每次运行都可能得到不同的结果，因此输出的结果存在不确定性（indeterminate）。\n由于多线程执行操作共享变量的这段代码可能会导致竞争状态，因此我们将此段代码称为临界区（critical section），它是访问共享资源的代码片段，一定不能给多线程同时执行。\n我们希望这段代码是互斥（mutualexclusion）的，也就说保证一个线程在临界区执行时，其他线程应该被阻止进入临界区，说白了，就是这段代码执行过程中，最多只能出现一个线程。\n同步 互斥解决了并发进程/线程对临界区的使用问题。这种基于临界区控制的交互作用是比较简单的，只要一个进程/线程进入了临界区，其他试图想进入临界区的进程/线程都会被阻塞着，直到第一个进程/线程离开了临界区。\n我们都知道在多线程里，每个线程并不一定是顺序执行的，它们基本是以各自独立的、不可预知的速度向前推进，但有时候我们又希望多个线程能密切合作，以实现一个共同的任务。\n所谓同步，就是并发进程/线程在一些关键点上可能需要互相等待与互通消息，这种相互制约的等待与互通信息称为进程/线程同步。\n互斥与同步的实现和使用 在进程/线程并发执行的过程中，进程/线程之间存在协作的关系，例如有互斥、同步的关系。\n为了实现进程/线程间正确的协作，操作系统必须提供实现进程协作的措施和方法，主要的方法有两种：\n 锁：加锁、解锁操作； 信号量：P、V 操作；  哲学家就餐问题 解决方案一：限制四个人同时就餐（信号量初始化为4）\n解决方案二：仅当哲学家的左右手筷子都拿起时才允许进餐（拿起左右叉子原子操作）。\n解决方案二：即让偶数编号的哲学家「先拿左边的叉子后拿右边的叉子」，奇数编号的哲学家「先拿右边的叉子后拿左边的叉子」。\n解决方案三：另一个简单的解法是为资源（这里是筷子）分配一个偏序或者分级的关系，并约定所有资源都按照这种顺序获取，按相反顺序释放，而且保证不会有两个无关资源同时被同一项工作所需要。在哲学家就餐问题中，筷子按照某种规则编号为1至5，每一个工作单元（哲学家）总是先拿起左右两边编号较低的筷子，再拿编号较高的。用完筷子后，他总是先放下编号较高的筷子，再放下编号较低的。在这种情况下，当四位哲学家同时拿起他们手边编号较低的筷子时，只有编号最高的筷子留在桌上，从而第五位哲学家就不能使用任何一只筷子了。而且，只有一位哲学家能使用最高编号的筷子，所以他能使用两只筷子用餐。当他吃完后，他会先放下编号最高的筷子，再放下编号较低的筷子，从而让另一位哲学家拿起后边的这只开始吃东西。\n死锁 两个线程都在等待对方释放锁，在没有外力的作用下，这些线程会一直相互等待，就没办法继续运行，这种情况就是发生了死锁。\n死锁只有同时满足以下四个条件才会发生：\n 互斥条件：互斥条件是指多个线程不能同时使用同一个资源。 持有并等待条件：线程 A 在等待资源 2 的同时并不会释放自己已经持有的资源 1。 不可剥夺条件：当线程已经持有了资源 ，在自己使用完之前不能被其他线程获取，线程 B 如果也想使用此资源，则只能在线程 A 使用完并释放后才能获取。 环路等待条件：环路等待条件指都是，在死锁发生的时候，两个线程获取资源的顺序构成了环形链。  互斥锁与自旋锁 互斥锁 加锁失败后，线程会释放 CPU ，给其他线程；\n互斥锁加锁失败时，会从用户态陷入到内核态，让内核帮我们切换线程，虽然简化了使用锁的难度，但是存在一定的性能开销成本。\n那这个开销成本是什么呢？会有两次线程上下文切换的成本：\n 当线程加锁失败时，内核会把线程的状态从「运行」状态设置为「睡眠」状态，然后把 CPU 切换给其他线程运行； 接着，当锁被释放时，之前「睡眠」状态的线程会变为「就绪」状态，然后内核会在合适的时间，把 CPU 切换给该线程运行。  自旋锁 加锁失败后，线程会忙等待，直到它拿到锁\n自旋锁是通过 CPU 提供的 CAS 函数（Compare And Swap），在「用户态」完成加锁和解锁操作，不会主动产生线程上下文切换，所以相比互斥锁来说，会快一些，开销也小一些。\n一般加锁的过程，包含两个步骤：\n 第一步，查看锁的状态，如果锁是空闲的，则执行第二步； 第二步，将锁设置为当前线程持有；  CAS 函数就把这两个步骤合并成一条硬件级指令，形成原子指令，这样就保证了这两个步骤是不可分割的，要么一次性执行完两个步骤，要么两个步骤都不执行。\n使用自旋锁的时候，当发生多线程竞争锁的情况，加锁失败的线程会「忙等待」，直到它拿到锁。这里的「忙等待」可以用 while 循环等待实现，不过最好是使用 CPU 提供的 PAUSE 指令来实现「忙等待」，因为可以减少循环等待时的耗电量。\n自旋锁是最比较简单的一种锁，一直自旋，利用 CPU 周期，直到锁可用。需要注意，在单核 CPU 上，需要抢占式的调度器（即不断通过时钟中断一个线程，运行其他线程）。否则，自旋锁在单 CPU 上无法使用，因为一个自旋的线程永远不会放弃 CPU。\n自旋锁开销少，在多核系统下一般不会主动产生线程切换，适合异步、协程等在用户态切换请求的编程方式，但如果被锁住的代码执行时间过长，自旋的线程会长时间占用 CPU 资源，所以自旋的时间和被锁住的代码执行的时间是成「正比」的关系，我们需要清楚的知道这一点。\n自旋锁与互斥锁使用层面比较相似，但实现层面上完全不同：当加锁失败时，互斥锁用「线程切换」来应对，自旋锁则用「忙等待」来应对。\n悲观锁与乐观锁 悲观锁做事比较悲观，它认为多线程同时修改共享资源的概率比较高，于是很容易出现冲突，所以访问共享资源前，先要上锁。\n那相反的，如果多线程同时修改共享资源的概率比较低，就可以采用乐观锁。\n乐观锁做事比较乐观，它假定冲突的概率很低，它的工作方式是：先修改完共享资源，再验证这段时间内有没有发生冲突，如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作。\n乐观锁的应用：\n 多人在线编辑，先修改，再判断是否发生冲突 SVG，Git也是提交时才判断冲突  ","date":"2022-07-19T19:28:08+08:00","permalink":"https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F02-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/","title":"操作系统02-进程管理"},{"content":"虚拟地址 我们可以把进程所使用的地址「隔离」开来，即让操作系统为每个进程分配独立的一套「虚拟地址」，人人都有，大家自己玩自己的地址就行，互不干涉。但是有个前提每个进程都不能访问物理地址，至于虚拟地址最终怎么落到物理内存里，对进程来说是透明的，操作系统已经把这些都安排的明明白白了。\n操作系统会提供一种机制，将不同进程的虚拟地址和不同内存的物理地址映射起来。\n如果程序要访问虚拟地址的时候，由操作系统转换成不同的物理地址，这样不同的进程运行的时候，写入的是不同的物理地址，这样就不会冲突了。\n于是，这里就引出了两种地址的概念：\n 我们程序所使用的内存地址叫做虚拟内存地址（Virtual Memory Address） 实际存在硬件里面的空间地址叫物理内存地址（Physical Memory Address）。  操作系统引入了虚拟内存，进程持有的虚拟地址会通过 CPU 芯片中的内存管理单元（MMU）的映射关系，来转换变成物理地址，然后再通过物理地址访问内存，如下图所示：\n内存分段 虚拟地址是通过段表与物理地址进行映射的，分段机制会把程序的虚拟地址分成 4 个段，每个段在段表中有一个项，在这一项找到段的基地址，再加上偏移量，于是就能找到物理内存中的地址，如下图：\n分段的办法很好，解决了程序本身不需要关心具体的物理内存地址的问题，但它也有一些不足之处：\n 第一个就是内存碎片的问题。 第二个就是内存交换的效率低的问题（内存交换粒度太大）。  内存分页 分段的好处就是能产生连续的内存空间，但是会出现内存碎片和内存交换的空间太大的问题。\n要解决这些问题，那么就要想出能少出现一些内存碎片的办法。另外，当需要进行内存交换的时候，让需要交换写入或者从磁盘装载的数据更少一点，这样就可以解决问题了。这个办法，也就是内存分页（Paging）。\n分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小。这样一个连续并且尺寸固定的内存空间，我们叫页（Page）。在 Linux 下，每一页的大小为 4KB。\n虚拟地址与物理地址之间通过页表来映射，如下图：\n缺页中断：而当进程访问的虚拟地址在页表中查不到时，系统会产生一个缺页异常，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。\n分页是怎么解决分段的内存碎片、内存交换效率低的问题？\n由于内存空间都是预先划分好的，也就不会像分段会产生间隙非常小的内存，这正是分段会产生内存碎片的原因。而采用了分页，那么释放的内存都是以页为单位释放的，也就不会产生无法给进程使用的小内存。\n如果内存空间不够，操作系统会把其他正在运行的进程中的「最近没被使用」的内存页面给释放掉，也就是暂时写在硬盘上，称为换出（Swap Out）。一旦需要的时候，再加载进来，称为换入（Swap In）。所以，一次性写入磁盘的也只有少数的一个页或者几个页，不会花太多时间，内存交换的效率就相对比较高。\n在分页机制下，虚拟地址分为两部分，页号和页内偏移。页号作为页表的索引，页表包含物理页每页所在物理内存的基地址，这个基地址与页内偏移的组合就形成了物理内存地址，见下图。\n总结一下，对于一个内存地址转换，其实就是这样三个步骤：\n 把虚拟内存地址，切分成页号和偏移量； 根据页号，从页表里面，查询对应的物理页号； 直接拿物理页号，加上前面的偏移量，就得到了物理内存地址。  多级页表 因为操作系统是可以同时运行非常多的进程的，那这不就意味着页表会非常的庞大。\n在 32 位的环境下，虚拟地址空间共有 4GB，假设一个页的大小是 4KB（2^12），那么就需要大约 100 万 （2^20） 个页，每个「页表项」需要 4 个字节大小来存储，那么整个 4GB 空间的映射就需要有 4MB 的内存来存储页表。\n这 4MB 大小的页表，看起来也不是很大。但是要知道每个进程都是有自己的虚拟地址空间的，也就说都有自己的页表。\n那么，100 个进程的话，就需要 400MB 的内存来存储页表，这是非常大的内存了，更别说 64 位的环境了\n要解决上面的问题，就需要采用一种叫作多级页表（Multi-Level Page Table）的解决方案。\n在前面我们知道了，对于单页表的实现方式，在 32 位和页大小 4KB 的环境下，一个进程的页表需要装下 100 多万个「页表项」，并且每个页表项是占用 4 字节大小的，于是相当于每个页表需占用 4MB 大小的空间。\n我们把这个 100 多万个「页表项」的单级页表再分页，将页表（一级页表）分为 1024 个页表（二级页表），每个表（二级页表）中包含 1024 个「页表项」，形成二级分页。如下图所示：\n 你可能会问，分了二级表，映射 4GB 地址空间就需要 4KB（一级页表）+ 4MB（二级页表）的内存，这样占用空间不是更大了吗？\n 当然如果 4GB 的虚拟地址全部都映射到了物理内存上的话，二级分页占用空间确实是更大了，但是，我们往往不会为一个进程分配那么多内存。\n其实我们应该换个角度来看问题，还记得计算机组成原理里面无处不在的局部性原理么？\n每个进程都有 4GB 的虚拟地址空间，而显然对于大多数程序来说，其使用到的空间远未达到 4GB，因为会存在部分对应的页表项都是空的，根本没有分配，对于已分配的页表项，如果存在最近一定时间未访问的页表，在物理内存紧张的情况下，操作系统会将页面换出到硬盘，也就是说不会占用物理内存。\n如果使用了二级分页，一级页表就可以覆盖整个 4GB 虚拟地址空间，但如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表了，即可以在需要时才创建二级页表。做个简单的计算，假设只有 20% 的一级页表项被用到了，那么页表占用的内存空间就只有 4KB（一级页表） + 20% * 4MB（二级页表）= 0.804MB，这对比单级页表的 4MB 是不是一个巨大的节约？\n那么为什么不分级的页表就做不到这样节约内存呢？我们从页表的性质来看，保存在内存中的页表承担的职责是将虚拟地址翻译成物理地址。假如虚拟地址在页表中找不到对应的页表项，计算机系统就不能工作了。所以页表一定要覆盖全部虚拟地址空间，不分级的页表就需要有 100 多万个页表项来映射，而二级分页则只需要 1024 个页表项（此时一级页表覆盖到了全部虚拟地址空间，二级页表在需要时创建）。\nTLB（快表） 多级页表虽然解决了空间上的问题，但是虚拟地址到物理地址的转换就多了几道转换的工序，这显然就降低了这俩地址转换的速度，也就是带来了时间上的开销。\n程序是有局部性的，即在一段时间内，整个程序的执行仅限于程序中的某一部分。相应地，执行所访问的存储空间也局限于某个内存区域。\n我们就可以利用这一特性，把最常访问的几个页表项存储到访问速度更快的硬件，于是计算机科学家们，就在 CPU 芯片中，加入了一个专门存放程序最常访问的页表项的 Cache，这个 Cache 就是 TLB（Translation Lookaside Buffer） ，通常称为页表缓存、转址旁路缓存、快表等。\n在 CPU 芯片里面，封装了内存管理单元（Memory Management Unit）芯片，它用来完成地址转换和 TLB 的访问与交互。\n有了 TLB 后，那么 CPU 在寻址时，会先查 TLB，如果没找到，才会继续查常规的页表。\nTLB 的命中率其实是很高的，因为程序最常访问的页就那么几个。\n段页式内存管理 内存分段和内存分页并不是对立的，它们是可以组合起来在同一个系统中使用的，那么组合起来后，通常称为段页式内存管理。\n段页式内存管理实现的方式：\n 先将程序划分为多个有逻辑意义的段，也就是前面提到的分段机制； 接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页；  这样，地址结构就由段号、段内页号和页内位移三部分组成。\n用于段页式地址变换的数据结构是每一个程序一张段表，每个段又建立一张页表，段表中的地址是页表的起始地址，而页表中的地址则为某页的物理页号，如图所示：\n段页式地址变换中要得到物理地址须经过三次内存访问：\n 第一次访问段表，得到页表起始地址； 第二次访问页表，得到物理页号； 第三次将物理页号与页内位移组合，得到物理地址。  可用软、硬件相结合的方法实现段页式地址变换，这样虽然增加了硬件成本和系统开销，但提高了内存的利用率。\n内存页面置换算法 在了解内存页面置换算法前，我们得先谈一下缺页异常（缺页中断）。\n当 CPU 访问的页面不在物理内存时，便会产生一个缺页中断，请求操作系统将所缺页调入到物理内存。那它与一般中断的主要区别在于：\n 缺页中断在指令执行「期间」产生和处理中断信号，而一般中断在一条指令执行「完成」后检查和处理中断信号。 缺页中断返回到该指令的开始重新执行「该指令」，而一般中断返回回到该指令的「下一个指令」执行。  我们来看一下缺页中断的处理流程，如下图：\n找不到空闲页的话，就说明此时内存已满了，这时候，就需要「页面置换算法」选择一个物理页，如果该物理页有被修改过（脏页），则把它换出到磁盘，然后把该被置换出去的页表项的状态改成「无效的」，最后把正在访问的页面装入到这个物理页中。\n页表项通常有如下图的字段：\n 状态位：用于表示该页是否有效，也就是说是否在物理内存中，供程序访问时参考。 访问字段：用于记录该页在一段时间被访问的次数，供页面置换算法选择出页面时参考。 修改位：表示该页在调入内存后是否有被修改过，由于内存中的每一页都在磁盘上保留一份副本，因此，如果没有修改，在置换该页时就不需要将该页写回到磁盘上，以减少系统的开销；如果已经被修改，则将该页重写到磁盘上，以保证磁盘中所保留的始终是最新的副本。 硬盘地址：用于指出该页在硬盘上的地址，通常是物理块号，供调入该页时使用。  最佳页面置换算法 最佳页面置换算法基本思路是，置换在「未来」最长时间不访问的页面。\n这很理想，但是实际系统中无法实现，因为程序访问页面时是动态的，我们是无法预知每个页面在「下一次」访问前的等待时间。\n所以，最佳页面置换算法作用是为了衡量你的算法的效率，你的算法效率越接近该算法的效率，那么说明你的算法是高效的。\n先进先出置换算法 选择在内存驻留时间很长的页面进行中置换，这个就是「先进先出置换」算法的思想\n最近最久未使用的置换算法 最近最久未使用（LRU）的置换算法的基本思路是，发生缺页时，选择最长时间没有被访问的页面进行置换，也就是说，该算法假设已经很久没有使用的页面很有可能在未来较长的一段时间内仍然不会被使用。\n这种算法近似最优置换算法，最优置换算法是通过「未来」的使用情况来推测要淘汰的页面，而 LRU 则是通过「历史」的使用情况来推测要淘汰的页面。\n虽然 LRU 在理论上是可以实现的，但代价很高。为了完全实现 LRU，需要在内存中维护一个所有页面的链表，最近最多使用的页面在表头，最近最少使用的页面在表尾。\n困难的是，在每次访问内存时都必须要更新「整个链表」。在链表中找到一个页面，删除它，然后把它移动到表头是一个非常费时的操作。\n所以，LRU 虽然看上去不错，但是由于开销比较大，实际应用中比较少使用。\n时钟页面置换算法 那有没有一种即能优化置换的次数，也能方便实现的算法呢？\n时钟页面置换算法就可以两者兼得，它跟 LRU 近似，又是对 FIFO 的一种改进。\n该算法的思路是，把所有的页面都保存在一个类似钟面的「环形链表」中，一个表针指向最老的页面。\n当发生缺页中断时，算法首先检查表针指向的页面：\n 如果它的访问位是 0 就淘汰该页面，并把新的页面插入这个位置，然后把表针前移一个位置； 如果访问位是 1 就清除访问位，并把表针前移一个位置，重复这个过程直到找到了一个访问位为 0 的页面为止；  最不常用算法 最不常用（LFU）算法，这名字听起来很调皮，但是它的意思不是指这个算法不常用，而是当发生缺页中断时，选择「访问次数」最少的那个页面，并将其淘汰。\n它的实现方式是，对每个页面设置一个「访问计数器」，每当一个页面被访问时，该页面的访问计数器就累加 1。在发生缺页中断时，淘汰计数器值最小的那个页面。\n看起来很简单，每个页面加一个计数器就可以实现了，但是在操作系统中实现的时候，我们需要考虑效率和硬件成本的。\n要增加一个计数器来实现，这个硬件成本是比较高的，另外如果要对这个计数器查找哪个页面访问次数最小，查找链表本身，如果链表长度很大，是非常耗时的，效率不高。\n但还有个问题，LFU 算法只考虑了频率问题，没考虑时间的问题，比如有些页面在过去时间里访问的频率很高，但是现在已经没有访问了，而当前频繁访问的页面由于没有这些页面访问的次数高，在发生缺页中断时，就会可能会误伤当前刚开始频繁访问，但访问次数还不高的页面。\n那这个问题的解决的办法还是有的，可以定期减少访问的次数，比如当发生时间中断时，把过去时间访问的页面的访问次数除以 2，也就说，随着时间的流失，以前的高访问次数的页面会慢慢减少，相当于加大了被置换的概率。\n","date":"2022-07-19T17:05:50+08:00","permalink":"https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F03-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/","title":"操作系统03-内存管理"},{"content":"冯诺伊曼模型 线路位宽与CPU位宽 数据是如何通过线路传输的呢？其实是通过操作电压，低电压表示 0，高压电压则表示 1。如果构造了高低高这样的信号，其实就是 101 二进制数据，十进制则表示 5，如果只有⼀条线路，就意味着每次只能传递 1 bit 的数据，即 0 或 1，那么传输 101 这个数据，就需要 3 次才能传输完成，这样的效率非常低。\n这样⼀位⼀位传输的方式，称为串行，下⼀个 bit 必须等待上⼀个 bit 传输完成才能进行传输。当然，想⼀次多传⼀些数据，增加线路即可，这时数据就可以并行传输。 为了避免低效率的串行传输的⽅式，线路的位宽最好⼀次就能访问到所有的内存地址。 CPU 要想操作的内存地址就需要地址总线，如果地址总线只有 1 条，那每次只能表示 「0 或 1」这两种情况，所以 CPU ⼀次只能操作 2 个内存地址，如果想要 CPU 操作 4G 的内存，那么就需要 32 条地址总线，因为 2 ^ 32 =4G 。\n知道了线路位宽的意义后，我们再来看看 CPU 位宽。\nCPU 的位宽最好不要小于线路位宽，比如 32 位 CPU 控制 40 位宽的地址总线和数据总线的话，工作起来就会非常复杂且麻烦，所以 32 位的 CPU 最好和 32 位宽的线路搭配，因为 32 位 CPU ⼀次最多只能操作32 位宽的地址总线和数据总线。\n但是并不代表 64 位 CPU 性能比32 位 CPU 高很多，很少应用需要算超过 32 位的数字，所以如果计算的数额不超过 32 位数字的情况下，32 位和 64 位 CPU 之间没什么区别的，只有当计算超过 32 位数字的情况下，64 位的优势才能体现出来。\n另外，32 位 CPU 最大只能操作 4GB 内存，就算你装了 8 GB 内存条，也没用。而 64 位 CPU 寻址范围则很大，理论最大的寻址空间为 2^64 。\n存储器的层次 CPU Cache 用的是⼀种叫 SRAM（Static Random-Access Memory，静态随机存储器） 的芯片。SRAM 之所以叫「静态」存储器，是因为只要有电，数据就可以保持存在，而⼀旦断电，数据就会丢失了。\n在 SRAM 里面，⼀个 bit 的数据，通常需要 6 个晶体管，所以 SRAM 的存储密度不高，同样的物理空间下，能存储的数据是有限的，不过也因为 SRAM 的电路简单，所以访问速度非常快。\n内存用的芯片和 CPU Cache 有所不同，它使用的是⼀种叫作 DRAM （Dynamic Random AccessMemory，动态随机存取存储器） 的芯片。\n相比 SRAM，DRAM 的密度更高，功耗更低，有更大的容量，而且造价比 SRAM 芯片便宜很多。DRAM 存储⼀个 bit 数据，只需要⼀个晶体管和⼀个电容就能存储，但是因为数据会被存储在电容里，电容会不断漏电，所以需要「定时刷新」电容，才能保证数据不会被丢失，这就是 DRAM 之所以被称为「动态」存储器的原因，只有不断刷新，数据才能被存储起来。\nCache伪共享 相邻的数据可能会被两个线程同时访问，这样每个线程都会将这个两个数据加入cache，但是这两个数据又相邻很近，会被记载进同一个cache Line中，这样另一个线程修改一个数据会造成cache的刷新，这样就失去了cache的意义，叫做伪共享。\n避免伪共享：数据对齐，每个cache Line大约为64字节，填充一个不足64字节的数据，就可以独占一个 cache Line。\n","date":"2022-07-19T15:05:03+08:00","permalink":"https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F01-%E7%A1%AC%E4%BB%B6%E5%8E%9F%E7%90%86/","title":"操作系统01-硬件原理"},{"content":"状态码 1xx 1xx 类状态码属于提示信息，是协议处理中的⼀种中间状态，实际用到的比较少。\n2xx 2xx 类状态码表示服务器成功处理了客户端的请求，也是我们最愿意看到的状态。\n 200 OK：是最常⻅的成功状态码，表示⼀切正常。如果是⾮ HEAD 请求，服务器返回的响应头都会有 body数据。 204 No Content：也是常⻅的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。 206 Partial Content：是应用于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，⽽是其中的⼀部分，也是服务器处理成功的状态。  3xx 3xx 类状态码表示客户端请求的资源发送了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是重定向。\n 301 Moved Permanently：表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。 302 Found：表示临时重定向，说明请求的资源还在，但暂时需要用另⼀个 URL 来访问。301 和 302 都会在响应头⾥使用字段 Location ，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。 304 Not Modified：不具有跳转的含义，表示资源未修改，重定向已存在的缓冲⽂件，也称缓存重定向，用于缓存控制。  4xx 4xx 类状态码表示客户端发送的报⽂有误，服务器无法处理，也就是错误码的含义。\n 400 Bad Request：表示客户端请求的报⽂有错误，但只是个笼统的错误。 403 Forbidden：表示服务器禁⽌访问资源，并不是客户端的请求出错。 404 Not Found：表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。  5xx 5xx 类状态码表示客户端请求报⽂正确，但是服务器处理时内部发生了错误，属于服务器端的错误码。\n 500 Internal Server Error：与 400 类型，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。 501 Not Implemented：表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。 502 Bad Gateway：通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。 503 Service Unavailable：表示服务器当前很忙，暂时无法响应服务器，类似“网络服务正忙，请稍后重试”的意思。  HTTP常见字段 Host：客户端发送请求时，用来指定服务器的域名\nContent-Length：服务器在返回数据时，表明本次回应的数据长度。\nConnection：Connection 字段最常用于客户端要求服务器使用 TCP 持久连接，以便其他请求复用。HTTP/1.1 版本的默认连接都是持久连接，但为了兼容老版本的 HTTP，需要指定 Connection ⾸部字段的值为Keep-Alive 。⼀个可以复用的 TCP 连接就建⽴了，直到客户端或服务器主动关闭连接。但是，这不是标准字段\nContent-Type：用于服务器回应时，告诉客户端，本次数据是什么格式。\nContent-Encoding：说明数据的压缩方法。表示服务器返回的数据使用了什么压缩格式；客户端在请求时，用 Accept-Encoding 字段说明自⼰可以接受哪些压缩方法。\nGET 与 POST  GET 是安全且幂等的，因为他是只读操作，无论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。 POST 因为是新增或提交数据的操作，会修改服务器上的资源，所以是不安全的，且多次提交就会创建多个资源，所以不是幂等的  HTTP 与 HTTPS  HTTP 是超⽂本传输协议，信息是明文传输，存在安全⻛险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。 HTTP 连接建立相对简单， TCP 三次握手之后便可进⾏ HTTP 的报⽂传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。 HTTP 的端口号是 80，HTTPS 的端口号是 443。 HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。  消息摘要、消息认证码与数字签名的区别 加解密算法+消息摘要+消息认证技术+数字签名+公钥证书_\nSSL/TLS握手 SSL/TLS 协议建⽴的详细流程：\n ClientHello：首先，由客户端向服务器发起加密通信请求，也就是 ClientHello 请求。在这⼀步，客户端主要向服务器发送以下信息：  客户端支持的 SSL/TLS 协议版本，如 TLS 1.2 版本。 客户端生产的随机数（ Client Random ），后面用于生产「会话秘钥」。 客户端⽀持的密码套件列表，如 RSA 加密算法。   SeverHello：服务器收到客户端请求后，向客户端发出响应，也就是 SeverHello 。服务器回应的内容有如下内容：  确认 SSL/ TLS 协议版本，如果浏览器不支持，则关闭加密通信。 服务器生产的随机数（ Server Random ），后面用于生产「会话秘钥」。 确认的密码套件列表，如 RSA 加密算法。 服务器的数字证书。   客户端回应：客户端收到服务器的回应之后，⾸先通过浏览器或者操作系统中的 CA 公钥，确认服务器的数字证书的真实性。如果证书没有问题，客户端会从数字证书中取出服务器的公钥，然后使用它加密报文，向服务器发送如下信息：  ⼀个随机数（ pre-master key ）。该随机数会被服务器公钥加密。 加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。 客户端握手结束通知，表示客户端的握手阶段已经结束。这⼀项同时把之前所有内容的发生的数据做个摘要，用来供服务端校验。上面第⼀项的随机数是整个握手阶段的第三个随机数，这样服务器和客户端就同时有三个随机数，接着就用双方协商的加密算法，各自生成本次通信的「会话秘钥」。   服务器的最后回应：服务器收到客户端的第三个随机数（ pre-master key ）之后，通过协商的加密算法，计算出本次通信的「会话秘钥」。然后，向客户端发出最后的信息：  加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。 服务器握手结束通知，表示服务器的握手阶段已经结束。这⼀项同时把之前所有内容的发生的数据做个摘要，用来供客户端校验。 至此，整个 SSL/TLS 的握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的 HTTP协议，只不过用「会话秘钥」加密内容。    HTTP/1.0、HTTP/1.1、HTTP/2、HTTP/3演变 HTTP/1.1 相比 HTTP/1.0 的改进 HTTP 1.0 vs HTTP 1.1（应用层） | JavaGuide\n  连接方式 : HTTP 1.0 为短连接，HTTP 1.1 支持长连接。\n  状态响应码 : HTTP/1.1中新加入了大量的状态码，光是错误响应状态码就新增了24种。比如说，100 (Continue)——在请求大资源前的预热请求，206 (Partial Content)——范围请求的标识码，409 (Conflict)——请求与当前资源的规定冲突，410 (Gone)——资源已被永久转移，而且没有任何已知的转发地址。\n  缓存处理 : 在 HTTP1.0 中主要使用 header 里的 If-Modified-Since,Expires 来做为缓存判断的标准，HTTP1.1 则引入了更多的缓存控制策略例如 Entity tag，If-Unmodified-Since, If-Match, If-None-Match 等更多可供选择的缓存头来控制缓存策略。\n  带宽优化及网络连接的使用 :HTTP1.0 中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1 则在请求头引入了 range 头域，它允许只请求资源的某个部分，即返回码是 206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。\n  Host头处理 : HTTP/1.1在请求头中加入了Host字段。\n  使用TCP 长连接的方式改善了 HTTP/1.0 短链接造成的性能开销\n  支持管道网络传输，只要第一个请求发出去了，不必等期回来，就可以发第二个请求出去，可以减少整体的响应时间\n  HTTP/2 针对 HTTP/1.1 优化  头部压缩，如果同时发出多个请求，他们的头是一样的或是相似的，那么下一会帮你消除重复部分。这就是 HPACK 算法：客户端和服务端同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后不发送同样字段了，只发送索引号，这样就提高速度。 HTTP/2 不再像 HTTP/1.1 里的纯文本形式的报文，而是全面采用了二进制格式，头和数据体都是二进制。收到报文后无需再将铭文的报文转成二进制，而是直接解析二进制报文，这增加了数据传输的效率。 数据流：HTTP/2 的数据包不是按顺序发送的，同⼀个连接⾥⾯连续的数据包，可能属于不同的回应。因此，必须要对数据包做标记，指出它属于哪个回应。每个请求或回应的所有数据包，称为⼀个数据流（ Stream ）。每个数据流都标记着⼀个独一无二的编号，其中规定客户端发出的数据流编号为奇数， 服务器发出的数据流编号为偶数。 多路复用：HTTP/2 是可以在⼀个连接中并发多个请求或回应，而不用按照顺序⼀⼀对应。移除了 HTTP/1.1 中的串⾏请求，不需要排队等待，也就不会再出现「队头阻塞」问题，降低了延迟，⼤幅度提高了连接的利⽤率。  HTTP/3 HTTP/2 主要的问题在于，多个 HTTP 请求在复⽤⼀个 TCP 连接，下层的 TCP 协议是不知道有多少个 HTTP 请求的。所以⼀旦发生了丢包现象，就会触发 TCP 的重传机制，这样在⼀个 TCP 连接中的所有的 HTTP 请求都必须等待这个丢了的包被重传回来。\n HTTP/1.1 中的管道（ pipeline）传输中如果有⼀个请求阻塞了，那么队列后请求也统统被阻塞住了 HTTP/2 多个请求复用⼀个TCP连接，⼀旦发生丢包，就会阻塞住所有的 HTTP 请求。  这都是基于 TCP 传输层的问题，所以 HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP！\nUDP 是不可靠传输的，但基于 UDP 的 QUIC 协议 可以实现类似 TCP 的可靠性传输。\n QUIC 有自己的⼀套机制可以保证传输的可靠性的。当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响。 TLS3 升级成了最新的 1.3 版本，头部压缩算法也升级成了 QPack 。 HTTPS 要建⽴⼀个连接，要花费 6 次交互，先是建⽴三次握⼿，然后是 TLS/1.3 的三次握⼿。QUIC 直接把以往的 TCP 和 TLS/1.3 的 6 次交互合并成了 3 次，减少了交互次数。  ","date":"2022-07-18T15:15:33+08:00","permalink":"https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C01-http%E5%8D%8F%E8%AE%AE/","title":"网络01-HTTP协议"},{"content":"什么是TCP IP 层是「不可靠」的，它不保证网络包的交付、不保证网络包的按序交付、也不保证网络包中的数据的完整性。\n如果需要保障网络数据包的可靠性，那么就需要由上层（传输层）的 TCP 协议来负责。因为 TCP 是⼀个⼯作在传输层的可靠数据传输的服务，它能确保接收端接收的网络包是无损坏、无间隔、非冗余和按序的。\nTCP 是面向连接的、可靠的、基于字节流的传输层通信协议。\n 面向连接：⼀定是「⼀对⼀」才能连接，不能像 UDP 协议可以⼀个主机同时向多个主机发送消息，也就是⼀对多是无法做到的； 可靠的：无论的网络链路中出现了怎样的链路变化，TCP 都可以保证⼀个报文⼀定能够到达接收端； 字节流：消息是「没有边界」的，所以无论我们消息有多大都可以进⾏传输。并且消息是「有序的」，当「前⼀个」消息没有收到的时候，即使它先收到了后面的字节，那么也不能扔给应用层去处理，同时对「重复」的报文会⾃动丢弃。  TCP 四元组可以唯⼀的确定⼀个连接，四元组包括如下：\n 源地址 源端口 目的地址 目的端口  源地址和⽬的地址的字段（32位）是在 IP 头部 中，作用是通过 IP 协议发送报文给对方主机。\n源端口和⽬的端口的字段（16位）是在 TCP 头部 中，作用是告诉 TCP 协议应该把报文发给哪个进程。\n什么是TCP连接 简单来说就是，用于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，包括Socket、序列号和窗口大小称为连接。\n所以我们可以知道，建⽴⼀个 TCP 连接是需要客户端与服务器端达成上述三个信息的共识。\n Socket：由 IP 地址和端口号组成 序列号：用来解决乱序问题等 窗口大小：用来做流量控制  TCP 格式 序列号：在建⽴连接时由计算机生成的随机数作为其初始值，通过 SYN 包传给接收端主机，每发送⼀次数据，就「累加」⼀次该「数据字节数」的大小。用来解决网络包乱序问题。\n确认应答号：指下⼀次「期望」收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。用来解决不丢包的问题。\n控制位：\n ACK：该位为 1 时，「确认应答」的字段变为有效，TCP 规定除了最初建⽴连接时的 SYN 包之外该位必须设置为 1 。 RST：该位为 1 时，表示 TCP 连接中出现异常必须强制断开连接。 SYN：该位为 1 时，表示希望建⽴连接，并在其「序列号」的字段进⾏序列号初始值的设定。 FIN：该位为 1 时，表示今后不会再有数据发送，希望断开连接。当通信结束希望断开连接时，通信双方的主机之间就可以相互交换 FIN 位为 1 的 TCP 段。  TCP 和 UDP 区别 UDP 不提供复杂的控制机制，利用 IP 提供面向「无连接」的通信服务。UDP 协议真的非常简，头部只有 8 个字节（ 64 位），UDP 的头部格式如下：\n ⽬标和源端口：主要是告诉 UDP 协议应该把报文发给哪个进程。 包长度：该字段保存了 UDP 首部的长度跟数据的长度之和。 校验和：校验和是为了提供可靠的 UDP 首部和数据而设计。  区别   连接：\n TCP 是面向连接的传输层协议，传输数据前先要建⽴连接。 UDP 是不需要连接，即刻传输数据。    服务对象\n TCP 是⼀对⼀的两点服务，即⼀条连接只有两个端点。 UDP ⽀持⼀对⼀、⼀对多、多对多的交互通信    可靠性\n TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按需到达。 UDP 是尽最大努⼒交付，不保证可靠交付数据。    拥塞控制、流量控制\n TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。 UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。    首部开销\n TCP 首部长度较长，会有⼀定的开销，首部在没有使用「选项」字段时是 20 个字节，如果使用了「选项」字段则会变长的。 UDP 首部只有 8 个字节，并且是固定不变的，开销较小。    传输方式\n TCP 是流式传输，没有边界，但保证顺序和可靠。 UDP 是⼀个包⼀个包的发送，是有边界的，但可能会丢包和乱序。    分片不同\n TCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP数据包，如果中途丢失了⼀个分片，只需要传输丢失的这个分片。 UDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层，但是如果中途丢了⼀个分片，在实现可靠传输的 UDP 时则就需要重传所有的数据包，这样传输效率非常差，所以通常 UDP 的报文应该小于 MTU。    TCP 和 UDP 应用场景：  FTP 文件传输 HTTP / HTTPS  由于 UDP 面向无连接，它可以随时发送数据，再加上UDP本身的处理既简单又高效，因此经常用于：\n 包总量较少的通信，如 DNS 、 SNMP 等 视频、音频等多媒体通信 广播通信  为什么 UDP 头部没有「首部长度」字段，而TCP 头部有「首部长度」字段呢？\n原因是 TCP 有可变长的「选项」字段，而UDP 头部长度则是不会变化的，无需多⼀个字段去记录 UDP 的首部长度。\n为什么 UDP 头部有「包长度」字段，而 TCP 头部则没有「包长度」字段呢？\n其中 IP 总长度 和 IP 首部长度，在 IP 首部格式是已知的。TCP 首部长度，则是在 TCP 首部格式已知的，所以就可以求得 TCP 数据的长度。\n因为为了网络设备硬件设计和处理方便，首部长度需要是 4 字节的整数倍。\nTCP连接 两张动图-彻底明白TCP的三次握手与四次挥手\n ⼀开始，客户端和服务端都处于 CLOSED 状态。先是服务端主动监听某个端口，处于 LISTEN 状态   客户端会随机初始化序号（ client_isn ），将此序号置于 TCP 首部的「序号」字段中，同时把 SYN 标志位置为 1 ，表示 SYN 报文。接着把第⼀个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于 SYN-SENT 状态。   服务端收到客户端的 SYN 报文后，首先服务端也随机初始化⾃⼰的序号（ server_isn ），将此序号填入TCP 首部的「序号」字段中，其次把 TCP 首部的「确认应答号」字段填入 client_isn + 1 , 接着把 SYN和 ACK 标志位置为 1 。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 SYN-RCVD 状态。   客户端收到服务端报文后，还要向服务端回应最后⼀个应答报文，首先该应答报文 TCP 首部 ACK 标志位置为 1 ，其次「确认应答号」字段填入 server_isn + 1 ，最后把报文发送给服务端，这次报文可以携带客户到服务器的数据，之后客户端处于 ESTABLISHED 状态。 服务器收到客户端的应答报文后，也进入 ESTABLISHED 状态。  如何在 Linux 系统中查看 TCP 状态？ netstat -napt\n为什么是三次握手？不是两次、四次？ 以三个方面分析三次握手的原因\n三次握手才可以阻止重复历史连接的初始化 避免资源浪费（主要原因） 如果只有「两次握手」，当客户端的 SYN 请求连接在网络中阻塞，客户端没有接收到 ACK 报文，就会重新发送 SYN ，由于没有第三次握手，服务器不清楚客户端是否收到了自己发送的建⽴连接的 ACK 确认信号，所以每收到⼀个 SYN 就只能先主动建立⼀个连接，这会造成什么情况呢？\n如果客户端的 SYN 阻塞了，重复发送多次 SYN 报文，那么服务器在收到请求后就会建立多个冗余的无效链接，造成不必要的资源浪费。\n ⼀个「旧 SYN 报文」比「最新的 SYN 」 报文早到达了服务端； 那么此时服务端就会回⼀个 SYN + ACK 报文给客户端； 客户端收到后可以根据自身的上下文，判断这是⼀个历史连接（序列号过期或超时），那么客户端就会发送RST 报文给服务端，表示中止这⼀次连接。  三次握手才可以同步双方的初始序列号 互相发送序列号并互相得到对方的确认，至少需要三次握手。如果两次握手那么服务端无法得到客户端的确认信息。\nTCP连接断开  客户端打算关闭连接，此时会发送⼀个 TCP 首部 FIN 标志位被置为 1 的报文，也即 FIN 报文，之后客户端进入 FIN_WAIT_1 状态。 服务端收到该报文后，就向客户端发送 ACK 应答报文，接着服务端进入 CLOSED_WAIT 状态。 客户端收到服务端的 ACK 应答报文后，之后进入 FIN_WAIT_2 状态。 等待服务端处理完数据后，也向客户端发送 FIN 报文，之后服务端进入 LAST_ACK 状态。 客户端收到服务端的 FIN 报文后，回⼀个 ACK 应答报文，之后进入 TIME_WAIT 状态 服务器收到了 ACK 应答报文后，就进入了 CLOSED 状态，⾄此服务端已经完成连接的关闭。 客户端在经过 2MSL ⼀段时间后，⾃动进入 CLOSED 状态，⾄此客户端也完成连接的关闭。  每个方向都需要⼀个 FIN 和⼀个 ACK，因此通常被称为四次挥手。这⾥⼀点需要注意是：主动关闭连接的，才有 TIME_WAIT 状态。\n为什么需要四次挥手  关闭连接时，客户端向服务端发送 FIN 时，仅仅表示客户端不再发送数据了但是还能接收数据。 服务器收到客户端的 FIN 报文时，先回⼀个 ACK 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 FIN 报文给客户端来表示同意现在关闭连接。 从上面过程可知，服务端通常需要等待完成数据的发送和处理，所以服务端的 ACK 和 FIN ⼀般都会分开发送，从而比三次握手导致多了⼀次。  为什么 TIME_WAIT 等待的时间是 2MSL？ MSL 是 Maximum Segment Lifetime，报文最大生存时间，它是任何报文在网络上存在的最⻓时间，超过这个时间报文将被丢弃。因为 TCP 报文基于是 IP 协议的，而 IP 头中有⼀个 TTL 字段，是 IP 数据报可以经过的最大路由数，每经过⼀个处理他的路由器此值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。\nMSL 与 TTL 的区别： MSL 的单位是时间，而 TTL 是经过路由跳数。所以 MSL 应该要大于等于 TTL 消耗为 0 的时间，以确保报文已被⾃然消亡。TIME_WAIT 等待 2 倍的 MSL，比较合理的解释是： 网络中可能存在来⾃发送方的数据包，当这些发送方的数据包被接收方处理后⼜会向对方发送响应，所以⼀来⼀回需要等待 2倍的时间。\n比如如果被动关闭方没有收到断开连接的最后的 ACK 报文，就会触发超时重发 Fin 报文，另⼀方接收到 FIN 后，会重发 ACK 给被动关闭方， ⼀来⼀去正好 2 个MSL。\n2MSL 的时间是从客户端接收到 FIN 后发送 ACK 开始计时的。如果在 TIME-WAIT 时间内，因为客户端的 ACK没有传输到服务端，客户端⼜接收到了服务端重发的 FIN 报文，那么 2MSL 时间将重新计时。\n在 Linux 系统⾥ 2MSL 默认是 60 秒，那么⼀个 MSL 也就是 30 秒。Linux 系统停留在 TIME_WAIT 的时间为固定的 60 秒。\n为什么需要 TIME_WAIT 状态？ 防止旧连接的数据包 经过 2MSL 这个时间，⾜以让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都⾃然消失，再出现的数据包⼀定都是新建⽴连接所产生的。\n保证连接正确关闭 TIME-WAIT 作用是等待⾜够的时间以确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭。\nTIME_WAIT 过多有什么危害？ 过多的 TIME-WAIT 状态主要的危害有两种：\n 第⼀是内存资源占用； 第⼆是对端口资源的占用，⼀个 TCP 连接⾄少消耗⼀个本地端口；如果发起连接⼀方的 TIME_WAIT 状态过多，占满了所有端口资源，则会导致无法创建新连接。  如何优化 TIME_WAIT？ Linux 内核参数开启后，则可以复用处于 TIME_WAIT 的 socket 为新的连接所用。tcp_tw_reuse 功能只能用客户端（连接发起方），因为开启了该功能，在调用 connect()函数时，内核会随机找⼀个 time_wait 状态超过 1 秒的连接给新的连接复用。\nTCP保活机制 TCP短连接:\nTCP短连接的情况，client向server发起连接请求，server接到请求，然后双方建立连接。client向server发送消息，server回应client，然后一次读写就完成了，这时候双方任何一个都可以发起close操作，不过一般都是client先发起close操作。\n为什么呢，一般的server不会回复完client后立即关闭连接的，当然不排除有特殊的情况。从上面的描述看，短连接一般只会在client/server间传递一次读写操作\n短连接的优点是：管理起来比较简单，存在的连接都是有用的连接，不需要额外的控制手段。\nTCP长连接：\n长连接的情况，client向server发起连接，server接受client连接，双方建立连接。Client与server完成一次读写之后，它们之间的连接并不会主动关闭，后续的读写操作会继续使用这个连接。\n首先说一下TCP/IP详解上讲到的TCP保活功能，保活功能主要为服务器应用提供，服务器应用希望知道客户主机是否崩溃，从而可以代表客户使用资源。如果客户已经消失，使得服务器上保留一个半开放的连接，而服务器又在等待来自客户端的数据，则服务器将应远等待客户端的数据，保证功能就是试图在服务器端检测到这种半开放的连接。\n如果一个给定的连接在两小时内没有任何的动作，则服务器就向客户发一个探测报文段，客户主机必须处于以下4个状态之一：\n 客户主机依然正常运行，并从服务器可达。客户的TCP响应正常，而服务器也知道对方是正常的，服务器在两小时后将保证定时器复位。 客户主机已经崩溃，并且关闭或者正在重新启动。在任何一种情况下，客户的TCP都没有响应。服务端将不能收到对探测的响应，并在75秒后超时。服务器总共发送10个这样的探测 ，每个间隔75秒。如果服务器没有收到一个响应，它就认为客户主机已经关闭并终止连接。 客户主机崩溃并已经重新启动。服务器将收到一个对其保证探测的响应，这个响应是一个复位，使得服务器终止这个连接。 客户机正常运行，但是服务器不可达，这种情况与2类似，TCP能发现的就是没有收到探查的响应。  从上面可以看出，TCP保活功能主要为探测长连接的存活状况，不过这里存在一个问题，存活功能的探测周期太长，还有就是它只是探测TCP连接的存活，属于比较斯文的做法，遇到恶意的连接时，保活功能就不够使了。\n既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？  MTU ：⼀个网络包的最大长度，以太网中⼀般为 1500 字节； MSS ：除去 IP 和 TCP 头部之后，⼀个网络包所能容纳的 TCP 数据的最大度；  当 IP 层有⼀个超过 MTU 大小的数据（TCP 头部 + TCP 数据）要发送，那么 IP 层就要进⾏分片，把数据分片成若⼲片，保证每⼀个分片都小于 MTU。把⼀份 IP 数据报进⾏分片以后，由⽬标主机的 IP 层来进⾏重新组装后，再交给上⼀层 TCP 传输层。\n这看起来井然有序，但这存在隐患的，那么当如果⼀个 IP 分片丢失，整个 IP 报文的所有分片都得重传。\n因为 IP 层本身没有超时重传机制，它由传输层的 TCP 来负责超时和重传。\n当接收方发现 TCP 报文（头部 + 数据）的某⼀片丢失后，则不会响应 ACK 给对方，那么发送方的 TCP 在超时后，就会重发「整个 TCP 报文（头部 + 数据）」。\n因此，可以得知由 IP 层进⾏分片传输，是非常没有效率的。\n所以，为了达到最佳的传输效能 TCP 协议在建⽴连接的时候通常要协商双方的 MSS 值，当 TCP 层发现数据超过MSS 时，则就先会进⾏分片，当然由它形成的 IP 包的⻓度也就不会大于 MTU ，⾃然也就不用 IP 分片了。\n经过 TCP 层分片后，如果⼀个 TCP 分片丢失后，进⾏重发时也是以 MSS 为单位，而不用重传所有的分片，大大增加了重传的效率。\n什么是 SYN 攻击？如何避免 SYN 攻击？ SYN攻击 我们都知道 TCP 连接建⽴是需要三次握手，假设攻击者短时间伪造不同 IP 地址的 SYN 报文，服务端每接收到⼀个 SYN 报文，就进入 SYN_RCVD 状态，但服务端发送出去的 ACK + SYN 报文，无法得到未知 IP 主机的ACK 应答，久而久之就会占满服务端的 SYN 接收队列（未连接队列），使得服务器不能为正常用户服务。\n解决方法 方法一：\n其中⼀种解决方式是通过修改 Linux 内核参数，控制队列大小和当队列满时应做什么处理。\n 当网卡接收数据包的速度大于内核处理的速度时，会有⼀个队列保存这些数据包。控制该队列的最大值如下参数：net.core.netdev_max_backlog SYN_RCVD 状态连接的最大个数：net.ipv4.tcp_max_syn_backlog 超出处理能时，对新的 SYN 直接回报 RST，丢弃连接：net.ipv4.tcp_abort_on_overflow  方法二：\n 当 「 SYN 队列」满之后，后续服务器收到 SYN 包，不进入「 SYN 队列」； 计算出⼀个 cookie 值，再以 SYN + ACK 中的「序列号」返回客户端，（cookie 的作用是验证之后可能到达的ACK的有效性，保证这是一次完整的握手获得SYN报文中携带的TCP选项信息） 服务端接收到客户端的应答报文时，服务器会检查这个 ACK 包的合法性。如果合法，直接放入到「 Accept队列」。 最后应用通过调用 accpet() socket 接口，从「 Accept 队列」取出的连接。  TCP重传机制 超时重传 重传机制的其中⼀个方式，就是在发送数据时，设定⼀个定时器，当超过指定的时间后，没有收到对方的 ACK确认应答报文，就会重发该数据，也就是我们常说的超时重传。 TCP 会在以下两种情况发生超时重传：\n 数据包丢失 确认应答丢失  超时时间 RTT 就是数据从网络⼀端传送到另⼀端所需的时间，也就是包的往返时间。超时重传时间是以 RTO （Retransmission Timeout 超时重传时间）表示。\n超时重传时间 RTO 的值应该略大于报文往返 RTT 的值。\n 当超时时间 RTO 较大时，重发就慢，丢了老半天才重发，没有效率，性能差； 当超时时间 RTO 较小时，会导致可能并没有丢就重发，于是重发的就快，会增加网络拥塞，导致更多的超时，更多的超时导致更多的重发。  快速重传 TCP 还有另外⼀种快速重传（Fast Retransmit）机制，它不以时间为驱动，而是以数据驱动重传\n快速重传的⼯作方式是当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。\n快速重传机制只解决了⼀个问题，就是超时时间的问题，但是它依然面临着另外⼀个问题。就是重传的时候，是重传之前的⼀个，还是重传所有的问题。\nSACK 还有一种实现重传机制的方式叫：SACK（ Selective Acknowledgment 选择性确认）。 这种方式需要在 TCP 头部「选项」字段里加一个 SACK 的东西，它可以将缓存的地图发送给发送方，这样发送方就可以知道哪些数据收到了，哪些数据没收到知道了这些信息，就可以只重传丢失的数据。\nDSACK Duplicate SACK ⼜称 D-SACK ，其主要使用了 SACK 来告诉「发送方」有哪些数据被重复接收了。\n滑动窗口 累计确认不怕ACK信息丢失\n累计确认：只要发送方收到了 ACK700 确认应答，就意味着 700 之前的所有数据「接收方」都收到了。这个模式就叫累计确认或者累计应答。\n窗口大小如何确定 这个字段是接收端告诉发送端 还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能⼒来发送数据，而不会导致接收端处理不过来。所以，通常窗口的大小是由接收方的窗口大小来决定的。\n发送方发送的数据大小不能超过接收方的窗口大小，否则接收方就无法正常接收到数据。\n流量控制 发送方不能无脑的发数据给接收方，要考虑接收方处理能⼒。\n如果⼀直无脑的发数据给对方，但对方处理不过来，那么就会导致触发重发机制，从而导致网络流量的无端的浪费。\n为了解决这种现象发生，TCP 提供⼀种机制可以让「发送方」根据「接收方」的实际接收能⼒控制发送的数据量，这就是所谓的流量控制。\n根据调整窗口的大小来控制发送方与接收方的流量\n拥塞控制 流量控制与拥塞控制对比 前面的流量控制是避免「发送方」的数据填满「接收方」的缓存，但是并不知道网络的中发生了什么。⼀般来说，计算机网络都处在⼀个共享的环境。因此也有可能会因为其他主机之间的通信使得网络拥堵。\n在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是⼀重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放大\u0026hellip;.\n于是，就有了拥塞控制，控制的⽬的就是避免「发送方」的数据填满整个网络。为了在「发送方」调节所要发送数据的量，定义了⼀个叫做「拥塞窗口」的概念。\n拥塞窗口 cwnd是发送方维护的⼀个的状态变量，它会根据网络的拥塞程度动态变化的。\n我们在前面提到过发送窗口 swnd 和接收窗口 rwnd 是约等于的关系，那么由于加入了拥塞窗口的概念后，此时发送窗口的值是swnd = min(cwnd, rwnd)，也就是拥塞窗口和接收窗口中的最小值。\n拥塞窗口 cwnd 变化的规则：\n 只要网络中没有出现拥塞， cwnd 就会增大； 但网络中出现了拥塞， cwnd 就减少；  传输轮次：每一个窗口为一轮，例如当前轮次窗口为4，那么传输完4个TCP报文后，开始下一轮。\n","date":"2022-07-18T00:04:43+08:00","permalink":"https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C02-tcp%E5%8D%8F%E8%AE%AE/","title":"网络02-TCP协议"},{"content":"数据链路层 [计算机网络 - 链路层 | CS-Notes (cyc2018.xyz)](http://www.cyc2018.xyz/计算机基础/网络基础/计算机网络 - 链路层.html)\n网络层和数据链路层的关系 IP 的作用是主机之间通信用的，而 MAC 的作用则是实现「直连」的两个设备之间通信，而 IP 则负责在「没有直连」的两个网络之间进行通信传输。\nIP地址分类 D类地址用于组播（多播用于将包发送给特定组内的所有主机。）、E类地址为保留用\n主机个数 每类地址的最大主机个数要看主机号的位数，例如C类地址的主机号占8位，那么C类地址的最大主机个数位：\n为什么要减2呢？因为在 IP 地址中，有两个 IP 是特殊的，分别是主机号全为 1 和 全为 0 地址。\n广播地址可以分为本地广播和直接广播两种。\n 在本网络内广播的叫做本地广播。例如网络地址为 192.168.0.0/24 的情况下，广播地址是 192.168.0.255 。因为这个广播地址的 IP 包会被路由器屏蔽，所以不会到达 192.168.0.0/24 以外的其他链路上。 在不同网络之间的广播叫做直接广播。例如网络地址为 192.168.0.0/24 的主机向 192.168.1.255/24 的目标地址发送 IP 包。收到这个包的路由器，将数据转发给 192.168.1.0/24，从而使得所有192.168.1.1~192.168.1.254 的主机都能收到这个包（由于直接广播有⼀定的安全问题，多数情况下会在路由器上设置为不转发）。  IP分类的优缺点 优点  不管是路由器还是主机解析到⼀个 IP 地址时候，我们判断其 IP 地址的首位是否为 0，为 0 则为 A 类地址，那么就能很快的找出网络地址和主机地址。优点就是简单明了、选路（基于网络地址）简单。  缺点   同⼀网络下没有地址层次，比如⼀个公司⾥用了 B 类地址，但是可能需要根据⽣产环境、测试环境、开发环境来划分地址层次，而这种 IP 分类是没有地址层次划分的功能，所以这就缺少地址的灵活性。\n  A、B、C类有个尴尬处境，就是不能很好的与现实网络匹配。C 类地址能包含的最大主机数量实在太少了，只有 254 个，估计⼀个网吧都不够用。而 B 类地址能包含的最大主机数量⼜太多了，6 万多台机器放在⼀个网络下面，⼀般的企业基本达不到这个规模，闲着的地址就是浪费。这两个缺点，都可以在 CIDR ⽆分类地址解决。\n  无分类地址 CIDR ⼦网掩码，掩码的意思就是掩盖掉主机号，剩余的就是网络号。将⼦网掩码和 IP 地址按位计算 AND，就可得到网络号。\n子网划分：从主机号中借几位作为子网号，同时搭配对应的子网掩码。\nIP地址与路由控制 IP地址的网络地址这⼀部分是用于进行路由控制。\n路由控制表中记录着网络地址与下⼀步应该发送至路由器的地址。在主机和路由器上都会有各自的路由器控制表。\n在发送 IP 包时，首先要确定 IP 包首部中的目标地址，再从路由控制表中找到与该地址具有相同网络地址的记录，根据该记录将 IP 包转发给相应的下⼀个路由器。如果路由控制表中存在多条相同网络地址的记录，就选择相同位数最多的网络地址，也就是最长匹配。\n下面以下图的网络链路作为例⼦说明\n环回地址 环回地址是在同⼀台计算机上的程序之间进行网络通信时所使用的⼀个默认地址。计算机使用⼀个特殊的 IP 地址 127.0.0.1 作为环回地址。与该地址具有相同意义的是⼀个叫做 localhost 的主机名。使用这个 IP 或主机名时，数据包不会流向网络。\nIP分片与重组 每种数据链路的最大传输单元 MTU 都是不相同的，如 FDDI 数据链路 MTU 4352、以太网的 MTU 是 1500 字节等。\n每种数据链路的 MTU 之所以不同，是因为每个不同类型的数据链路的使用目的不同。使用目的不同，可承载的MTU 也就不同。\n其中，我们最常见数据链路是以太网，它的 MTU 是 1500 字节。\n那么当 IP 数据包大小大于 MTU 时， IP 数据包就会被分片。\n经过分片之后的 IP 数据报在被重组的时候，只能由目标主机进行，路由器是不会进行重组的。\n假设发送⽅发送⼀个 4000 字节的大数据报，若要传输在以太网链路，则需要把数据报分片成 3 个小数据报进行传输，再交由接收⽅重组成大数据报。\nIPV6 IPv4 地址长度共 32 位，是以每 8 位作为⼀组，并用点分⼗进制的表示⽅式。\nIPv6 地址长度是 128 位，是以每 16 位作为⼀组，每组用冒号 「:」 隔开。\nIPv6 相比 IPv4 的首部改进：\n 取消了首部校验和字段。 因为在数据链路层和传输层都会校验，因此 IPv6 直接取消了 IP 的校验。 取消了分片/重新组装相关字段。 分片与重组是耗时的过程，IPv6 不允许在中间路由器进行分片与重组，这种操作只能在源与目标主机，这将大大提⾼了路由器转发的速度。 取消选项字段。 选项字段不再是标准 IP 首部的⼀部分了，但它并没有消失，而是可能出现在 IPv6 首部中的「下⼀个首部」指出的位置上。删除该选项字段使的 IPv6 的首部成为固定长度的 40 字节。  IP协议相关技术 DNS 根域是在最顶层，它的下⼀层就是 com 顶级域，再下面是 server.com。\n所以域名的层级关系类似⼀个树状结构：\n 根 DNS 服务器 顶级域 DNS 服务器（com） 权威 DNS 服务器（server.com）  ARP 在传输⼀个 IP 数据报的时候，确定了源 IP 地址和目标 IP 地址后，就会通过主机「路由表」确定 IP 数据包下⼀跳。然而，网络层的下⼀层是数据链路层，所以我们还要知道「下⼀跳」的 MAC 地址。\n由于主机的路由表中可以找到下⼀跳的 IP 地址，所以可以通过 ARP 协议，求得下⼀跳的 MAC 地址。\n那么 ARP ⼜是如何知道对⽅ MAC 地址的呢？\n简单地说，ARP 是借助 ARP 请求与 ARP 响应两种类型的包确定 MAC 地址的。\n 主机会通过广播发送 ARP 请求，这个包中包含了想要知道的 MAC 地址的主机 IP 地址。 当同个链路中的所有设备收到 ARP 请求时，会去拆开 ARP 请求包⾥的内容，如果 ARP 请求包中的目标 IP地址与自己的 IP 地址⼀致，那么这个设备就将自己的 MAC 地址塞入 ARP 响应包返回给主机。  操作系统通常会把第⼀次通过 ARP 获取的 MAC 地址缓存起来，以便下次直接从缓存中找到对应 IP 地址的 MAC地址。不过，MAC 地址的缓存是有⼀定期限的，超过这个期限，缓存的内容将被清除。\nRARP ARP 协议是已知 IP 地址求 MAC 地址，那 RARP 协议正好相反，它是已知 MAC 地址求 IP 地址。例如将打印机服务器等小型嵌入式设备接入到网络时就经常会用得到。\n通常这需要架设⼀台 RARP 服务器，在这个服务器上注册设备的 MAC 地址及其 IP 地址。然后再将这个设备接入到网络，接着：\n 该设备会发送⼀条「我的 MAC 地址是XXXX，请告诉我，我的IP地址应该是什么」的请求信息。 RARP 服务器接到这个消息后返回「MAC地址为 XXXX 的设备，IP地址为 XXXX」的信息给这个设备。 最后，设备就根据从 RARP 服务器所收到的应答信息设置自己的 IP 地址。  DHCP DHCP 在⽣活中我们是很常见的了，我们的电脑通常都是通过 DHCP 动态获取 IP 地址，大大省去了配 IP 信息繁琐的过程\nDHCP 交互中，全程都是使用 UDP 广播通信 。\n先说明⼀点，DHCP 客户端进程监听的是 68 端口号，DHCP 服务端进程监听的是 67 端口号。\n这 4 个步骤：\n 客户端首先发起 DHCP 发现报文（DHCP DISCOVER） 的 IP 数据报，由于客户端没有 IP 地址，也不知道DHCP 服务器的地址，所以使用的是 UDP 广播通信，其使用的广播目的地址是 255.255.255.255（端口67） 并且使用 0.0.0.0（端口 68） 作为源 IP 地址。DHCP 客户端将该 IP 数据报传递给链路层，链路层然后将帧广播到所有的网络中设备。 DHCP 服务器收到 DHCP 发现报文时，用 DHCP 提供报文（DHCP OFFER） 向客户端做出响应。该报文仍然使用 IP 广播地址 255.255.255.255，该报文信息携带服务器提供可租约的 IP 地址、⼦网掩码、默认网关、DNS 服务器以及 IP 地址租用期。 客户端收到⼀个或多个服务器的 DHCP 提供报文后，从中选择⼀个服务器，并向选中的服务器发送 DHCP 请求报文（DHCP REQUEST进行响应，回显配置的参数。 最后，服务端用 DHCP ACK 报文对 DHCP 请求报文进行响应，应答所要求的参数。  ⼀旦客户端收到 DHCP ACK 后，交互便完成了，并且客户端能够在租用期内使用 DHCP 服务器分配的 IP 地址。如果租约的 DHCP IP 地址快期后，客户端会向服务器发送 DHCP 请求报文：\n 服务器如果同意继续租用，则用 DHCP ACK 报文进行应答，客户端就会延长租期。 服务器如果不同意继续租用，则用 DHCP NACK 报文，客户端就要停⽌使用租约的 IP 地址。  NAT IPv4 的地址是非常紧缺的，在前面我们也提到可以通过⽆分类地址来减缓 IPv4 地址耗尽的速度，但是互联网的用户增速是非常惊⼈的，所以 IPv4 地址依然有被耗尽的危险。于是，提出了⼀种网络地址转换 NAT 的⽅法，再次缓解了 IPv4 地址耗尽的问题。\n简单的来说 NAT 就是同个公司、家庭、教室内的主机对外部通信时，把私有 IP 地址转换成公有 IP 地址。\n那不是 N 个私有 IP 地址，你就要 N 个公有 IP 地址？这怎么就缓解了 IPv4 地址耗尽的问题？\n由于绝大多数的网络应用都是使用传输层协议 TCP 或 UDP 来传输数据的。因此，可以把 IP 地址 + 端口号⼀起进行转换。这样，就用⼀个全球 IP 地址就可以了，这种转换技术就叫网络地址与端口转换 NAPT。\n图中有两个客户端 192.168.1.10 和 192.168.1.11 同时与服务器 183.232.231.172 进行通信，并且这两个客户端的本地端口都是 1025。\n此时，两个私有 IP 地址都转换 IP 地址为公有地址 120.229.175.121，但是以不同的端口号作为区分。\n于是，⽣成⼀个 NAPT 路由器的转换表，就可以正确地转换地址跟端口的组合，令客户端 A、B 能同时与服务器之间进行通信。\n这种转换表在 NAT 路由器上自动⽣成。例如，在 TCP 的情况下，建⽴ TCP 连接首次握⼿时的 SYN 包⼀经发出，就会⽣成这个表。而后⼜随着收到关闭连接时发出 FIN 包的确认应答从表中被删除。\nNAT 的缺点 由于 NAT/NAPT 都依赖于自己的转换表，因此会有以下的问题：\n 外部⽆法主动与 NAT 内部服务器建⽴连接，因为 NAPT 转换表没有转换记录。 转换表的⽣成与转换操作都会产⽣性能开销。 通信过程中，如果 NAT 路由器重启了，所有的 TCP 连接都将被重置。  解决  改用IPV6，每台机器一个公网IP NAT穿透技术： 客户端主动从 NAT 设备获取公有 IP 地址，然后自己建⽴端口映射条目，然后用这个条目对外通信，就不需要 NAT 设备来进行转换了  ICMP ICMP 全称是 Internet Control Message Protocol，也就是互联网控制报文协议。\nICMP 主要的功能包括：确认 IP 包是否成功送达目标地址、报告发送过程中 IP 包被废弃的原因和改善网络设置等。\n在 IP 通信中如果某个 IP 包因为某种原因未能达到目标地址，那么这个具体的原因将由 ICMP 负责通知。\nPing工作原理 traceroute命令 有⼀款充分利用 ICMP 差错报文类型的应用叫做 traceroute （在UNIX、MacOS中是这个命令，而在Windows中对等的命令叫做 tracert ）\n作用 traceroute 的第⼀个作用就是故意设置特殊的 TTL，来追踪去往目的地时沿途经过的路由器。\ntraceroute 的参数指向某个目的 IP 地址：\n1  traceout 192.168.1.100   原理 它的原理就是利用 IP 包的⽣存期限 从 1 开始按照顺序递增的同时发送 UDP 包，强制接收 ICMP 超时消息的⼀种⽅法。\n比如，将 TTL 设置 为 1 ，则遇到第⼀个路由器，就牺牲了，接着返回 ICMP 差错报文网络包，类型是时间超时。\n接下来将 TTL 设置为 2 ，第⼀个路由器过了，遇到第⼆个路由器也牺牲了，也同时返回了 ICMP 差错报文数据包，如此往复，直到到达目的主机。\n这样的过程，traceroute 就可以拿到了所有的路由器 IP。当然有的路由器根本就不会返回这个 ICMP，所以对于有的公网地址，是看不到中间经过的路由的。\n发送⽅如何知道发出的 UDP 包是否到达了目的主机呢？\ntraceroute 在发送 UDP 包时，会填入⼀个不可能的端口号值作为 UDP 目标端口号（大于 3000 ）。当目的主机，收到 UDP 包后，会返回 ICMP 差错报文消息，但这个差错报文消息的类型是「端口不可达」。所以，当差错报文类型是端口不可达时，说明发送⽅发出的 UDP 包到达了目的主机。\n","date":"2022-07-18T00:04:34+08:00","permalink":"https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C03-ip%E5%8D%8F%E8%AE%AE/","title":"网络03-IP协议"},{"content":"类加载过程 生命周期 类是在运行期间第一次使用时动态加载的（不使用不加载），而不是一次性加载所有类，因为一次性加载会占用很多的内存，加载的类信息存放于一块成为方法区的内存空间\n包括 7 个阶段：\n 加载（Loading） 链接：验证（Verification）、准备（Preparation）、解析（Resolution） 初始化（Initialization） 使用（Using） 卸载（Unloading）  加载阶段 加载是类加载的其中一个阶段，注意不要混淆\n加载过程完成以下三件事：\n 通过类的完全限定名称获取定义该类的二进制字节流（二进制字节码） 将该字节流表示的静态存储结构转换为方法区的运行时存储结构（Java 类模型） 在内存中生成一个代表该类的 Class 对象，作为该类在方法区中的各种数据的访问入口  其中二进制字节流可以从以下方式中获取：\n 从 ZIP 包读取，成为 JAR、EAR、WAR 格式的基础 从网络中获取，最典型的应用是 Applet 由其他文件生成，例如由 JSP 文件生成对应的 Class 类 运行时计算生成，例如动态代理技术，在 java.lang.reflect.Proxy 使用 ProxyGenerator.generateProxyClass 生成字节码  将字节码文件加载至方法区后，会在堆中创建一个 java.lang.Class 对象，用来引用位于方法区内的数据结构，该 Class 对象是在加载类的过程中创建的，每个类都对应有一个 Class 类型的对象\n方法区内部采用 C++ 的 instanceKlass 描述 Java 类的数据结构：\n _java_mirror 即 Java 的类镜像，例如对 String 来说就是 String.class，作用是把 class 暴露给 Java 使用 _super 即父类、_fields 即成员变量、_methods 即方法、_constants 即常量池、_class_loader 即类加载器、_vtable 虚方法表、_itable 接口方法表  加载过程：\n 如果这个类还有父类没有加载，先加载父类 加载和链接可能是交替运行的 Class 对象和 _java_mirror 相互持有对方的地址，堆中对象通过 instanceKlass 和元空间进行交互  创建数组类有些特殊，因为数组类本身并不是由类加载器负责创建，而是由 JVM 在运行时根据需要而直接创建的，但数组的元素类型仍然需要依靠类加载器去创建，创建数组类的过程：\n 如果数组的元素类型是引用类型，那么遵循定义的加载过程递归加载和创建数组的元素类型 JVM 使用指定的元素类型和数组维度来创建新的数组类 基本数据类型由启动类加载器加载  链接阶段 验证 确保 Class 文件的字节流中包含的信息是否符合 JVM 规范，保证被加载类的正确性，不会危害虚拟机自身的安全\n主要包括四种验证：\n  文件格式验证\n  语义检查，但凡在语义上不符合规范的，虚拟机不会给予验证通过\n  是否所有的类都有父类的存在（除了 Object 外，其他类都应该有父类）\n  是否一些被定义为 final 的方法或者类被重写或继承了\n  非抽象类是否实现了所有抽象方法或者接口方法\n  是否存在不兼容的方法\n    字节码验证，试图通过对字节码流的分析，判断字节码是否可以被正确地执行\n 在字节码的执行过程中，是否会跳转到一条不存在的指令 函数的调用是否传递了正确类型的参数 变量的赋值是不是给了正确的数据类型 栈映射帧（StackMapTable）在这个阶段用于检测在特定的字节码处，其局部变量表和操作数栈是否有着正确的数据类型    符号引用验证，Class 文件在其常量池会通过字符串记录将要使用的其他类或者方法\n  准备 准备阶段为静态变量（类变量）分配内存并设置初始值，使用的是方法区的内存：\n说明：实例变量不会在这阶段分配内存，它会在对象实例化时随着对象一起被分配在堆中，类加载发生在所有实例化操作之前，并且类加载只进行一次，实例化可以进行多次\n类变量初始化：\n static 变量分配空间和赋值是两个步骤：分配空间在准备阶段完成，赋值在初始化阶段完成 如果 static 变量是 final 的基本类型以及字符串常量，那么编译阶段值（方法区）就确定了，准备阶段会显式初始化 如果 static 变量是 final 的，但属于引用类型或者构造器方法的字符串，赋值在初始化阶段完成  实例：\n  初始值一般为 0 值，例如下面的类变量 value 被初始化为 0 而不是 123：\n1  public static int value = 123;     常量 value 被初始化为 123 而不是 0：\n1  public static final int value = 123;     Java 并不支持 boolean 类型，对于 boolean 类型，内部实现是 int，由于 int 的默认值是0，故 boolean 的默认值就是 false\n  解析 将常量池中类、接口、字段、方法的符号引用替换为直接引用（内存地址）的过程：\n 符号引用：一组符号来描述目标，可以是任何字面量，属于编译原理方面的概念，如：包括类和接口的全限名、字段的名称和描述符、方法的名称和方法描述符（因为类还没有加载完，很多方法是找不到的） 直接引用：直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄，如果有了直接引用，那说明引用的目标必定已经存在于内存之中  例如：在 com.demo.Solution 类中引用了 com.test.Quest，把 com.test.Quest 作为符号引用存进类常量池，在类加载完后，用这个符号引用去方法区找这个类的内存地址\n解析动作主要针对类或接口、字段、类方法、接口方法、方法类型等\n 在类加载阶段解析的是非虚方法，静态绑定 也可以在初始化阶段之后再开始解析，这是为了支持 Java 的动态绑定 通过解析操作，符号引用就可以转变为目标方法在类的虚方法表中的位置，从而使得方法被成功调用  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  public class Load2 { public static void main(String[] args) throws Exception{ ClassLoader classloader = Load2.class.getClassLoader(); // cloadClass 加载类方法不会导致类的解析和初始化，也不会加载D  Class\u0026lt;?\u0026gt; c = classloader.loadClass(\u0026#34;cn.jvm.t3.load.C\u0026#34;); // new C();会导致类的解析和初始化，从而解析初始化D  System.in.read(); } } class C { D d = new D(); } class D { }   初始化 介绍 初始化阶段才真正开始执行类中定义的 Java 程序代码，在准备阶段，类变量已经赋过一次系统要求的初始值；在初始化阶段，通过程序制定的计划去初始化类变量和其它资源，执行 clinit ()\n在编译生成 class 文件时，编译器会产生两个方法加于 class 文件中，一个是类的初始化方法 clinit，另一个是实例的初始化方法 init\n类构造器 clinit () 与实例构造器 init() 不同，它不需要程序员进行显式调用，在一个类的生命周期中，类构造器最多被虚拟机调用一次，而实例构造器则会被虚拟机调用多次，只要程序员创建对象\n类在第一次实例化加载一次，把 class 读入内存，后续实例化不再加载，引用第一次加载的类\nclinit clinit ()：类构造器，由编译器自动收集类中所有类变量的赋值动作和静态语句块中的语句合并产生的\n作用：是在类加载过程中的初始化阶段进行静态变量初始化和执行静态代码块\n 如果类中没有静态变量或静态代码块，那么 clinit 方法将不会被生成 clinit 方法只执行一次，在执行 clinit 方法时，必须先执行父类的clinit方法 static 变量的赋值操作和静态代码块的合并顺序由源文件中出现的顺序决定 static 不加 final 的变量都在初始化环节赋值  线程安全问题：\n 虚拟机会保证一个类的 clinit () 方法在多线程环境下被正确的加锁和同步，如果多个线程同时初始化一个类，只会有一个线程执行这个类的 clinit () 方法，其它线程都阻塞等待，直到活动线程执行clinit () 方法完毕 如果在一个类的 clinit () 方法中有耗时的操作，就可能造成多个线程阻塞，在实际过程中此种阻塞很隐蔽  特别注意：静态语句块只能访问到定义在它之前的类变量，定义在它之后的类变量只能赋值，不能访问\n1 2 3 4 5 6 7  public class Test { static { //i = 0; // 给变量赋值可以正常编译通过  System.out.print(i); // 这句编译器会提示“非法向前引用”  } static int i = 1; }   接口中不可以使用静态语句块，但仍然有类变量初始化的赋值操作，因此接口与类一样都会生成 clinit ()方法，两者不同的是：\n 在初始化一个接口时，并不会先初始化它的父接口，所以执行接口的 clinit ()方法不需要先执行父接口的clinit () 方法 在初始化一个类时，不会先初始化所实现的接口，所以接口的实现类在初始化时不会执行接口的 clinit () 方法 只有当父接口中定义的变量使用时，父接口才会初始化  时机 类的初始化是懒惰的，只有在首次使用时才会被装载，JVM 不会无条件地装载 Class 类型，Java 虚拟机规定，一个类或接口在初次使用前，必须要进行初始化\n主动引用：虚拟机规范中并没有强制约束何时进行加载，但是规范严格规定了有且只有下列情况必须对类进行初始化（加载、验证、准备都会发生）：\n 当创建一个类的实例时，使用 new 关键字，或者通过反射、克隆、反序列化（前文讲述的对象的创建时机） 当调用类的静态方法或访问静态字段时，遇到 getstatic、putstatic、invokestatic 这三条字节码指令，如果类没有进行过初始化，则必须先触发其初始化  getstatic：程序访问类的静态变量（不是静态常量，常量会被加载到运行时常量池） putstatic：程序给类的静态变量赋值 invokestatic ：调用一个类的静态方法   使用 java.lang.reflect 包的方法对类进行反射调用时，如果类没有进行初始化，则需要先触发其初始化 当初始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化，但这条规则并不适用于接口 当虚拟机启动时，需要指定一个要执行的主类（包含 main() 方法的那个类），虚拟机会先初始化这个主类 MethodHandle 和 VarHandle 可以看作是轻量级的反射调用机制，而要想使用这两个调用， 就必须先使用 findStaticVarHandle 来初始化要调用的类 补充：当一个接口中定义了 JDK8 新加入的默认方法（被 default 关键字修饰的接口方法）时，如果有这个接口的实现类发生了初始化，那该接口要在其之前被初始化  被动引用：所有引用类的方式都不会触发初始化，称为被动引用\n 通过子类引用父类的静态字段，不会导致子类初始化，只会触发父类的初始化 通过数组定义来引用类，不会触发此类的初始化。该过程会对数组类进行初始化，数组类是一个由虚拟机自动生成的、直接继承自 Object 的子类，其中包含了数组的属性和方法 常量（final 修饰）在编译阶段会存入调用类的常量池中，本质上没有直接引用到定义常量的类，因此不会触发定义常量的类的初始化 调用 ClassLoader 类的 loadClass() 方法加载一个类，并不是对类的主动使用，不会导致类的初始化  init init 指的是实例构造器，主要作用是在类实例化过程中执行，执行内容包括成员变量初始化和代码块的执行\n实例化即调用 init() ，虚拟机会保证这个类的构造方法的线程安全，先为实例变量分配内存空间，再执行赋默认值，然后根据源码中的顺序执行赋初值或代码块，没有成员变量初始化和代码块则不会执行\n类实例化过程：父类的类构造器 init() -\u0026gt; 子类的类构造器 init() -\u0026gt; 父类的成员变量和实例代码块 -\u0026gt; 父类的构造函数 -\u0026gt; 子类的成员变量和实例代码块 -\u0026gt; 子类的构造函数\nnew 关键字会创建对象并复制 dup 一个对象引用，一个调用 init() 方法，另一个用来赋值给接收者\n卸载阶段 时机：执行了 System.exit() 方法，程序正常执行结束，程序在执行过程中遇到了异常或错误而异常终止，由于操作系统出现错误而导致Java虚拟机进程终止\n卸载类即该类的 Class 对象被 GC，卸载类需要满足3个要求:\n 该类的所有的实例对象都已被 GC，也就是说堆不存在该类的实例对象 该类没有在其他任何地方被引用 该类的类加载器的实例已被 GC，一般是可替换类加载器的场景，如 OSGi、JSP 的重加载等，很难达成  在 JVM 生命周期类，由 JVM 自带的类加载器加载的类是不会被卸载的，自定义的类加载器加载的类是可能被卸载。因为 JVM 会始终引用启动、扩展、系统类加载器，这些类加载器始终引用它们所加载的类，这些类始终是可及的\n类加载器 类加载 类加载方式：\n 隐式加载：不直接在代码中调用 ClassLoader 的方法加载类对象  创建类对象、使用类的静态域、创建子类对象、使用子类的静态域 在 JVM 启动时，通过三大类加载器加载 class   显式加载：  ClassLoader.loadClass(className)：只加载和连接，不会进行初始化 Class.forName(String name, boolean initialize, ClassLoader loader)：使用 loader 进行加载和连接，根据参数 initialize 决定是否初始化    类的唯一性：\n 在 JVM 中表示两个 class 对象判断为同一个类存在的两个必要条件：  类的完整类名必须一致，包括包名 加载这个类的 ClassLoader（指 ClassLoader 实例对象）必须相同   这里的相等，包括类的 Class 对象的 equals() 方法、isAssignableFrom() 方法、isInstance() 方法的返回结果为 true，也包括使用 instanceof 关键字做对象所属关系判定结果为 true  命名空间：\n 每个类加载器都有自己的命名空间，命名空间由该加载器及所有的父加载器所加载的类组成 在同一命名空间中，不会出现类的完整名字（包括类的包名）相同的两个类  基本特征：\n 可见性，子类加载器可以访问父加载器加载的类型，但是反过来是不允许的 单一性，由于父加载器的类型对于子加载器是可见的，所以父加载器中加载过的类型，不会在子加载器中重复加载  加载器 类加载器是 Java 的核心组件，用于加载字节码到 JVM 内存，得到 Class 类的对象\n从 Java 虚拟机规范来讲，只存在以下两种不同的类加载器：\n 启动类加载器（Bootstrap ClassLoader）：使用 C++ 实现，是虚拟机自身的一部分 自定义类加载器（User-Defined ClassLoader）：Java 虚拟机规范将所有派生于抽象类 ClassLoader 的类加载器都划分为自定义类加载器，使用 Java 语言实现，独立于虚拟机  从 Java 开发人员的角度看：\n 启动类加载器（Bootstrap ClassLoader）：  处于安全考虑，Bootstrap 启动类加载器只加载包名为 java、javax、sun 等开头的类 类加载器负责加载在 JAVA_HOME/jre/lib 或 sun.boot.class.path 目录中的，或者被 -Xbootclasspath 参数所指定的路径中的类，并且是虚拟机识别的类库加载到虚拟机内存中 仅按照文件名识别，如 rt.jar 名字不符合的类库即使放在 lib 目录中也不会被加载 启动类加载器无法被 Java 程序直接引用，编写自定义类加载器时，如果要把加载请求委派给启动类加载器，直接使用 null 代替   扩展类加载器（Extension ClassLoader）：  由 ExtClassLoader (sun.misc.Launcher$ExtClassLoader) 实现，上级为 Bootstrap，显示为 null 将 JAVA_HOME/jre/lib/ext 或者被 java.ext.dir 系统变量所指定路径中的所有类库加载到内存中 开发者可以使用扩展类加载器，创建的 JAR 放在此目录下，会由扩展类加载器自动加载   应用程序类加载器（Application ClassLoader）：  由 AppClassLoader(sun.misc.Launcher$AppClassLoader) 实现，上级为 Extension 负责加载环境变量 classpath 或系统属性 java.class.path 指定路径下的类库 这个类加载器是 ClassLoader 中的 getSystemClassLoader() 方法的返回值，因此称为系统类加载器 可以直接使用这个类加载器，如果应用程序中没有自定义类加载器，这个就是程序中默认的类加载器   自定义类加载器：由开发人员自定义的类加载器，上级是 Application  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  public static void main(String[] args) { //获取系统类加载器  ClassLoader systemClassLoader = ClassLoader.getSystemClassLoader(); System.out.println(systemClassLoader);//sun.misc.Launcher$AppClassLoader@18b4aac2  //获取其上层 扩展类加载器  ClassLoader extClassLoader = systemClassLoader.getParent(); System.out.println(extClassLoader);//sun.misc.Launcher$ExtClassLoader@610455d6  //获取其上层 获取不到引导类加载器  ClassLoader bootStrapClassLoader = extClassLoader.getParent(); System.out.println(bootStrapClassLoader);//null  //对于用户自定义类来说：使用系统类加载器进行加载  ClassLoader classLoader = ClassLoaderTest.class.getClassLoader(); System.out.println(classLoader);//sun.misc.Launcher$AppClassLoader@18b4aac2  //String 类使用引导类加载器进行加载的 --\u0026gt; java核心类库都是使用启动类加载器加载的  ClassLoader classLoader1 = String.class.getClassLoader(); System.out.println(classLoader1);//null  }   补充两个类加载器：\n SecureClassLoader 扩展了 ClassLoader，新增了几个与使用相关的代码源和权限定义类验证（对 class 源码的访问权限）的方法，一般不会直接跟这个类打交道，更多是与它的子类 URLClassLoader 有所关联 ClassLoader 是一个抽象类，很多方法是空的没有实现，而 URLClassLoader 这个实现类为这些方法提供了具体的实现，并新增了 URLClassPath 类协助取得 Class 字节流等功能。在编写自定义类加载器时，如果没有太过于复杂的需求，可以直接继承 URLClassLoader 类，这样就可以避免去编写 findClass() 方法及其获取字节码流的方式，使自定义类加载器编写更加简洁  常用API ClassLoader 类，是一个抽象类，其后所有的类加载器都继承自 ClassLoader（不包括启动类加载器）\n获取 ClassLoader 的途径：\n 获取当前类的 ClassLoader：clazz.getClassLoader() 获取当前线程上下文的 ClassLoader：Thread.currentThread.getContextClassLoader() 获取系统的 ClassLoader：ClassLoader.getSystemClassLoader() 获取调用者的 ClassLoader：DriverManager.getCallerClassLoader()  ClassLoader 类常用方法：\n getParent()：返回该类加载器的超类加载器 loadclass(String name)：加载名为 name 的类，返回结果为 Class 类的实例，该方法就是双亲委派模式 findclass(String name)：查找二进制名称为 name 的类，返回结果为 Class 类的实例，该方法会在检查完父类加载器之后被 loadClass() 方法调用 findLoadedClass(String name)：查找名称为 name 的已经被加载过的类，final 修饰无法重写 defineClass(String name, byte[] b, int off, int len)：将字节流解析成 JVM 能够识别的类对象 resolveclass(Class\u0026lt;?\u0026gt; c)：链接指定的 Java 类，可以使类的 Class 对象创建完成的同时也被解析 InputStream getResourceAsStream(String name)：指定资源名称获取输入流  加载模型 加载机制 在 JVM 中，对于类加载模型提供了三种，分别为全盘加载、双亲委派、缓存机制\n  全盘加载： 当一个类加载器负责加载某个 Class 时，该 Class 所依赖和引用的其他 Class 也将由该类加载器负责载入，除非显示指定使用另外一个类加载器来载入\n  双亲委派： 先让父类加载器加载该 Class，在父类加载器无法加载该类时才尝试从自己的类路径中加载该类。简单来说就是，某个特定的类加载器在接到加载类的请求时，首先将加载任务委托给父加载器，依次递归，如果父加载器可以完成类加载任务，就成功返回；只有当父加载器无法完成此加载任务时，才自己去加载\n  缓存机制： 会保证所有加载过的 Class 都会被缓存，当程序中需要使用某个 Class 时，类加载器先从缓存区中搜寻该 Class，只有当缓存区中不存在该 Class 对象时，系统才会读取该类对应的二进制数据，并将其转换成 Class 对象存入缓冲区（方法区）中\n 这就是修改了 Class 后，必须重新启动 JVM，程序所做的修改才会生效的原因    双亲委派 双亲委派模型（Parents Delegation Model）：该模型要求除了顶层的启动类加载器外，其它类加载器都要有父类加载器，这里的父子关系一般通过组合关系（Composition）来实现，而不是继承关系（Inheritance）\n工作过程：一个类加载器首先将类加载请求转发到父类加载器，只有当父类加载器无法完成时才尝试自己加载\n双亲委派机制的优点：\n  可以避免某一个类被重复加载，当父类已经加载后则无需重复加载，保证全局唯一性\n  Java 类随着它的类加载器一起具有一种带有优先级的层次关系，从而使得基础类得到统一\n  保护程序安全，防止类库的核心 API 被随意篡改\n例如：在工程中新建 java.lang 包，接着在该包下新建 String 类，并定义 main 函数\n1 2 3 4 5  public class String { public static void main(String[] args) { System.out.println(\u0026#34;demo info\u0026#34;); } }   此时执行 main 函数，会出现异常，在类 java.lang.String 中找不到 main 方法，防止恶意篡改核心 API 库。出现该信息是因为双亲委派的机制，java.lang.String 的在启动类加载器（Bootstrap）得到加载，启动类加载器优先级更高，在核心 jre 库中有其相同名字的类文件，但该类中并没有 main 方法\n  双亲委派机制的缺点：检查类是否加载的委托过程是单向的，这个方式虽然从结构上看比较清晰，使各个 ClassLoader 的职责非常明确，但顶层的 ClassLoader 无法访问底层的 ClassLoader 所加载的类（可见性）\n源码分析 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  protected Class\u0026lt;?\u0026gt; loadClass(String name, boolean resolve) throws ClassNotFoundException { synchronized (getClassLoadingLock(name)) { // 调用当前类加载器的 findLoadedClass(name)，检查当前类加载器是否已加载过指定 name 的类  Class c = findLoadedClass(name); // 当前类加载器如果没有加载过  if (c == null) { long t0 = System.nanoTime(); try { // 判断当前类加载器是否有父类加载器  if (parent != null) { // 如果当前类加载器有父类加载器，则调用父类加载器的 loadClass(name,false)  // 父类加载器的 loadClass 方法，又会检查自己是否已经加载过  c = parent.loadClass(name, false); } else { // 当前类加载器没有父类加载器，说明当前类加载器是 BootStrapClassLoader  // 则调用 BootStrap ClassLoader 的方法加载类  c = findBootstrapClassOrNull(name); } } catch (ClassNotFoundException e) { } if (c == null) { // 如果调用父类的类加载器无法对类进行加载，则用自己的 findClass() 方法进行加载  // 可以自定义 findClass() 方法  long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats  sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); } } if (resolve) { // 链接指定的 Java 类，可以使类的 Class 对象创建完成的同时也被解析  resolveClass(c); } return c; } }   破坏委派 双亲委派模型并不是一个具有强制性约束的模型，而是 Java 设计者推荐给开发者的类加载器实现方式\n破坏双亲委派模型的方式：\n  自定义 ClassLoader\n 如果不想破坏双亲委派模型，只需要重写 findClass 方法 如果想要去破坏双亲委派模型，需要去**重写 loadClass **方法    引入线程上下文类加载器\nJava 提供了很多服务提供者接口（Service Provider Interface，SPI），允许第三方为这些接口提供实现。常见的 SPI 有 JDBC、JCE、JNDI 等。这些 SPI 接口由 Java 核心库来提供，而 SPI 的实现代码则是作为 Java 应用所依赖的 jar 包被包含进类路径 classpath 里，SPI 接口中的代码需要加载具体的实现类：\n SPI 的接口是 Java 核心库的一部分，是由引导类加载器来加载的 SPI 的实现类是由系统类加载器加载，引导类加载器是无法找到 SPI 的实现类，因为双亲委派模型中 BootstrapClassloader 无法委派 AppClassLoader 来加载类  JDK 开发人员引入了线程上下文类加载器（Thread Context ClassLoader），这种类加载器可以通过 Thread 类的 setContextClassLoader 方法进行设置线程上下文类加载器，在执行线程中抛弃双亲委派加载模式，使程序可以逆向使用类加载器，使 Bootstrap 加载器拿到了 Application 加载器加载的类，破坏了双亲委派模型\n  实现程序的动态性，如代码热替换（Hot Swap）、模块热部署（Hot Deployment）\nIBM 公司主导的 JSR一291（OSGiR4.2）实现模块化热部署的关键是它自定义的类加载器机制的实现，每一个程序模块（OSGi 中称为 Bundle）都有一个自己的类加载器，当更换一个 Bundle 时，就把 Bundle 连同类加载器一起换掉以实现代码的热替换，在 OSGi 环境下，类加载器不再双亲委派模型推荐的树状结构，而是进一步发展为更加复杂的网状结构\n当收到类加载请求时，OSGi 将按照下面的顺序进行类搜索:\n 将以 java.* 开头的类，委派给父类加载器加载 否则，将委派列表名单内的类，委派给父类加载器加载 否则，将 Import 列表中的类，委派给 Export 这个类的 Bundle 的类加载器加载 否则，查找当前 Bundle 的 ClassPath，使用自己的类加载器加载 否则，查找类是否在自己的 Fragment Bundle 中，如果在就委派给 Fragment Bundle 类加载器加载 否则，查找 Dynamic Import 列表的 Bundle，委派给对应 Bundle 的类加载器加载 否则，类查找失败  热替换是指在程序的运行过程中，不停止服务，只通过替换程序文件来修改程序的行为，热替换的关键需求在于服务不能中断，修改必须立即表现正在运行的系统之中\n  对象创建 生命周期 在 Java 中，对象的生命周期包括以下几个阶段：\n   创建阶段 (Created)：\r    应用阶段 (In Use)：对象至少被一个强引用持有着\r    不可见阶段 (Invisible)：程序的执行已经超出了该对象的作用域，不再持有该对象的任何强引用\r    不可达阶段 (Unreachable)：该对象不再被任何强引用所持有，包括 GC Root 的强引用\r    收集阶段 (Collected)：垃圾回收器对该对象的内存空间重新分配做好准备，该对象如果重写了 finalize() 方法，则会去执行该方法\r    终结阶段 (Finalized)：等待垃圾回收器对该对象空间进行回收，当对象执行完 finalize() 方法后仍然处于不可达状态时进入该阶段\r    对象空间重分配阶段 (De-allocated)：垃圾回收器对该对象的所占用的内存空间进行回收或者再分配\r   参考文章：https://blog.csdn.net/sodino/article/details/38387049\n创建时机 类在第一次实例化加载一次，后续实例化不再加载，引用第一次加载的类\nJava 对象创建时机：\n  使用 new 关键字创建对象：由执行类实例创建表达式而引起的对象创建\n  使用 Class 类的 newInstance 方法（反射机制）\n  使用 Constructor 类的 newInstance 方法（反射机制）\n1 2 3 4 5 6 7 8 9 10  public class Student { private int id; public Student(Integer id) { this.id = id; } public static void main(String[] args) throws Exception { Constructor\u0026lt;Student\u0026gt; c = Student.class.getConstructor(Integer.class); Student stu = c.newInstance(123); } }   使用 newInstance 方法的这两种方式创建对象使用的就是 Java 的反射机制，事实上 Class 的 newInstance 方法内部调用的也是 Constructor 的 newInstance 方法\n  使用 Clone 方法创建对象：用 clone 方法创建对象的过程中并不会调用任何构造函数，要想使用 clone 方法，我们就必须先实现 Cloneable 接口并实现其定义的 clone 方法\n  使用（反）序列化机制创建对象：当反序列化一个对象时，JVM 会创建一个单独的对象，在此过程中，JVM 并不会调用任何构造函数，为了反序列化一个对象，需要让类实现 Serializable 接口\n  从 Java 虚拟机层面看，除了使用 new 关键字创建对象的方式外，其他方式全部都是通过转变为 invokevirtual 指令直接创建对象的\n创建过程 创建对象的过程：\n  判断对象对应的类是否加载、链接、初始化\n  为对象分配内存：指针碰撞、空闲链表。当一个对象被创建时，虚拟机就会为其分配内存来存放对象的实例变量及其从父类继承过来的实例变量，即使从隐藏变量也会被分配空间（继承部分解释了为什么会隐藏）\n  处理并发安全问题：\n 采用 CAS 配上自旋保证更新的原子性 每个线程预先分配一块 TLAB    初始化分配的空间：虚拟机将分配到的内存空间都初始化为零值（不包括对象头），保证对象实例字段在不赋值时可以直接使用，程序能访问到这些字段的数据类型所对应的零值\n  设置对象的对象头：将对象的所属类（类的元数据信息）、对象的 HashCode、对象的 GC 信息、锁信息等数据存储在对象头中\n  执行 init 方法进行实例化：实例变量初始化、实例代码块初始化 、构造函数初始化\n  实例变量初始化与实例代码块初始化：\n对实例变量直接赋值或者使用实例代码块赋值，编译器会将其中的代码放到类的构造函数中去，并且这些代码会被放在对超类构造函数的调用语句之后（Java 要求构造函数的第一条语句必须是超类构造函数的调用语句），构造函数本身的代码之前\n  构造函数初始化：\nJava 要求在实例化类之前，必须先实例化其超类，以保证所创建实例的完整性，在准备实例化一个类的对象前，首先准备实例化该类的父类，如果该类的父类还有父类，那么准备实例化该类的父类的父类，依次递归直到递归到 Object 类。然后从 Object 类依次对以下各类进行实例化，初始化父类中的变量和执行构造函数\n    TLAB TLAB：Thread Local Allocation Buffer，为每个线程在堆内单独分配了一个缓冲区，多线程分配内存时，使用 TLAB 可以避免线程安全问题，同时还能够提升内存分配的吞吐量，这种内存分配方式叫做快速分配策略\n 栈上分配使用的是栈来进行对象内存的分配 TLAB 分配使用的是 Eden 区域进行内存分配，属于堆内存  堆区是线程共享区域，任何线程都可以访问到堆区中的共享数据，由于对象实例的创建在 JVM 中非常频繁，因此在并发环境下为避免多个线程操作同一地址，需要使用加锁等机制，进而影响分配速度\n问题：堆空间都是共享的么？ 不一定，因为还有 TLAB，在堆中划分出一块区域，为每个线程所独占\nJVM 是将 TLAB 作为内存分配的首选，但不是所有的对象实例都能够在 TLAB 中成功分配内存，一旦对象在 TLAB 空间分配内存失败时，JVM 就会通过使用加锁机制确保数据操作的原子性，从而直接在堆中分配内存\n栈上分配优先于 TLAB 分配进行，逃逸分析中若可进行栈上分配优化，会优先进行对象栈上直接分配内存\n参数设置：\n  -XX:UseTLAB：设置是否开启 TLAB 空间\n  -XX:TLABWasteTargetPercent：设置 TLAB 空间所占用 Eden 空间的百分比大小，默认情况下 TLAB 空间的内存非常小，仅占有整个 Eden 空间的1%\n  -XX:TLABRefillWasteFraction：指当 TLAB 空间不足，请求分配的对象内存大小超过此阈值时不会进行 TLAB 分配，直接进行堆内存分配，否则还是会优先进行 TLAB 分配\n  承上启下   一个实例变量在对象初始化的过程中会被赋值几次？一个实例变量最多可以被初始化 4 次\nJVM 在为一个对象分配完内存之后，会给每一个实例变量赋予默认值，这个实例变量被第一次赋值；在声明实例变量的同时对其进行了赋值操作，那么这个实例变量就被第二次赋值；在实例代码块中又对变量做了初始化操作，那么这个实例变量就被第三次赋值；；在构造函数中也对变量做了初始化操作，那么这个实例变量就被第四次赋值\n  类的初始化过程与类的实例化过程的异同？\n类的初始化是指类加载过程中的初始化阶段对类变量按照代码进行赋值的过程；类的实例化是指在类完全加载到内存中后创建对象的过程（类的实例化触发了类的初始化，先初始化才能实例化）\n  假如一个类还未加载到内存中，那么在创建一个该类的实例时，具体过程是怎样的？（经典案例）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  public class StaticTest { public static void main(String[] args) { staticFunction();//调用静态方法，触发初始化  } static StaticTest st = new StaticTest(); static { //静态代码块  System.out.println(\u0026#34;1\u0026#34;); } { // 实例代码块  System.out.println(\u0026#34;2\u0026#34;); } StaticTest() { // 实例构造器  System.out.println(\u0026#34;3\u0026#34;); System.out.println(\u0026#34;a=\u0026#34; + a + \u0026#34;,b=\u0026#34; + b); } public static void staticFunction() { // 静态方法  System.out.println(\u0026#34;4\u0026#34;); } int a = 110; // 实例变量  static int b = 112; // 静态变量 }/* Output: 2 3 a=110,b=0 1 4 *///:~   static StaticTest st = new StaticTest();：\n  实例实例化不一定要在类初始化结束之后才开始\n  在同一个类加载器下，一个类型只会被初始化一次。所以一旦开始初始化一个类，无论是否完成后续都不会再重新触发该类型的初始化阶段了（只考虑在同一个类加载器下的情形）。因此在实例化上述程序中的 st 变量时，实际上是把实例化嵌入到了静态初始化流程中，并且在上面的程序中，嵌入到了静态初始化的起始位置，这就导致了实例初始化完全发生在静态初始化之前，这也是导致 a 为 110，b 为 0 的原因\n  代码等价于：\n1 2 3 4 5 6 7 8 9 10 11  public class StaticTest { \u0026lt;clinit\u0026gt;(){ a = 110; // 实例变量  System.out.println(\u0026#34;2\u0026#34;);\t// 实例代码块  System.out.println(\u0026#34;3\u0026#34;);\t// 实例构造器中代码的执行  System.out.println(\u0026#34;a=\u0026#34; + a + \u0026#34;,b=\u0026#34; + b); // 实例构造器中代码的执行  类变量st被初始化 System.out.println(\u0026#34;1\u0026#34;);\t//静态代码块  类变量b被初始化为112 } }     ","date":"2022-07-15T20:17:48+08:00","permalink":"https://isheihei.github.io/posts/java/jvm-%E7%B1%BB%E5%8A%A0%E8%BD%BD/","title":"JVM-类加载"},{"content":"Redis事件 事件模型 Redis 基于 Reactor 模式开发了自己的网络事件处理器。\n  I/O多路复用程序同时监听多个套接字，并向文件事件分派器传送那些产生了事件的套接字。\n  文件事件分派器则接收I/O多路复用程序传来的套接字，并根据套接字产生的事件的类型，调用相应的事件处理器\n  尽管多个文件事件可能会并发地出现，但I/O多路复用程序会将所有产生的套接字都放到一个队列里面，然后通过这个队列向文件事件分派器传送套接字（一个一个顺序进行）。\n  IO模型详解：IO模型分析与对比\n文件事件 Redis事件分为文件事件和时间事件，文件事件就是服务器对套接字操作的抽象，服务器与客户端的通信会产生相应的文件事件，通俗点来说，就是客户端通过命令等方式发送给服务端的请求事件就是文件事件。\n文件事件是以单线程方式运行。\n文件事件处理器主要有：命令请求处理器、命令回复处理器、连接应答处理器\n时间事件 时间时间主要是周期性事件。\nserverCron 函数就是一个时间事件实例，它主要做的工作包括：\n 更新服务器各种统计信息，比如事件、内存占用、数据库占用等 清理数据库中的过期键值对 关闭和清理连接失效的客户端 尝试进行AOF或RDB持久化操作 如果服务器是主服务器，那么对从服务器进行定期同步 如果出于集群模式，对集群进行定期同步和连接测试  事件的调度和执行规则\n 因为文件事件是随机出现的，如果等待并处理完一次文件事件后，仍未有任何时间事件到达，那么服务器将再次等待并处理文件事件。随着文件事件的不断执行，时间会逐渐向时间事件所设置的到达时间逼近，并最终来到到达时间，这时服务器就可以开始处理到达的时间事件了。 文件事件和时间事件的处理都是同步、有序、原子地执行，服务器不会中途中断事件处理，也不会对事件进行抢占。 因为时间事件在文件事件之后执行，并且事件之间不会抢占，所以时间事件的实际处理时间，通常会比时间事件设定的到达事件稍晚一些。  Redis协议详细规范 此章节为转载，原文链接：Redis协议详细规范\nRedis客户端和服务器端通信使用名为 RESP (REdis Serialization Protocol) 的协议。虽然这个协议是专门为Redis设计的，它也可以用在其它 client-server 通信模式的软件上。\nRESP 是下面条件的折中：\n 实现起来简单。 解析速度快。 有可读性。  RESP 能序列化不同的数据类型，例如整型(integers)、字符串(strings)、数组(arrays)。额外还有特殊的错误类型。请求从客户端以字符串数组的形式发送到redis服务器，这些字符串表示要执行的命令的参数。Redis用特定于命令的数据类型回复。\nRESP 是二进制安全的，并且不需要处理从一个进程发到另外一个进程的批量数据，因为它使用前缀长度来传输批量数据。\n注意：这里概述的协议仅用于客户机-服务器通信。Redis集群使用不同的二进制协议在节点之间交换消息。\n网络层 连到Redis服务器的客户端建立了一个到6379端口的TCP连接。\n虽然RESP在技术上不特定于TCP，但是在Redis的上下文中，该协议仅用于TCP连接（或类似的面向流的连接，如unix套接字）。\n请求-响应模型 Redis接受由不同参数组成的命令。一旦收到命令，就会对其进行处理，并将应答发送回客户端。\n这是最简单的模型，但是有两个例外：\n Redis 支持管道pipelining。所以，客户端可以一次发送多个命令，然后再等待应答。 当一个Redis客户端订阅一个频道，那么协议会改变语义并变成pushprotocol, 也就是说，客户客户端不再需要发送命令，因为服务器端会一收到新消息，就会自动发送给客户端。  除了上面两个例外情况，Redis协议是一个简单的请求-响应协议。\nRESP 协议解释 RESP 协议在Redis1.2被引入，直到Redis2.0才成为和Redis服务器通信的标准。这个协议需要在你的Redis客户端实现。\nRESP 是一个支持多种数据类型的序列化协议：简单字符串（Simple Strings）,错误（ Errors）,整型（ Integers）, 大容量字符串（Bulk Strings）和数组（Arrays）。\nRESP在Redis中作为一个请求-响应协议以如下方式使用：\n 客户端以大容量字符串RESP数组的方式发送命令给服务器端。 服务器端根据命令的具体实现返回某一种RESP数据类型。  在 RESP 中，数据的类型依赖于首字节：\n 单行字符串（Simple Strings）： 响应的首字节是 \u0026ldquo;+\u0026rdquo; 错误（Errors）： 响应的首字节是 \u0026ldquo;-\u0026rdquo; 整型（Integers）： 响应的首字节是 \u0026ldquo;:\u0026rdquo; 多行字符串（Bulk Strings）： 响应的首字节是\u0026quot;$\u0026quot; 数组（Arrays）： 响应的首字节是 \u0026ldquo;*\u0026rdquo;  另外，RESP可以使用大容量字符串或者数组类型的特殊变量表示空值，下面会具体解释。RESP协议的不同部分总是以 \u0026ldquo;\\r\\n\u0026rdquo; (CRLF) 结束。\nRESP 单行字符串 单行字符串编码方法: 加号后面跟着一个不包含回车或换行字符的字符串 (不允许出现换行)，以CRLF(\u0026quot;\\r\\n\u0026quot;)结尾。\n单行字符串通常被用来传输非二进制安全字符串并且消耗极小。例如，许多redis命令在成功时回复\u0026quot;OK\u0026quot;，即简单字符串用以下5个字节编码：\n1  \u0026#34;+OK\\r\\n\u0026#34;   为了发送二进制安全的字符串，需要使用RESP的多行字符串（Bulk Strings）替代。\n当Redis返回单行字符串（Simple String）时，客户端lib应该返回去掉首字符加号和结尾CRLF字符的字符串给调用者。\nRESP 错误 RESP 有特殊类型来处理错误。errors类型除了首字符是减号 \u0026lsquo;-\u0026lsquo;不是加号以外，其它跟简单字符串一样。RESP中简单字符和错误的真正区别是：错误被客户端当作异常处理，组成错误类型的字符串是错误消息自身。\n基本格式如下:\n1  \u0026#34;-Error message\\r\\n\u0026#34;   错误应答只在发生异常时发送，例如，要执行命令的参数数据类型不匹配或者命令不存在等。当收到错误返回时，客户端lib应该抛出一个异常。\n错误返回例子:\n1 2  -ERR unknown command \u0026#39;foobar\u0026#39; -WRONGTYPE Operation against a key holding the wrong kind of value   从\u0026quot;-\u0026ldquo;后面第一个单词起，直到第一个空格或者换行，表示返回的错误类型。这是Redis的一种约定，并不是RESP协议的要求。\nERR 是一个通用错误, 而 WRONGTYPE 是表示更具体的错误，意味着客户端在错误的数据类型上执行操作。这被叫做错误前缀（Error Prefix）， 使客户端不用依赖具体错误消息就知道返回的错误类型，错误消息可能会随着时间而变化。\n客户端实现可能会对不同异常返回不同类型的错误，或者可能提供一种通用的方式来捕获错误，通过以字符串的形式直接返回错误名给调用者。\n尽管如此，这种特性不能认为很重要，因为它很少被使用。一小部分客户端的实现可能会返回通用错误条件，例如false。\nRESP 整数 整数类型是由以冒号开头，CRLF结尾，中间是字符串形式表示的数字。 例如 \u0026ldquo;:0\\r\\n\u0026rdquo;, 或 \u0026ldquo;:1000\\r\\n\u0026rdquo; 都是整数回复。\n很多Redis命令返回RESP整数，像 INCR, LLEN 和 LASTSAVE.\n返回的整数并没有特别的意义， INCR 返回的是一个递增的数字， LASTSAVE 返回的是Unix时间戳等。返回的整数有效值需要在有符号64位整数范围内。\n整数返回也被广泛的用来返回 true 或 false。比如 EXISTS 或 SISMEMBER 命令返回1表示true，返回0表示false。\n其它命令像 SADD, SREM 和 SETNX 如果操作被执行则返回1，否则返回0。\n返回整数回复的命令： SETNX, DEL, EXISTS, INCR, INCRBY, DECR, DECRBY, DBSIZE, LASTSAVE, RENAMENX, MOVE, LLEN, SADD, SREM, SISMEMBER, SCARD.\nRESP 多行字符串 多行字符串被用来表示最大512MB长的二进制安全字符串。\n多行字符串编码方式：\n 美元符 \u0026ldquo;$\u0026rdquo; 后面跟着组成字符串的字节数(前缀长度)，并以 CRLF 结尾。 实际的字符串数据。 结尾是 CRLF。  所以，字符串 \u0026ldquo;foobar\u0026rdquo; 编码如下:\n1  \u0026#34;$6\\r\\nfoobar\\r\\n\u0026#34;   空字符串编码格式：\n1  \u0026#34;$0\\r\\n\\r\\n\u0026#34;   RESP 多行字符串（Bulk Strings） 也可以使用一个特殊的用来表示空值的格式表示不存在的值。在这种格式里长度值为-1，数据部分不存在，所以空（Null）用如下方式表示：\n1  \u0026#34;$-1\\r\\n\u0026#34;   叫做空的多行字符串Null Bulk String。\n客户端API库不应该返回空串，当服务器端响应一个空的多行字符串时，API库可以返回一个空对象给调用者。例如，Ruby库应该返回 \u0026rsquo;nil\u0026rsquo; ，而C库应该返回NULL。\nRESP 数组 客户端使用 RESP 数组发送命令到 Redis 服务端。同样地，某些命令的应答使用RESP数组返回元素的集合给Redis客户端。 LRANGE 命令返回元素列表就是一个例子。\nRESP 数组使用如下格式发送：\n 以星号* 为首字符，接着是表示数组中元素个数的十进制数，最后以 CRLF 结尾。 外加数组中每个 RESP 类型的元素。  空数组表示：\n1  \u0026#34;*0\\r\\n\u0026#34;   有两个 RESP 多行字符串\u0026quot;foo\u0026rdquo; 和\u0026quot;bar\u0026quot;元素的 RESP 数组 ：\n1  \u0026#34;*2\\r\\n$3\\r\\nfoo\\r\\n$3\\r\\nbar\\r\\n\u0026#34;   在前缀 *\u0026lt;count\u0026gt;CRLF 的后面，组成数组的其它数据类型一个接在另一个后面。 例如包含三个整数的数组编码方式：\n1  \u0026#34;*3\\r\\n:1\\r\\n:2\\r\\n:3\\r\\n\u0026#34;   数组可以包含混合类型，不一定必须是同一种类型。例如，4个整型和1个多行字符串编码方式：\n1 2 3 4 5 6 7  *5\\r\\n :1\\r\\n :2\\r\\n :3\\r\\n :4\\r\\n $6\\r\\n foobar\\r\\n   (为了方便阅读，应答分成多行来展示)\n第一个行表示 *5\\r\\n 说明后面有5个应答。这些应答组成一个大的应答一起发送。\n空数组的概念也是存在的，另一个表示空值的方式(通常使用多行空字符串，历史遗留导致有这两种格式)。\n例如，当 BLPOP 命令超时，它会返回一个空数组，数组的计数器是-1 :\n1  \u0026#34;*-1\\r\\n\u0026#34;   当 Redis 返回一个空数组的时候，Redis客户端库API应该返回一个空对象而不是返回一个空数组。 这对区分空列表和其它不同情况（像 BLPOP 命令超时情况）是必要的。\n数组的数组也是可行的。例如，一个含有两个数组元素的数组编码方式：\n1 2 3 4 5 6 7 8  *2\\r\\n *3\\r\\n :1\\r\\n :2\\r\\n :3\\r\\n *2\\r\\n +Foo\\r\\n -Bar\\r\\n   (为了方便阅读，分成多行来展示).\n上面的 RESP 数据类型包含两个数组，一个数组包含三个整数1, 2, 3 ，另一个是简单字符串和一个错误类型。\n数组中的空元素 数组中可以有为空的元素。主要使用在Redis应答中，为了表示这个元素丢失并且不是一个空的字符串。当SORT命令使用GET 模式选项，并且特定的key丢失的时会出现这种应答。 含有有空元素的应答数组例子：\n1 2 3 4 5 6  *3\\r\\n $3\\r\\n foo\\r\\n $-1\\r\\n $3\\r\\n bar\\r\\n   第二个元素是空，客户端库应该返回像下面这样的数据：\n1  [\u0026#34;foo\u0026#34;,nil,\u0026#34;bar\u0026#34;]   这不是前面提到的异常情况，这只是说明协议的一个例子。\n发送命令到Redis服务器 至此，我们已经很熟悉RESP序列化格式，写一个Redis客户端库的实现会变得很容易。我们可以进一步说明客户端和服务端如何交互工作：\n 客户端发送包含只有多行字符串的数组给Redis服务器。 Redis 服务器给客户端发送任意有效的 RESP 数据类型作为应答。  下面是一个典型的交互过程例子：\n客户端发送命令 LLEN mylist 来获取存储在 mylist 键中列表的长读，然后服务器端返回整数应答(C: 代表客户端, S: 代表服务器端).\n1 2 3 4 5 6 7  C: *2\\r\\n C: $4\\r\\n C: LLEN\\r\\n C: $6\\r\\n C: mylist\\r\\n S: :48293\\r\\n   为了方便理解我们用换行把协议分成不同部分，实际上客户端发送的是一个整体没有换行：*2\\r\\n$4\\r\\nLLEN\\r\\n$6\\r\\nmylist\\r\\n as a whole.\nRedis 协议的高性能解析器 虽然redis协议是非常容易被人阅读和实现的，但是它可以以类似于二进制协议的性能来实现。\nRESP 使用带前缀的长度来传输批量数据，因此不需要像使用json那样扫描有效负载以查找特殊字符，也不需要引用需要发送到服务器的有效负载。\n批量和多批量长度可以使用代码进行处理，代码对每个字符执行单个操作，同时扫描CR字符，如以下C代码：\nRESP 使用带前缀的长度来传输多行数据，因此不需要像使用json那样扫描有效负载以查找特殊字符，也不需要引用需要发送到服务器的有效负载。\n多行和多个多行长度可以使用代码进行处理，代码对每个字符执行单个操作，同时扫描CR字符，如以下C代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  #include \u0026lt;stdio.h\u0026gt; int main(void) { unsigned char *p = \u0026#34;$123\\r\\n\u0026#34;; int len = 0; p++; while(*p != \u0026#39;\\r\u0026#39;) { len = (len*10)+(*p - \u0026#39;0\u0026#39;); p++; } /* Now p points at \u0026#39;\\r\u0026#39;, and the len is in bulk_len. */ printf(\u0026#34;%d\\n\u0026#34;, len); return 0; }   在识别出第一个CR之后，可以跳过它和下面的LF，而不需要任何处理。然后，可以使用不以任何方式检查有效负载的单个读取操作读取大容量数据。最后，剩余的CR和LF字符将被丢弃，而不进行任何处理。\nRedis协议有着与二进制协议可比的性能，更重要的是易于在大多数高级语言中实现，从而减少了客户端软件中的错误数量。\n实现 事件模型 对于Redis事件模型，java-redis 基于netty实现nio，并使用单线程事件处理器执行文件事件操作。如下图所示\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48  public class RedisNetServer implements RedisServer { private final ServerBootstrap serverBootstrap = new ServerBootstrap(); // 处理 redis 核心操作的线程，是单线程的  private final EventExecutorGroup redisSingleEventExecutor = new NioEventLoopGroup(1); // 处理连接和io操作的线程  private LocalChannelOption channelOption; @Override public void start() { start0(); } private void start0() { serverBootstrap.group(channelOption.boss(), channelOption.selectors()) .channel(channelOption.getChannelClass()) .handler(new LoggingHandler(LogLevel.INFO)) .option(ChannelOption.SO_BACKLOG, 1024) .option(ChannelOption.SO_REUSEADDR, true) .localAddress(new InetSocketAddress(ip, port)) .childHandler(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() { @Override protected void initChannel(SocketChannel socketChannel) { // 初始化客户端  int id = clientId.incrementAndGet(); RedisClient client = new RedisNormalClient(socketChannel.localAddress().toString(), id, dbs); // 初始化 channel  ChannelPipeline channelPipeline = socketChannel.pipeline(); channelPipeline.addLast( new ResponseEncoder(), new CommandDecoder(aof) ); channelPipeline.addLast(redisSingleEventExecutor, new CommandHandler(client, rdb)); } }); try { ChannelFuture sync = serverBootstrap.bind().sync(); LOGGER.info(sync.channel().localAddress().toString()); } catch (InterruptedException e) { LOGGER.warn(\u0026#34;Interrupted!\u0026#34;, e); throw new RuntimeException(e); } } }   nio多路复用模型，实现了单路模型，以及基于Epoll，Kqueue的多路模型。netty默认的nio模型底层是select。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  /** * @ClassName: SingleSelectChannelOption * @Description: 单路模型 * @Date: 2022/6/8 20:56 * @Author: isheihei */ public class SingleSelectChannelOption implements LocalChannelOption { private final NioEventLoopGroup single; public SingleSelectChannelOption(NioEventLoopGroup single) { this.single = single; } public SingleSelectChannelOption() { this.single = new NioEventLoopGroup(1, new ThreadFactory() { private AtomicInteger index = new AtomicInteger(0); @Override public Thread newThread(Runnable r) { return new Thread(r, \u0026#34;Server_boss_\u0026#34; + index.getAndIncrement()); } }); } @Override public EventLoopGroup boss() { return this.single; } @Override public EventLoopGroup selectors() { return this.single; } @Override public Class getChannelClass() { return NioServerSocketChannel.class; } }   协议 共五种消息类型：SimplString、BulkString、RespInt、RespArray、Errors\n协议编解码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177  /** * @ClassName: Resp * @Description: Redis Serialization Protocol协议 * @Date: 2022/6/1 13:15 * @Author: isheihei */ public interface Resp { org.apache.log4j.Logger LOGGER = org.apache.log4j.Logger.getLogger(Resp.class); Charset CHARSET = StandardCharsets.UTF_8; /** * @Description: 回写 * @Param: resp * @Param: buffer * @Return: void * @Author: isheihei */ static void write(Resp resp, ByteBuf buffer) { if (resp instanceof SimpleString) { buffer.writeByte(RespType.STATUS.getCode()); String content = ((SimpleString) resp).getContent(); buffer.writeBytes(content.getBytes(CHARSET)); writeEof(buffer); } else if (resp instanceof Errors) { buffer.writeByte(RespType.ERROR.getCode()); String content = ((Errors) resp).getContent(); buffer.writeBytes(content.getBytes(CHARSET)); writeEof(buffer); } else if (resp instanceof RespInt) { buffer.writeByte(RespType.INTEGER.getCode()); String content = String.valueOf(((RespInt) resp).getValue()); buffer.writeBytes(content.getBytes(CHARSET)); writeEof(buffer); } else if (resp instanceof BulkString) { buffer.writeByte(RespType.BULK.getCode()); BytesWrapper content = ((BulkString) resp).getContent(); if (content == null) { // null: \u0026#34;$-1\\r\\n\u0026#34;  buffer.writeByte(RespType.ERROR.getCode()); buffer.writeByte(RespType.ONE.getCode()); writeEof(buffer); } else if (content.getByteArray().length == 0) { // 空串: \u0026#34;$0\\r\\n\\r\\n\u0026#34;  buffer.writeByte(RespType.ZERO.getCode()); writeEof(buffer); writeEof(buffer); } else { // 正常编码：\u0026#34;foobar\u0026#34; 的编码为 \u0026#34;$6\\r\\nfoobar\\r\\n\u0026#34;，其中 6 是字节数  String length = String.valueOf(content.getByteArray().length); buffer.writeBytes(length.getBytes(CHARSET)); writeEof(buffer); buffer.writeBytes(content.getByteArray()); writeEof(buffer); } } else if (resp instanceof RespArray) { buffer.writeByte(RespType.MULTYBULK.getCode()); Resp[] array = ((RespArray) resp).getArray(); String length = String.valueOf(array.length); buffer.writeBytes(length.getBytes(CHARSET)); writeEof(buffer); for (Resp each : array) { write(each, buffer); } } else { throw new IllegalArgumentException(); } } /** * @Description: 解码为协议对应具体格式 * @Param: buffer * @Return: Resp * @Author: isheihei */ static Resp decode(ByteBuf buffer) { if (buffer.readableBytes() \u0026lt;= 0) { throw new IllegalStateException(\u0026#34;没有读取到完整的命令\u0026#34;); } byte b =buffer.readByte(); if (b == RespType.STATUS.getCode()) { return new SimpleString(getString(buffer)); } else if (b == RespType.ERROR.getCode()) { return new Errors(getString(buffer)); } else if (b == RespType.INTEGER.getCode()) { int value = getNumber(buffer); return new RespInt(value); } else if (b == RespType.BULK.getCode()) { int length = getNumber(buffer); if (buffer.readableBytes() \u0026lt; length + 2) { throw new IllegalStateException(\u0026#34;没有读取到完整的命令\u0026#34;); } byte[] content; if (length == -1) { content = null; } else { content = new byte[length]; buffer.readBytes(content); } if (buffer.readByte() != RespType.R.getCode() || buffer.readByte() != RespType.N.getCode()) { throw new IllegalStateException(\u0026#34;没有读取到完整的命令\u0026#34;); } return new BulkString(new BytesWrapper(content)); } else if (b == RespType.MULTYBULK.getCode()) { int numOfElement = getNumber(buffer); Resp[] array = new Resp[numOfElement]; for (int i = 0; i \u0026lt; numOfElement; i++) { array[i] = decode(buffer); } return new RespArray(array); } else { throw new IllegalStateException(\u0026#34;无法解析命令\u0026#34;); } } /** * @Description: 读取整数类型 * @Param: buffer * @Return: int * @Author: isheihei */ static int getNumber(ByteBuf buffer) { byte b; b = buffer.readByte(); boolean positive = true; int value = 0; // 错误（Errors）： 响应的首字节是 \u0026#34;-\u0026#34;  if (b == RespType.ERROR.getCode()) { positive = false; } else { value = b - RespType.ZERO.getCode(); } while (buffer.readableBytes() \u0026gt; 0 \u0026amp;\u0026amp; (b = buffer.readByte()) != RespType.R.getCode()) { value = value * 10 + (b - RespType.ZERO.getCode()); } if (buffer.readableBytes() == 0 || buffer.readByte() != RespType.N.getCode()) { throw new IllegalStateException(\u0026#34;没有读取到完整的命令\u0026#34;); } if (!positive) { value = -value; } return value; } /** * @Description: 读取一条字符串 * @Param: buffer * @Return: String * @Author: isheihei */ static String getString(ByteBuf buffer) { byte b; ByteBuf byteBuf = PooledByteBufAllocator.DEFAULT.directBuffer(); // 以终止符 /R 为结束标志  while (buffer.readableBytes() \u0026gt; 0 \u0026amp;\u0026amp; (b = buffer.readByte()) != RespType.R.getCode()) { byteBuf.writeByte(b); } // /R 后面必须紧接 /N  if (buffer.readableBytes() == 0 || buffer.readableBytes() != RespType.N.getCode()) { throw new IllegalStateException(\u0026#34;没有读取到完整的命令\u0026#34;); } return byteBuf.toString(CHARSET); } /** * @Description: 写协议终止符：\u0026#34;\\r\\n\u0026#34; (CRLF) * @Param: buffer * @Return: void * @Author: isheihei */ static void writeEof(ByteBuf buffer) { buffer.writeByte(RespType.R.getCode()); buffer.writeByte(RespType.N.getCode()); }   ","date":"2022-06-26T16:32:54+08:00","image":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B001-%E9%80%9A%E4%BF%A1%E4%B8%8E%E5%8D%8F%E8%AE%AE/log_hu0a4ba87b3d81b22780f8a722f1e0fc9b_1722333_120x120_fill_q75_box_smart1.jpg","permalink":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B001-%E9%80%9A%E4%BF%A1%E4%B8%8E%E5%8D%8F%E8%AE%AE/","title":"Redis设计与实现01-通信与协议"},{"content":"数据结构 简单动态字符串（SDS） 1 2 3 4 5 6 7 8 9 10 11  struct sdshdr { //\t记录 buf 数组已使用字节的数量  //\t等于 SDS 所保存字符串的长度  int len; //\t记录 buf 数组中未使用字节的数量  int free; //\t字节数组，用于保存字符串  char buf[]; }    常数复杂度获取字符串长度 杜绝缓冲区溢出，修改前会检查空间是否满足所需要求，不满足会扩展空间 空间预分配，减少修改字符串长度时所需的内存重分配次数。 二进制安全（byte数组） 兼容部分 C 字符串函数  链表（双端列表） 1 2 3 4 5 6 7 8 9 10  typedef struct listNode { //\t前置节点  struct listNode *prev; //\t后置节点  struct listNode *next; //\t节点的值  void *value } listNode;   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  typedef struct list { //\t表头节点  listNode *head; //\t表位节点  listNode *tail; //\t链表所包含的节点数量  unsigned long len; //\t节点值复制函数  void (*free)(void *ptr); //\t节点值对比函数  int (*match)(void *ptr, void *key); } list;    双端 无环，表头结点的 prev 指针和表位节点的 next 指针都指向 NULL，对链表的访问以 NULL 为终点。 带表头和表尾指针，程序获取链表的表头节点和表尾节点的复杂度为O（1） 带链表长度计数器：程序使用 list 结构的 len 属性来对 list 持有的链表节点进行计数，程序获取链表中节点数量的复杂度为 O（1）。 泛型：可以保存不同类型的节点  字典（Map） 哈希表：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  typedef struct dictht { //\t哈希表数组  dictEntry **table; //\t哈希表大小  unsigned long size; //\t哈希表大小掩码，用于计算索引值  //\t总是等于 size - 1  unsigned long sizemask; //\t该哈希表已有节点的数量  unsigned long used; } dictht;   哈希表节点：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  typedef struct dictEntry { //\t键  void *key; //\t值  union{ void *val; uint64_tu64; int64_ts64; } v; //\t指向下个哈希表节点，形成链表  struct dictEntry *next; } dictEntry;   字典：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  typedef struct dict { //\t类型特定函数  dictType *type; //\t私有数据  void *privdata; //\t哈希表，ht[1]用于ht[0]在rehash的时候使用  dictht ht[2]; //\trehash 索引  //\t当 rehash 不在进行时 值为-1  int trehashidx; } dict;   type 属性和 privdata 属性是针对不同类型的键值对，为创建多态字典而设置的\n type 属性是一个指向 dictType 结构的指针，每个 dictType 结构保存了一簇用于操作特定类型键值对的函数，Redis会为用途不同的字典设置不同类型特定函数。 privdata 属性保存了需要传给那些类型特定函数的可选参数。  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  typedef struct dictType { // 计算哈希值的函数  unsigned int (*hashFunction)(const void *key); //\t复制键的函数  void *(*keyDup)(void *privdata, const void *key); //\t复制值的函数  void *(\u0026amp;valDup)(void *privdata, const coid *obj); // 对比键的函数  int (*keyCompare)(void *privdata, const void *key1, const void *key2); //\t销毁键的函数  void (*keyDestructor)(void *privdata, void *key); //\t销毁值的函数  void (*valDestructor)(void *privdata, void *obj); } dictType;   特点\n 拉练法解决哈希冲突,头插（因为拉链没有表位节点），java-HashMap 1.8 后是尾插 扩容和收缩 都是 2^n 双 table 、渐进式 rehash  rehash 步骤\n 为 ht[1]分配空间，让字典同时持有 ht[0] 和ht[1] 两个哈希表 在字典中维持一个索引计数变量rehashidx，并将它的值设置为 0，表示rehash工作正式开始 在rehash 进行期间，每次对字典执行添加、删除、查找或者更新操作时，程序除了执行指定的操作以外，还会顺带将 ht[0] 哈希表在 rehashidx 索引上的所有键值对 rehash 到ht[1]，当rehash 工作完成之后，程序将 rehashidx 属性的值增一。 随着字典操作的不断执行，最终在某个时间点上，ht[0] 的所有键值对都会被 rehash 至 ht[1] , 这时程序将 rehashidx 属性的值设为 -1，表示 rehash操作已完成。  因为在渐进式 rehash 过程中，字典会同时使用 ht[0] 和 ht[1] 两个哈希表，所以在渐进式 rehash 进行期间，字典的删除、查找、更新等操作会在两个哈希表上进行。例如要在字典里面查找一个键的话，程序会先在 ht[0] 里面进行查找，如果没找到的话，就会继续到 ht[1] 里面进行查找。\n另外，在渐进式 rehash 执行期间，新添加到字典的键值对一律会被保存到 ht[1] 里面，而 ht[0] 则不在进行任何添加操作，这一措施保证了 ht[0] 包含的键值对数量会只减不增，并随着 rehash 操作的执行而最终变成空表。\n跳表（SkipList） 跳表详解：Skip List\u0026ndash;跳表（全网最详细的跳表文章没有之一） - 简书 (jianshu.com)\nRedis-zset源码：redis/t_zset.c at unstable · redis/redis (github.com)\n跳跃表节点：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  typedef struct zskiplistNode { //\t层  struct zskiplistLevel { //\t前进指针  struct zskiplistNode *forward; //\t跨度  unsigned int span; } level[]; //\t后退指针  struct zskiplistNode *backward; //\t分值  double score; //\t成员对象  robj *obj; } zskiplistNode;   层\n跳跃表的 level 数组可以包含多个元素，所有包含同层的节点组合构成了跳表该层链表。每次创建一个新的跳跃表节点，程序根据幂次定律（power law， 越大的数出现的概率越小）随机生成一个介于1和32之间的值作为level数组的大小（索引的层数，即该节点要建立几层索引），这个大小就是层的高度。\n前进指针：每个层有一个前进指针，指向该层的下一个节点。\n跨度：跨度记录了两个节点之间的距离，指向NULL的所有前进指针的跨度都为0\n后退指针\n用于从表位向表头方向访问节点，与前进指针不同，每个节点无论高度，都只有一个后退指针，即最底层有后退指针，每次只能后退一个节点。\n跳跃表：\n1 2 3 4 5 6 7 8 9 10  typedef struct zskiplist { // 表头节点和表位节点  struct skiplistNode *header, *tail; //\t表中节点的数量  unsigned long length; //\t表中层数最大的节点的层数  int level; } zskiplist;   整数集合（IntSet） 整数集合（intset）是集合键的底层实现之一，当一个集合只包含整数值元素，并且这个集合的元素数量不多时，Redis 就会使用整数集合作为集合键的底层实现\n1 2 3 4 5 6 7 8 9 10  typedefg struct intset { //\t编码方式  uint32_t encoding; //\t集合包含的元素数量  uint32_t length; //\t保存元素的数组 有序且不重复  int8_t contents[]; } intset;   升级\n当新增的元素编码大于当前集合编码时候，例如当前编码为 INTSET_ENC_INT16 ，新添加一个 INTSET_ENC_INT32 类型元素。那么会引发整数集合的升级，把所有元素扩展为INTSET_ENC_INT32 类型，对应的 contents 字节数组的长度也会相应增加。\n升级的好处：提升灵活性、节约内存。但是不支持降级，一旦升级，编码就会一直保持升级后的状态。\n 升级之后新元素的摆放位置\n因为引发升级的新元素的长度总是比整数集合现有所有元素的长度都打，所以这个新元素值要么就大于所有现有元素，要么就小于所有现有元素。\n怎么理解？\n前一句话是因，后一句话是果。\n当新插入元素的数据类型大小大于已有元素的数据类型大小时，会触发intset的升级操作。\n这个时候 新插入的元素要么大于所有的已有的元素，要么小于所有的已有元素。\n假设现在的元素类型是int16，所有元素的取值范围都在区间[-32768,32767]。\n如果想触发intset的升级，将元素类型升级为int32，新加入元素的范围区间应该是[-2147483648,-32768)和(32767,2147483647)。\n如果新元素在前一个区间，那么它小于-32768，小于所有的int16。\n如果新元素在后一个区间，那么它大于32767，大于所有的int16。\n 压缩列表 压缩列表（ziplist）是列表键和哈希键的底层实现之一。当一个列表键只包含少量列表项，并且每个列表项要么就是小整数值，要么就是长度比较短的字符串，那么 Redis 就会使用压缩列表来做列表键的底层实现。\n压缩列表节点的构成：\n1  previous_entry_length | encoding | content    previous_entry_length：以字节为单位，记录了压缩列表中前一个节点的长度。可以通过指针计算，根据当前节点的起始地址来计算出前一个节点的起始地址。可能为1或者5字节（根据前一个节点的大小），如果前一个节点的长度小于 254 字节，需要1字节；如果前一个节点的长度大于 254 字节，那么需要 5字节。 encoding：节点的 encoding 属性记录了节点的 content 属性所保存数据的类型以及长度 content：节点的 content 属性负责保存节点的值，节点值可以是一个字节数组或者整数，值的类型和长度由节点的 encoding 属性决定  连锁更新\n考虑这样一个情况：在一个压缩列表中，有多个连续的、长度介于 250 字节到 253 字节之间的节点。因为 previous_entry_length 字段只需1字节，那么如果新增一个长度大于254的节点放在列表头，就需要更新之前第一个节点的 previous_entry_length，并且1字节放不下，需要扩展到 5 字节。\n扩展后又出现问题了，因为第二个节点的 previous_entry_length 也放不下第一个节点的长度了，所有就引发后面的一系列连续节点都需要重新分配内存。\n最坏的情况下需要对压缩列表执行 O(N) 次内存重分配操作。\n尽管连锁个更新的复杂度较高，但它真正造成性能问题的几率是很低的：\n 首先压缩列表里要恰好有多个连续的、长度介于 250 字节至 253 字节之间的节点，连锁更新才有可能被引发，实际情况中并不多见 其次，即使出现连锁更新，但只要被更新的节点数量不多，就不会对性能造成任何影响。  对象 对象类型与编码\n类型：数据库键对应的对象类型\n编码：对象具体的底层实现\n字符串对象 编码：int、raw或者 embstr\nembstr编码是专门用于保存短字符串的一种优化编码方式，这种编码和 raw 编码一样，都是用redisObject 和sdshdr 结构来表示字符串对象，但 raw 编码会调用两次分配函数来分别创建 redisObject 结构和 sdshdr 结构，而 embstr 编码通过一次内存分配函数分配一块连续空间，一次包含 redisObject 和 sdshdr两个结构。\n列表对象 编码：ziplist 或者 linkedlist\n哈希对象 编码：ziplist 或者 hashtable\n集合对象 编码：intset 或者 hashtable\n有序集合对象 编码：ziplist 或者 skiplist\n实现 对象和数据结构部分的实现在 java-redis-core模块 org.isheihei.redis.core.obj 和 org.isheihei.redis.core.struct包下。\n由于 java 中的string类型保存的是char数组，且不支持修改。所以新增了一个 BytesWapper 字节包装类以字节数组的形式保存字符串。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64  public class BytesWrapper implements Comparable\u0026lt;BytesWrapper\u0026gt; { static final Charset CHARSET = StandardCharsets.UTF_8; private final byte[] content; public BytesWrapper() { content = new byte[0]; } public BytesWrapper(byte[] content) { this.content = content; } public byte[] getByteArray() { return content; } public int length() { return content == null ? 0 : content.length; } @Override public boolean equals(Object o) { if (this == o) { return true; } if (o == null || getClass() != o.getClass()) { return false; } BytesWrapper that = (BytesWrapper) o; return Arrays.equals(content, that.content); } public String toUtf8String() { return new String(content, CHARSET); } @Override public int hashCode() { return Arrays.hashCode(content); } @Override public int compareTo(BytesWrapper o) { int len1 = content.length; int len2 = o.getByteArray().length; int lim = Math.min(len1, len2); byte v1[] = content; byte v2[] = o.getByteArray(); int k = 0; while (k \u0026lt; lim) { byte c1 = v1[k]; byte c2 = v2[k]; if (c1 != c2) { return c1 - c2; } k++; } return len1 - len2; } }   为了降低系统实现的复杂性，对于五种对象，分别对应了五种数据结构类型，并尽可能复用 Java 已有的数据类和工具。\n五种数据对象分别对应\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84  //\t字符串对象 RedisStringObject{ RedisString.value = BytesWrapper } //\t列表对象 RedisListObject{ RedisDoubleLinkedListextends LinkedList\u0026lt;BytesWrapper\u0026gt; } //\t哈希对象 RedisMapObject{ RedisMap extends HashMap\u0026lt;BytesWrapper, BytesWrapper\u0026gt; } //\t集合对象 RedisSetObject{ RedisSet extends HashSet\u0026lt;BytesWrapper\u0026gt; } //\t有序集合对象 RedisZSetObject{ RedisZSet extends TreeSet\u0026lt;ZNode\u0026gt; } //\tZNode 为有序集合节点： public class ZNode implements Comparable\u0026lt;ZNode\u0026gt; { private BytesWrapper member; private double score; public ZNode(double score, BytesWrapper member) { this.member = member; this.score = score; } public BytesWrapper getMember() { return member; } public double getScore() { return score; } @Override public boolean equals(Object o) { if (this == o) { return true; } if (o == null || getClass() != o.getClass()) { return false; } ZNode zNode = (ZNode) o; return member.equals(zNode.member); } @Override public int hashCode() { return member.hashCode(); } @Override public int compareTo(ZNode o) { int scoreComp = Double.compare(score, o.score); int memberComp = member.compareTo(o.member); if (memberComp == 0) { // member 相等 则相等  return 0; } else if (scoreComp == 0) { // member不相等且 score相等 按照member排序  return memberComp; } else { // member 和 score都不相等 按照score排序  return scoreComp; } } }   其中要单独说一下 TreeSet\nTreeSet 内部封装了一个 TreeMap 成员对象，底层是红黑树实现了有序，并且不允许重复。TreeSet中的元素必须实现Comparable接口并重写compareTo()方法，TreeSet判断元素是否重复 、以及确定元素的顺序 靠的都是这个方法；\n所以 ZNode 的 compare 方法非常关键，因为 ZNode有两个属性，一个 member， 一个 score。按照我们的需求，我们允许 score 重复，但是不允许 member 重复；且排序是优先按照 score 排序，score 相等的情况下再按照 member 字典排序。\n经过一番尝试与不断的思考，给出以下排序代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  @Override public int compareTo(ZNode o) { int scoreComp = Double.compare(score, o.score); int memberComp = member.compareTo(o.member); if (memberComp == 0) { // member 相等 则相等  return 0; } else if (scoreComp == 0) { // member不相等且 score相等 按照member排序  return memberComp; } else { // member 和 score都不相等 按照score排序  return scoreComp; } }   但是这种方案还是有问题，目前已知的有两点：\n add方法不能覆盖旧的节点，如果想对 member 相同但是分数不同的节点进行修改，无法直接add，因为compareTo()的结果虽然是相等，但是add通过比较判断相等则没有添加覆盖的操作，目前的方案是先删除旧节点，再添加。 在使用 TreeSet 方法 subSet() 截取区间时，无法保留右边界元素会失败。例如：this.subSet(new ZNode(min, new BytesWrapper()),true,new ZNode(max, new BytesWrapper()),true); 无法取到保留右边界元素。原因是：在创建ZNode的时候使用了空字符数组创建，当compareTo()比较的时候，如果 score 相等，则会比较 member，因为空串永远是最小的，所以我们想要取到的 score 值相同的 ZNode 永远比我们传入的这个节点大。  ","date":"2022-06-25T16:39:36+08:00","image":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B002-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E5%AF%B9%E8%B1%A1/log_hu0a4ba87b3d81b22780f8a722f1e0fc9b_1722333_120x120_fill_q75_box_smart1.jpg","permalink":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B002-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E5%AF%B9%E8%B1%A1/","title":"Redis设计与实现02-数据结构与对象"},{"content":"命令 继承结构 对于 redis 的众多命令，在设计实现的时候，尽可能的去抽象代码。除了抽象出命令的顶层 interface 之外，对于查询命令和修改命令，又划分出两个抽象类。最终的继承结构如下：\nclassDiagram\rCommand Command接口三个主要方法\n type()：返回命令类型 setContent(RespArray arrays)：设置命令参数 handle(RedisClient redisClient)：执行命令逻辑  AbstractCommand ：抽象了查询命令并实现了setContent(RespArray arrays)方法\nAbstractWriteCommand：\n抽象了更新修改命令并实现了setContent(RespArray arrays)、handle(RedisClient redisClient)方法。并使用了模板方法模式用于写入AOF。提供了一个钩子变量 aofOn，当该变量为 true 时，handle 方法会执行 aof.putAof 操作。\n1 2 3 4 5 6 7 8 9  @Override public Resp handle(RedisClient redisClient) { if (aofOn) { putAof(); } return handleWrite(redisClient); } public abstract Resp handleWrite(RedisClient redisClient);   实现的命令 命令手册：\nCommands | Redis\nredis 命令手册\nCONNECTION 1 2 3  auth(Auth::new), client(Client::new), config(Config::new), echo(Echo::new), ping(Ping::new), quit(Quit::new)   SEVER 1 2 3  select(Select::new), flushall(FlushAll::new), dbsize(DbSize::new), flushdb(FlushDb::new), bgsave(BgSave::new), save(Save::new)   KEY 1 2 3 4  expire(Expire::new), del(Del::new), exists(Exists::new), keys(Keys::new), persist(Persist::new), rename(Rename::new), ttl(Ttl::new), type(Type::new),   TRANSACTION 1 2 3  multi(Multi::new), exec(Exec::new), unwatch(UnWatch::new), watch(Watch::new), discard(Discard::new)   STRING 1 2 3 4  get(Get::new), set(Set::new), mget(MGet::new), mset(MSet::new), append(Append::new), setex(SetEx::new), setnx(SetNx::new)   LIST 1 2 3 4 5  lpush(LPush::new), lrange(LRange::new), lrem(LRem::new), rpush(RPush::new), lpop(LPop::new), rpop(RPop::new), lset(LSet::new), lindex(LIndex::new), llen(LLen::new),   HASH 1 2 3 4 5  hdel(HDel::new), hexists(HExists::new), hget(HGet::new), hgetall(HGetAll::new), hkeys(HKeys::new), hset(HSet::new), hmset(HMSet::new), hvals(HVals::new), hmget(HMGet::new),   SET 1 2 3 4 5 6  sadd(SAdd::new), scard(SCard::new), sdiff(SDiff::new), smembers(SMembers::new), sismember(SIsMember::new), sdiffstore(SDiffStore::new), sinter(SInter::new), sinterstore(SInterStore::new), srem(SRem::new), sunion(SUnion::new), sunionstore(SUnionStore::new),   ZSET 1 2 3 4 5  zadd(ZAdd::new), zcard(ZCard::new), zcount(ZCount::new), zrange(ZRange::new), zrangebyscore(ZRangeByScore::new), zrank(ZRank::new), zrem(ZRem::new), zscore(ZScore::new),   ","date":"2022-06-24T16:40:04+08:00","image":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B003-%E5%91%BD%E4%BB%A4/log_hu0a4ba87b3d81b22780f8a722f1e0fc9b_1722333_120x120_fill_q75_box_smart1.jpg","permalink":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B003-%E5%91%BD%E4%BB%A4/","title":"Redis设计与实现03-命令"},{"content":"参考：\nLinux IO模式及 select、poll、epoll详解 - SegmentFault 思否\n一文搞懂select、poll和epoll区别 - 知乎 (zhihu.com)\n一些前置概念 用户空间与内核空间 现在操作系统都是采用虚拟存储器，那么对32位操作系统而言，它的寻址空间（虚拟存储空间）为4G（2的32次方）。操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。为了保证用户进程不能直接操作内核（kernel），保证内核的安全，操心系统将虚拟空间划分为两部分，一部分为内核空间，一部分为用户空间。\n进程阻塞 正在执行的进程，由于期待的某些事件未发生，如请求系统资源失败、等待某种操作的完成、新数据尚未到达或无新工作做等，则由系统自动执行阻塞原语(Block)，使自己由运行状态变为阻塞状态。可见，进程的阻塞是进程自身的一种主动行为，也因此只有处于运行态的进程（获得CPU），才可能将其转为阻塞状态。当进程进入阻塞状态，是不占用CPU资源的。\n文件描述符 fd 文件描述符（File descriptor）是计算机科学中的一个术语，是一个用于表述指向文件的引用的抽象化概念。\n文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展开。但是文件描述符这一概念往往只适用于UNIX、Linux这样的操作系统。\n缓存 I/O 缓存 I/O 又被称作标准 I/O，大多数文件系统的默认 I/O 操作都是缓存 I/O。在 Linux 的缓存 I/O 机制中，操作系统会将 I/O 的数据缓存在文件系统的页缓存（ page cache ）中，也就是说，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。\n缓存 I/O 的缺点： 数据在传输过程中需要在应用程序地址空间和内核进行多次数据拷贝操作，这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的\nI/O 模式 对于一次IO访问（以read举例），数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。所以说，当一个read操作发生时，它会经历两个阶段：\n 等待数据准备 (Waiting for the data to be ready) 将数据从内核拷贝到进程中 (Copying the data from the kernel to the process)  正是因为这两个阶段，linux系统产生了下面五种网络模式的方案。\n 阻塞 I/O（blocking IO） 非阻塞 I/O（nonblocking IO） I/O 多路复用（ IO multiplexing） 信号驱动 I/O（ signal driven IO） 异步 I/O（asynchronous IO）  阻塞 I/O（blocking IO） 在linux中，默认情况下所有的socket都是blocking，一个典型的读操作流程大概是这样：\n当用户进程调用了recvfrom这个系统调用，kernel就开始了IO的第一个阶段：准备数据（对于网络IO来说，很多时候数据在一开始还没有到达。比如，还没有收到一个完整的UDP包。这个时候kernel就要等待足够的数据到来）。这个过程需要等待，也就是说数据被拷贝到操作系统内核的缓冲区中是需要一个过程的。而在用户进程这边，整个进程会被阻塞（当然，是进程自己选择的阻塞）。当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。\n 所以，blocking IO的特点就是在IO执行的两个阶段都被block了。\n 非阻塞 I/O（nonblocking IO） linux下，可以通过设置socket使其变为non-blocking。当对一个non-blocking socket执行读操作时，流程是这个样子：\n当用户进程发出read操作时，如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error。从用户进程角度讲 ，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的system call，那么它马上就将数据拷贝到了用户内存，然后返回。\n 所以，nonblocking IO的特点是用户进程需要不断的主动询问kernel数据好了没有。\n I/O 多路复用（ IO multiplexing） IO multiplexing就是我们说的select，poll，epoll，有些地方也称这种IO方式为event driven IO。select/epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基本原理就是select，poll，epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。\n当用户进程调用了select，那么整个进程会被block，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。\n 所以，I/O 多路复用的特点是通过一种机制一个进程能同时等待多个文件描述符，而这些文件描述符（套接字描述符）其中的任意一个进入读就绪状态，select()函数就可以返回。\n 这个图和blocking IO的图其实并没有太大的不同，事实上，还更差一些。因为这里需要使用两个system call (select 和 recvfrom)，而blocking IO只调用了一个system call (recvfrom)。但是，用select的优势在于它可以同时处理多个connection。\n所以，如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好，可能延迟还更大。select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。）\n在IO multiplexing Model中，实际中，对于每一个socket，一般都设置成为non-blocking，但是，如上图所示，整个用户的process其实是一直被block的。只不过process是被select这个函数block，而不是被socket IO给block。\n异步 I/O（asynchronous IO） inux下的asynchronous IO其实用得很少。先看一下它的流程：\n用户进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。\n信号驱动 I/O（ signal driven IO） 在信号驱动式I/O模型中，应用程序使用套接口进行信号驱动I/O，并安装一个信号处理函数，进程继续运行并不阻塞。当数据准备好时，进程会收到一个SIGIO信号，可以在信号处理函数中调用I/O操作函数处理数据\n异步 I/O与信号驱动 I/O的主要区别在于：信号驱动I/O是由内核通知应用程序何时启动一个I/O操作，而异步I/O模型是由内核通知应用程序I/O操作何时完成\n优点：线程并没有在等待数据时被阻塞，可以提高资源的利用率\n缺点：信号I/O在大量IO操作时可能会因为信号队列溢出导致没法通知。\n信号驱动I/O尽管对于处理UDP套接字来说有用，即这种信号通知意味着到达一个数据报，或者返回一个异步错误。但是，对于TCP而言，信号驱动的I/O方式近乎无用，因为导致这种通知的条件为数众多，每一个来进行判别会消耗很大资源。\nIO模式总结 blocking和non-blocking的区别 调用blocking IO会一直block住对应的进程直到操作完成，而 non-blocking IO在 kernel 还未准备好数据的情况下会立刻返回。\nsynchronous IO和asynchronous IO的区别 在说明synchronous IO和asynchronous IO的区别之前，需要先给出两者的定义。POSIX的定义是这样子的：\n A synchronous I/O operation causes the requesting process to be blocked until that I/O operation completes; An asynchronous I/O operation does not cause the requesting process to be blocked;  两者的区别就在于synchronous IO做”IO operation”的时候会将process阻塞。按照这个定义，之前所述的blocking IO，non-blocking IO，IO multiplexing都属于synchronous IO。\n这里有个非常“狡猾”的地方，定义中所指的”IO operation”是指真实的IO操作，就是例子中的recvfrom这个system call。non-blocking IO在执行recvfrom这个system call的时候，如果kernel的数据没有准备好，这时候不会block进程。但是，当kernel中数据准备好的时候，recvfrom会将数据从kernel拷贝到用户内存中，这个时候进程是被block了，在这段时间内，进程是被block的。\n而asynchronous IO则不一样，当进程发起IO 操作之后，就直接返回再也不理睬了，直到kernel发送一个信号，告诉进程说IO完成。在这整个过程中，进程完全没有被block。\n同步IO和异步IO的区别就在于：数据拷贝的时候进程是否阻塞！\n阻塞IO和非阻塞IO的区别就在于：应用程序的调用是否立即返回！\n各个IO Model的比较如图所示：\n通过上面的图片，可以发现non-blocking IO和asynchronous IO的区别还是很明显的。在non-blocking IO中，虽然进程大部分时间都不会被block，但是它仍然要求进程去主动的check，并且当数据准备完成以后，也需要进程主动的再次调用recvfrom来将数据拷贝到用户内存。而asynchronous IO则完全不同。它就像是用户进程将整个IO操作交给了他人（kernel）完成，然后他人做完后发信号通知。在此期间，用户进程不需要去检查IO操作的状态，也不需要主动的去拷贝数据。\nI/O 多路复用之select、poll、epoll、kqueue详解 select，poll，epoll，kqueue都是IO多路复用的机制。I/O多路复用就是通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。（这里啰嗦下）\nselect 1 2 3 4  int select (int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout); //\twritefds、readfds、和exceptfds　是三个指针，分别记录了读、写和 except 事件描述符 //\t进程调用select的时候会把这三个指针传递进函数并阻塞直到有就绪事件 //\t如果有就绪的事件对应的描述符，会对其设置就绪，select 返回后进程可以遍历所有的描述符，找到就绪的进行处理。   select 函数监视的文件描述符分3类，分别是writefds、readfds、和exceptfds。调用后select函数会阻塞，直到有描述副就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以 通过遍历fdset，来找到就绪的描述符。\nselect目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点。select的一 个缺点在于单个进程能够监视的文件描述符的数量存在最大限制，在Linux上一般为1024，可以通过修改宏定义甚至重新编译内核的方式提升这一限制，但 是这样也会造成效率的降低。\n调用过程\n 使用copy_from_user从用户空间拷贝fd_set到内核空间 注册回调函数__pollwait 遍历所有fd，调用其对应的poll方法（对于socket，这个poll方法是sock_poll，sock_poll根据情况会调用到tcp_poll，udp_poll或datagram_poll），以tcp_poll为例，核心实现就是__pollwait，即上面注册的回调函数。__pollwait，就是把current（当前进程）挂到设备的等待队列，不同设备有不同等待队列，如tcp_poll的等待队列是sk-\u0026gt;sk_sleep（把进程挂到等待队列中并不代表进程已睡眠）。在设备收到一条消息（网络设备）或填写完文件数据（磁盘设备）后，会唤醒设备等待队列上睡眠的进程，这时current便被唤醒。 poll方法返回时会返回一个描述读写操作是否就绪的mask掩码，根据这个mask掩码给fd_set赋值 若遍历完所有fd，还没返回一个可读写的mask掩码，则调schedule_timeout是调用select的进程（也就是current）进入睡眠。当设备驱动发生自身资源可读写后，会唤醒其等待队列上睡眠的进程。若超过一定超时时间（schedule_timeout指定），还没人唤醒，则调用select的进程会重新被唤醒获得CPU，进而重新遍历fd，判断有无就绪的fd 把fd_set从内核空间拷贝到用户空间  缺点\n内核需要将消息传递到用户空间，都需要内核拷贝动作。需要维护一个用来存放大量fd的数据结构，使得用户空间和内核空间在传递该结构时复制开销大。\n 每次调用select，都需把fd集合从用户态拷贝到内核态，fd很多时开销就很大 同时每次调用select都需在内核遍历传递进来的所有fd，fd很多时开销就很大 select支持的文件描述符数量太小了，默认最大支持1024个 主动轮询效率很低  poll 1  int poll (struct pollfd *fds, unsigned int nfds, int timeout);   不同与select使用三个位图来表示三个fdset的方式，poll使用一个 pollfd的指针实现。\n1 2 3 4 5  struct pollfd { int fd; /* 文件描述符 */ short events; /* 要监视的事件 */ short revents; /* 发生的事件 */ };   pollfd结构包含了要监视的event和发生的event，不再使用select“参数-值”传递的方式。同时，pollfd并没有最大数量限制（但是数量过大后性能也是会下降）。 和select函数一样，poll返回后，需要轮询pollfd来获取就绪的描述符。\npoll和select同样存在一个缺点就是，包含大量文件描述符的数组被整体复制于用户态和内核的地址空间之间，而不论这些文件描述符是否就绪，它的开销随着文件描述符数量的增加而线性增大。\n  它将用户传入的数组拷贝到内核空间\n  然后查询每个fd对应的设备状态：\n   如果设备就绪 在设备等待队列中加入一项继续遍历 若遍历完所有fd后，都没发现就绪的设备 挂起当前进程，直到设备就绪或主动超时，被唤醒后它又再次遍历fd。这个过程经历多次无意义的遍历。     从上面看，select和poll都需要在返回后，通过遍历文件描述符来获取已经就绪的socket。事实上，同时连接的大量客户端在一时刻可能只有很少的处于就绪状态，因此随着监视的描述符数量的增长，其效率也会线性下降。\n epoll epoll是在2.6内核中提出的，是之前的select和poll的增强版本。相对于select和poll来说，epoll更加灵活，没有描述符限制。epoll使用一个文件描述符管理多个描述符，将用户关心的文件描述符的事件存放到内核的一个事件表中，用户每次新增和删除监听事件都通过内核中的这个事件表，这样在用户空间和内核空间的copy只需一次。select 和 poll 都需要把fd表或者数据结构拷贝到内核态再从内核态取出。\nepoll模型修改主动轮询为被动通知，当有事件发生时，被动接收通知。所以epoll模型注册套接字后，主程序可做其他事情，当事件发生时，接收到通知后再去处理。可理解为event poll，epoll会把哪个流发生哪种I/O事件通知我们。所以epoll是事件驱动（每个事件关联fd），此时我们对这些流的操作都是有意义的。复杂度也降到O(1)。\nepoll操作过程 epoll操作过程需要三个接口，分别如下：\n1 2 3  int epoll_create(int size)；//创建一个epoll的句柄（epfd），size用来告诉内核这个监听的数目一共有多大 int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；// 增删改某个fd的某个事件 int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);\t// 等待 epfd 上的事件   1. int epoll_create(int size); 创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大，这个参数不同于select()中的第一个参数，给出最大监听的fd+1的值，参数size并不是限制了epoll所能监听的描述符最大个数，只是对内核初始分配内部数据结构的一个建议。 当创建好epoll句柄后，它就会占用一个fd值，在linux下如果查看/proc/进程id/fd/，是能够看到这个fd的，所以在使用完epoll后，必须调用close()关闭，否则可能导致fd被耗尽。\n2. int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)； 函数是对指定描述符fd执行op操作。 - epfd：是epoll_create()的返回值。 - op：表示op操作，用三个宏来表示：添加EPOLL_CTL_ADD，删除EPOLL_CTL_DEL，修改EPOLL_CTL_MOD。分别添加、删除和修改对fd的监听事件。 - fd：是需要监听的fd（文件描述符） - epoll_event：是告诉内核需要监听什么事，struct epoll_event结构如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13  struct epoll_event { __uint32_t events; /* Epoll events */ epoll_data_t data; /* User data variable */ }; //events可以是以下几个宏的集合： EPOLLIN ：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）； EPOLLOUT：表示对应的文件描述符可以写； EPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）； EPOLLERR：表示对应的文件描述符发生错误； EPOLLHUP：表示对应的文件描述符被挂断； EPOLLET： 将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的。 EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里   3. int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout); 等待epfd上的io事件，最多返回maxevents个事件。 参数events用来从内核得到事件的集合，maxevents告知内核这个events有多大，这个maxevents的值不能大于创建epoll_create()时的size，参数timeout是超时时间（毫秒，0会立即返回，-1将不确定，也有说法说是永久阻塞）。该函数返回需要处理的事件数目，如返回0表示已超时。\n工作模式 epoll对文件描述符的操作有两种模式：LT（level trigger）和ET（edge trigger）。LT模式是默认模式，LT模式与ET模式的区别如下：\nLT模式，默认的模式（水平触发）：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用epoll_wait时，会再次响应应用程序并通知此事件。\nET模式，“高速”模式（边缘触发）：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。\nLT模式\nLT(level triggered)是缺省的工作方式，并且同时支持block和no-block socket.在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你的。\nET模式\nET(edge-triggered)是高速工作方式，只支持no-block socket。在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知，直到你做了某些操作导致那个文件描述符不再为就绪状态了(比如，你在发送，接收或者接收请求，或者发送接收的数据少于一定量时导致了一个EWOULDBLOCK 错误）。但是请注意，如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核不会发送更多的通知(only once)\nET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。epoll工作在ET模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。\n假如有这样一个例子：\n 我们已经把一个用来从管道中读取数据的文件句柄(RFD)添加到epoll描述符 这个时候从管道的另一端被写入了2KB的数据 调用epoll_wait(2)，并且它会返回RFD，说明它已经准备好读取操作 然后我们读取了1KB的数据 调用epoll_wait(2)\u0026hellip;\u0026hellip;  LT模式： 如果是LT模式，那么在第5步调用epoll_wait(2)之后，仍然能受到通知。\nET模式： 如果我们在第1步将RFD添加到epoll描述符的时候使用了EPOLLET标志，那么在第5步调用epoll_wait(2)之后将有可能会挂起，因为剩余的数据还存在于文件的输入缓冲区内，而且数据发出端还在等待一个针对已经发出数据的反馈信息。只有在监视的文件句柄上发生了某个事件的时候 ET 工作模式才会汇报事件。因此在第5步的时候，调用者可能会放弃等待仍在存在于文件输入缓冲区内的剩余数据。\n当使用epoll的ET模型来工作时，当产生了一个EPOLLIN事件后， 读数据的时候需要考虑的是当recv()返回的大小如果等于请求的大小，那么很有可能是缓冲区还有数据未读完，也意味着该次事件还没有处理完，所以还需要再次读取：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  while(rs){ buflen = recv(activeevents[i].data.fd, buf, sizeof(buf), 0); if(buflen \u0026lt; 0){ // 由于是非阻塞的模式,所以当errno为EAGAIN时,表示当前缓冲区已无数据可读  // 在这里就当作是该次事件已处理处.  if(errno == EAGAIN){ break; } else{ return; } } else if(buflen == 0){ // 这里表示对端的socket已正常关闭.  } if(buflen == sizeof(buf){ rs = 1; // 需要再次读取  } else{ rs = 0; } }    Linux中的EAGAIN含义\n Linux环境下开发经常会碰到很多错误(设置errno)，其中EAGAIN是其中比较常见的一个错误(比如用在非阻塞操作中)。 从字面上来看，是提示再试一次。这个错误经常出现在当应用程序进行一些非阻塞(non-blocking)操作(对文件或socket)的时候。\n例如，以 O_NONBLOCK的标志打开文件/socket/FIFO，如果你连续做read操作而没有数据可读。此时程序不会阻塞起来等待数据准备就绪返回，read函数会返回一个错误EAGAIN，提示你的应用程序现在没有数据可读请稍后再试。 又例如，当一个系统调用(比如fork)因为没有足够的资源(比如虚拟内存)而执行失败，返回EAGAIN提示其再调用一次(也许下次就能成功)。\n优点  没有最大并发连接的限制，能打开的FD的上限远大于1024（1G的内存上能监听约10万个端口） 效率提升，不是轮询，不会随着FD数目的增加效率下降。只有活跃可用的FD才会调用callback函数 即Epoll最大的优点就在于它只关心“活跃”的连接，而跟连接总数无关，因此在实际的网络环境中，Epoll的效率就会远远高于select和poll 内存拷贝，利用mmap()文件映射内存加速与内核空间的消息传递；即epoll使用mmap减少复制开销。 epoll通过内核和用户空间共享一块内存来实现的  kqueue kqueue和epoll一样，都是用来替换select和poll的。不同的是kqueue被用在FreeBSD,NetBSD, OpenBSD, DragonFly BSD, 和 macOS中。\nkqueue 不仅能够处理文件描述符事件，还可以用于各种其他通知，例如文件修改监视、信号、异步 I/O 事件 (AIO)、子进程状态更改监视和支持纳秒级分辨率的计时器，此外kqueue提供了一种方式除了内核提供的事件之外，还可以使用用户定义的事件。\nkqueue提供了两个API，第一个是构建kqueue：\n1  int kqueue(void);   第二个是创建kevent:\n1  int kevent(int kq, const struct kevent *changelist, int nchanges, struct kevent *eventlist, int nevents, const struct timespec *timeout);   kevent中的第一个参数是要注册的kqueue，changelist是要监视的事件列表，nchanges表示要监听事件的长度，eventlist是kevent返回的事件列表,nevents表示要返回事件列表的长度，最后一个参数是timeout。\n除此之外，kqueue还有一个用来初始化kevent结构体的EV_SET宏：\n1  EV_SET(\u0026amp;kev, ident, filter, flags, fflags, data, udata);   总结 在 select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，而epoll事先通过epoll_ctl()来注册一 个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait() 时便得到通知。(此处去掉了遍历文件描述符，而是通过监听回调的的机制。这正是epoll的魅力所在。)\nselect，poll，epoll都是IO多路复用机制，即可以监视多个描述符，一旦某个描述符就绪（读或写就绪），能够通知程序进行相应读写操作。 但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。\n select，poll实现需要自己不断轮询所有fd集合，直到设备就绪，期间可能要睡眠和唤醒多次交替。而epoll其实也需要调用epoll_wait不断轮询就绪链表，期间也可能多次睡眠和唤醒交替，但是它是设备就绪时，调用回调函数，把就绪fd放入就绪链表中，并唤醒在epoll_wait中进入睡眠的进程。虽然都要睡眠和交替，但是select和poll在“醒着”的时候要遍历整个fd集合，而epoll在“醒着”的时候只要判断一下就绪链表是否为空就行了，这节省了大量的CPU时间。这就是回调机制带来的性能提升。 select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把current往设备等待队列中挂一次，而epoll只要一次拷贝，而且把current往等待队列上挂也只挂一次（在epoll_wait的开始，注意这里的等待队列并不是设备等待队列，只是一个epoll内部定义的等待队列）。这也能节省不少的开销。   如果没有大量的idle -connection或者dead-connection，epoll的效率并不会比select/poll高很多，但是当遇到大量的idle- connection，就会发现epoll的效率大大高于select/poll。\n ","date":"2022-06-24T13:45:35+08:00","permalink":"https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/io%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90%E4%B8%8E%E5%AF%B9%E6%AF%94/","title":"IO模型分析与对比"},{"content":"过期策略 数据库中有一个过期字典，字典的 key 是被设置过期时间的键，字典的 value 是过期时间（long 类型 以毫秒为单位的 UNXI 时间戳）。\n删除策略 定时删除 在设置键的过期时间的同时，创建一个定时器，让定时器在键的过期时间来临时，立即执行对键的删除操作。\n优点：对内存最友好，通过使用定时器，定时删除策略可以保证过期键会尽可能快地被删除，并释放过期键所占用的内存。\n缺点：对CPU时间最不友好，在过期键比较多的情况下，删除过期键这一行为可能会占用相当一部分CPU时间。在内存不紧张但是CPU时间非常紧张的情况下，拿CPU去做与当前任务无关的过期键上没有意义。\n惰性删除 放任过期键不管，但是每次从键空间中获取键时，都检查取得的键是否过期，如果过期的话，就删除该键；如果没有过期，就返回该键。\n优点：对CPU时间最友好，不会在删除其他无关的过期键上花费任何CPU时间\n缺点：对内存最不友好，如果一个键已经过期，而这个键又仍然保留在数据库中，那么只要这个过期键不被删除，它所占用的内存就不会释放。可以把这种情况视为一种内存泄漏。\n定期删除 每隔一段时间， 程序就对数据库进行一次检查，删除里面的过期键。至于要删除多少过期键，以及要检查多少个数据库，则由算法决定。\n定期策略是前两种策略的一种整合和折中：\n 定期删除策略每隔一段时间执行一次删除过期键操作，并通过限制删除操作执行的时长和频率来减少删除操作对CPU时间的影响。 除此之外，通过定期删除过期键，定期删除策略有效地减少了因为过期键而带来的内存浪费  定期删除策略的难点是确定删除操作执行的时长和频率：\n 如果删除操作执行地太过频繁，或者执行的时间太长，定期删除策略就退化成定时删除策略 如果删除操作执行得太少，或者执行地太短，定期删除策略又会和惰性删除策略一样，出现浪费内存的情况  Redis 的过期键删除策略 Redis 使用了惰性删除策略和定期删除策略结合的方式\n惰性删除策略的实现 所有读写数据库的命令在执行之前都会先判断输入键是否已经过期\n 如果输入键已经过期，那么将输入键删除 如果输入键未过期，那么正常执行  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  public class RedisDBImpl implements RedisDB { // 过期字典  private final Map\u0026lt;BytesWrapper, Long\u0026gt; expires = new HashMap\u0026lt;\u0026gt;(); //\t在获取键的时候先判断是否已经过期，如果过期就删除  public RedisObject get(BytesWrapper key) { RedisObject redisObject = dict.get(key); if (redisObject == null) { return null; } else if (isExpired(key)){ expires.remove(key); dict.remove(key); return null; } else { redisObject.refreshLru(); redisObject.updateLfu(); return redisObject; } } }   定期删除策略的实现 ServerCron 是服务器的时间事件之一，主要执行一些周期性操作。定期策略在 ServerCron 类中被调用：\n1 2 3  private void databasesCron() { expireStrategy.activeExpireCycle(); }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  @Override public void activeExpireCycle() { start = System.currentTimeMillis(); int dbSize = dbs.size(); if (dbSize \u0026lt; dbNumbers) { // 如果数据库当前数量比默认的数量少，取当前数量  dbNumbers = dbSize; } // 当前遍历到的数据库索引  currentDb %= dbSize; int deleteCount = 0; // keyNumbers为每次从数据库过期字典中取出的键的数量，默认为20  for (int i = 0; i \u0026lt; keyNumbers; i++){ RedisDB redisDB = dbs.get(currentDb); int expiresSize = redisDB.expiresSize(); if (expiresSize == 0) return; // 随机取，看是否过期，过期就删除它  BytesWrapper randomKey = redisDB.getRandomExpires(); if (redisDB.isExpired(randomKey)) { LOGGER.info(\u0026#34;过期key: \u0026#34; + randomKey.toUtf8String() + \u0026#34;被删除\u0026#34;); deleteCount++; redisDB.delete(randomKey); } //\t执行事件到达上限则结束 timeLimit = TimeUnit.MICROSECONDS.toMillis(1000)  if (System.currentTimeMillis() - start \u0026gt; timeLimit) { return; } // 如果抽样的 20 个键过期的超过 1/4 则重复该过程  if (deleteCount \u0026gt; keyNumbers / 4) { deleteCount = 0; i = 0; } } }   扩展：从库的过期策略 从库不会进行过期扫描，从库对过期的处理是被动的。主库在 key 到期时，会在 AOF 文件里增加一条 del 指令，同步到所有的从库，从库通过执行这条 del 指令来删除过期的 key。\n因为指令同步是异步进行的，所以主库过期的 key 的 del 指令没有及时同步到从库的话，会出现主从数据的不一致，主库没有的数据在从库里还存在。\n逐出策略 数据淘汰机制 Redis 内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。Redis 提供 6 种数据淘汰策略：\n volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用 的数据淘汰 volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数 据淘汰，ttl （Time To Live）越小越优先被淘汰。 volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据 淘汰 allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰 allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰 no-enviction（驱逐）：禁止驱逐数据  redis5.0新增：\n volatile-lfu：从已设置过期时间的数据集挑选使用频率最低的数据淘汰。 allkeys-lfu：从数据集中挑选使用频率最低的数据淘汰。  volatile-xxx 策略只会针对带过期时间的 key 进行淘汰，allkeys-xxx 策略会对所有的 key 进行淘汰。如果你只是拿 Redis 做缓存，那应该使用 allkeys-xxx，客户端写缓存时不必携带过期时间。如果你还想同时使用 Redis 的持久化功能，那就使用 volatile-xxx 策略，这样可以保留没有设置过期时间的 key，它们是永久的 key 不会被 LRU 算法淘汰。\n实现 何时淘汰？ Redis实例支持通过修改配置参数（maxmemory-policy），修改数据逐出策略。在达到内存上限（maxmemory）时，Redis根据逐出策略进行数据逐出。\n而 Java-Redis 是基于 Java 语言实现，那么内存大小就受限于 JVM内存大小。\n  JVM初始分配的内存由-Xms指定，默认是物理内存的1/64;\n  JVM最大分配的内存由-Xmx指定，默认是物理内存的1/4。\n  默认空余堆内存**小于40%**时，JVM就会增大堆直到-Xmx的最大限制；\n  空余堆内存**大于70%**时，JVM会减少堆直到-Xms的最小限制。因此服务器一般设置-Xms、-Xmx相等以避免在每次GC后调整堆的大小。\n  而且 Java 提供的 Runtime.getRuntime().totalMemory() 、 Runtime.getRuntime().maxMemory() 、Runtime.getRuntime().freeMemory()方法能获取当前 JVM 已分配内存 、 JVM 最大可扩展内存以及 JVM 当前已分配内存中的空闲内存。\n为了适配 JVM 内存，给出以下内存策略：\n建议初始内存和最大内存参数相等，这样可以避免运行过程中的内存重分配过程，也更容易精确计算当前内存的占用情况。\n但是：由于 JVM 的内存的 GC 时间是不固定的，有些已经被淘汰的键不能被虚拟机及时回收，可能会造成获取的内存占用信息实时性不强的问题，这是由于 JVM 内存本身机制决定，能力有限，暂时没有想到更优的解决办法。\n 什么时候触发 GC？\n什么时候触发Young GC\u0026mdash;-针对年轻代\n当Eden区满了的时候，会触发Young GC\n什么时候触发 Full GC\u0026mdash;-针对整个堆\n 在发生Young GC的时候，虚拟机会检测之前每次晋升到老年代的平均大小是否大于年老代的剩余空间，如果大于，则直接进行Full GC； 如果小于，但设置了Handle PromotionFailure，那么也会执行Full GC。  1 2 3  -XX:HandlePromotionFailure：是否设置空间分配担保 JDK7及以后这个参数就失效了. 只要老年代的连续空间大于新生代对象的总大小或者历次晋升到老年代的对象的平均大小就进行MinorGC，否则FullGC    永久代空间不足，会触发Full GC\n  System.gc()也会触发Full GC\n  堆中分配很大的对象\n   1 2 3 4 5 6 7 8 9 10 11 12 13  private void evict() { Runtime runtime = Runtime.getRuntime(); int i = -1; while (runtime.freeMemory() \u0026lt; 0.2 * runtime.totalMemory()) { i = (i + 1) % dbs.size(); if (dbs.get(i).size() != 0) { evictStrategy.setDb(dbs.get(i)); evictStrategy.doEvict(); } else { continue; } } }   Volatile-Random-Evict 1 2 3 4 5 6 7 8 9  public class VolatileRandomEvict extends AbstractEvictStrategy { @Override public void doEvict() { // 从过期字典中随机删除一个  BytesWrapper randomKey = db.getRandomExpires(); db.delete(randomKey); LOGGER.info(\u0026#34;淘汰了key : \u0026#34; + randomKey); } }   AllKeys-Random-Evict 1 2 3 4 5 6 7 8  public class AllKeysRandomEvict extends AbstractEvictStrategy { @Override public void doEvict() { BytesWrapper randomKey = db.getRandomKey(); db.delete(randomKey); LOGGER.info(\u0026#34;淘汰了key : \u0026#34; + randomKey); } }   No-Evict 1 2 3 4 5 6  public class NoEvict extends AbstractEvictStrategy { @Override public void doEvict() { return; } }   Volatile-Lru-Evict 近似 LRU 算法\n严格的 LRU 算法需要单独维护一个访问队列，这对于数据量很大的缓存系统来说是极度影响性能的。\nRedis 使用的是一种近似 LRU 算法，因为 LRU 算法消耗大量的额外的内存。近似 LRU 算法则很简单，在现有数据结构的基础上使用随机采样法来淘汰元素，能达到和 LRU 算法非常近似的效果。\n它给每个 key 增加了一个额外的小字段 lru，也就是最后一次被访问的时间戳。然后从过期字典种随机采样出 samples（默认为20） 个 key，然后淘汰掉最旧的 key，如果淘汰后内存还是超出 maxmemory，那就继续随机采样淘汰，直到内存低于 maxmemory 为止。\n每次访问到key的时候会更调用 refreshLru() 新键对应的数据对象的 lru 记录。\n Redis3.0之后又改善了算法的性能，会提供一个待淘汰候选key的pool，里面默认有16个key，按照空闲时间排好序。更新时从Redis键空间随机选择N个key，分别计算它们的空闲时间idle，key只会在pool不满或者空闲时间大于pool里最小的时，才会进入pool，然后从pool中选择空闲时间最大的key淘汰掉。\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  public class VolatileLruEvict extends AbstractEvictStrategy { @Override public void doEvict() { if (db.expiresSize() == 0) { LOGGER.info(\u0026#34;没有易失键，尝试淘汰失败\u0026#34;); return; } BytesWrapper lruKey = null; long min = Long.MAX_VALUE; for (int i = 0; i \u0026lt; samples; i++) { BytesWrapper randomKey = db.getRandomExpires(); long lru = db.get(randomKey).getLru(); if (lru \u0026lt; min) { lruKey = randomKey; min = lru; } } db.delete(lruKey); LOGGER.info(\u0026#34;淘汰了key : \u0026#34; + lruKey.toUtf8String()); } }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  public abstract class AbstractRedisObject implements RedisObject{ // 最近访问时间  private long lru; @Override public long getLru() { return lru; } @Override public void refreshLru() { lru = System.currentTimeMillis(); } }   AllKeys-Lru-Evict 同 VolatileLruEvict，只不过采样的键的来源从过期字典变为全部键空间。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  public class AllKeysLruEvict extends AbstractEvictStrategy { @Override public void doEvict() { BytesWrapper lruKey = null; long min = Long.MAX_VALUE; for (int i = 0; i \u0026lt; samples; i++) { BytesWrapper randomKey = db.getRandomKey(); long lru = db.get(randomKey).getLru(); if (lru \u0026lt; min) { lruKey = randomKey; min = lru; } } db.delete(lruKey); LOGGER.info(\u0026#34;淘汰了key : \u0026#34; + lruKey.toUtf8String()); } }   Volatile-Lfu-Evict 强烈推荐阅读！👀：Redis中的LFU算法 - 再见紫罗兰 - 博客园 (cnblogs.com)\nLFU 思路：在LFU算法中，可以为每个key维护一个计数器。每次key被访问的时候，计数器增大。计数器越大，可以约等于访问越频繁。\n上述简单算法存在两个问题：\n 在LRU算法中可以维护一个双向链表，然后简单的把被访问的节点移至链表开头，但在LFU中是不可行的，节点要严格按照计数器进行排序，新增节点或者更新节点位置时，时间复杂度可能达到O(N)。 只是简单的增加计数器的方法并不完美。访问模式是会频繁变化的，一段时间内频繁访问的key一段时间之后可能会很少被访问到，只增加计数器并不能体现这种趋势。  第一个问题很好解决，可以借鉴LRU实现的经验，维护一个待淘汰key的pool。\n第二个问题的解决办法是，记录key最后一个被访问的时间，然后随着时间推移，降低计数器。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  public class VolatileLfuEvict extends AbstractEvictStrategy { @Override public void doEvict() { BytesWrapper lfuKey = null; long min = Long.MAX_VALUE; for (int i = 0; i \u0026lt; samples; i++) { BytesWrapper randomKey = db.getRandomExpires(); long lfu = db.get(randomKey).lfuDecrAndReturn(); if (lfu \u0026lt; min) { lfuKey = randomKey; min = lfu; } } db.delete(lfuKey); LOGGER.info(\u0026#34;淘汰了key : \u0026#34; + lfuKey.toUtf8String()); } }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61  public abstract class AbstractRedisObject implements RedisObject{ // 访问计数  private int accessCount; // 最近一次 accessCount 降低的时间  private long ldt; // 65535 分钟为一个周期 每过一个周期降低accessCount  private static final long LFU_DECAY_TIME = 3932100000L; // accessCount 初始值  private static final int LFU_INIT_VAL = 5; // 控制 accessCount 增长的因子 因子越大，增长的概率越小  private static final int LFU_LOG_FACTOR = 10; public AbstractRedisObject() { this.lru = System.currentTimeMillis(); this.accessCount = LFU_INIT_VAL; this.ldt = System.currentTimeMillis(); } /** * redis 源码逻辑 * void updateLFU(robj *val) { * unsigned long counter = LFUDecrAndReturn(val); * counter = LFULogIncr(counter); * val-\u0026gt;lru = (LFUGetTimeInMinutes()\u0026lt;\u0026lt;8) | counter; * } */ @Override public void updateLfu() { lfuDecrAndReturn(); // 最大值为255  if (accessCount == 255) { return; } // 取一个0-1之间的随机数r与p比较，当r\u0026lt;p时，才增加 accessCount，这和比特币中控制产出的策略类似。  // p取决于当前 accessCount 值与 LFU_LOG_FACTOR 因子，  // accessCount 值与 LFU_LOG_FACTOR 因子越大，p越小，r\u0026lt;p 的概率也越小，accessCount 增长的概率也就越小。  // 可见 accessCount 增长与访问次数呈现对数增长的趋势，随着访问次数越来越大，accessCount 增长的越来越慢  double r = new Random().nextDouble(); double baseval = accessCount - LFU_INIT_VAL; if (baseval \u0026lt; 0) baseval = 0; double p = 1.0 / (baseval * LFU_LOG_FACTOR + 1); if (r \u0026lt; p) accessCount++; } //\t距离该key上次被访问，每过去一个周期即LFU_DECAY_TIME，accessCount就要减少1  //\t这样即使以前被经常访问的key，后来不再访问，也会慢慢降低其accessCount  @Override public int lfuDecrAndReturn() { long l = System.currentTimeMillis() - ldt; long decr = l / LFU_DECAY_TIME; if (decr != 0) { accessCount -= decr; ldt = System.currentTimeMillis(); } return accessCount; } }   AllKeys-Lfu-Evict 同 VolatileLfuEvict，只不过采样的键的来源从过期字典变为全部键空间。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  public class AllKeysLfuEvict extends AbstractEvictStrategy { @Override public void doEvict() { BytesWrapper lfuKey = null; long min = Long.MAX_VALUE; for (int i = 0; i \u0026lt; samples; i++) { BytesWrapper randomKey = db.getRandomKey(); long lfu = db.get(randomKey).lfuDecrAndReturn(); if (lfu \u0026lt; min) { lfuKey = randomKey; min = lfu; } } db.delete(lfuKey); LOGGER.info(\u0026#34;淘汰了key : \u0026#34; + lfuKey.toUtf8String()); } }   Volatile-Ttl-Evict 仅限于易失键，即过期字典中的键，随机采样并淘汰其中最早过期的键。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  public class VolatileTtlEvict extends AbstractEvictStrategy { @Override public void doEvict() { BytesWrapper ttlKey = null; long min = Long.MAX_VALUE; for (int i = 0; i \u0026lt; samples; i++) { BytesWrapper randomKey = db.getRandomKey(); Long ttl = db.getTtl(randomKey); if (ttl \u0026lt; min) { ttlKey = randomKey; min = ttl; } } db.delete(ttlKey); LOGGER.info(\u0026#34;淘汰了key : \u0026#34; + ttlKey.toUtf8String()); } }   ","date":"2022-06-23T16:40:14+08:00","image":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B004-%E8%BF%87%E6%9C%9F%E7%AD%96%E7%95%A5%E4%B8%8E%E9%80%90%E5%87%BA%E7%AD%96%E7%95%A5/log_hu0a4ba87b3d81b22780f8a722f1e0fc9b_1722333_120x120_fill_q75_box_smart1.jpg","permalink":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B004-%E8%BF%87%E6%9C%9F%E7%AD%96%E7%95%A5%E4%B8%8E%E9%80%90%E5%87%BA%E7%AD%96%E7%95%A5/","title":"Redis设计与实现04-过期策略与逐出策略"},{"content":"Redis 中的事务 事务 Redis 通过 MULTI、 EXEC、 WATCH等命令来实现事务功能。事务提供了一种将多个命令请求打包，然后一次性、按顺序地执行多个命令机制，并且再事务执行期间，服务器不会中断事务而改去执行其他客户端的命令请求，它会将事务中的所有命令都执行完毕，然后采取处理其他客户端的命令请求。\n事务首先以 MULTI 命令为开始，接着将多个命令放入事务当中，最后由 EXEC 命令将这个事务提交给服务器执行。\n一个事务从卡死hi到结束通常会经历以下三个阶段：\n 事务开始 命令入队 事务执行  当客户端处于非事务状态时，这个客户端发送的命令会立即被服务器执行。\n当一个客户端切换到事务状态之后，服务器会根据这个客户端发来的不同命令执行不同的操作：\n 如果客户端发送的命令为 EXEC DISCARD、 WATCH， MULTI四个命令的其中一个，那么服务器立即执行这个命令 与此相反，如果客户端发送的命令是 EXEC DISCARD、 WATCH， MULTI 四个命令以外的命令，那么服务器并不立即执行这个命令，而是将这个命令放入一个事务队列里面，然后向客户端返回 QUEUED 回复  每个客户端都有自己的事务状态，这个事务状态保存在客户端状态的 mstate 属性里面\n1 2 3 4 5 6 7  typedef struct multiState { //\t事务队列，FIFO顺序  multiCmd *commands; //\t已入队命令计数  int count; } multiState;   WATCH 命令 WATCH 命令是一个乐观锁，它可以在 EXEC 命令执行之前，监视任意熟练高端数据库键，并在 EXEC 命令执行时，检查被监视的键是否至少有一个已经被修改过了，瑞国是的话，服务器将拒绝执行事务，并向客户端返回代表事务失败的空回复。\n每个 Redis 数据库都保存着一个 watched_keys 字典，这个字典的键是某个被 WATCH 命令监视的数据库键，而字典的值则是一个链表，链表中记录了所有监视相应数据库键的客户端\n监视机制的触发\n对数据库进行修改的命令，在执行之后都会调用 touchWatchKey 函数对 watched_keys 字典进行检查，查看是否由客户端正在监视刚刚被命令修改过的数据库键，如果有的话，那么 touchWatchKey 函数会将监视被修改键的客户端 REDIS_DIRTY_CAS 标识打开，表示该客户端的事务安全性已经被破坏。\n1 2 3 4 5 6 7 8 9 10 11 12  def touchWatchKey(db, key){ # 如果键 key 存在于数据库的 watched_keys 字典中  # 那么说明至少有一个客户端在监视这个 key  if key in db.watch_keys: # 遍历所有监视键 key 的客户端 \tfor client in db.watch_keys[key]: # 打开标识  client.flags |= REDIS_DIRTY_CAS }   判断事务是否安全\n当服务器其接收到一个客户端发来的 EXEC 命令时，服务器会根据这个客户端是否打开了 REDIS_DIRTY_CAS 标识来决定是否执行事务：\n 如果客户端的 REDIS_DIRTY_CAS 标识已经被打开，那么说明客户端所监视的键当中，至少一个键已经被修改过了，在这种情况下，客户端提交的事务已经不再安全，所以服务器会拒绝执行客户端提交的事务。 如果客户端的 REDIS_DIRTY_CAS 标识没有被打开，那么说明客户端监视的所有键都没有被修改过（或者客户端没有监视任何键），事务仍然是安全的，服务器将执行客户端提交的事务。  Redis 事务的 ACID 特性 在 Redis 中，事务总具有原子性（Atomicity）、一致性（Consistency）和隔离性（Isolation），并且当 Redis 运行在某种特定的持久化模式下，事务也具有持久性（Durability）。\n原子性\n事务具有原子性是指，数据库将事务中的多个操作当作一个整体来执行，服务器要么就执行事务中的所有操作，要么就一个操作也不执行。Redis是满足原子性的。\n但是 Redis的事务和传统的关系型数据库事务最大的区别在于，Redis 不支持事务回滚机制（rollback），即使事务队列中的某个命令在执行期间出现了错误，整个事务也会继续执行下去，直到事务队列中的所有命令都执行完毕为止。\nRedis 的作者在事务功能的文档中解释说，不支持事务回滚是因为这种复杂的功能和 Redis 追求简单高效的设计主旨不相符，并且它认为，Redis事务的执行时错误通常都是编程错误产生的，这种错误通常只会出现在开发环境中，而很少会在实际的生产环境中出现，所以他认为没有必要为Redis开发事务回滚功能。\n一致性\n事务具有一致性指的是，如果数据库在执行事务之前是一致的，那么在事务执行之后，无论事务是否执行成功，数据库也仍然是一致的。\n”一致“指的是数据符合数据库本身的定义和要求，没有包含非法或者无效的错误数据。\n  入队错误：如果一个事务在入队命令的过程中，出现了命令不存在，或者命令的格式不正确等情况，那么 Redis 将拒绝执行这个事务。\n  执行错误：除了入队时可能发生错误以外，事务还可能在执行的过程中发生错误。\n 执行过程中发生的错误都是一些不能再入队时被服务器发现的错误，这些错误会在命令实际执行时被触发 即使在事务的执行过程中发生了错误，服务器也不会中断事务的执行，它会继续执行事务中余下的其他命令，并且已执行的命令（包括执行命令所产生的结果）不会被出错的命令影响。    服务器停机\n 如果服务器运行在无持久化的内存模式下，那么重启之后的数据库将是空白，因此数据库总是一致 如果服务器运行在 RDB 模式下，那么事务中途停机不会导致不一致性，因为服务器可以根据现有的 RDB 文件来回复数据，从而将数据库还原到一个一致的状态。如果找不到可供使用的 RDB 文件，那么重启之后的数据库将是空白的，而空白数据库总是一致的。 如果服务器运行在 AOF 模式下，那么事务中途停机不会导致不一致性，因为服务器可以根据现有的 AOF文件来回复数据，从而将数据库还原到一个一致的状态。如果找不到可供使用的 AOF文件，那么重启之后的数据库将是空白的，而空白数据库总是一致的。    隔离性\n事务的隔离性指的是，即使数据库中有多个事务并发地执行，各个事务之间也不会互相影响，并在并发状态下执行的事务和串行执行的事务产生的结果完全相同。\n因为 Redis 使用单线程的方式来执行事务（以及事务队列中的命令），并且服务器保证，在执行事务期间不会对事务进行中断，因此，Redis 的事务总是以串行的方式运行的，并且事务也总是具有隔离性的。\n持久性\n事务的持久性指的是，当一个事务执行完毕时，执行这个事务所得的结果已被保存到永久性存储介质（比如硬盘）里面了，即使服务器在事务执行完毕之后停机，执行事务所得的结果也不会丢失。\n因为 Redis 的事务不过是简单地用队列包裹起了一组 Redis 命令，Redis 并没有为事务提供任何额外的持久化功能没所以 Redis 事务的持久性由 Redis 所使用的持久化模式决定。\n 当服务器在无持久化的内存模式下运作时，事务不具有持久性：一旦服务器停机，包括事务数据在内的所有服务器数据都将丢失 当服务器在 RDB 持久化模式下运作时，服务器只会在特定的保存条件被满足时，才会被执行 BGSAVE 命令，对数据库进行保存操作，并且异步执行的 BGSAVE 不能保证事务数据第一时间保存到硬盘里面，因此 RDB 持久化模式下的事务也不具有耐久性。 当服务器运行在 AOF 持久化模式下  appendfsync 选项的值为 always ，程序总会在执行命令之后调用同步函数，将命令数据真正地保存到硬盘里，这种配置下时具有持久性的 appendfsync 选项的值为 everysec 时，程序会每秒同步一次命令数据到硬盘。因为停机可能会恰好发生在等待同步的那一秒钟之内，这可能会造成事务数据丢失，所以这种配置下的事务不具有持久性。 appendfsync 选项的值为 no 时，程序会交由操作系统来决定何时将命令数据同步到硬盘。因为事务数据可能在等待同步的过程中丢失，所以这种配置下的事务不具有持久性    实现 客户端 org.isheihei.redis.core.client.RedisNormalClient 是客户端类，flag 标识当前客户端是否处在事务开启状态，dirtyCas 则标识当前客户端 WATCH 的键是否被更改过。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  public class RedisNormalClient implements RedisClient{ // 事务标志 true表示开启了一个事务  private boolean flag = false; private final Queue\u0026lt;Command\u0026gt; multiCmd = new LinkedList\u0026lt;\u0026gt;(); // 事务安全性标志 false表示安全  private boolean dirtyCas = false; @Override public void setFlag(boolean flag) { this.flag = flag; } @Override public boolean getFlag() { return this.flag; } @Override public void setDirtyCas(boolean dirtyCas) { this.dirtyCas = dirtyCas; } @Override public boolean getDirtyCas() { return dirtyCas; } @Override public void addCommand(Command command) { multiCmd.add(command); } @Override public void unWatchKeys(RedisClient redisClient) { for (RedisDB db : dbs) { db.unWatchKeys(redisClient); } } }   WATCH org.isheihei.redis.server.handler.CommandHandler 中给出了命令的处理逻辑，即\n 如果客户端发送的命令为 EXEC DISCARD、 WATCH， MULTI四个命令的其中一个，那么服务器立即执行这个命令 与此相反，如果客户端发送的命令是 EXEC DISCARD、 WATCH， MULTI 四个命令以外的命令，那么服务器并不立即执行这个命令，而是将这个命令放入一个事务队列里面，然后向客户端返回 QUEUED 回复  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44  protected void channelRead0(ChannelHandlerContext ctx, Command command) { try { if (command instanceof Quit) { ctx.close(); return; } // 如果开启了认证功能，所有命令执行前需要检查认证是否成功  if (ConfigUtil.getRequirePass() != null \u0026amp;\u0026amp; client.getAuth() == 0 \u0026amp;\u0026amp; command.type() != CommandType.auth) { ctx.writeAndFlush(new Errors(ErrorsConst.NO_AUTH)); return; } if (client.getFlag()) { if (command instanceof Exec || command instanceof Watch || command instanceof UnWatch || command instanceof Discard) { ctx.writeAndFlush(command.handle(client)); } else if (command instanceof Multi) { ctx.writeAndFlush(new Errors(ErrorsConst.MULTI_CAN_NOT_NESTED)); } else { client.addCommand(command); ctx.writeAndFlush(new SimpleString(\u0026#34;QUEUED\u0026#34;)); } } else { if (command instanceof Exec) { ctx.writeAndFlush(new Errors(ErrorsConst.EXEC_WITHOUT_MULTI)); } else if (command instanceof Discard) { ctx.writeAndFlush(new Errors(ErrorsConst.DISCARD_WITHOUT_MULTI)); } else if (command instanceof Save) { if (rdb != null) { rdb.save(); } ctx.writeAndFlush(command.handle(client)); } else if (command instanceof BgSave) { if (rdb != null) { rdb.bgSave(); } ctx.writeAndFlush(command.handle(client)); } else { ctx.writeAndFlush(command.handle(client)); } } } catch (Exception e) { LOGGER.error(\u0026#34;执行命令出错\u0026#34;, e); ctx.writeAndFlush(new Errors(ErrorsConst.INTERNEL_ERROR)); } }   WATCH 和 UNWATCH 命令的实现，用了一个 watchKeys 字典，其中字典的 key 是监视的键的 key，字典的 value 是弱引用 WeakHashMap。\n 弱引用（WeakReference）无法阻止GC回收，如果一个对象时弱引用可到达，那么在下一个GC回收执行时，该对象就会被回收掉。\nWeakHashMap如何不阻止对象回收呢\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  //\tWeakHashMap的Entry继承了WeakReference。 private static final class Entry\u0026lt;K, V\u0026gt; extends WeakReference\u0026lt;K\u0026gt; implements Map.Entry\u0026lt;K, V\u0026gt; { int hash; boolean isNull; V value; Entry\u0026lt;K, V\u0026gt; next; interface Type\u0026lt;R, K, V\u0026gt; { R get(Map.Entry\u0026lt;K, V\u0026gt; entry); } Entry(K key, V object, ReferenceQueue\u0026lt;K\u0026gt; queue) { //\tKey作为了WeakReference指向的对象  super(key, queue); isNull = key == null; hash = isNull ? 0 : key.hashCode(); value = object; }   WeakHashMap 通过在get()，size() 等操作前执行，删除掉引用为null的Entry。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  private void expungeStaleEntries() { for (Object x; (x = queue.poll()) != null; ) { synchronized (queue) { @SuppressWarnings(\u0026#34;unchecked\u0026#34;) Entry\u0026lt;K,V\u0026gt; e = (Entry\u0026lt;K,V\u0026gt;) x; int i = indexFor(e.hash, table.length); Entry\u0026lt;K,V\u0026gt; prev = table[i]; Entry\u0026lt;K,V\u0026gt; p = prev; while (p != null) { Entry\u0026lt;K,V\u0026gt; next = p.next; if (p == e) { if (prev == e) table[i] = next; else prev.next = next; // Must not null out e.next;  // stale entries may be in use by a HashIterator  e.value = null; // Help GC  size--; break; } prev = p; p = next; } } } }    这里为什么要用弱引用呢？\n当我们使用客户端连接的时候，服务器会创建一个对应的 RedisClien 对象，该连接的所有信息以及事务队列等都保存在这个客户端对象中。\n想象一个场景：当我们在使用 WATCH 监视了一个key，但是没有调用 EXEC 、UNWATCH 或 DISCARD 清空监视的key，而是直接断开了客户端连接。那么这个客户端对象实际上就是一个应该被回收的对象，但是由于 watchKeys 中还保留了该对象的引用，所以无法对该客户端对象进行 GC 回收，造成了内存泄漏。\n如果使用 WeakHashMap 弱引用，当客户端强行断开连接后， JVM 不会阻止只有一个弱引用对象的 GC 回收。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  public class RedisDBImpl implements RedisDB { // watch_keys 客户端使用弱引用对象 当客户端在事务执行中意外关闭的时候 会自动gc 防止占用内存  private final Map\u0026lt;BytesWrapper, WeakHashMap\u0026lt;RedisClient, Boolean\u0026gt;\u0026gt; watchKeys = new HashMap\u0026lt;\u0026gt;(); // 每对一个键进行修改时，需要进行判断该键是否被某些客户端监视，并修改对应客户端的事务安全性标志  @Override public void touchWatchKey(BytesWrapper key) { WeakHashMap\u0026lt;RedisClient, Boolean\u0026gt; map = watchKeys.get(key); if (map != null) { map.forEach((redisClient, aBoolean) -\u0026gt; redisClient.setDirtyCas(true)); } } @Override public void watchKeys(List\u0026lt;BytesWrapper\u0026gt; keys, RedisClient redisClient) { keys.forEach(key -\u0026gt; { if (watchKeys.containsKey(key)) { watchKeys.get(key).put(redisClient, true); } else { WeakHashMap\u0026lt;RedisClient, Boolean\u0026gt; clients = new WeakHashMap\u0026lt;\u0026gt;(); clients.put(redisClient, true); watchKeys.put(key, clients); } }); } @Override public void unWatchKeys(RedisClient redisClient) { for (Map.Entry\u0026lt;BytesWrapper, WeakHashMap\u0026lt;RedisClient, Boolean\u0026gt;\u0026gt; mapEntry : watchKeys.entrySet()) { mapEntry.getValue().remove(redisClient); } } }   EXEC 事务的执行与 Redis 不同的一点是，如果事务中某条命令存在语法错误，Redis 会在命令入队时就进行报错，并废弃整个事务。\n而我的实现中由于命令的检查过程是在命令实际执行时，所以没有分离出两步检查，无法在入队时进行语法检查。但是实际执行的过程中，只会执行那些语法和实际执行都合法的操作。\n后续也可以进行优化，改为和 Redis 一致的语法检查顺序，但是需要重构所有的命令处理类，工作量比较大，以后有机会的话会慢慢实现。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  public class Exec extends AbstractCommand { @Override public CommandType type() { return CommandType.exec; } @Override public Resp handle(RedisClient redisClient) { // 如果watch key被改动了 则全部拒绝执行  // 如果watch未被改动，则全部执行（执行出错或者语法错误的命令都会失败）  ArrayList\u0026lt;Resp\u0026gt; resps = new ArrayList\u0026lt;\u0026gt;(); if (redisClient.getDirtyCas()) { resps.add(BulkString.NullBulkString); } else { Command cmd; while ((cmd = redisClient.getCommand()) != null) { Resp resp = cmd.handle(redisClient); resps.add(resp); } } redisClient.flushCommand(); redisClient.setDirtyCas(false); redisClient.getDb().unWatchKeys(redisClient); redisClient.setFlag(false); return new RespArray(resps.toArray(new Resp[0])); } }   ","date":"2022-06-22T16:40:21+08:00","image":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B005-%E4%BA%8B%E5%8A%A1/log_hu0a4ba87b3d81b22780f8a722f1e0fc9b_1722333_120x120_fill_q75_box_smart1.jpg","permalink":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B005-%E4%BA%8B%E5%8A%A1/","title":"Redis设计与实现05-事务"},{"content":"持久化分为 RDB 和 AOF 两种。相关实现位于org.isheihei.redis.core.persist\nRDB RDB 文件的创建与载入 RDB 文件创建的条件有两种\n 通过执行 SVAE 和 BGSAVE 命令手动保存。其中 SAVE 会阻塞当前所有命令；而 BGSAVE 是在子进程中执行，服务器在期间仍然可以处理命令。 自动间隔性保存  自动间隔性保存\n在 RDB 中有一些保存条件，他们是一个二元组形式的集合，如果满足其中任何一个条件，就会执行 RDB 文件保存\n1 2 3 4 5  /** * 保存条件 * 900 1 ： 900s内对数据库进行了至少1次修改 */ private Map\u0026lt;Long, Long\u0026gt; saveParams = new HashMap\u0026lt;\u0026gt;();   除了 saveParams 数组之外，还会维护 dirty 计数器，以及一个 lastSave 属性\n dirty 计数器记录距离上一次 RDB 持久化后，数据库的修改次数 lastSave 是一个 UNIX 时间戳，记录了服务器上一次成功执行 RDB 持久化的时间  通过周期事件 ServerCron 调用函数判断是否满足间隔保存条件，如果满足条件，则执行持久化操作：\n1 2 3 4 5 6 7 8  public boolean satisfySaveParams() { long dirtyCount = dbs.stream().mapToLong(RedisDB::getDirty).sum(); long interVal = TimeUnit.MICROSECONDS.toSeconds(System.currentTimeMillis() - lastSave); boolean anyMatch = saveParams.entrySet().stream() .filter(param -\u0026gt; param.getValue() \u0026lt;= dirtyCount) .anyMatch(param -\u0026gt; param.getKey() \u0026gt; interVal); return anyMatch; }   RDB 文件的载入\n会在服务器初始化时进行，如果 RDB 和 AOF 持久化同时开启，会优先使用 AOF 文件进行加载\n1 2 3 4 5 6 7 8 9 10 11 12  // rdb 和 aof 同时开启优先使用aof文件加载 if (dataBase \u0026amp;\u0026amp; appendOnlyFile) { redisSingleEventExecutor.submit(() -\u0026gt; aof.load()); serverCron.aof(aof); serverCron.rdb(rdb); } else if (dataBase) { redisSingleEventExecutor.submit(() -\u0026gt; rdb.load()); serverCron.rdb(rdb); } else if (appendOnlyFile){ redisSingleEventExecutor.submit(() -\u0026gt; aof.load()); serverCron.aof(aof); }   RDB 文件格式 Redis 的 RDB 持久化文件是二进制文件，这里同样参考 Redis 的格式，可能会有些许差异。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  /** * RDB文件结构 * REDIS | db_version | databases | EOF | check_sum * 5B | 4B | | 1B | 8B * * databases部分 * SELECTDB | db_number | key_value_pairs * 1B | 4B | * * key_value_pairs部分 * EXPIRETIME_MS | ms | TYPE | key | value * 1B | 8B | 1B | key_len(4B) + key(ken_len) | value_len(4B) + value(value_len) * * TYPE: * string 0 * map 1 * list 2 * set 3 * zset 4 */   文件读写操作使用的是 MappedByteBuffer\n相对于java io操作中通常采用BufferedReader，BufferedInputStream等带缓冲的IO类处理大文件，java nio中引入了一种基于MappedByteBuffer操作大文件的方式，把文件映射到虚拟内存，其读写性能极高。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161  @Override public synchronized void save() { LOGGER.info(\u0026#34;开始进行rdb持久化...\u0026#34;); try { // 每次持久化需要创建新的文件  deleteFile(); createFile(); long writeIndex = 0L; FileChannel channel = new RandomAccessFile(fileName + suffix, \u0026#34;rw\u0026#34;).getChannel(); MappedByteBuffer mappedByteBuffer = channel.map(FileChannel.MapMode.READ_WRITE, 0, 9); mappedByteBuffer.put(REDIS); //REDIS 5  mappedByteBuffer.putInt(DB_VERSION); // 0001 4  writeIndex += 9; for (int dbIndex = 0; dbIndex \u0026lt; dbs.size(); dbIndex ++) { RedisDB db = dbs.get(dbIndex); if (db.size() == 0) { continue; } mappedByteBuffer = channel.map(FileChannel.MapMode.READ_WRITE, writeIndex, 5); mappedByteBuffer.put(SELECTDB); // X 1  mappedByteBuffer.putInt(dbIndex); // NULL * 4  writeIndex += 5; Map\u0026lt;BytesWrapper, RedisObject\u0026gt; dict = db.dict(); Map\u0026lt;BytesWrapper, Long\u0026gt; expires = db.expires(); Iterator\u0026lt;Map.Entry\u0026lt;BytesWrapper, RedisObject\u0026gt;\u0026gt; entryIterator = dict.entrySet().iterator(); while (entryIterator.hasNext()) { Map.Entry\u0026lt;BytesWrapper, RedisObject\u0026gt; next = entryIterator.next(); BytesWrapper nextKey = next.getKey(); RedisObject value = next.getValue(); mappedByteBuffer = channel.map(FileChannel.MapMode.READ_WRITE, writeIndex, 10); mappedByteBuffer.put(EXPIRETIME_MS); // V  if (db.expires().containsKey(nextKey)) { mappedByteBuffer.putLong(db.getTtl(nextKey)); } else { mappedByteBuffer.putLong(0L); // NULL * 4  } mappedByteBuffer.put(value.getCode()); // 1  writeIndex += 10; int nextLen = nextKey.length(); mappedByteBuffer = channel.map(FileChannel.MapMode.READ_WRITE, writeIndex, 4 + nextLen); mappedByteBuffer.putInt(nextLen); mappedByteBuffer.put(next.getKey().getByteArray()); writeIndex += (nextLen + 4); byte[] objectBytes = next.getValue().objectToBytes(); int objectLen = objectBytes.length; mappedByteBuffer = channel.map(FileChannel.MapMode.READ_WRITE, writeIndex, objectLen + 4); mappedByteBuffer.putInt(objectLen); mappedByteBuffer.put(objectBytes); writeIndex += (objectLen + 4); } mappedByteBuffer = channel.map(FileChannel.MapMode.READ_WRITE, writeIndex, 1); mappedByteBuffer.put(EOF); writeIndex += 1; } mappedByteBuffer = channel.map(FileChannel.MapMode.READ_WRITE, writeIndex, 1); mappedByteBuffer.put(EOF); writeIndex += 1; channel.close(); lastSave = System.currentTimeMillis(); resetDbDirty(); LOGGER.info(\u0026#34;rdb持久化完成\u0026#34;); } catch (FileNotFoundException e) { LOGGER.error(\u0026#34;未找到.rdb文件\u0026#34;); throw new RuntimeException(e); } catch (IOException e) { LOGGER.error(\u0026#34;rdb持久化出错\u0026#34;); throw new RuntimeException(e); } } @Override public void load() { try { long readIndex = 0L; FileChannel channel = new RandomAccessFile(fileName + suffix, \u0026#34;rw\u0026#34;).getChannel(); if (channel.size() == 0) { LOGGER.info(\u0026#34;rdb文件为空\u0026#34;); return; } MappedByteBuffer mappedByteBuffer = channel.map(FileChannel.MapMode.READ_ONLY, 0, 9); for (int i = 0; i \u0026lt; 5; i++) { if (REDIS[i] != mappedByteBuffer.get()) { LOGGER.error(\u0026#34;rdb文件魔数错误\u0026#34;); throw new IOException(); } } if (DB_VERSION != mappedByteBuffer.getInt()) { LOGGER.error(\u0026#34;rdb文件版本错误\u0026#34;); throw new IOException(); } readIndex += 9; while (true){ mappedByteBuffer = channel.map(FileChannel.MapMode.READ_ONLY, readIndex, 1); if (SELECTDB != mappedByteBuffer.get()) { LOGGER.info(\u0026#34;数据库已经加载完成\u0026#34;); break; } readIndex += 1; mappedByteBuffer = channel.map(FileChannel.MapMode.READ_ONLY, readIndex, 4); int dbIndex = mappedByteBuffer.getInt(); RedisDB db = dbs.get(dbIndex); readIndex += 4; while (EOF != channel.map(FileChannel.MapMode.READ_ONLY, readIndex, 1).get(0)) { mappedByteBuffer = channel.map(FileChannel.MapMode.READ_ONLY, readIndex, 14); if (EXPIRETIME_MS != mappedByteBuffer.get()) { LOGGER.error(\u0026#34;rdb文件格式错误\u0026#34;); throw new IOException(); } long ttl = mappedByteBuffer.getLong(); byte type = mappedByteBuffer.get(); RedisObject redisObject; if (type == (byte) 0) { redisObject = new RedisStringObject(); } else if (type == (byte) 1) { redisObject = new RedisMapObject(); } else if (type == (byte) 2) { redisObject = new RedisListObject(); } else if (type == (byte) 3) { redisObject = new RedisSetObject(); } else{ redisObject = new RedisZSetObject(); } int keyLen = mappedByteBuffer.getInt(); readIndex += 14; mappedByteBuffer = channel.map(FileChannel.MapMode.READ_ONLY, readIndex, keyLen); bufferPolled.writeBytes(mappedByteBuffer); readIndex += keyLen; byte[] keyBytes = ByteBufUtil.getBytes(bufferPolled); bufferPolled.clear(); BytesWrapper key = new BytesWrapper(keyBytes); db.put(key, redisObject); db.expire(key, ttl); // ttl 为0即不设置过期  mappedByteBuffer = channel.map(FileChannel.MapMode.READ_ONLY, readIndex, 4); int valueLen = mappedByteBuffer.getInt(); readIndex += 4; mappedByteBuffer = channel.map(FileChannel.MapMode.READ_ONLY, readIndex, valueLen); bufferPolled.writeBytes(mappedByteBuffer); redisObject.loadRdb(bufferPolled); bufferPolled.clear(); readIndex += valueLen; } if (EOF != channel.map(FileChannel.MapMode.READ_ONLY, readIndex, 1).get(0)) { channel.close(); LOGGER.info(\u0026#34;rdb数据全部加载完成\u0026#34;); return; } lastSave = System.currentTimeMillis(); deleteFile(); } } catch (FileNotFoundException e) { e.printStackTrace(); LOGGER.error(\u0026#34;rdb文件加载失败\u0026#34;); } catch (IOException e) { LOGGER.error(\u0026#34;rdb文件加载失败\u0026#34;); e.printStackTrace(); } } public void bgSave() { new Thread(this::save).start(); }   AOF 持久化 AOF 持久化主要通过将修改命令追加到持久化文件中。在Redis设计与实现03-命令 (isheihei.cn)中介绍了写命令的命令执行过程。即：先执行数据库写命令，如果 AOF 开启，则将命令写入 AOF 写队列中。\nAOF 写队列持久化到磁盘的过程还是在周期事件 ServerCron 中被调用。周期是每 100ms 一次。目前只实现了这一种同步方式，所以可能会有极端情况导致数据丢失的情况。\n文件读写操作依然使用的是 MappedByteBuffer\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49  @Override public void save() { if (bufferQueue.isEmpty()) { return; } try (FileChannel channel = new RandomAccessFile(fileName + suffix, \u0026#34;rw\u0026#34;).getChannel()){ LOGGER.info(\u0026#34;开始rdb持久化...\u0026#34;); do { bufferPolled.clear(); long len = channel.size(); Resp resp = bufferQueue.peek(); Resp.write(resp, bufferPolled); int respLen = bufferPolled.readableBytes(); MappedByteBuffer mappedByteBuffer = channel.map(FileChannel.MapMode.READ_WRITE, len, respLen); mappedByteBuffer.put(ByteBufUtil.getBytes(bufferPolled)); bufferQueue.poll(); } while (!bufferQueue.isEmpty()); LOGGER.info(\u0026#34;rdb持久化完成\u0026#34;); } catch (Exception e) { bufferPolled.release(); LOGGER.error(\u0026#34;aof Exception \u0026#34;, e); } } @Override public void load() { try (FileChannel channel = new RandomAccessFile(fileName + suffix, \u0026#34;rw\u0026#34;).getChannel()) { long len = channel.size(); if (len == 0) { LOGGER.info(\u0026#34;aof文件为空\u0026#34;); return; } MappedByteBuffer mappedByteBuffer = channel.map(FileChannel.MapMode.READ_ONLY, 0, len); bufferPolled.writeBytes(mappedByteBuffer); while (bufferPolled.readableBytes() \u0026gt; 0) { Resp resp = Resp.decode(bufferPolled); Command command = CommandFactory.from((RespArray) resp); if (command != null) { AbstractWriteCommand writeCommand = (AbstractWriteCommand) command; writeCommand.handleLoadAof(this.mockClient); } } LOGGER.info(\u0026#34;加载aof文件完成\u0026#34;); } catch (Exception e) { bufferPolled.release(); LOGGER.error(\u0026#34;加载aof文件失败\u0026#34;); LOGGER.error(\u0026#34;aof Exception \u0026#34;, e); } }   ","date":"2022-06-21T16:40:26+08:00","image":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B006-%E6%8C%81%E4%B9%85%E5%8C%96/log_hu0a4ba87b3d81b22780f8a722f1e0fc9b_1722333_120x120_fill_q75_box_smart1.jpg","permalink":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B006-%E6%8C%81%E4%B9%85%E5%8C%96/","title":"Redis设计与实现06-持久化"},{"content":"测试环境 测试环境 CentOS-7，2核2G，网络带宽 4M\n连接并发数 50\n本地测试 请求数量1000000\nRedis 吞吐量：\n set ：96404.12 requests per second get：95392.54 requests per second  延迟：99% 小于 2ms，100 % 小于 3ms\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  [root@ecs bin]# redis-benchmark -h 127.0.0.1 -p 6379 -c 50 -t set,get -n 1000000 ====== SET ====== 1000000 requests completed in 10.37 seconds 50 parallel clients 3 bytes payload keep alive: 1 98.77% \u0026lt;= 1 milliseconds 99.97% \u0026lt;= 2 milliseconds 100.00% \u0026lt;= 3 milliseconds 100.00% \u0026lt;= 3 milliseconds 96404.12 requests per second ====== GET ====== 1000000 requests completed in 10.48 seconds 50 parallel clients 3 bytes payload keep alive: 1 99.98% \u0026lt;= 1 milliseconds 100.00% \u0026lt;= 2 milliseconds 100.00% \u0026lt;= 2 milliseconds 95392.54 requests per second   Java-Redis 吞吐量：\n set ：96852.30 requests per second get：98931.54 requests per second  延迟：99% 以上 小于 1ms，100 % 小于 2ms。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  [root@ecs-215297 ~]# redis-benchmark -h 127.0.0.1 -p 6379 -c 50 -t set,get -n 1000000 ====== SET ====== 1000000 requests completed in 10.32 seconds 50 parallel clients 3 bytes payload keep alive: 1 99.19% \u0026lt;= 1 milliseconds 100.00% \u0026lt;= 2 milliseconds 100.00% \u0026lt;= 2 milliseconds 96852.30 requests per second ====== GET ====== 1000000 requests completed in 10.11 seconds 50 parallel clients 3 bytes payload keep alive: 1 99.99% \u0026lt;= 1 milliseconds 100.00% \u0026lt;= 1 milliseconds 98931.54 requests per second   网络测试结果 请求数量 50000\nRedis 吞吐量：\n set ：1564.46 requests per second get： 1572.67 requests per second  延迟：99% 以上小于 36ms，100% 小于 78ms\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105  D:redis\u0026gt;redis-benchmark -h **** -p 6379 -c 50 -t set,get -n 50000 ====== SET ====== 50000 requests completed in 31.96 seconds 50 parallel clients 3 bytes payload keep alive: 1 0.00% \u0026lt;= 28 milliseconds 0.07% \u0026lt;= 29 milliseconds 6.09% \u0026lt;= 30 milliseconds 30.29% \u0026lt;= 31 milliseconds 52.48% \u0026lt;= 32 milliseconds 82.82% \u0026lt;= 33 milliseconds 95.00% \u0026lt;= 34 milliseconds 98.62% \u0026lt;= 35 milliseconds 99.35% \u0026lt;= 36 milliseconds 99.62% \u0026lt;= 37 milliseconds 99.76% \u0026lt;= 38 milliseconds 99.83% \u0026lt;= 39 milliseconds 99.85% \u0026lt;= 40 milliseconds 99.86% \u0026lt;= 41 milliseconds 99.87% \u0026lt;= 42 milliseconds 99.88% \u0026lt;= 43 milliseconds 99.89% \u0026lt;= 44 milliseconds 99.90% \u0026lt;= 45 milliseconds 99.90% \u0026lt;= 46 milliseconds 99.90% \u0026lt;= 48 milliseconds 99.90% \u0026lt;= 49 milliseconds 99.91% \u0026lt;= 50 milliseconds 99.91% \u0026lt;= 51 milliseconds 99.91% \u0026lt;= 52 milliseconds 99.92% \u0026lt;= 53 milliseconds 99.93% \u0026lt;= 54 milliseconds 99.93% \u0026lt;= 55 milliseconds 99.93% \u0026lt;= 56 milliseconds 99.94% \u0026lt;= 57 milliseconds 99.94% \u0026lt;= 58 milliseconds 99.94% \u0026lt;= 59 milliseconds 99.95% \u0026lt;= 60 milliseconds 99.95% \u0026lt;= 61 milliseconds 99.96% \u0026lt;= 66 milliseconds 99.96% \u0026lt;= 67 milliseconds 99.96% \u0026lt;= 68 milliseconds 99.97% \u0026lt;= 69 milliseconds 99.98% \u0026lt;= 70 milliseconds 99.98% \u0026lt;= 72 milliseconds 99.99% \u0026lt;= 74 milliseconds 99.99% \u0026lt;= 75 milliseconds 99.99% \u0026lt;= 76 milliseconds 99.99% \u0026lt;= 77 milliseconds 100.00% \u0026lt;= 78 milliseconds 100.00% \u0026lt;= 78 milliseconds 1564.46 requests per second ====== GET ====== 50000 requests completed in 31.79 seconds 50 parallel clients 3 bytes payload keep alive: 1 0.00% \u0026lt;= 28 milliseconds 0.65% \u0026lt;= 29 milliseconds 10.31% \u0026lt;= 30 milliseconds 29.60% \u0026lt;= 31 milliseconds 62.84% \u0026lt;= 32 milliseconds 85.18% \u0026lt;= 33 milliseconds 95.62% \u0026lt;= 34 milliseconds 98.32% \u0026lt;= 35 milliseconds 99.14% \u0026lt;= 36 milliseconds 99.49% \u0026lt;= 37 milliseconds 99.66% \u0026lt;= 38 milliseconds 99.77% \u0026lt;= 39 milliseconds 99.81% \u0026lt;= 40 milliseconds 99.84% \u0026lt;= 41 milliseconds 99.86% \u0026lt;= 42 milliseconds 99.87% \u0026lt;= 43 milliseconds 99.88% \u0026lt;= 44 milliseconds 99.90% \u0026lt;= 45 milliseconds 99.90% \u0026lt;= 46 milliseconds 99.90% \u0026lt;= 47 milliseconds 99.90% \u0026lt;= 49 milliseconds 99.91% \u0026lt;= 51 milliseconds 99.91% \u0026lt;= 53 milliseconds 99.91% \u0026lt;= 54 milliseconds 99.92% \u0026lt;= 55 milliseconds 99.92% \u0026lt;= 56 milliseconds 99.93% \u0026lt;= 57 milliseconds 99.93% \u0026lt;= 58 milliseconds 99.94% \u0026lt;= 61 milliseconds 99.94% \u0026lt;= 62 milliseconds 99.95% \u0026lt;= 64 milliseconds 99.95% \u0026lt;= 65 milliseconds 99.96% \u0026lt;= 66 milliseconds 99.96% \u0026lt;= 67 milliseconds 99.96% \u0026lt;= 68 milliseconds 99.96% \u0026lt;= 69 milliseconds 99.97% \u0026lt;= 70 milliseconds 99.97% \u0026lt;= 71 milliseconds 99.98% \u0026lt;= 72 milliseconds 99.98% \u0026lt;= 73 milliseconds 99.99% \u0026lt;= 74 milliseconds 99.99% \u0026lt;= 75 milliseconds 100.00% \u0026lt;= 77 milliseconds 100.00% \u0026lt;= 78 milliseconds 1572.67 requests per second   Java-Redis 吞吐量：\n set ：1552.36 requests per second get： 1558.46 requests per second  延迟：99% 以上小于 42 ms，100% 小于 72 ms。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87  D:redis\u0026gt;redis-benchmark -h 120.46.135.216 -p 6379 -c 50 -t set,get -n 50000 ====== SET ====== 50000 requests completed in 32.21 seconds 50 parallel clients 3 bytes payload keep alive: 1 0.00% \u0026lt;= 27 milliseconds 0.00% \u0026lt;= 28 milliseconds 0.88% \u0026lt;= 29 milliseconds 8.23% \u0026lt;= 30 milliseconds 28.70% \u0026lt;= 31 milliseconds 53.11% \u0026lt;= 32 milliseconds 78.21% \u0026lt;= 33 milliseconds 90.96% \u0026lt;= 34 milliseconds 94.83% \u0026lt;= 35 milliseconds 96.62% \u0026lt;= 36 milliseconds 97.55% \u0026lt;= 37 milliseconds 98.04% \u0026lt;= 38 milliseconds 98.48% \u0026lt;= 39 milliseconds 98.78% \u0026lt;= 40 milliseconds 98.94% \u0026lt;= 41 milliseconds 99.12% \u0026lt;= 42 milliseconds 99.31% \u0026lt;= 43 milliseconds 99.39% \u0026lt;= 44 milliseconds 99.48% \u0026lt;= 45 milliseconds 99.53% \u0026lt;= 46 milliseconds 99.58% \u0026lt;= 47 milliseconds 99.63% \u0026lt;= 48 milliseconds 99.73% \u0026lt;= 49 milliseconds 99.76% \u0026lt;= 50 milliseconds 99.80% \u0026lt;= 51 milliseconds 99.83% \u0026lt;= 52 milliseconds 99.86% \u0026lt;= 53 milliseconds 99.88% \u0026lt;= 54 milliseconds 99.89% \u0026lt;= 55 milliseconds 99.90% \u0026lt;= 56 milliseconds 99.93% \u0026lt;= 57 milliseconds 99.94% \u0026lt;= 58 milliseconds 99.94% \u0026lt;= 59 milliseconds 99.96% \u0026lt;= 60 milliseconds 99.96% \u0026lt;= 61 milliseconds 99.97% \u0026lt;= 62 milliseconds 99.97% \u0026lt;= 63 milliseconds 99.97% \u0026lt;= 64 milliseconds 99.98% \u0026lt;= 65 milliseconds 99.98% \u0026lt;= 67 milliseconds 99.98% \u0026lt;= 68 milliseconds 99.99% \u0026lt;= 69 milliseconds 99.99% \u0026lt;= 70 milliseconds 99.99% \u0026lt;= 71 milliseconds 100.00% \u0026lt;= 72 milliseconds 100.00% \u0026lt;= 75 milliseconds 1552.36 requests per second ====== GET ====== 50000 requests completed in 32.08 seconds 50 parallel clients 3 bytes payload keep alive: 1 0.00% \u0026lt;= 27 milliseconds 0.01% \u0026lt;= 28 milliseconds 0.89% \u0026lt;= 29 milliseconds 4.70% \u0026lt;= 30 milliseconds 27.64% \u0026lt;= 31 milliseconds 49.15% \u0026lt;= 32 milliseconds 76.35% \u0026lt;= 33 milliseconds 93.47% \u0026lt;= 34 milliseconds 97.96% \u0026lt;= 35 milliseconds 99.14% \u0026lt;= 36 milliseconds 99.62% \u0026lt;= 37 milliseconds 99.82% \u0026lt;= 38 milliseconds 99.90% \u0026lt;= 39 milliseconds 99.94% \u0026lt;= 40 milliseconds 99.96% \u0026lt;= 41 milliseconds 99.98% \u0026lt;= 42 milliseconds 99.98% \u0026lt;= 43 milliseconds 99.98% \u0026lt;= 44 milliseconds 99.99% \u0026lt;= 45 milliseconds 99.99% \u0026lt;= 47 milliseconds 99.99% \u0026lt;= 49 milliseconds 99.99% \u0026lt;= 50 milliseconds 99.99% \u0026lt;= 52 milliseconds 100.00% \u0026lt;= 53 milliseconds 100.00% \u0026lt;= 56 milliseconds 1558.46 requests per second   结论 可以看出，无论是本地测试还是网络测试， Java-Redis 的吞吐量和延迟与 Redis 基本相当。\n","date":"2022-06-20T22:34:42+08:00","image":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B007-%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/log_hu0a4ba87b3d81b22780f8a722f1e0fc9b_1722333_120x120_fill_q75_box_smart1.jpg","permalink":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B007-%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/","title":"Redis设计与实现07 性能测试"},{"content":"Arrays.sort(arr) 冒泡排序（超时） 快排 单指针版 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  public int[] MySort(int[] arr) { quickSort(arr, 0, arr.length - 1); return arr; } private void quickSort(int[] array, int start, int end) { if (start \u0026lt; end) { int key = array[start];//用待排数组的第一个作为中枢  int i = start; for (int j = start + 1; j \u0026lt;= end; j++) { if (key \u0026gt; array[j]) { swap(array, j, ++i); } } array[start] = array[i];//先挪，然后再把中枢放到指定位置  array[i] = key; quickSort(array, start, i - 1); quickSort(array, i + 1, end); } } //交换两个数的值  public void swap(int[] A, int i, int j) { if (i != j) { A[i] ^= A[j]; A[j] ^= A[i]; A[i] ^= A[j]; } }   双指针优化 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  public class Solution { public int[] MySort (int[] arr) { quickSort(arr, 0, arr.length - 1); return arr; } public void quickSort(int[] arr, int start, int end){ if(start \u0026gt;= end){ return; } int pivot = arr[start]; int left = start, right = end; while(left \u0026lt; right){ while(left \u0026lt; right \u0026amp;\u0026amp; arr[right] \u0026gt;= pivot){ right--; } swap(arr, left, right); while(left \u0026lt; right \u0026amp;\u0026amp; arr[left] \u0026lt;= pivot){ left++; } swap(arr, left, right); } quickSort(arr, start, left - 1); quickSort(arr, left + 1, end); } private void swap(int[] arr, int i, int j) { int temp = arr[i]; arr[i] = arr[j]; arr[j] = temp; } }   归并 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44  public class Solution { public int[] MySort (int[] arr) { mergeSort(arr, 0, arr.length - 1); return arr; } public void mergeSort(int[] arr, int left, int right){ if(left ==right){ return; } int mid = left + (right - left) / 2; mergeSort(arr, left, mid); mergeSort(arr, mid + 1, right); merge(arr, left, mid, right); } private void merge(int[] arr, int left, int mid, int right){ //辅助数组，先把合并结果放进去，再拷贝回原数组  int[] temp = new int[right - left + 1]; int i = 0; int p1 = left; int p2 = mid + 1; //比较拷贝，直其中一半已经拷贝完成  while(p1 \u0026lt;= mid \u0026amp;\u0026amp; p2 \u0026lt;= right){ temp[i++] = arr[p1] \u0026lt;= arr[p2] ? arr[p1++] : arr[p2++]; } //p2先完成，把p1直接拷贝进去即可  while(p1 \u0026lt;= mid){ temp[i++] = arr[p1++]; } //p1先完成，把p2直接拷贝进去即可  while(p2 \u0026lt;= right){ temp[i++] = arr[p2++]; } for(i = 0; i \u0026lt; temp.length; i++){ arr[left + i] = temp[i]; } } }   堆排序 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78  public class Solution { public int[] MySort (int[] arr) { heapSort(arr); return arr; } /** * 堆是完全二叉树 * 使用数组存储 * 一个节点下标为i： * - 父节点: (i-1)/2 * - 左子节点：2i+1 * - 右子节点: 2i+2 */ public int[] heapSort(int[] nums) { int len = nums.length; // 将数组整理成堆  heapify(nums); // 循环不变量：区间 [0, i] 堆有序  for (int i = len - 1; i \u0026gt;= 1; ) { // 把堆顶元素（当前最大）交换到数组末尾  swap(nums, 0, i); // 把排好的元素剔除堆的范围  i--; // 堆顶元素进行下沉操作，使得区间 [0, i] 堆有序  siftDown(nums, 0, i); } return nums; } /** * 将数组整理成堆（堆有序） * * @param nums */ private void heapify(int[] nums) { int len = nums.length; // 只需要从 i = (len - 1) / 2 这个节点开始，倒序进行逐个下沉调整  // 每个节点调整的过程中可能会对下面已经调整过的产生影响，如果子节点变化需要递归的向下调整  for (int i = (len - 1) / 2; i \u0026gt;= 0; i--) { siftDown(nums, i, len - 1); } } /** * @param nums * @param k 当前进行下沉的元素的下标 * @param end [0, end] 是 nums 的有效部分 */ private void siftDown(int[] nums, int k, int end) { while (2 * k + 1 \u0026lt;= end) { int j = 2 * k + 1; //如果左子节点小于右子节点：将j指向右子节点  if (j + 1 \u0026lt;= end \u0026amp;\u0026amp; nums[j + 1] \u0026gt; nums[j]) { j++; } //如果子节点中较大的与父节点进行比较  if (nums[j] \u0026gt; nums[k]) { swap(nums, j, k); } else { //不需要任何交换，满足堆的条件  break; } //！重要：因为j可能变换，所以继续的向下调整  k = j; } } private void swap(int[] arr, int i, int j){ int temp = arr[i]; arr[i] = arr[j]; arr[j] = temp; } }   ","date":"2022-05-24T18:18:45+08:00","permalink":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E6%8E%92%E5%BA%8F/","title":"排序"},{"content":"可达性分析 GC Roots 可达性分析算法：也可以称为根搜索算法、追踪性垃圾收集\nGC Roots 对象：\n 虚拟机栈中局部变量表中引用的对象：各个线程被调用的方法中使用到的参数、局部变量等 本地方法栈中引用的对象 堆中类静态属性引用的对象 方法区中的常量引用的对象 字符串常量池（string Table）里的引用 同步锁 synchronized 持有的对象  GC Roots 是一组活跃的引用，不是对象，放在 GC Roots Set 集合\n工作原理 可达性分析算法以根对象集合（GCRoots）为起始点，从上至下的方式搜索被根对象集合所连接的目标对象\n分析工作必须在一个保障一致性的快照中进行，否则结果的准确性无法保证，这也是导致 GC 进行时必须 Stop The World 的一个原因\n基本原理：\n  可达性分析算法后，内存中的存活对象都会被根对象集合直接或间接连接着，搜索走过的路径称为引用链\n  如果目标对象没有任何引用链相连，则是不可达的，就意味着该对象己经死亡，可以标记为垃圾对象\n  在可达性分析算法中，只有能够被根对象集合直接或者间接连接的对象才是存活对象\n  三色标记 标记算法 三色标记法把遍历对象图过程中遇到的对象，标记成以下三种颜色：\n 白色：尚未访问过 灰色：本对象已访问过，但是本对象引用到的其他对象尚未全部访问 黑色：本对象已访问过，而且本对象引用到的其他对象也全部访问完成  当 Stop The World (STW) 时，对象间的引用是不会发生变化的，可以轻松完成标记，遍历访问过程为：\n 初始时，所有对象都在白色集合 将 GC Roots 直接引用到的对象挪到灰色集合 从灰色集合中获取对象：  将本对象引用到的其他对象全部挪到灰色集合中 将本对象挪到黑色集合里面   重复步骤 3，直至灰色集合为空时结束 结束后，仍在白色集合的对象即为 GC Roots 不可达，可以进行回收  并发标记 并发标记时，对象间的引用可能发生变化，多标和漏标的情况就有可能发生\n多标情况：当 E 变为灰色或黑色时，其他线程断开的 D 对 E 的引用，导致这部分对象仍会被标记为存活，本轮 GC 不会回收这部分内存，这部分本应该回收但是没有回收到的内存，被称之为浮动垃圾\n 针对并发标记开始后的新对象，通常的做法是直接全部当成黑色，也算浮动垃圾 浮动垃圾并不会影响应用程序的正确性，只是需要等到下一轮垃圾回收中才被清除  漏标情况：\n 条件一：灰色对象断开了对一个白色对象的引用（直接或间接），即灰色对象原成员变量的引用发生了变化 条件二：其他线程中修改了黑色对象，插入了一条或多条对该白色对象的新引用 结果：导致该白色对象当作垃圾被 GC，影响到了程序的正确性  代码角度解释漏标：\n1 2 3  Object G = objE.fieldG; // 读 objE.fieldG = null; // 写 objD.fieldG = G; // 写   为了解决问题，可以操作上面三步，将对象 G 记录起来，然后作为灰色对象再进行遍历，比如放到一个特定的集合，等初始的 GC Roots 遍历完（并发标记），再遍历该集合（重新标记）\n 所以重新标记需要 STW，应用程序一直在运行，该集合可能会一直增加新的对象，导致永远都运行不完\n 解决方法：添加读写屏障，读屏障拦截第一步，写屏障拦截第二三步，在读写前后进行一些后置处理：\n  写屏障 + 增量更新：黑色对象新增引用，会将黑色对象变成灰色对象，最后对该节点重新扫描\n增量更新 (Incremental Update) 破坏了条件二，从而保证了不会漏标\n缺点：对黑色变灰的对象重新扫描所有引用，比较耗费时间\n  写屏障 (Store Barrier) + SATB：当原来成员变量的引用发生变化之前，记录下原来的引用对象\n保留 GC 开始时的对象图，即原始快照 SATB，当 GC Roots 确定后，对象图就已经确定，那后续的标记也应该是按照这个时刻的对象图走，如果期间对白色对象有了新的引用会记录下来，并且将白色对象变灰（说明可达了），重新扫描该对象的引用关系\nSATB (Snapshot At The Beginning) 破坏了条件一，从而保证了不会漏标\n  读屏障 (Load Barrier)：破坏条件二，黑色对象引用白色对象的前提是获取到该对象，此时读屏障发挥作用\n  以 Java HotSpot VM 为例，其并发标记时对漏标的处理方案如下：\n CMS：写屏障 + 增量更新 G1：写屏障 + SATB ZGC：读屏障  垃圾回收器 普通 Serial Serial：串行垃圾收集器，作用于新生代，是指使用单线程进行垃圾回收，采用复制算法，新生代基本都是复制算法，因为分区了\nSTW（Stop-The-World）：垃圾回收时，只有一个线程在工作，并且 Java 应用中的所有线程都要暂停，等待垃圾回收的完成\nSerial old：执行老年代垃圾回收的串行收集器，内存回收算法使用的是标记-整理算法，同样也采用了串行回收和 STW 机制\n Serial old 是 Client 模式下默认的老年代的垃圾回收器 Serial old 在 Server 模式下主要有两个用途：  在 JDK 1.5 以及之前版本（Parallel Old 诞生以前）中与 Parallel Scavenge 收集器搭配使用 作为老年代 CMS 收集器的后备垃圾回收方案，在并发收集发生 Concurrent Mode Failure 时使用    开启参数：-XX:+UseSerialGC 等价于新生代用 Serial GC 且老年代用 Serial old GC\n优点：简单而高效（与其他收集器的单线程比），对于限定单个 CPU 的环境来说，Serial 收集器由于没有线程交互的开销，可以获得最高的单线程收集效率\n缺点：对于交互性较强的应用而言，这种垃圾收集器是不能够接受的，比如 JavaWeb 应用\nParNew Par 是 Parallel 并行的缩写，New 是只能处理的是新生代\n并行垃圾收集器在串行垃圾收集器的基础之上做了改进，采用复制算法，将单线程改为了多线程进行垃圾回收，可以缩短垃圾回收的时间\n对于其他的行为（收集算法、stop the world、对象分配规则、回收策略等）同 Serial 收集器一样，应用在年轻代，除 Serial 外，只有ParNew GC 能与 CMS 收集器配合工作\n相关参数：\n  -XX：+UseParNewGC：表示年轻代使用并行收集器，不影响老年代\n  -XX:ParallelGCThreads：默认开启和 CPU 数量相同的线程数\n  ParNew 是很多 JVM 运行在 Server 模式下新生代的默认垃圾收集器\n 对于新生代，回收次数频繁，使用并行方式高效 对于老年代，回收次数少，使用串行方式节省资源（CPU 并行需要切换线程，串行可以省去切换线程的资源）  Parallel Parallel Scavenge 收集器是应用于新生代的并行垃圾回收器，采用复制算法、并行回收和 Stop the World 机制\n**Parallel Old ** 收集器：是一个应用于老年代的并行垃圾回收器，采用标记-整理算法\n对比其他回收器：\n 其它收集器目标是尽可能缩短垃圾收集时用户线程的停顿时间 Parallel 目标是达到一个可控制的吞吐量，被称为吞吐量优先收集器 Parallel Scavenge 对比 ParNew 拥有自适应调节策略，可以通过一个开关参数打开 GC Ergonomics  应用场景：\n 停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验 高吞吐量可以高效率地利用 CPU 时间，尽快完成程序的运算任务，适合在后台运算而不需要太多交互  停顿时间和吞吐量的关系：新生代空间变小 → 缩短停顿时间 → 垃圾回收变得频繁 → 导致吞吐量下降\n在注重吞吐量及 CPU 资源敏感的场合，都可以优先考虑 Parallel Scavenge + Parallel Old 收集器，在 Server 模式下的内存回收性能很好，Java8 默认是此垃圾收集器组合\n参数配置：\n -XX：+UseParallelGC：手动指定年轻代使用 Paralle 并行收集器执行内存回收任务 -XX：+UseParalleloldcc：手动指定老年代使用并行回收收集器执行内存回收任务  上面两个参数，默认开启一个，另一个也会被开启（互相激活），默认 JDK8 是开启的   -XX:+UseAdaptivesizepplicy：设置 Parallel scavenge 收集器具有自适应调节策略，在这种模式下，年轻代的大小、Eden 和 Survivor 的比例、晋升老年代的对象年龄等参数会被自动调整，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量 -XX:ParallelGcrhreads：设置年轻代并行收集器的线程数，一般与 CPU 数量相等，以避免过多的线程数影响垃圾收集性能  在默认情况下，当 CPU 数量小于 8 个，ParallelGcThreads 的值等于 CPU 数量 当 CPU 数量大于 8 个，ParallelGCThreads 的值等于 3+[5*CPU Count]/8]   -XX:MaxGCPauseMillis：设置垃圾收集器最大停顿时间（即 STW 的时间），单位是毫秒  对于用户来讲，停顿时间越短体验越好；在服务器端，注重高并发，整体的吞吐量 为了把停顿时间控制在 MaxGCPauseMillis 以内，收集器在工作时会调整 Java 堆大小或其他一些参数   -XX:GCTimeRatio：垃圾收集时间占总时间的比例 =1/(N+1)，用于衡量吞吐量的大小  取值范围（0，100）。默认值 99，也就是垃圾回收时间不超过 1 与 -xx:MaxGCPauseMillis 参数有一定矛盾性，暂停时间越长，Radio 参数就容易超过设定的比例    并发 CMS CMS 全称 Concurrent Mark Sweep，是一款并发的、使用标记-清除算法、针对老年代的垃圾回收器，其最大特点是让垃圾收集线程与用户线程同时工作\nCMS 收集器的关注点是尽可能缩短垃圾收集时用户线程的停顿时间，停顿时间越短（低延迟）越适合与用户交互的程序，良好的响应速度能提升用户体验\n分为以下四个流程：\n 初始标记：使用 STW 出现短暂停顿，仅标记一下 GC Roots 能直接关联到的对象，速度很快 并发标记：进行 GC Roots 开始遍历整个对象图，在整个回收过程中耗时最长，不需要 STW，可以与用户线程并发运行 重新标记：修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，比初始标记时间长但远比并发标记时间短，需要 STW（不停顿就会一直变化，采用写屏障 + 增量更新来避免漏标情况） 并发清除：清除标记为可以回收对象，不需要移动存活对象，所以这个阶段可以与用户线程同时并发的  Mark Sweep 会造成内存碎片，不把算法换成 Mark Compact 的原因：Mark Compact 算法会整理内存，导致用户线程使用的对象的地址改变，影响用户线程继续执行\n在整个过程中耗时最长的并发标记和并发清除过程中，收集器线程都可以与用户线程一起工作，不需要进行停顿\n优点：并发收集、低延迟\n缺点：\n  吞吐量降低：在并发阶段虽然不会导致用户停顿，但是会因为占用了一部分线程而导致应用程序变慢，CPU 利用率不够高\n  CMS 收集器无法处理浮动垃圾，可能出现 Concurrent Mode Failure 导致另一次 Full GC 的产生\n浮动垃圾是指并发清除阶段由于用户线程继续运行而产生的垃圾（产生了新对象），这部分垃圾只能到下一次 GC 时才能进行回收。由于浮动垃圾的存在，CMS 收集需要预留出一部分内存，不能等待老年代快满的时候再回收。如果预留的内存不够存放浮动垃圾，就会出现 Concurrent Mode Failure，这时虚拟机将临时启用 Serial Old 来替代 CMS，导致很长的停顿时间\n  标记 - 清除算法导致的空间碎片，往往出现老年代空间无法找到足够大连续空间来分配当前对象，不得不提前触发一次 Full GC；为新对象分配内存空间时，将无法使用指针碰撞（Bump the Pointer）技术，而只能够选择空闲列表（Free List）执行内存分配\n  参数设置：\n  -XX：+UseConcMarkSweepGC：手动指定使用 CMS 收集器执行内存回收任务\n开启该参数后会自动将 -XX:+UseParNewGC 打开，即：ParNew + CMS + Serial old的组合\n  -XX:CMSInitiatingoccupanyFraction：设置堆内存使用率的阈值，一旦达到该阈值，便开始进行回收\n JDK5 及以前版本的默认值为 68，即当老年代的空间使用率达到 68% 时，会执行一次CMS回收 JDK6 及以上版本默认值为 92%    -XX:+UseCMSCompactAtFullCollection：用于指定在执行完 Full GC 后对内存空间进行压缩整理，以此避免内存碎片的产生，由于内存压缩整理过程无法并发执行，所带来的问题就是停顿时间变得更长\n  -XX:CMSFullGCsBeforecompaction：设置在执行多少次 Full GC 后对内存空间进行压缩整理\n  -XX:ParallelCMSThreads：设置 CMS 的线程数量\n CMS 默认启动的线程数是 (ParallelGCThreads+3)/4，ParallelGCThreads 是年轻代并行收集器的线程数 收集线程占用的 CPU 资源多于25%，对用户程序影响可能较大；当 CPU 资源比较紧张时，受到 CMS 收集器线程的影响，应用程序的性能在垃圾回收阶段可能会非常糟糕    G1 收集器 G1 特点 G1（Garbage-First）是一款面向服务端应用的垃圾收集器，应用于新生代和老年代、采用标记-整理算法、软实时、低延迟、可设定目标（最大 STW 停顿时间）的垃圾回收器，用于代替 CMS，适用于较大的堆（\u0026gt;4 ~ 6G），在 JDK9 之后默认使用 G1\nG1 对比其他处理器的优点：\n  并发与并行：\n 并行性：G1 在回收期间，可以有多个 GC 线程同时工作，有效利用多核计算能力，此时用户线程 STW 并发性：G1 拥有与应用程序交替执行的能力，部分工作可以和应用程序同时执行，因此不会在整个回收阶段发生完全阻塞应用程序的情况 其他的垃圾收集器使用内置的 JVM 线程执行 GC 的多线程操作，而 G1 GC 可以采用应用线程承担后台运行的 GC 工作，JVM 的 GC 线程处理速度慢时，系统会调用应用程序线程加速垃圾回收过程    分区算法：\n  从分代上看，G1 属于分代型垃圾回收器，区分年轻代和老年代，年轻代依然有 Eden 区和 Survivor 区。从堆结构上看，新生代和老年代不再物理隔离，不用担心每个代内存是否足够，这种特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一次 GC\n  将整个堆划分成约 2048 个大小相同的独立 Region 块，每个 Region 块大小根据堆空间的实际大小而定，整体被控制在 1MB 到 32 MB之间且为 2 的 N 次幂，所有 Region 大小相同，在 JVM 生命周期内不会被改变。G1 把堆划分成多个大小相等的独立区域，使得每个小空间可以单独进行垃圾回收\n  新的区域 Humongous：本身属于老年代区，当出现了一个巨型对象超出了分区容量的一半，该对象就会进入到该区域。如果一个 H 区装不下一个巨型对象，那么 G1 会寻找连续的 H 分区来存储，为了能找到连续的 H 区，有时候不得不启动 Full GC\n  G1 不会对巨型对象进行拷贝，回收时被优先考虑，G1 会跟踪老年代所有 incoming 引用，这样老年代 incoming 引用为 0 的巨型对象就可以在新生代垃圾回收时处理掉\n  Region 结构图：\n    ​\t  空间整合：\n CMS：标记-清除算法、内存碎片、若干次 GC 后进行一次碎片整理 G1：整体来看是基于标记 - 整理算法实现的收集器，从局部（Region 之间）上来看是基于复制算法实现的，两种算法都可以避免内存碎片    可预测的停顿时间模型（软实时 soft real-time）：可以指定在 M 毫秒的时间片段内，消耗在 GC 上的时间不得超过 N 毫秒\n 由于分块的原因，G1 可以只选取部分区域进行内存回收，这样缩小了回收的范围，对于全局停顿情况也能得到较好的控制 G1 跟踪各个 Region 里面的垃圾堆积的价值大小（回收所获得的空间大小以及回收所需时间，通过过去回收的经验获得），在后台维护一个优先列表，每次根据允许的收集时间优先回收价值最大的 Region，保证了 G1 收集器在有限的时间内可以获取尽可能高的收集效率   相比于 CMS GC，G1 未必能做到 CMS 在最好情况下的延时停顿，但是最差情况要好很多    G1 垃圾收集器的缺点：\n 相较于 CMS，G1 还不具备全方位、压倒性优势。比如在用户程序运行过程中，G1 无论是为了垃圾收集产生的内存占用还是程序运行时的额外执行负载都要比 CMS 要高 从经验上来说，在小内存应用上 CMS 的表现大概率会优于 G1，而 G1 在大内存应用上则发挥其优势，平衡点在 6-8GB 之间  应用场景：\n 面向服务端应用，针对具有大内存、多处理器的机器 需要低 GC 延迟，并具有大堆的应用程序提供解决方案  记忆集 对象不是孤立的，对象之间会存在跨代引用。\n 假如只局限于新生代的收集，那么我们将错误的回收E；若想正确回收，那就需要对老年区同样做一次GC搜索，明显效率低下。\n 假如要现在进行一次只局限于新生代区域内的收集（Minor GC），但新生代中的对象是完全有可能被老年代所引用的，为了找出该区域中的存活对象，不得不在固定的GC Roots之外，再额外遍历整个老年代中所有对象来确保可达性分析结果的正确性，反过来也是一样 。遍历整个老年代所有对象 的方案虽然理论上可行，但无疑会为内存回收带来很大的性能负担。\n记忆集 Remembered Set 在新生代中，每个 Region 都有一个 Remembered Set，用来被哪些其他 Region 里的对象引用（谁引用了我就记录谁）\n 程序对 Reference 类型数据写操作时，产生一个 Write Barrier 暂时中断操作，检查该对象和 Reference 类型数据是否在不同的 Region（跨代引用），不同就将相关引用信息记录到 Reference 类型所属的 Region 的 Remembered Set 之中 进行内存回收时，在 GC 根节点的枚举范围中加入 Remembered Set 即可保证不对全堆扫描也不会有遗漏  垃圾收集器在新生代中建立了记忆集这样的数据结构，可以理解为它是一个抽象类，具体实现记忆集的三种方式：\n 字长精度 对象精度 卡精度(卡表)  卡表（Card Table）在老年代中，是一种对记忆集的具体实现，主要定义了记忆集的记录精度、与堆内存的映射关系等，卡表中的每一个元素都对应着一块特定大小的内存块，这个内存块称之为卡页（card page），当存在跨代引用时，会将卡页标记为 dirty，JVM 对于卡页的维护也是通过写屏障的方式\n收集集合 CSet 代表每次 GC 暂停时回收的一系列目标分区，在任意一次收集暂停中，CSet 所有分区都会被释放，内部存活的对象都会被转移到分配的空闲分区中。年轻代收集 CSet 只容纳年轻代分区，而混合收集会通过启发式算法，在老年代候选回收分区中，筛选出回收收益最高的分区添加到 CSet 中\n CSet of Young Collection CSet of Mix Collection  工作原理 G1 中提供了三种垃圾回收模式：YoungGC、Mixed GC 和 Full GC，在不同的条件下被触发\n 当堆内存使用达到一定值（默认 45%）时，开始老年代并发标记过程 标记完成马上开始混合回收过程  顺时针：Young GC → Young GC + Concurrent Mark → Mixed GC 顺序，进行垃圾回收\n  Young GC：发生在年轻代的 GC 算法，一般对象（除了巨型对象）都是在 eden region 中分配内存，当所有 eden region 被耗尽无法申请内存时，就会触发一次 Young GC，G1 停止应用程序的执行 STW，把活跃对象放入老年代，垃圾对象回收\n回收过程：\n 扫描根：根引用连同 RSet 记录的外部引用作为扫描存活对象的入口 更新 RSet：处理 dirty card queue 更新 RS，此后 RSet 准确的反映对象的引用关系  dirty card queue：类似缓存，产生了引用先记录在这里，然后更新到 RSet 作用：产生引用直接更新 RSet 需要线程同步开销很大，使用队列性能好   处理 RSet：识别被老年代对象指向的 Eden 中的对象，这些被指向的对象被认为是存活的对象，把需要回收的分区放入 Young CSet 中进行回收 复制对象：Eden 区内存段中存活的对象会被复制到 survivor 区，survivor 区内存段中存活的对象如果年龄未达阈值，年龄会加1，达到阀值会被会被复制到 old 区中空的内存分段，如果 survivor 空间不够，Eden 空间的部分数据会直接晋升到老年代空间 处理引用：处理 Soft，Weak，Phantom，JNI Weak 等引用，最终 Eden 空间的数据为空，GC 停止工作    **Concurrent Mark **：\n 初始标记：标记从根节点直接可达的对象，这个阶段是 STW 的，并且会触发一次年轻代 GC 并发标记 (Concurrent Marking)：在整个堆中进行并发标记（应用程序并发执行），可能被 YoungGC 中断。会计算每个区域的对象活性，即区域中存活对象的比例，若区域中的所有对象都是垃圾，则这个区域会被立即回收（实时回收），给浮动垃圾准备出更多的空间，把需要收集的 Region 放入 CSet 当中 最终标记：为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程的 Remembered Set Logs 里面，最终标记阶段需要把 Remembered Set Logs 的数据合并到 Remembered Set 中，这阶段需要停顿线程，但是可并行执行（防止漏标） 筛选回收：并发清理阶段，首先对 CSet 中各个 Region 中的回收价值和成本进行排序，根据用户所期望的 GC 停顿时间来制定回收计划，也需要 STW    Mixed GC：当很多对象晋升到老年代时，为了避免堆内存被耗尽，虚拟机会触发一个混合的垃圾收集器，即 Mixed GC，除了回收整个 young region，还会回收一部分的 old region，过程同 YGC\n注意：是一部分老年代，而不是全部老年代，可以选择哪些老年代 region 收集，对垃圾回收的时间进行控制\n在 G1 中，Mixed GC 可以通过 -XX:InitiatingHeapOccupancyPercent 设置阈值\n  Full GC：对象内存分配速度过快，Mixed GC 来不及回收，导致老年代被填满，就会触发一次 Full GC，G1 的 Full GC 算法就是单线程执行的垃圾回收，会导致异常长时间的暂停时间，需要进行不断的调优，尽可能的避免 Full GC\n产生 Full GC 的原因：\n 晋升时没有足够的空间存放晋升的对象 并发处理过程完成之前空间耗尽，浮动垃圾    相关参数  -XX:+UseG1GC：手动指定使用 G1 垃圾收集器执行内存回收任务 -XX:G1HeapRegionSize：设置每个 Region 的大小。值是 2 的幂，范围是 1MB 到 32MB 之间，目标是根据最小的 Java 堆大小划分出约 2048 个区域，默认是堆内存的 1/2000 -XX:MaxGCPauseMillis：设置期望达到的最大 GC 停顿时间指标，JVM会尽力实现，但不保证达到，默认值是 200ms -XX:+ParallelGcThread：设置 STW 时 GC 线程数的值，最多设置为 8 -XX:ConcGCThreads：设置并发标记线程数，设置为并行垃圾回收线程数 ParallelGcThreads 的1/4左右 -XX:InitiatingHeapoccupancyPercent：设置触发并发 Mixed GC 周期的 Java 堆占用率阈值，超过此值，就触发 GC，默认值是 45 -XX:+ClassUnloadingWithConcurrentMark：并发标记类卸载，默认启用，所有对象都经过并发标记后，就可以知道哪些类不再被使用，当一个类加载器的所有类都不再使用，则卸载它所加载的所有类 -XX:G1NewSizePercent：新生代占用整个堆内存的最小百分比（默认5％） -XX:G1MaxNewSizePercent：新生代占用整个堆内存的最大百分比（默认60％） -XX:G1ReservePercent=10：保留内存区域，防止 to space（Survivor中的 to 区）溢出  G1 (Garbage-First) 是一款面向服务器的垃圾收集器,主要针对配备多颗处理器及大容量内存的机器. 以极高概率满足 GC 停顿时间要求的同时,还具备高吞吐量性能特征.\n被视为 JDK1.7 中 HotSpot 虚拟机的一个重要进化特征。它具备一下特点：\n 并行与并发：G1 能充分利用 CPU、多核环境下的硬件优势，使用多个 CPU（CPU 或者 CPU 核心）来缩短 Stop-The-World 停顿时间。部分其他收集器原本需要停顿 Java 线程执行的 GC 动作，G1 收集器仍然可以通过并发的方式让 java 程序继续执行。 分代收集：虽然 G1 可以不需要其他收集器配合就能独立管理整个 GC 堆，但是还是保留了分代的概念。 空间整合：与 CMS 的“标记-清理”算法不同，G1 从整体来看是基于“标记-整理”算法实现的收集器；从局部上来看是基于“标记-复制”算法实现的。 可预测的停顿：这是 G1 相对于 CMS 的另一个大优势，降低停顿时间是 G1 和 CMS 共同的关注点，但 G1 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为 M 毫秒的时间片段内。  G1 收集器的运作大致分为以下几个步骤：\n  初始标记(Initial Marking)：这阶段仅仅只是标记GC Roots能直接关联到的对象并修改TAMS(Next Top at Mark Start)的值，让下一阶段用户程序并发运行时，能在正确的可用的Region中创建新对象，这阶段需要停顿线程，但是耗时很短。而且是借用进行Minor GC的时候同步完成的，所以G1收集器在这个阶段实际并没有额外的停顿。\n  并发标记(Concurrent Marking)：从GC Roots开始对堆的对象进行可达性分析，递归扫描整个堆里的对象图，找出存活的对象，这阶段耗时较长，但是可以与用户程序并发执行。当对象图扫描完成以后，还要重新处理SATB记录下的在并发时有引用变动的对象。\n  最终标记(Final Marking)：对用户线程做另一个短暂的暂停，用于处理并发阶段结束后仍遗留下来的最后那少量的 SATB 记录。\n  筛选回收(Live Data Counting and Evacuation)：负责更新 Region 的统计数据，对各个 Region 的回收价值和成本进行排序，根据用户所期望的停顿时间来制定回收计划。可以自由选择多个Region来构成回收集，然后把回收的那一部分Region中的存活对象==复制==到空的Region中，在对那些Region进行清空。\n 除了并发标记外，其余过程都要 STW\n   G1 收集器在后台维护了一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的 Region(这也就是它的名字 Garbage-First 的由来) 。这种使用 Region 划分内存空间以及有优先级的区域回收方式，保证了 G1 收集器在有限时间内可以尽可能高的收集效率（把内存化整为零）。\n 不管是G1还是其他分代收集器，JVM都是使用 记忆集(Remembered Set) 来避免全局扫描。 每个Region都有一个对应的记忆集。 每次Reference类型数据写操作时，都会产生一个 写屏障（Write Barrier）暂时去终止操作 然后检查将要写入的引用 指向的对象是否和该Reference类型数据在不同的 Region（其他收集器：检查老年代对象是否引用了新生代对象） 如果不同，通过 卡表（Card Table）把相关引用信息记录到引用指向对象的所在Region对应的记忆集(Remembered Set) 中，被引用对象记录引用自己的对象，这样被引用对象要可达性分析时候，可以找记忆集中的对象 当进行垃圾收集时，在GC Roots枚举范围加上记忆集；就可以保证不进行全局扫描了。  参考  《深入理解 Java 虚拟机：JVM 高级特性与最佳实践（第二版》 https://docs.oracle.com/javase/specs/jvms/se8/html/index.html 参考文章：https://www.jianshu.com/p/12544c0ad5c1  ","date":"2022-05-24T17:24:10+08:00","permalink":"https://isheihei.github.io/posts/java/jvm-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/","title":"JVM-垃圾回收"},{"content":"主要参考：《深入理解Java虚拟机》-周志明\n线程安全 Java语言中的线程安全 不可变\nJava语言中，如果多线程共享的数据是一个基本数据类型，那么只要在定义时使用final关键字修饰它就可以保证它是不可变的\n只要一个不可变的对象被正确地构建出来（即没有发生this引用逃逸的情况），那其外部的可见状态永远都不会改变，永远都不会看到它在多个线程之中处于不一致的状态。“不可变”带来的安全性是最直接、最纯粹的。\n绝对线程安全\n这个定义其实是很严格的，一个类要达到“不管运行时环境如何，调用者都不需要任何额外的同步措施”可能需要付出非常高昂的，甚至不切实际的代价。\n在Java API中标注自己是线程安全的类，大多数都不是绝对的线程安全。\n相对线程安全\n相对线程安全就是我们通常意义上所讲的线程安全，它需要保证对这个对象单次的操作是线程安全的，我们在调用的时候不需要进行额外的保障措施，但是对于一些特定顺序的连续调用，就可能需要在调用端使用额外的同步手段来保证调用的正确性。\n线程兼容\n线程兼容是指对象本身并不是线程安全的，但是可以通过在调用端正确地使用同步手段来保证对象在并发环境中可以安全地使用。\n线程对立\n线程对立是指不管调用端是否采取了同步措施，都无法在多线程环境中并发使用代码。\n一个线程对立的例子是Thread类的suspend()和resume()方法。如果有两个线程同时持有一个线程对象，一个尝试去中断线程，一个尝试去恢复线程，在并发进行的情况下，无论调用时是否进行了同步，目标线程都存在死锁风险——假如suspend()中断的线程就是即将要执行resume()的那个线程，那就肯定要产生死锁了。\n线程安全的实现方法 互斥同步\n在Java里面，最基本的互斥同步手段就是synchronized关键字，这是一种块结构（Block Structured）的同步语法。synchronized关键字经过Javac编译之后，会在同步块的前后分别形成monitorenter和monitorexit这两个字节码指令。\n这两个字节码指令都需要一个reference类型的参数来指明要锁定和解锁的对象。如果Java源码中的synchronized明确指定了对象参数，那就以这个对象的引用作为reference；如果没有明确指定，那将根据synchronized修饰的方法类型（如实例方法或类方法），来决定是取代码所在的对象实例还是取类型对应的Class对象来作为线程要持有的锁\n从功能上看，根据以上《Java虚拟机规范》对monitorenter和monitorexit的行为描述，我们可以得出两个关于synchronized的直接推论，这是使用它时需特别注意的：\n 被synchronized修饰的同步块对同一条线程来说是可重入的。这意味着同一线程反复进入同步块也不会出现自己把自己锁死的情况。 被synchronized修饰的同步块在持有锁的线程执行完毕并释放锁之前，会无条件地阻塞后面其他线程的进入。这意味着无法像处理某些数据库中的锁那样，强制已获取锁的线程释放锁；也无法强制正在等待锁的线程中断等待或超时退出。  从执行成本的角度看，持有锁是一个重量级（Heavy-Weight）的操作。在主流Java虚拟机实现中，Java的线程是映射到操作系统的原生内核线程之上的，如果要阻塞或唤醒一条线程，则需要操作系统来帮忙完成，这就不可避免地陷入用户态到核心态的转换中，进行这种状态转换需要耗费很多的处理器时间。尤其是对于代码特别简单的同步块（譬如被synchronized修饰的getter()或setter()方法），状态转换消耗的时间甚至会比用户代码本身执行的时间还要长。因此才说，synchronized是Java语言中一个重量级的操作，有经验的程序员都只会在确实必要的情况下才使用这种操作。\n**重入锁（ReentrantLock）**是Lock接口最常见的一种实现，顾名思义，它与synchronized一样是可重入的。在基本用法上，ReentrantLock也与synchronized很相似，只是代码写法上稍有区别而已。不过，ReentrantLock与synchronized相比增加了一些高级功能，主要有以下三项：等待可中断、可实现公平锁及锁可以绑定多个条件。\n 等待可中断：是指当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情。可中断特性对处理执行时间非常长的同步块很有帮助。 公平锁：是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁；而非公平 锁则不保证这一点，在锁被释放时，任何一个等待锁的线程都有机会获得锁。synchronized中的锁是非公平的，ReentrantLock在默认情况下也是非公平的，但可以通过带布尔值的构造函数要求使用公平锁。不过一旦使用了公平锁，将会导致ReentrantLock的性能急剧下降，会明显影响吞吐量。 锁绑定多个条件：是指一个ReentrantLock对象可以同时绑定多个Condition对象。在synchronized中，锁对象的wait()跟它的notify()或者notifyAll()方法配合可以实现一个隐含的条件，如果要和多于一个的条件关联的时候，就不得不额外添加一个锁；而ReentrantLock则无须这样做，多次调用newCondition()方法即可。  ReentrantLock在功能上是synchronized的超集，在性能上又至少不会弱于synchronized，那synchronized修饰符是否应该被直接抛弃，不再使用了呢？当然不是，基于以下理由，笔者仍然推荐在synchronized与ReentrantLock都可满足需要时优先使用synchronized：\n synchronized是在Java语法层面的同步，足够清晰，也足够简单。每个Java程序员都熟悉synchronized，但J.U.C中的Lock接口则并非如此。因此在只需要基础的同步功能时，更推荐synchronized。 Lock应该确保在finally块中释放锁，否则一旦受同步保护的代码块中抛出异常，则有可能永远不会释放持有的锁。这一点必须由程序员自己来保证，而使用synchronized的话则可以由Java虚拟机来确保即使出现异常，锁也能被自动释放。 尽管在JDK 5时代ReentrantLock曾经在性能上领先过synchronized，但这已经是十多年之前的胜利了。从长远来看，Java虚拟机更容易针对synchronized来进行优化，因为Java虚拟机可以在线程和对象的元数据中记录synchronized中锁的相关信息，而使用J.U.C中的Lock的话，Java虚拟机是很难得知具体哪些锁对象是由特定线程锁持有的。  非阻塞同步\n随着硬件指令集的发展，我们已经有了另外一个选择：基于冲突检测的乐观并发策略，通俗地说就是不管风险，先进行操作，如果没有其他线程争用共享数据，那操作就直接成功了；如果共享的数据的确被争用，产生了冲突，那再进行其他的补偿措施，最常用的补偿措施是不断地重试，直到出现没有竞争的共享数据为止。这种乐观并发策略的实现不再需要把线程阻塞挂起，因此这种同步操作被称为非阻塞同步（Non-Blocking Synchronization），使用这种措施的代码也常被称为无锁（Lock-Free）编程。\n硬件保证某些从语义上看起来需要多次操作的行为可以只通过一条处理器指令就能完成，这类指令常用的有：\n 测试并设置（Test-and-Set）； 获取并增加（Fetch-and-Increment）； 交换（Swap）； 比较并交换（Compare-and-Swap，下文称CAS）； 加载链接/条件储存（Load-Linked/Store-Conditional，下文称LL/SC）。  CAS指令需要有三个操作数，分别是内存位置（在Java中可以简单地理解为变量的内存地址，用V表示）、旧的预期值（用A表示）和准备设置的新值（用B表示）。CAS指令执行时，当且仅当V符合A时，处理器才会用B更新V的值，否则它就不执行更新。但是，不管是否更新了V的值，都会返回V的旧值，上述的处理过程是一个原子操作，执行期间不会被其他线程中断。\n无同步方案\n要保证线程安全，也并非一定要进行阻塞或非阻塞同步，同步与线程安全两者没有必然的联系。同步只是保障存在共享数据争用时正确性的手段，如果能让一个方法本来就不涉及共享数据，那它自然就不需要任何同步措施去保证其正确性，因此会有一些代码天生就是线程安全的，简单介绍其中的两类。\n可重入代码（Reentrant Code）：这种代码又称纯代码（Pure Code），是指可以在代码执行的任何时刻中断它，转而去执行另外一段代码（包括递归调用它本身），而在控制权返回后，原来的程序不会出现任何错误，也不会对结果有所影响。在特指多线程的上下文语境里（不涉及信号量等因素），我们可以认为可重入代码是线程安全代码的一个真子集，这意味着相对线程安全来说，可重入性是更为基础的特性，它可以保证代码线程安全，即所有可重入的代码都是线程安全的，但并非所有的线程安全的代码都是可重入的。\n可重入代码有一些共同的特征，例如，不依赖全局变量、存储在堆上的数据和公用的系统资源，用到的状态量都由参数中传入，不调用非可重入的方法等。我们可以通过一个比较简单的原则来判断代码是否具备可重入性：如果一个方法的返回结果是可以预测的，只要输入了相同的数据，就都能返回相同的结果，那它就满足可重入性的要求，当然也就是线程安全的。\n线程本地存储（Thread Local Storage）：如果一段代码中所需要的数据必须与其他代码共享，那就看看这些共享数据的代码是否能保证在同一个线程中执行。如果能保证，我们就可以把共享数据的可见范围限制在同一个线程之内，这样，无须同步也能保证线程之间不出现数据争用的问题。\n锁优化 Java虚拟机中，synchronized支持的同步方法和同步语句都是使用monitor来实现的。每个对象都与一个monitor相关联，当一个线程执行到一个monitor监视下的代码块中的第一个指令时，该线程必须在引用的对象上获得一个锁，这个锁是monitor实现的。在HotSpot虚拟机中，monitor是由ObjectMonitor实现，使用C++编写实现，具体代码在HotSpot虚拟机源码ObjectMonitor.hpp文件中。\n查看源码会发现，主要的属性有_count(记录该线程获取锁的次数)、_recursions(锁的重入次数)、_owner(指向持有ObjectMonitor对象的线程)、_WaitSet(处于wait状态的线程集合)、_EntryList(处于等待锁block状态的线程队列)。\n当并发线程执行synchronized修饰的方法或语句块时，先进入_EntryList中，当某个线程获取到对象的monitor后，把monitor对象中的_owner变量设置为当前线程，同时monitor对象中的计数器_count加1，当前线程获取同步锁成功。\n当synchronized修饰的方法或语句块中的线程调用wait()方法时，当前线程将释放持有的monitor对象，monitor对象中的_owner变量赋值为null，同时，monitor对象中的_count值减1，然后当前线程进入_WaitSet集合中等待被唤醒。\n自旋锁与自适应自旋 如果物理机器有一个以上的处理器或者处理器核心，能让两个或以上的线程同时并行执行，我们就可以让后面请求锁的那个线程“稍等一会”，但不放弃处理器的执行时间，看看持有锁的线程是否很快就会释放锁。为了让线程等待，我们只须让线程执行一个忙循环（自旋），这项技术就是所谓的自旋锁。\n在JDK 6中对自旋锁的优化，引入了自适应的自旋。自适应意味着自旋的时间不再是固定的了，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定的。如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也很有可能再次成功，进而允许自旋等待持续相对更长的时间\n如果对于某个锁，自旋很少成功获得过锁，那在以后要获取这个锁时将有可能直接省略掉自旋过程，以避免浪费处理器资源。\n锁消除 锁消除是指虚拟机即时编译器在运行时，对一些代码要求同步，但是对被检测到不可能存在共享数据竞争的锁进行消除。锁消除的主要判定依据来源于逃逸分析的数据支持（第11章已经讲解过逃逸分析技术），如果判断到一段代码中，在堆上的所有数据都不会逃逸出去被其他线程访问到，那就可以把它们当作栈上数据对待，认为它们是线程私有的，同步加锁自然就无须再进行。\n锁粗化 原则上，我们在编写代码的时候，总是推荐将同步块的作用范围限制得尽量小——只在共享数据的实际作用域中才进行同步，这样是为了使得需要同步的操作数量尽可能变少，即使存在锁竞争，等待锁的线程也能尽可能快地拿到锁。\n大多数情况下，上面的原则都是正确的，但是如果一系列的连续操作都对同一个对象反复加锁和解锁，甚至加锁操作是出现在循环体之中的，那即使没有线程竞争，频繁地进行互斥同步操作也会导致不必要的性能损耗。\n如果虚拟机探测到有这样一串零碎的操作都对同一个对象加锁，将会把加锁同步的范围扩展（粗化）到整个操作序列的外部\n轻量级锁 轻量级锁并不是用来代替重量级锁的，它设计的初衷是在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗。\n32位HotSpot虚拟机对象头Mark Word\n接下来介绍轻量级锁的工作过程：在代码即将进入同步块的时候，如果此同步对象没有被锁定（锁标志位为“01”状态），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝（官方为这份拷贝加了一个Displaced前缀，即Displaced Mark Word），这时候线程堆栈与对象头的状态如图。\n然后，虚拟机将使用CAS操作尝试把对象的Mark Word更新为指向Lock Record的指针。如果这个更新动作成功了，即代表该线程拥有了这个对象的锁，并且对象Mark Word的锁标志位（Mark Word的最后两个比特）将转变为“00”，表示此对象处于轻量级锁定状态。这时候线程堆栈与对象头的状态如图所示。\n如果这个更新操作失败了，那就意味着至少存在一条线程与当前线程竞争获取该对象的锁。虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是，说明当前线程已经拥有了这个对象的锁，那直接进入同步块继续执行就可以了，否则就说明这个锁对象已经被其他线程抢占了。如果出现两条以上的线程争用同一个锁的情况，那轻量级锁就不再有效，必须要膨胀为重量级锁，锁标志的状态值变为“10”，此时Mark Word中存储的就是指向重量级锁（互斥量）的指针，后面等待锁的线程也必须进入阻塞状态。\n上面描述的是轻量级锁的加锁过程，它的解锁过程也同样是通过CAS操作来进行的，如果对象的Mark Word仍然指向线程的锁记录，那就用CAS操作把对象当前的Mark Word和线程中复制DisplacedMark Word替换回来。假如能够成功替换，那整个同步过程就顺利完成了；如果替换失败，则说明有其他线程尝试过获取该锁，就要在释放锁的同时，唤醒被挂起的线程。\n轻量级锁能提升程序同步性能的依据是“对于绝大部分的锁，在整个同步周期内都是不存在竞争的”这一经验法则。如果没有竞争，轻量级锁便通过CAS操作成功避免了使用互斥量的开销；但如果确实存在锁竞争，除了互斥量的本身开销外，还额外发生了CAS操作的开销。因此在有竞争的情况下，轻量级锁反而会比传统的重量级锁更慢。\n偏向锁 偏向锁的思想是偏向于让第一个获取锁对象的线程，这个线程在之后获取该锁就不再需要进行同步操作，甚至连 CAS 操作也不再需要。\n当锁对象第一次被线程获得的时候，进入偏向状态，标记为 |1|01|（前面内存布局图中说明了，这属于偏向锁状态）。同时使用 CAS 操作将线程 ID （ThreadID）记录到 Mark Word 中，如果 CAS 操作成功，这个线程以后每次进入这个锁相关的同步块就不需要再进行任何同步操作。\n当有另外一个线程去尝试获取这个锁对象时，偏向状态就宣告结束，此时撤销偏向（Revoke Bias）后恢复到未锁定状态或者轻量级锁状态。\n偏向锁是为了在资源没有被多线程竞争的情况下尽量减少锁带来的性能开销。\n在锁对象的对象头中有一个ThreadId字段，当第一个线程访问锁时，如果该锁没有被其他线程访问过，即ThreadId字段为空，那么JVM让其持有偏向锁，并将ThreadId字段的值设置为该线程的ID。当下一次获取锁的时候，会判断ThreadId是否相等，如果一致就不会重复获取锁，从而提高了运行率\n如果存在锁的竞争情况，偏向锁就会被撤销并升级为轻量级锁。\n总结 synchronized的执行过程：\n 检测Mark Word里面是不是当前线程的ID，如果是，表示当前线程处于偏向锁 如果不是，则使用CAS将当前线程的ID替换Mark Word，如果成功则表示当前线程获得偏向锁，置偏向标志位1 如果失败，则说明发生竞争，撤销偏向锁，进而升级为轻量级锁。 当前线程使用CAS将对象头的Mark Word替换为锁记录指针，如果成功，当前线程获得锁 如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。 如果自旋成功则依然处于轻量级状态。 如果自旋失败，则升级为重量级锁。  偏向锁、轻量级锁、重量级锁的区别\n偏向锁的优点是加解锁不需要额外消耗，和执行非同步方法比仅存在纳秒级差距，缺点是如果存在锁竞争会带来额外锁撤销的消耗，适用只有一个线程访问同步代码块的场景。\n轻量级锁的优点是竞争线程不阻塞，程序响应速度快，缺点是如果线程始终得不到锁会自旋消耗 CPU，适用追求响应时间、同步代码块执行快的场景。\n重量级锁的优点是线程竞争不使用自旋不消耗CPU，缺点是线程会阻塞，响应时间慢，适应追求吞吐量、同步代码块执行慢的场景。\n","date":"2022-05-24T14:11:07+08:00","permalink":"https://isheihei.github.io/posts/java/jvm-%E9%94%81%E4%BC%98%E5%8C%96/","title":"线程安全与锁优化"},{"content":"  将 zip 包解压到相应的目录，这里我将解压后的文件夹放在D:\\software\\mysql\\mysql-8.0.22-winx64 下。\n  以管理员身份打开cmd命令行工具，切换目录到：D:\\software\\mysql\\mysql-8.0.22-winx64\\bin\n  初始化数据库：\n mysqld \u0026ndash;initialize \u0026ndash;console\n   执行完场后，会输出root默认的随机密码，如：\n 2021-01-18T03:55:52.326932Z 6 [Note] [MY-010454] [Server] A temporary password is generated for root@localhost: =tL5\u0026gt;rI40v_\u0026gt;\n 随机密码就是：=tL5\u0026gt;rI40v_\u0026gt;\n  安装\n 1  mysqld install      启动\n 1  net start mysql      输入以下命令登录数据库\n mysql -u root -p\n 需要输入密码，默认密码就是步骤4中的随机密码\n  登陆后输入命令\n alter user \u0026lsquo;root\u0026rsquo;@\u0026rsquo;localhost\u0026rsquo; identified by \u0026lsquo;想要设置的密码\u0026rsquo;;\ncommit;\n 修改密码\n  将Mysql的bin目录配置到环境变量中\n  属性配置文件\n1 2 3 4  jdbc.driver=com.mysql.cj.jdbc.Driver jdbc.url=jdbc:mysql://localhost:3306/db0?useUnicode=true\u0026amp;characterEncoding=utf-8\u0026amp;useSSL=false\u0026amp;serverTimezone=GMT jdbc.user=root jdbc.password=root    ","date":"2021-01-29T23:28:00+08:00","permalink":"https://isheihei.github.io/posts/tips/mysql%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/","title":"Mysql安装配置"},{"content":"解压maven压缩包 配置环境变量   新建系统变量 MAVEN_HOME 变量值：E:\\Maven\\apache-maven-3.3.9\n  编辑系统变量 Path 添加变量值： %MAVEN_HOME%\\bin\n  打开cmd，输入  mvn \u0026ndash;version\n 查看安装配置是否成功","date":"2021-01-29T23:25:33+08:00","permalink":"https://isheihei.github.io/posts/tips/maven%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/","title":"Maven安装配置"},{"content":"新建JAVA_HOME变量，填写jdk安装路径：bin目录的上一级 PATH变量添加两个：  %JAVA_HOME%\\bin %JAVA_HOME%\\jre\\bin  新建CLASSPATH变量：  .;%JAVA_HOME%\\lib;%JAVA_HOME%\\lib\\tools.jar ","date":"2021-01-29T23:21:58+08:00","permalink":"https://isheihei.github.io/posts/tips/jdk%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE/","title":"Jdk环境变量配置"},{"content":"将rpm 安装包拷贝到usr/local/sql目录下 卸载mariadb 1 2  # rpm -qa | grep mariadb # rpm -e --nodeps mariadb-libs-5.5.68-1.el7.x86_64   解压mysql.tar包,解压后目录下会有一些rpm文件。 1  # tar -xvf MySQL-5.6.25-1.el6.x86_64.rpm-bundle.tar   安装Mysql.server和Mysql.client 1 2 3 4  # rp-ivh MySQL-server-5.6.25-1.el6.x86_64.rpm # 打开/root/.mysql_secret文件，获取随机生成的密码： mAw0cco4dAVG332x # cat /root/.mysql_secret   启动mysql服务 1  # service mysql start   修改密码 1  mysql\u0026gt; set password = password(\u0026#39;root\u0026#39;);   授权远程访问 1 2 3 4 5  mysql\u0026gt; grant all privileges on *.* to \u0026#39;root\u0026#39; @\u0026#39;%\u0026#39; identified by \u0026#39;root\u0026#39;; mysql\u0026gt; flush privileges; # 关闭防火墙 # systemctl stop firewalld   ","date":"2021-01-29T23:17:20+08:00","permalink":"https://isheihei.github.io/posts/tips/centos7%E9%85%8D%E7%BD%AEmysql/","title":"Centos7配置 ysql"}]