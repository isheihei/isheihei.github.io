[{"content":"hugo 安装 参考官方文档：Hugo Documentation | Hugo (gohugo.io)\ngithub仓库：Releases · gohugoio/hugo (github.com)\n由于我使用的主题是 stack [CaiJimmy/hugo-theme-stack: Card-style Hugo theme designed for bloggers (github.com)]，主题要求下载 hugo-extended 版本\nstack中文文档：介绍 | Hugo 主题 Stack (jimmycai.com)\n下载完成后解压并配置环境变量\nhugo 基本命令 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  # 新建 site-name：quickstart hugo new site \u0026#34;quickstart\u0026#34; # 添加或者修改主题  cd quickstart git init git submodule add https://github.com/CaiJimmy/hugo-theme-stack.git # 方法1： echo theme = \\\u0026#34;stack\\\u0026#34; \u0026gt;\u0026gt; config.toml #方法2（建议）： #使用主题的 \\themes\\hugo-theme-stack\\exampleSite\\config.yaml 文件覆盖 site 的配置文件，这样做是因为主题自带的样例配置已经做了很多默认配置，自己只需要进行简单的定制化即可 # 添加一篇文章 hugo new posts/my-first-post.md # 启动 hugoserver hugo server -D # 访问 http://localhost:1313/   部署 方式1：使用 github 托管  新建仓库：仓库名必须为 {github-username}.github.io 将 hugo 生成的 public 目录作为 git仓库 push 到新建的远程仓库即可  为了避免每次更新都要重新更新仓库，我使用了shell脚本自动化完成，可参考如下脚本：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  #!/bin/sh  # If a command fails then the deploy stops set -e printf \u0026#34;\\033[0;32mDeploying updates to GitHub...\\033[0m\\n\u0026#34; # push meta files git add . msg=\u0026#34;update site $(date)\u0026#34; if [ -n \u0026#34;$*\u0026#34; ]; then msg=\u0026#34;$*\u0026#34; fi git commit -m \u0026#34;$msg\u0026#34; git push -u origin main # Build the project. hugo -D --cleanDestinationDir # if using a theme, replace with `hugo -t \u0026lt;YOURTHEME\u0026gt;` # Go To Public folder cd public # Add changes to git. git add . # Commit changes. msg=\u0026#34;rebuilding site $(date)\u0026#34; if [ -n \u0026#34;$*\u0026#34; ]; then msg=\u0026#34;$*\u0026#34; fi git commit -m \u0026#34;$msg\u0026#34; # Push source and build repos. git push -u origin main   方式2：部署到服务器 服务器安装nginx\n1  yum install nginx -y   配置\n1  vim /etc/nginx/nginx.conf   1 2 3 4 5 6 7 8 9 10 11 12  server { listen 80; listen [::]:80; server_name isheihei.cn; root /root/isheihei.github.io; //网站目录 # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; error_page 404 /404.html; location = /404.html { }   启动\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  // 启动 nginx // 重启 nginx -s reload // 设置开机自启动 systemcel enable nginx.service // 查看nginx状态 systemctl status nginx.service // 杀死nginx重启nginx pkill -9 nginx ps aux | grep nginx systemctl start nginx   遇到的一些问题及解决方案 问题1：插入图片问题 如果需要在博文中插入图片的话，可以使用同图床，但是我自身习惯是所有的博客和资源统一静态管理，那么就需要在生成站点的时候将一些静态图片文件也一起打包。好在 hugo 也提供了这样一种机制。参考：Content Organization | Hugo (gohugo.io)\n遗憾的是我并没有完全搞懂官方的组织管理的方法，这里提供我自己的实现方案供参考\n默认情况下，我们的文章都是在 content/posts/ 目录下，官方提供了一种打包方案：一个文件夹下命名为 index.md 的文档可以访问本文件夹下的静态资源。那么我们只需要给每篇文章使用单独的文件夹目录，该文档包含的图片一并放在该目录下即可。\n为了方便，使用 shell 脚本自动化创建目录和文档\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  #!/bin/sh blog_path=\u0026#34;./content/posts/$2\u0026#34; category_path=\u0026#34;./content/categories/$2\u0026#34; # new blog if [ $1 == \u0026#34;-b\u0026#34; ] then mkdir ${blog_path} hugo new ${blog_path}/index.md # new category elif [ $1 == \u0026#34;-c\u0026#34; ] then mkdir ${category_path} hugo new ${category_path}/_index.md elif [ $1 == \u0026#34;help\u0026#34; -o $1 == \u0026#34;-h\u0026#34; ] then echo \u0026#34;var1\u0026#34; echo \u0026#34;-b:new blog, -c:new category, -h/help:help\u0026#34; echo \u0026#34;var2\u0026#34; echo \u0026#34;path:base is ./content/posts or ./content/categories\u0026#34; # new tag fi   问题2：网页favcoin无法显示 stack 主题提供了配置文件自定义配置 favcoin ，但是我实测后好像一直无法使用静态相对路径访问到。最终的解决方案是修改主题网页模板代码\n文件目录为：\\themes\\hugo-theme-stack\\layouts\\partials\\head.html\n参考作者对于 avator 的处理方法，先对图标进行裁剪，再引入。\n以下是参考对象 \\themes\\hugo-theme-stack\\layouts\\partials\\sidebar\\left.html\n效果：\n","date":"2022-05-19T14:11:07+08:00","image":"https://isheihei.github.io/posts/tips/hugo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E9%83%A8%E7%BD%B2%E4%BB%A5%E5%8F%8A%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/hugo-logo-wide.svg","permalink":"https://isheihei.github.io/posts/tips/hugo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E9%83%A8%E7%BD%B2%E4%BB%A5%E5%8F%8A%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/","title":"Hugo博客搭建部署以及问题解决"},{"content":"状态码 1xx 1xx 类状态码属于提示信息，是协议处理中的⼀种中间状态，实际用到的比较少。\n2xx 2xx 类状态码表示服务器成功处理了客户端的请求，也是我们最愿意看到的状态。\n 200 OK：是最常⻅的成功状态码，表示⼀切正常。如果是⾮ HEAD 请求，服务器返回的响应头都会有 body数据。 204 No Content：也是常⻅的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。 206 Partial Content：是应用于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，⽽是其中的⼀部分，也是服务器处理成功的状态。  3xx 3xx 类状态码表示客户端请求的资源发送了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是重定向。\n 301 Moved Permanently：表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。 302 Found：表示临时重定向，说明请求的资源还在，但暂时需要用另⼀个 URL 来访问。301 和 302 都会在响应头⾥使用字段 Location ，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。 304 Not Modified：不具有跳转的含义，表示资源未修改，重定向已存在的缓冲⽂件，也称缓存重定向，用于缓存控制。  4xx 4xx 类状态码表示客户端发送的报⽂有误，服务器无法处理，也就是错误码的含义。\n 400 Bad Request：表示客户端请求的报⽂有错误，但只是个笼统的错误。 403 Forbidden：表示服务器禁⽌访问资源，并不是客户端的请求出错。 404 Not Found：表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。  5xx 5xx 类状态码表示客户端请求报⽂正确，但是服务器处理时内部发生了错误，属于服务器端的错误码。\n 500 Internal Server Error：与 400 类型，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。 501 Not Implemented：表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。 502 Bad Gateway：通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。 503 Service Unavailable：表示服务器当前很忙，暂时无法响应服务器，类似“网络服务正忙，请稍后重试”的意思。  HTTP常见字段 Host：客户端发送请求时，用来指定服务器的域名\nContent-Length：服务器在返回数据时，表明本次回应的数据长度。\nConnection：Connection 字段最常用于客户端要求服务器使用 TCP 持久连接，以便其他请求复用。HTTP/1.1 版本的默认连接都是持久连接，但为了兼容老版本的 HTTP，需要指定 Connection ⾸部字段的值为Keep-Alive 。⼀个可以复用的 TCP 连接就建⽴了，直到客户端或服务器主动关闭连接。但是，这不是标准字段\nContent-Type：用于服务器回应时，告诉客户端，本次数据是什么格式。\nContent-Encoding：说明数据的压缩方法。表示服务器返回的数据使用了什么压缩格式；客户端在请求时，用 Accept-Encoding 字段说明自⼰可以接受哪些压缩方法。\nGET 与 POST  GET 是安全且幂等的，因为他是只读操作，无论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。 POST 因为是新增或提交数据的操作，会修改服务器上的资源，所以是不安全的，且多次提交就会创建多个资源，所以不是幂等的  HTTP 与 HTTPS  HTTP 是超⽂本传输协议，信息是明文传输，存在安全⻛险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。 HTTP 连接建立相对简单， TCP 三次握手之后便可进⾏ HTTP 的报⽂传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。 HTTP 的端口号是 80，HTTPS 的端口号是 443。 HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。  消息摘要、消息认证码与数字签名的区别 加解密算法+消息摘要+消息认证技术+数字签名+公钥证书_\nSSL/TLS握手 SSL/TLS 协议建⽴的详细流程：\n ClientHello：首先，由客户端向服务器发起加密通信请求，也就是 ClientHello 请求。在这⼀步，客户端主要向服务器发送以下信息：  客户端支持的 SSL/TLS 协议版本，如 TLS 1.2 版本。 客户端生产的随机数（ Client Random ），后面用于生产「会话秘钥」。 客户端⽀持的密码套件列表，如 RSA 加密算法。   SeverHello：服务器收到客户端请求后，向客户端发出响应，也就是 SeverHello 。服务器回应的内容有如下内容：  确认 SSL/ TLS 协议版本，如果浏览器不支持，则关闭加密通信。 服务器生产的随机数（ Server Random ），后面用于生产「会话秘钥」。 确认的密码套件列表，如 RSA 加密算法。 服务器的数字证书。   客户端回应：客户端收到服务器的回应之后，⾸先通过浏览器或者操作系统中的 CA 公钥，确认服务器的数字证书的真实性。如果证书没有问题，客户端会从数字证书中取出服务器的公钥，然后使用它加密报文，向服务器发送如下信息：  ⼀个随机数（ pre-master key ）。该随机数会被服务器公钥加密。 加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。 客户端握手结束通知，表示客户端的握手阶段已经结束。这⼀项同时把之前所有内容的发生的数据做个摘要，用来供服务端校验。上面第⼀项的随机数是整个握手阶段的第三个随机数，这样服务器和客户端就同时有三个随机数，接着就用双方协商的加密算法，各自生成本次通信的「会话秘钥」。   服务器的最后回应：服务器收到客户端的第三个随机数（ pre-master key ）之后，通过协商的加密算法，计算出本次通信的「会话秘钥」。然后，向客户端发出最后的信息：  加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。 服务器握手结束通知，表示服务器的握手阶段已经结束。这⼀项同时把之前所有内容的发生的数据做个摘要，用来供客户端校验。 至此，整个 SSL/TLS 的握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的 HTTP协议，只不过用「会话秘钥」加密内容。    HTTP/1.0、HTTP/1.1、HTTP/2、HTTP/3演变 HTTP/1.1 相比 HTTP/1.0 的改进 HTTP 1.0 vs HTTP 1.1（应用层） | JavaGuide\n  连接方式 : HTTP 1.0 为短连接，HTTP 1.1 支持长连接。\n  状态响应码 : HTTP/1.1中新加入了大量的状态码，光是错误响应状态码就新增了24种。比如说，100 (Continue)——在请求大资源前的预热请求，206 (Partial Content)——范围请求的标识码，409 (Conflict)——请求与当前资源的规定冲突，410 (Gone)——资源已被永久转移，而且没有任何已知的转发地址。\n  缓存处理 : 在 HTTP1.0 中主要使用 header 里的 If-Modified-Since,Expires 来做为缓存判断的标准，HTTP1.1 则引入了更多的缓存控制策略例如 Entity tag，If-Unmodified-Since, If-Match, If-None-Match 等更多可供选择的缓存头来控制缓存策略。\n  带宽优化及网络连接的使用 :HTTP1.0 中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1 则在请求头引入了 range 头域，它允许只请求资源的某个部分，即返回码是 206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。\n  Host头处理 : HTTP/1.1在请求头中加入了Host字段。\n  使用TCP 长连接的方式改善了 HTTP/1.0 短链接造成的性能开销\n  支持管道网络传输，只要第一个请求发出去了，不必等期回来，就可以发第二个请求出去，可以减少整体的响应时间\n  HTTP/2 针对 HTTP/1.1 优化  头部压缩，如果同时发出多个请求，他们的头是一样的或是相似的，那么下一会帮你消除重复部分。这就是 HPACK 算法：客户端和服务端同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后不发送同样字段了，只发送索引号，这样就提高速度。 HTTP/2 不再像 HTTP/1.1 里的纯文本形式的报文，而是全面采用了二进制格式，头和数据体都是二进制。收到报文后无需再将铭文的报文转成二进制，而是直接解析二进制报文，这增加了数据传输的效率。 数据流：HTTP/2 的数据包不是按顺序发送的，同⼀个连接⾥⾯连续的数据包，可能属于不同的回应。因此，必须要对数据包做标记，指出它属于哪个回应。每个请求或回应的所有数据包，称为⼀个数据流（ Stream ）。每个数据流都标记着⼀个独一无二的编号，其中规定客户端发出的数据流编号为奇数， 服务器发出的数据流编号为偶数。 多路复用：HTTP/2 是可以在⼀个连接中并发多个请求或回应，而不用按照顺序⼀⼀对应。移除了 HTTP/1.1 中的串⾏请求，不需要排队等待，也就不会再出现「队头阻塞」问题，降低了延迟，⼤幅度提高了连接的利⽤率。  HTTP/3 HTTP/2 主要的问题在于，多个 HTTP 请求在复⽤⼀个 TCP 连接，下层的 TCP 协议是不知道有多少个 HTTP 请求的。所以⼀旦发生了丢包现象，就会触发 TCP 的重传机制，这样在⼀个 TCP 连接中的所有的 HTTP 请求都必须等待这个丢了的包被重传回来。\n HTTP/1.1 中的管道（ pipeline）传输中如果有⼀个请求阻塞了，那么队列后请求也统统被阻塞住了 HTTP/2 多个请求复用⼀个TCP连接，⼀旦发生丢包，就会阻塞住所有的 HTTP 请求。  这都是基于 TCP 传输层的问题，所以 HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP！\nUDP 是不可靠传输的，但基于 UDP 的 QUIC 协议 可以实现类似 TCP 的可靠性传输。\n QUIC 有自己的⼀套机制可以保证传输的可靠性的。当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响。 TLS3 升级成了最新的 1.3 版本，头部压缩算法也升级成了 QPack 。 HTTPS 要建⽴⼀个连接，要花费 6 次交互，先是建⽴三次握⼿，然后是 TLS/1.3 的三次握⼿。QUIC 直接把以往的 TCP 和 TLS/1.3 的 6 次交互合并成了 3 次，减少了交互次数。  ","date":"2022-07-18T15:15:33+08:00","permalink":"https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/http%E5%8D%8F%E8%AE%AE/","title":"HTTP协议"},{"content":"什么是TCP IP 层是「不可靠」的，它不保证网络包的交付、不保证网络包的按序交付、也不保证网络包中的数据的完整性。\n如果需要保障网络数据包的可靠性，那么就需要由上层（传输层）的 TCP 协议来负责。因为 TCP 是⼀个⼯作在传输层的可靠数据传输的服务，它能确保接收端接收的网络包是无损坏、无间隔、非冗余和按序的。\nTCP 是面向连接的、可靠的、基于字节流的传输层通信协议。\n 面向连接：⼀定是「⼀对⼀」才能连接，不能像 UDP 协议可以⼀个主机同时向多个主机发送消息，也就是⼀对多是无法做到的； 可靠的：无论的网络链路中出现了怎样的链路变化，TCP 都可以保证⼀个报文⼀定能够到达接收端； 字节流：消息是「没有边界」的，所以无论我们消息有多大都可以进⾏传输。并且消息是「有序的」，当「前⼀个」消息没有收到的时候，即使它先收到了后面的字节，那么也不能扔给应用层去处理，同时对「重复」的报文会⾃动丢弃。  TCP 四元组可以唯⼀的确定⼀个连接，四元组包括如下：\n 源地址 源端口 目的地址 目的端口  源地址和⽬的地址的字段（32位）是在 IP 头部 中，作用是通过 IP 协议发送报文给对方主机。\n源端口和⽬的端口的字段（16位）是在 TCP 头部 中，作用是告诉 TCP 协议应该把报文发给哪个进程。\n什么是TCP连接 简单来说就是，用于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，包括Socket、序列号和窗口大小称为连接。\n所以我们可以知道，建⽴⼀个 TCP 连接是需要客户端与服务器端达成上述三个信息的共识。\n Socket：由 IP 地址和端口号组成 序列号：用来解决乱序问题等 窗口大小：用来做流量控制  TCP 格式 序列号：在建⽴连接时由计算机生成的随机数作为其初始值，通过 SYN 包传给接收端主机，每发送⼀次数据，就「累加」⼀次该「数据字节数」的大小。用来解决网络包乱序问题。\n确认应答号：指下⼀次「期望」收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。用来解决不丢包的问题。\n控制位：\n ACK：该位为 1 时，「确认应答」的字段变为有效，TCP 规定除了最初建⽴连接时的 SYN 包之外该位必须设置为 1 。 RST：该位为 1 时，表示 TCP 连接中出现异常必须强制断开连接。 SYN：该位为 1 时，表示希望建⽴连接，并在其「序列号」的字段进⾏序列号初始值的设定。 FIN：该位为 1 时，表示今后不会再有数据发送，希望断开连接。当通信结束希望断开连接时，通信双方的主机之间就可以相互交换 FIN 位为 1 的 TCP 段。  TCP 和 UDP 区别 UDP 不提供复杂的控制机制，利用 IP 提供面向「无连接」的通信服务。UDP 协议真的非常简，头部只有 8 个字节（ 64 位），UDP 的头部格式如下：\n ⽬标和源端口：主要是告诉 UDP 协议应该把报文发给哪个进程。 包长度：该字段保存了 UDP 首部的长度跟数据的长度之和。 校验和：校验和是为了提供可靠的 UDP 首部和数据而设计。  区别   连接：\n TCP 是面向连接的传输层协议，传输数据前先要建⽴连接。 UDP 是不需要连接，即刻传输数据。    服务对象\n TCP 是⼀对⼀的两点服务，即⼀条连接只有两个端点。 UDP ⽀持⼀对⼀、⼀对多、多对多的交互通信    可靠性\n TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按需到达。 UDP 是尽最大努⼒交付，不保证可靠交付数据。    拥塞控制、流量控制\n TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。 UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。    首部开销\n TCP 首部长度较长，会有⼀定的开销，首部在没有使用「选项」字段时是 20 个字节，如果使用了「选项」字段则会变长的。 UDP 首部只有 8 个字节，并且是固定不变的，开销较小。    传输方式\n TCP 是流式传输，没有边界，但保证顺序和可靠。 UDP 是⼀个包⼀个包的发送，是有边界的，但可能会丢包和乱序。    分片不同\n TCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP数据包，如果中途丢失了⼀个分片，只需要传输丢失的这个分片。 UDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层，但是如果中途丢了⼀个分片，在实现可靠传输的 UDP 时则就需要重传所有的数据包，这样传输效率非常差，所以通常 UDP 的报文应该小于 MTU。    TCP 和 UDP 应用场景：  FTP 文件传输 HTTP / HTTPS  由于 UDP 面向无连接，它可以随时发送数据，再加上UDP本身的处理既简单又高效，因此经常用于：\n 包总量较少的通信，如 DNS 、 SNMP 等 视频、音频等多媒体通信 广播通信  为什么 UDP 头部没有「首部长度」字段，而TCP 头部有「首部长度」字段呢？\n原因是 TCP 有可变长的「选项」字段，而UDP 头部长度则是不会变化的，无需多⼀个字段去记录 UDP 的首部长度。\n为什么 UDP 头部有「包长度」字段，而 TCP 头部则没有「包长度」字段呢？\n其中 IP 总长度 和 IP 首部长度，在 IP 首部格式是已知的。TCP 首部长度，则是在 TCP 首部格式已知的，所以就可以求得 TCP 数据的长度。\n因为为了网络设备硬件设计和处理方便，首部长度需要是 4 字节的整数倍。\nTCP连接 两张动图-彻底明白TCP的三次握手与四次挥手\n ⼀开始，客户端和服务端都处于 CLOSED 状态。先是服务端主动监听某个端口，处于 LISTEN 状态   客户端会随机初始化序号（ client_isn ），将此序号置于 TCP 首部的「序号」字段中，同时把 SYN 标志位置为 1 ，表示 SYN 报文。接着把第⼀个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于 SYN-SENT 状态。   服务端收到客户端的 SYN 报文后，首先服务端也随机初始化⾃⼰的序号（ server_isn ），将此序号填⼊TCP 首部的「序号」字段中，其次把 TCP 首部的「确认应答号」字段填⼊ client_isn + 1 , 接着把 SYN和 ACK 标志位置为 1 。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 SYN-RCVD 状态。   客户端收到服务端报文后，还要向服务端回应最后⼀个应答报文，首先该应答报文 TCP 首部 ACK 标志位置为 1 ，其次「确认应答号」字段填⼊ server_isn + 1 ，最后把报文发送给服务端，这次报文可以携带客户到服务器的数据，之后客户端处于 ESTABLISHED 状态。 服务器收到客户端的应答报文后，也进⼊ ESTABLISHED 状态。  如何在 Linux 系统中查看 TCP 状态？ netstat -napt\n为什么是三次握手？不是两次、四次？ 以三个方面分析三次握手的原因\n三次握手才可以阻止重复历史连接的初始化 避免资源浪费（主要原因） 如果只有「两次握手」，当客户端的 SYN 请求连接在网络中阻塞，客户端没有接收到 ACK 报文，就会重新发送 SYN ，由于没有第三次握手，服务器不清楚客户端是否收到了自己发送的建⽴连接的 ACK 确认信号，所以每收到⼀个 SYN 就只能先主动建立⼀个连接，这会造成什么情况呢？\n如果客户端的 SYN 阻塞了，重复发送多次 SYN 报文，那么服务器在收到请求后就会建立多个冗余的无效链接，造成不必要的资源浪费。\n ⼀个「旧 SYN 报文」比「最新的 SYN 」 报文早到达了服务端； 那么此时服务端就会回⼀个 SYN + ACK 报文给客户端； 客户端收到后可以根据自身的上下文，判断这是⼀个历史连接（序列号过期或超时），那么客户端就会发送RST 报文给服务端，表示中止这⼀次连接。  三次握手才可以同步双方的初始序列号 互相发送序列号并互相得到对方的确认，至少需要三次握手。如果两次握手那么服务端无法得到客户端的确认信息。\nTCP连接断开  客户端打算关闭连接，此时会发送⼀个 TCP 首部 FIN 标志位被置为 1 的报文，也即 FIN 报文，之后客户端进⼊ FIN_WAIT_1 状态。 服务端收到该报文后，就向客户端发送 ACK 应答报文，接着服务端进⼊ CLOSED_WAIT 状态。 客户端收到服务端的 ACK 应答报文后，之后进⼊ FIN_WAIT_2 状态。 等待服务端处理完数据后，也向客户端发送 FIN 报文，之后服务端进⼊ LAST_ACK 状态。 客户端收到服务端的 FIN 报文后，回⼀个 ACK 应答报文，之后进⼊ TIME_WAIT 状态 服务器收到了 ACK 应答报文后，就进⼊了 CLOSED 状态，⾄此服务端已经完成连接的关闭。 客户端在经过 2MSL ⼀段时间后，⾃动进⼊ CLOSED 状态，⾄此客户端也完成连接的关闭。  每个方向都需要⼀个 FIN 和⼀个 ACK，因此通常被称为四次挥手。这⾥⼀点需要注意是：主动关闭连接的，才有 TIME_WAIT 状态。\n为什么需要四次挥手  关闭连接时，客户端向服务端发送 FIN 时，仅仅表示客户端不再发送数据了但是还能接收数据。 服务器收到客户端的 FIN 报文时，先回⼀个 ACK 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 FIN 报文给客户端来表示同意现在关闭连接。 从上面过程可知，服务端通常需要等待完成数据的发送和处理，所以服务端的 ACK 和 FIN ⼀般都会分开发送，从而比三次握手导致多了⼀次。  为什么 TIME_WAIT 等待的时间是 2MSL？ MSL 是 Maximum Segment Lifetime，报文最大生存时间，它是任何报文在网络上存在的最⻓时间，超过这个时间报文将被丢弃。因为 TCP 报文基于是 IP 协议的，而 IP 头中有⼀个 TTL 字段，是 IP 数据报可以经过的最大路由数，每经过⼀个处理他的路由器此值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。\nMSL 与 TTL 的区别： MSL 的单位是时间，而 TTL 是经过路由跳数。所以 MSL 应该要大于等于 TTL 消耗为 0 的时间，以确保报文已被⾃然消亡。TIME_WAIT 等待 2 倍的 MSL，比较合理的解释是： 网络中可能存在来⾃发送方的数据包，当这些发送方的数据包被接收方处理后⼜会向对方发送响应，所以⼀来⼀回需要等待 2倍的时间。\n比如如果被动关闭方没有收到断开连接的最后的 ACK 报文，就会触发超时重发 Fin 报文，另⼀方接收到 FIN 后，会重发 ACK 给被动关闭方， ⼀来⼀去正好 2 个MSL。\n2MSL 的时间是从客户端接收到 FIN 后发送 ACK 开始计时的。如果在 TIME-WAIT 时间内，因为客户端的 ACK没有传输到服务端，客户端⼜接收到了服务端重发的 FIN 报文，那么 2MSL 时间将重新计时。\n在 Linux 系统⾥ 2MSL 默认是 60 秒，那么⼀个 MSL 也就是 30 秒。Linux 系统停留在 TIME_WAIT 的时间为固定的 60 秒。\n为什么需要 TIME_WAIT 状态？ 防止旧连接的数据包 经过 2MSL 这个时间，⾜以让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都⾃然消失，再出现的数据包⼀定都是新建⽴连接所产生的。\n保证连接正确关闭 TIME-WAIT 作用是等待⾜够的时间以确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭。\nTIME_WAIT 过多有什么危害？ 过多的 TIME-WAIT 状态主要的危害有两种：\n 第⼀是内存资源占用； 第⼆是对端口资源的占用，⼀个 TCP 连接⾄少消耗⼀个本地端口；如果发起连接⼀方的 TIME_WAIT 状态过多，占满了所有端口资源，则会导致无法创建新连接。  如何优化 TIME_WAIT？ Linux 内核参数开启后，则可以复用处于 TIME_WAIT 的 socket 为新的连接所用。tcp_tw_reuse 功能只能用客户端（连接发起方），因为开启了该功能，在调用 connect()函数时，内核会随机找⼀个 time_wait 状态超过 1 秒的连接给新的连接复用。\nTCP保活机制 TCP短连接:\nTCP短连接的情况，client向server发起连接请求，server接到请求，然后双方建立连接。client向server发送消息，server回应client，然后一次读写就完成了，这时候双方任何一个都可以发起close操作，不过一般都是client先发起close操作。\n为什么呢，一般的server不会回复完client后立即关闭连接的，当然不排除有特殊的情况。从上面的描述看，短连接一般只会在client/server间传递一次读写操作\n短连接的优点是：管理起来比较简单，存在的连接都是有用的连接，不需要额外的控制手段。\nTCP长连接：\n长连接的情况，client向server发起连接，server接受client连接，双方建立连接。Client与server完成一次读写之后，它们之间的连接并不会主动关闭，后续的读写操作会继续使用这个连接。\n首先说一下TCP/IP详解上讲到的TCP保活功能，保活功能主要为服务器应用提供，服务器应用希望知道客户主机是否崩溃，从而可以代表客户使用资源。如果客户已经消失，使得服务器上保留一个半开放的连接，而服务器又在等待来自客户端的数据，则服务器将应远等待客户端的数据，保证功能就是试图在服务器端检测到这种半开放的连接。\n如果一个给定的连接在两小时内没有任何的动作，则服务器就向客户发一个探测报文段，客户主机必须处于以下4个状态之一：\n 客户主机依然正常运行，并从服务器可达。客户的TCP响应正常，而服务器也知道对方是正常的，服务器在两小时后将保证定时器复位。 客户主机已经崩溃，并且关闭或者正在重新启动。在任何一种情况下，客户的TCP都没有响应。服务端将不能收到对探测的响应，并在75秒后超时。服务器总共发送10个这样的探测 ，每个间隔75秒。如果服务器没有收到一个响应，它就认为客户主机已经关闭并终止连接。 客户主机崩溃并已经重新启动。服务器将收到一个对其保证探测的响应，这个响应是一个复位，使得服务器终止这个连接。 客户机正常运行，但是服务器不可达，这种情况与2类似，TCP能发现的就是没有收到探查的响应。  从上面可以看出，TCP保活功能主要为探测长连接的存活状况，不过这里存在一个问题，存活功能的探测周期太长，还有就是它只是探测TCP连接的存活，属于比较斯文的做法，遇到恶意的连接时，保活功能就不够使了。\n既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？  MTU ：⼀个网络包的最大长度，以太网中⼀般为 1500 字节； MSS ：除去 IP 和 TCP 头部之后，⼀个网络包所能容纳的 TCP 数据的最大度；  当 IP 层有⼀个超过 MTU 大小的数据（TCP 头部 + TCP 数据）要发送，那么 IP 层就要进⾏分片，把数据分片成若⼲片，保证每⼀个分片都小于 MTU。把⼀份 IP 数据报进⾏分片以后，由⽬标主机的 IP 层来进⾏重新组装后，再交给上⼀层 TCP 传输层。\n这看起来井然有序，但这存在隐患的，那么当如果⼀个 IP 分片丢失，整个 IP 报文的所有分片都得重传。\n因为 IP 层本身没有超时重传机制，它由传输层的 TCP 来负责超时和重传。\n当接收方发现 TCP 报文（头部 + 数据）的某⼀片丢失后，则不会响应 ACK 给对方，那么发送方的 TCP 在超时后，就会重发「整个 TCP 报文（头部 + 数据）」。\n因此，可以得知由 IP 层进⾏分片传输，是非常没有效率的。\n所以，为了达到最佳的传输效能 TCP 协议在建⽴连接的时候通常要协商双方的 MSS 值，当 TCP 层发现数据超过MSS 时，则就先会进⾏分片，当然由它形成的 IP 包的⻓度也就不会大于 MTU ，⾃然也就不用 IP 分片了。\n经过 TCP 层分片后，如果⼀个 TCP 分片丢失后，进⾏重发时也是以 MSS 为单位，而不用重传所有的分片，大大增加了重传的效率。\n什么是 SYN 攻击？如何避免 SYN 攻击？ SYN攻击 我们都知道 TCP 连接建⽴是需要三次握手，假设攻击者短时间伪造不同 IP 地址的 SYN 报文，服务端每接收到⼀个 SYN 报文，就进⼊ SYN_RCVD 状态，但服务端发送出去的 ACK + SYN 报文，无法得到未知 IP 主机的ACK 应答，久而久之就会占满服务端的 SYN 接收队列（未连接队列），使得服务器不能为正常用户服务。\n解决方法 方法一：\n其中⼀种解决方式是通过修改 Linux 内核参数，控制队列大小和当队列满时应做什么处理。\n 当网卡接收数据包的速度大于内核处理的速度时，会有⼀个队列保存这些数据包。控制该队列的最大值如下参数：net.core.netdev_max_backlog SYN_RCVD 状态连接的最大个数：net.ipv4.tcp_max_syn_backlog 超出处理能时，对新的 SYN 直接回报 RST，丢弃连接：net.ipv4.tcp_abort_on_overflow  方法二：\n 当 「 SYN 队列」满之后，后续服务器收到 SYN 包，不进⼊「 SYN 队列」； 计算出⼀个 cookie 值，再以 SYN + ACK 中的「序列号」返回客户端，（cookie 的作用是验证之后可能到达的ACK的有效性，保证这是一次完整的握手获得SYN报文中携带的TCP选项信息） 服务端接收到客户端的应答报文时，服务器会检查这个 ACK 包的合法性。如果合法，直接放⼊到「 Accept队列」。 最后应用通过调用 accpet() socket 接口，从「 Accept 队列」取出的连接。  TCP重传机制 超时重传 重传机制的其中⼀个方式，就是在发送数据时，设定⼀个定时器，当超过指定的时间后，没有收到对方的 ACK确认应答报文，就会重发该数据，也就是我们常说的超时重传。 TCP 会在以下两种情况发生超时重传：\n 数据包丢失 确认应答丢失  超时时间 RTT 就是数据从网络⼀端传送到另⼀端所需的时间，也就是包的往返时间。超时重传时间是以 RTO （Retransmission Timeout 超时重传时间）表示。\n超时重传时间 RTO 的值应该略大于报文往返 RTT 的值。\n 当超时时间 RTO 较大时，重发就慢，丢了老半天才重发，没有效率，性能差； 当超时时间 RTO 较小时，会导致可能并没有丢就重发，于是重发的就快，会增加网络拥塞，导致更多的超时，更多的超时导致更多的重发。  快速重传 TCP 还有另外⼀种快速重传（Fast Retransmit）机制，它不以时间为驱动，而是以数据驱动重传\n快速重传的⼯作方式是当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。\n快速重传机制只解决了⼀个问题，就是超时时间的问题，但是它依然面临着另外⼀个问题。就是重传的时候，是重传之前的⼀个，还是重传所有的问题。\nSACK 还有一种实现重传机制的方式叫：SACK（ Selective Acknowledgment 选择性确认）。 这种方式需要在 TCP 头部「选项」字段里加一个 SACK 的东西，它可以将缓存的地图发送给发送方，这样发送方就可以知道哪些数据收到了，哪些数据没收到知道了这些信息，就可以只重传丢失的数据。\nDSACK Duplicate SACK ⼜称 D-SACK ，其主要使用了 SACK 来告诉「发送方」有哪些数据被重复接收了。\n滑动窗口 累计确认不怕ACK信息丢失\n累计确认：只要发送方收到了 ACK700 确认应答，就意味着 700 之前的所有数据「接收方」都收到了。这个模式就叫累计确认或者累计应答。\n窗口大小如何确定 这个字段是接收端告诉发送端 还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能⼒来发送数据，而不会导致接收端处理不过来。所以，通常窗口的大小是由接收方的窗口大小来决定的。\n发送方发送的数据大小不能超过接收方的窗口大小，否则接收方就无法正常接收到数据。\n流量控制 发送方不能无脑的发数据给接收方，要考虑接收方处理能⼒。\n如果⼀直无脑的发数据给对方，但对方处理不过来，那么就会导致触发重发机制，从而导致网络流量的无端的浪费。\n为了解决这种现象发生，TCP 提供⼀种机制可以让「发送方」根据「接收方」的实际接收能⼒控制发送的数据量，这就是所谓的流量控制。\n根据调整窗口的大小来控制发送方与接收方的流量\n拥塞控制 流量控制与拥塞控制对比 前面的流量控制是避免「发送方」的数据填满「接收方」的缓存，但是并不知道网络的中发生了什么。⼀般来说，计算机网络都处在⼀个共享的环境。因此也有可能会因为其他主机之间的通信使得网络拥堵。\n在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是⼀重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进⼊恶性循环被不断地放大\u0026hellip;.\n于是，就有了拥塞控制，控制的⽬的就是避免「发送方」的数据填满整个网络。为了在「发送方」调节所要发送数据的量，定义了⼀个叫做「拥塞窗口」的概念。\n拥塞窗口 cwnd是发送方维护的⼀个的状态变量，它会根据网络的拥塞程度动态变化的。\n我们在前面提到过发送窗口 swnd 和接收窗口 rwnd 是约等于的关系，那么由于加⼊了拥塞窗口的概念后，此时发送窗口的值是swnd = min(cwnd, rwnd)，也就是拥塞窗口和接收窗口中的最小值。\n拥塞窗口 cwnd 变化的规则：\n 只要网络中没有出现拥塞， cwnd 就会增大； 但网络中出现了拥塞， cwnd 就减少；  传输轮次：每一个窗口为一轮，例如当前轮次窗口为4，那么传输完4个TCP报文后，开始下一轮。\n","date":"2022-07-18T00:04:43+08:00","permalink":"https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/tcp%E5%8D%8F%E8%AE%AE/","title":"TCP协议"},{"content":"数据链路层 [计算机网络 - 链路层 | CS-Notes (cyc2018.xyz)](http://www.cyc2018.xyz/计算机基础/网络基础/计算机网络 - 链路层.html)\n网络层和数据链路层的关系 IP 的作用是主机之间通信用的，而 MAC 的作用则是实现「直连」的两个设备之间通信，而 IP 则负责在「没有直连」的两个网络之间进行通信传输。\nIP地址分类 D类地址用于组播（多播用于将包发送给特定组内的所有主机。）、E类地址为保留用\n主机个数 每类地址的最大主机个数要看主机号的位数，例如C类地址的主机号占8位，那么C类地址的最大主机个数位：\n为什么要减2呢？因为在 IP 地址中，有两个 IP 是特殊的，分别是主机号全为 1 和 全为 0 地址。\n广播地址可以分为本地广播和直接广播两种。\n 在本网络内广播的叫做本地广播。例如网络地址为 192.168.0.0/24 的情况下，广播地址是 192.168.0.255 。因为这个广播地址的 IP 包会被路由器屏蔽，所以不会到达 192.168.0.0/24 以外的其他链路上。 在不同网络之间的广播叫做直接广播。例如网络地址为 192.168.0.0/24 的主机向 192.168.1.255/24 的目标地址发送 IP 包。收到这个包的路由器，将数据转发给 192.168.1.0/24，从而使得所有192.168.1.1~192.168.1.254 的主机都能收到这个包（由于直接广播有⼀定的安全问题，多数情况下会在路由器上设置为不转发）。  IP分类的优缺点 优点  不管是路由器还是主机解析到⼀个 IP 地址时候，我们判断其 IP 地址的首位是否为 0，为 0 则为 A 类地址，那么就能很快的找出网络地址和主机地址。优点就是简单明了、选路（基于网络地址）简单。  缺点   同⼀网络下没有地址层次，比如⼀个公司⾥用了 B 类地址，但是可能需要根据⽣产环境、测试环境、开发环境来划分地址层次，而这种 IP 分类是没有地址层次划分的功能，所以这就缺少地址的灵活性。\n  A、B、C类有个尴尬处境，就是不能很好的与现实网络匹配。C 类地址能包含的最大主机数量实在太少了，只有 254 个，估计⼀个网吧都不够用。而 B 类地址能包含的最大主机数量⼜太多了，6 万多台机器放在⼀个网络下面，⼀般的企业基本达不到这个规模，闲着的地址就是浪费。这两个缺点，都可以在 CIDR ⽆分类地址解决。\n  无分类地址 CIDR ⼦网掩码，掩码的意思就是掩盖掉主机号，剩余的就是网络号。将⼦网掩码和 IP 地址按位计算 AND，就可得到网络号。\n子网划分：从主机号中借几位作为子网号，同时搭配对应的子网掩码。\nIP地址与路由控制 IP地址的网络地址这⼀部分是用于进行路由控制。\n路由控制表中记录着网络地址与下⼀步应该发送至路由器的地址。在主机和路由器上都会有各自的路由器控制表。\n在发送 IP 包时，首先要确定 IP 包首部中的目标地址，再从路由控制表中找到与该地址具有相同网络地址的记录，根据该记录将 IP 包转发给相应的下⼀个路由器。如果路由控制表中存在多条相同网络地址的记录，就选择相同位数最多的网络地址，也就是最长匹配。\n下面以下图的网络链路作为例⼦说明\n环回地址 环回地址是在同⼀台计算机上的程序之间进行网络通信时所使用的⼀个默认地址。计算机使用⼀个特殊的 IP 地址 127.0.0.1 作为环回地址。与该地址具有相同意义的是⼀个叫做 localhost 的主机名。使用这个 IP 或主机名时，数据包不会流向网络。\nIP分片与重组 每种数据链路的最大传输单元 MTU 都是不相同的，如 FDDI 数据链路 MTU 4352、以太网的 MTU 是 1500 字节等。\n每种数据链路的 MTU 之所以不同，是因为每个不同类型的数据链路的使用目的不同。使用目的不同，可承载的MTU 也就不同。\n其中，我们最常见数据链路是以太网，它的 MTU 是 1500 字节。\n那么当 IP 数据包大小大于 MTU 时， IP 数据包就会被分片。\n经过分片之后的 IP 数据报在被重组的时候，只能由目标主机进行，路由器是不会进行重组的。\n假设发送⽅发送⼀个 4000 字节的大数据报，若要传输在以太网链路，则需要把数据报分片成 3 个小数据报进行传输，再交由接收⽅重组成大数据报。\nIPV6 IPv4 地址长度共 32 位，是以每 8 位作为⼀组，并用点分⼗进制的表示⽅式。\nIPv6 地址长度是 128 位，是以每 16 位作为⼀组，每组用冒号 「:」 隔开。\nIPv6 相比 IPv4 的首部改进：\n 取消了首部校验和字段。 因为在数据链路层和传输层都会校验，因此 IPv6 直接取消了 IP 的校验。 取消了分片/重新组装相关字段。 分片与重组是耗时的过程，IPv6 不允许在中间路由器进行分片与重组，这种操作只能在源与目标主机，这将大大提⾼了路由器转发的速度。 取消选项字段。 选项字段不再是标准 IP 首部的⼀部分了，但它并没有消失，而是可能出现在 IPv6 首部中的「下⼀个首部」指出的位置上。删除该选项字段使的 IPv6 的首部成为固定长度的 40 字节。  IP协议相关技术 DNS 根域是在最顶层，它的下⼀层就是 com 顶级域，再下面是 server.com。\n所以域名的层级关系类似⼀个树状结构：\n 根 DNS 服务器 顶级域 DNS 服务器（com） 权威 DNS 服务器（server.com）  ARP 在传输⼀个 IP 数据报的时候，确定了源 IP 地址和目标 IP 地址后，就会通过主机「路由表」确定 IP 数据包下⼀跳。然而，网络层的下⼀层是数据链路层，所以我们还要知道「下⼀跳」的 MAC 地址。\n由于主机的路由表中可以找到下⼀跳的 IP 地址，所以可以通过 ARP 协议，求得下⼀跳的 MAC 地址。\n那么 ARP ⼜是如何知道对⽅ MAC 地址的呢？\n简单地说，ARP 是借助 ARP 请求与 ARP 响应两种类型的包确定 MAC 地址的。\n 主机会通过广播发送 ARP 请求，这个包中包含了想要知道的 MAC 地址的主机 IP 地址。 当同个链路中的所有设备收到 ARP 请求时，会去拆开 ARP 请求包⾥的内容，如果 ARP 请求包中的目标 IP地址与自己的 IP 地址⼀致，那么这个设备就将自己的 MAC 地址塞入 ARP 响应包返回给主机。  操作系统通常会把第⼀次通过 ARP 获取的 MAC 地址缓存起来，以便下次直接从缓存中找到对应 IP 地址的 MAC地址。不过，MAC 地址的缓存是有⼀定期限的，超过这个期限，缓存的内容将被清除。\nRARP ARP 协议是已知 IP 地址求 MAC 地址，那 RARP 协议正好相反，它是已知 MAC 地址求 IP 地址。例如将打印机服务器等小型嵌入式设备接入到网络时就经常会用得到。\n通常这需要架设⼀台 RARP 服务器，在这个服务器上注册设备的 MAC 地址及其 IP 地址。然后再将这个设备接入到网络，接着：\n 该设备会发送⼀条「我的 MAC 地址是XXXX，请告诉我，我的IP地址应该是什么」的请求信息。 RARP 服务器接到这个消息后返回「MAC地址为 XXXX 的设备，IP地址为 XXXX」的信息给这个设备。 最后，设备就根据从 RARP 服务器所收到的应答信息设置自己的 IP 地址。  DHCP DHCP 在⽣活中我们是很常见的了，我们的电脑通常都是通过 DHCP 动态获取 IP 地址，大大省去了配 IP 信息繁琐的过程\nDHCP 交互中，全程都是使用 UDP 广播通信 。\n先说明⼀点，DHCP 客户端进程监听的是 68 端口号，DHCP 服务端进程监听的是 67 端口号。\n这 4 个步骤：\n 客户端首先发起 DHCP 发现报文（DHCP DISCOVER） 的 IP 数据报，由于客户端没有 IP 地址，也不知道DHCP 服务器的地址，所以使用的是 UDP 广播通信，其使用的广播目的地址是 255.255.255.255（端口67） 并且使用 0.0.0.0（端口 68） 作为源 IP 地址。DHCP 客户端将该 IP 数据报传递给链路层，链路层然后将帧广播到所有的网络中设备。 DHCP 服务器收到 DHCP 发现报文时，用 DHCP 提供报文（DHCP OFFER） 向客户端做出响应。该报文仍然使用 IP 广播地址 255.255.255.255，该报文信息携带服务器提供可租约的 IP 地址、⼦网掩码、默认网关、DNS 服务器以及 IP 地址租用期。 客户端收到⼀个或多个服务器的 DHCP 提供报文后，从中选择⼀个服务器，并向选中的服务器发送 DHCP 请求报文（DHCP REQUEST进行响应，回显配置的参数。 最后，服务端用 DHCP ACK 报文对 DHCP 请求报文进行响应，应答所要求的参数。  ⼀旦客户端收到 DHCP ACK 后，交互便完成了，并且客户端能够在租用期内使用 DHCP 服务器分配的 IP 地址。如果租约的 DHCP IP 地址快期后，客户端会向服务器发送 DHCP 请求报文：\n 服务器如果同意继续租用，则用 DHCP ACK 报文进行应答，客户端就会延长租期。 服务器如果不同意继续租用，则用 DHCP NACK 报文，客户端就要停⽌使用租约的 IP 地址。  NAT IPv4 的地址是非常紧缺的，在前面我们也提到可以通过⽆分类地址来减缓 IPv4 地址耗尽的速度，但是互联网的用户增速是非常惊⼈的，所以 IPv4 地址依然有被耗尽的危险。于是，提出了⼀种网络地址转换 NAT 的⽅法，再次缓解了 IPv4 地址耗尽的问题。\n简单的来说 NAT 就是同个公司、家庭、教室内的主机对外部通信时，把私有 IP 地址转换成公有 IP 地址。\n那不是 N 个私有 IP 地址，你就要 N 个公有 IP 地址？这怎么就缓解了 IPv4 地址耗尽的问题？\n由于绝大多数的网络应用都是使用传输层协议 TCP 或 UDP 来传输数据的。因此，可以把 IP 地址 + 端口号⼀起进行转换。这样，就用⼀个全球 IP 地址就可以了，这种转换技术就叫网络地址与端口转换 NAPT。\n图中有两个客户端 192.168.1.10 和 192.168.1.11 同时与服务器 183.232.231.172 进行通信，并且这两个客户端的本地端口都是 1025。\n此时，两个私有 IP 地址都转换 IP 地址为公有地址 120.229.175.121，但是以不同的端口号作为区分。\n于是，⽣成⼀个 NAPT 路由器的转换表，就可以正确地转换地址跟端口的组合，令客户端 A、B 能同时与服务器之间进行通信。\n这种转换表在 NAT 路由器上自动⽣成。例如，在 TCP 的情况下，建⽴ TCP 连接首次握⼿时的 SYN 包⼀经发出，就会⽣成这个表。而后⼜随着收到关闭连接时发出 FIN 包的确认应答从表中被删除。\nNAT 的缺点 由于 NAT/NAPT 都依赖于自己的转换表，因此会有以下的问题：\n 外部⽆法主动与 NAT 内部服务器建⽴连接，因为 NAPT 转换表没有转换记录。 转换表的⽣成与转换操作都会产⽣性能开销。 通信过程中，如果 NAT 路由器重启了，所有的 TCP 连接都将被重置。  解决  改用IPV6，每台机器一个公网IP NAT穿透技术： 客户端主动从 NAT 设备获取公有 IP 地址，然后自己建⽴端口映射条目，然后用这个条目对外通信，就不需要 NAT 设备来进行转换了  ICMP ICMP 全称是 Internet Control Message Protocol，也就是互联网控制报文协议。\nICMP 主要的功能包括：确认 IP 包是否成功送达目标地址、报告发送过程中 IP 包被废弃的原因和改善网络设置等。\n在 IP 通信中如果某个 IP 包因为某种原因未能达到目标地址，那么这个具体的原因将由 ICMP 负责通知。\nPing工作原理 traceroute命令 有⼀款充分利用 ICMP 差错报文类型的应用叫做 traceroute （在UNIX、MacOS中是这个命令，而在Windows中对等的命令叫做 tracert ）\n作用 traceroute 的第⼀个作用就是故意设置特殊的 TTL，来追踪去往目的地时沿途经过的路由器。\ntraceroute 的参数指向某个目的 IP 地址：\n1  traceout 192.168.1.100   原理 它的原理就是利用 IP 包的⽣存期限 从 1 开始按照顺序递增的同时发送 UDP 包，强制接收 ICMP 超时消息的⼀种⽅法。\n比如，将 TTL 设置 为 1 ，则遇到第⼀个路由器，就牺牲了，接着返回 ICMP 差错报文网络包，类型是时间超时。\n接下来将 TTL 设置为 2 ，第⼀个路由器过了，遇到第⼆个路由器也牺牲了，也同时返回了 ICMP 差错报文数据包，如此往复，直到到达目的主机。\n这样的过程，traceroute 就可以拿到了所有的路由器 IP。当然有的路由器根本就不会返回这个 ICMP，所以对于有的公网地址，是看不到中间经过的路由的。\n发送⽅如何知道发出的 UDP 包是否到达了目的主机呢？\ntraceroute 在发送 UDP 包时，会填入⼀个不可能的端口号值作为 UDP 目标端口号（大于 3000 ）。当目的主机，收到 UDP 包后，会返回 ICMP 差错报文消息，但这个差错报文消息的类型是「端口不可达」。所以，当差错报文类型是端口不可达时，说明发送⽅发出的 UDP 包到达了目的主机。\n","date":"2022-07-18T00:04:34+08:00","permalink":"https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/ip%E5%8D%8F%E8%AE%AE/","title":"IP协议"},{"content":"类加载过程 生命周期 类是在运行期间第一次使用时动态加载的（不使用不加载），而不是一次性加载所有类，因为一次性加载会占用很多的内存，加载的类信息存放于一块成为方法区的内存空间\n包括 7 个阶段：\n 加载（Loading） 链接：验证（Verification）、准备（Preparation）、解析（Resolution） 初始化（Initialization） 使用（Using） 卸载（Unloading）  加载阶段 加载是类加载的其中一个阶段，注意不要混淆\n加载过程完成以下三件事：\n 通过类的完全限定名称获取定义该类的二进制字节流（二进制字节码） 将该字节流表示的静态存储结构转换为方法区的运行时存储结构（Java 类模型） 在内存中生成一个代表该类的 Class 对象，作为该类在方法区中的各种数据的访问入口  其中二进制字节流可以从以下方式中获取：\n 从 ZIP 包读取，成为 JAR、EAR、WAR 格式的基础 从网络中获取，最典型的应用是 Applet 由其他文件生成，例如由 JSP 文件生成对应的 Class 类 运行时计算生成，例如动态代理技术，在 java.lang.reflect.Proxy 使用 ProxyGenerator.generateProxyClass 生成字节码  将字节码文件加载至方法区后，会在堆中创建一个 java.lang.Class 对象，用来引用位于方法区内的数据结构，该 Class 对象是在加载类的过程中创建的，每个类都对应有一个 Class 类型的对象\n方法区内部采用 C++ 的 instanceKlass 描述 Java 类的数据结构：\n _java_mirror 即 Java 的类镜像，例如对 String 来说就是 String.class，作用是把 class 暴露给 Java 使用 _super 即父类、_fields 即成员变量、_methods 即方法、_constants 即常量池、_class_loader 即类加载器、_vtable 虚方法表、_itable 接口方法表  加载过程：\n 如果这个类还有父类没有加载，先加载父类 加载和链接可能是交替运行的 Class 对象和 _java_mirror 相互持有对方的地址，堆中对象通过 instanceKlass 和元空间进行交互  创建数组类有些特殊，因为数组类本身并不是由类加载器负责创建，而是由 JVM 在运行时根据需要而直接创建的，但数组的元素类型仍然需要依靠类加载器去创建，创建数组类的过程：\n 如果数组的元素类型是引用类型，那么遵循定义的加载过程递归加载和创建数组的元素类型 JVM 使用指定的元素类型和数组维度来创建新的数组类 基本数据类型由启动类加载器加载  链接阶段 验证 确保 Class 文件的字节流中包含的信息是否符合 JVM 规范，保证被加载类的正确性，不会危害虚拟机自身的安全\n主要包括四种验证：\n  文件格式验证\n  语义检查，但凡在语义上不符合规范的，虚拟机不会给予验证通过\n  是否所有的类都有父类的存在（除了 Object 外，其他类都应该有父类）\n  是否一些被定义为 final 的方法或者类被重写或继承了\n  非抽象类是否实现了所有抽象方法或者接口方法\n  是否存在不兼容的方法\n    字节码验证，试图通过对字节码流的分析，判断字节码是否可以被正确地执行\n 在字节码的执行过程中，是否会跳转到一条不存在的指令 函数的调用是否传递了正确类型的参数 变量的赋值是不是给了正确的数据类型 栈映射帧（StackMapTable）在这个阶段用于检测在特定的字节码处，其局部变量表和操作数栈是否有着正确的数据类型    符号引用验证，Class 文件在其常量池会通过字符串记录将要使用的其他类或者方法\n  准备 准备阶段为静态变量（类变量）分配内存并设置初始值，使用的是方法区的内存：\n说明：实例变量不会在这阶段分配内存，它会在对象实例化时随着对象一起被分配在堆中，类加载发生在所有实例化操作之前，并且类加载只进行一次，实例化可以进行多次\n类变量初始化：\n static 变量分配空间和赋值是两个步骤：分配空间在准备阶段完成，赋值在初始化阶段完成 如果 static 变量是 final 的基本类型以及字符串常量，那么编译阶段值（方法区）就确定了，准备阶段会显式初始化 如果 static 变量是 final 的，但属于引用类型或者构造器方法的字符串，赋值在初始化阶段完成  实例：\n  初始值一般为 0 值，例如下面的类变量 value 被初始化为 0 而不是 123：\n1  public static int value = 123;     常量 value 被初始化为 123 而不是 0：\n1  public static final int value = 123;     Java 并不支持 boolean 类型，对于 boolean 类型，内部实现是 int，由于 int 的默认值是0，故 boolean 的默认值就是 false\n  解析 将常量池中类、接口、字段、方法的符号引用替换为直接引用（内存地址）的过程：\n 符号引用：一组符号来描述目标，可以是任何字面量，属于编译原理方面的概念，如：包括类和接口的全限名、字段的名称和描述符、方法的名称和方法描述符（因为类还没有加载完，很多方法是找不到的） 直接引用：直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄，如果有了直接引用，那说明引用的目标必定已经存在于内存之中  例如：在 com.demo.Solution 类中引用了 com.test.Quest，把 com.test.Quest 作为符号引用存进类常量池，在类加载完后，用这个符号引用去方法区找这个类的内存地址\n解析动作主要针对类或接口、字段、类方法、接口方法、方法类型等\n 在类加载阶段解析的是非虚方法，静态绑定 也可以在初始化阶段之后再开始解析，这是为了支持 Java 的动态绑定 通过解析操作，符号引用就可以转变为目标方法在类的虚方法表中的位置，从而使得方法被成功调用  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  public class Load2 { public static void main(String[] args) throws Exception{ ClassLoader classloader = Load2.class.getClassLoader(); // cloadClass 加载类方法不会导致类的解析和初始化，也不会加载D  Class\u0026lt;?\u0026gt; c = classloader.loadClass(\u0026#34;cn.jvm.t3.load.C\u0026#34;); // new C();会导致类的解析和初始化，从而解析初始化D  System.in.read(); } } class C { D d = new D(); } class D { }   初始化 介绍 初始化阶段才真正开始执行类中定义的 Java 程序代码，在准备阶段，类变量已经赋过一次系统要求的初始值；在初始化阶段，通过程序制定的计划去初始化类变量和其它资源，执行 在编译生成 class 文件时，编译器会产生两个方法加于 class 文件中，一个是类的初始化方法 clinit，另一个是实例的初始化方法 init\n类构造器 () 与实例构造器 () 不同，它不需要程序员进行显式调用，在一个类的生命周期中，类构造器最多被虚拟机调用一次，而实例构造器则会被虚拟机调用多次，只要程序员创建对象\n类在第一次实例化加载一次，把 class 读入内存，后续实例化不再加载，引用第一次加载的类\nclinit ()：类构造器，由编译器自动收集类中所有类变量的赋值动作和静态语句块中的语句合并产生的\n作用：是在类加载过程中的初始化阶段进行静态变量初始化和执行静态代码块\n 如果类中没有静态变量或静态代码块，那么 clinit 方法将不会被生成 clinit 方法只执行一次，在执行 clinit 方法时，必须先执行父类的clinit方法 static 变量的赋值操作和静态代码块的合并顺序由源文件中出现的顺序决定 static 不加 final 的变量都在初始化环节赋值  线程安全问题：\n 虚拟机会保证一个类的 () 方法在多线程环境下被正确的加锁和同步，如果多个线程同时初始化一个类，只会有一个线程执行这个类的 () 方法，其它线程都阻塞等待，直到活动线程执行 () 方法完毕 如果在一个类的 () 方法中有耗时的操作，就可能造成多个线程阻塞，在实际过程中此种阻塞很隐蔽  特别注意：静态语句块只能访问到定义在它之前的类变量，定义在它之后的类变量只能赋值，不能访问\n1 2 3 4 5 6 7  public class Test { static { //i = 0; // 给变量赋值可以正常编译通过  System.out.print(i); // 这句编译器会提示“非法向前引用”  } static int i = 1; }   接口中不可以使用静态语句块，但仍然有类变量初始化的赋值操作，因此接口与类一样都会生成 () 方法，两者不同的是：\n 在初始化一个接口时，并不会先初始化它的父接口，所以执行接口的 () 方法不需要先执行父接口的 () 方法 在初始化一个类时，不会先初始化所实现的接口，所以接口的实现类在初始化时不会执行接口的 () 方法 只有当父接口中定义的变量使用时，父接口才会初始化  时机 类的初始化是懒惰的，只有在首次使用时才会被装载，JVM 不会无条件地装载 Class 类型，Java 虚拟机规定，一个类或接口在初次使用前，必须要进行初始化\n主动引用：虚拟机规范中并没有强制约束何时进行加载，但是规范严格规定了有且只有下列情况必须对类进行初始化（加载、验证、准备都会发生）：\n 当创建一个类的实例时，使用 new 关键字，或者通过反射、克隆、反序列化（前文讲述的对象的创建时机） 当调用类的静态方法或访问静态字段时，遇到 getstatic、putstatic、invokestatic 这三条字节码指令，如果类没有进行过初始化，则必须先触发其初始化  getstatic：程序访问类的静态变量（不是静态常量，常量会被加载到运行时常量池） putstatic：程序给类的静态变量赋值 invokestatic ：调用一个类的静态方法   使用 java.lang.reflect 包的方法对类进行反射调用时，如果类没有进行初始化，则需要先触发其初始化 当初始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化，但这条规则并不适用于接口 当虚拟机启动时，需要指定一个要执行的主类（包含 main() 方法的那个类），虚拟机会先初始化这个主类 MethodHandle 和 VarHandle 可以看作是轻量级的反射调用机制，而要想使用这两个调用， 就必须先使用 findStaticVarHandle 来初始化要调用的类 补充：当一个接口中定义了 JDK8 新加入的默认方法（被 default 关键字修饰的接口方法）时，如果有这个接口的实现类发生了初始化，那该接口要在其之前被初始化  被动引用：所有引用类的方式都不会触发初始化，称为被动引用\n 通过子类引用父类的静态字段，不会导致子类初始化，只会触发父类的初始化 通过数组定义来引用类，不会触发此类的初始化。该过程会对数组类进行初始化，数组类是一个由虚拟机自动生成的、直接继承自 Object 的子类，其中包含了数组的属性和方法 常量（final 修饰）在编译阶段会存入调用类的常量池中，本质上没有直接引用到定义常量的类，因此不会触发定义常量的类的初始化 调用 ClassLoader 类的 loadClass() 方法加载一个类，并不是对类的主动使用，不会导致类的初始化  init init 指的是实例构造器，主要作用是在类实例化过程中执行，执行内容包括成员变量初始化和代码块的执行\n实例化即调用 ()V ，虚拟机会保证这个类的构造方法的线程安全，先为实例变量分配内存空间，再执行赋默认值，然后根据源码中的顺序执行赋初值或代码块，没有成员变量初始化和代码块则不会执行\n类实例化过程：父类的类构造器() -\u0026gt; 子类的类构造器() -\u0026gt; 父类的成员变量和实例代码块 -\u0026gt; 父类的构造函数 -\u0026gt; 子类的成员变量和实例代码块 -\u0026gt; 子类的构造函数\nnew 关键字会创建对象并复制 dup 一个对象引用，一个调用 方法，另一个用来赋值给接收者\n卸载阶段 时机：执行了 System.exit() 方法，程序正常执行结束，程序在执行过程中遇到了异常或错误而异常终止，由于操作系统出现错误而导致Java虚拟机进程终止\n卸载类即该类的 Class 对象被 GC，卸载类需要满足3个要求:\n 该类的所有的实例对象都已被 GC，也就是说堆不存在该类的实例对象 该类没有在其他任何地方被引用 该类的类加载器的实例已被 GC，一般是可替换类加载器的场景，如 OSGi、JSP 的重加载等，很难达成  在 JVM 生命周期类，由 JVM 自带的类加载器加载的类是不会被卸载的，自定义的类加载器加载的类是可能被卸载。因为 JVM 会始终引用启动、扩展、系统类加载器，这些类加载器始终引用它们所加载的类，这些类始终是可及的\n类加载器 类加载 类加载方式：\n 隐式加载：不直接在代码中调用 ClassLoader 的方法加载类对象  创建类对象、使用类的静态域、创建子类对象、使用子类的静态域 在 JVM 启动时，通过三大类加载器加载 class   显式加载：  ClassLoader.loadClass(className)：只加载和连接，不会进行初始化 Class.forName(String name, boolean initialize, ClassLoader loader)：使用 loader 进行加载和连接，根据参数 initialize 决定是否初始化    类的唯一性：\n 在 JVM 中表示两个 class 对象判断为同一个类存在的两个必要条件：  类的完整类名必须一致，包括包名 加载这个类的 ClassLoader（指 ClassLoader 实例对象）必须相同   这里的相等，包括类的 Class 对象的 equals() 方法、isAssignableFrom() 方法、isInstance() 方法的返回结果为 true，也包括使用 instanceof 关键字做对象所属关系判定结果为 true  命名空间：\n 每个类加载器都有自己的命名空间，命名空间由该加载器及所有的父加载器所加载的类组成 在同一命名空间中，不会出现类的完整名字（包括类的包名）相同的两个类  基本特征：\n 可见性，子类加载器可以访问父加载器加载的类型，但是反过来是不允许的 单一性，由于父加载器的类型对于子加载器是可见的，所以父加载器中加载过的类型，不会在子加载器中重复加载  加载器 类加载器是 Java 的核心组件，用于加载字节码到 JVM 内存，得到 Class 类的对象\n从 Java 虚拟机规范来讲，只存在以下两种不同的类加载器：\n 启动类加载器（Bootstrap ClassLoader）：使用 C++ 实现，是虚拟机自身的一部分 自定义类加载器（User-Defined ClassLoader）：Java 虚拟机规范将所有派生于抽象类 ClassLoader 的类加载器都划分为自定义类加载器，使用 Java 语言实现，独立于虚拟机  从 Java 开发人员的角度看：\n 启动类加载器（Bootstrap ClassLoader）：  处于安全考虑，Bootstrap 启动类加载器只加载包名为 java、javax、sun 等开头的类 类加载器负责加载在 JAVA_HOME/jre/lib 或 sun.boot.class.path 目录中的，或者被 -Xbootclasspath 参数所指定的路径中的类，并且是虚拟机识别的类库加载到虚拟机内存中 仅按照文件名识别，如 rt.jar 名字不符合的类库即使放在 lib 目录中也不会被加载 启动类加载器无法被 Java 程序直接引用，编写自定义类加载器时，如果要把加载请求委派给启动类加载器，直接使用 null 代替   扩展类加载器（Extension ClassLoader）：  由 ExtClassLoader (sun.misc.Launcher$ExtClassLoader) 实现，上级为 Bootstrap，显示为 null 将 JAVA_HOME/jre/lib/ext 或者被 java.ext.dir 系统变量所指定路径中的所有类库加载到内存中 开发者可以使用扩展类加载器，创建的 JAR 放在此目录下，会由扩展类加载器自动加载   应用程序类加载器（Application ClassLoader）：  由 AppClassLoader(sun.misc.Launcher$AppClassLoader) 实现，上级为 Extension 负责加载环境变量 classpath 或系统属性 java.class.path 指定路径下的类库 这个类加载器是 ClassLoader 中的 getSystemClassLoader() 方法的返回值，因此称为系统类加载器 可以直接使用这个类加载器，如果应用程序中没有自定义类加载器，这个就是程序中默认的类加载器   自定义类加载器：由开发人员自定义的类加载器，上级是 Application  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  public static void main(String[] args) { //获取系统类加载器  ClassLoader systemClassLoader = ClassLoader.getSystemClassLoader(); System.out.println(systemClassLoader);//sun.misc.Launcher$AppClassLoader@18b4aac2  //获取其上层 扩展类加载器  ClassLoader extClassLoader = systemClassLoader.getParent(); System.out.println(extClassLoader);//sun.misc.Launcher$ExtClassLoader@610455d6  //获取其上层 获取不到引导类加载器  ClassLoader bootStrapClassLoader = extClassLoader.getParent(); System.out.println(bootStrapClassLoader);//null  //对于用户自定义类来说：使用系统类加载器进行加载  ClassLoader classLoader = ClassLoaderTest.class.getClassLoader(); System.out.println(classLoader);//sun.misc.Launcher$AppClassLoader@18b4aac2  //String 类使用引导类加载器进行加载的 --\u0026gt; java核心类库都是使用启动类加载器加载的  ClassLoader classLoader1 = String.class.getClassLoader(); System.out.println(classLoader1);//null  }   补充两个类加载器：\n SecureClassLoader 扩展了 ClassLoader，新增了几个与使用相关的代码源和权限定义类验证（对 class 源码的访问权限）的方法，一般不会直接跟这个类打交道，更多是与它的子类 URLClassLoader 有所关联 ClassLoader 是一个抽象类，很多方法是空的没有实现，而 URLClassLoader 这个实现类为这些方法提供了具体的实现，并新增了 URLClassPath 类协助取得 Class 字节流等功能。在编写自定义类加载器时，如果没有太过于复杂的需求，可以直接继承 URLClassLoader 类，这样就可以避免去编写 findClass() 方法及其获取字节码流的方式，使自定义类加载器编写更加简洁  常用API ClassLoader 类，是一个抽象类，其后所有的类加载器都继承自 ClassLoader（不包括启动类加载器）\n获取 ClassLoader 的途径：\n 获取当前类的 ClassLoader：clazz.getClassLoader() 获取当前线程上下文的 ClassLoader：Thread.currentThread.getContextClassLoader() 获取系统的 ClassLoader：ClassLoader.getSystemClassLoader() 获取调用者的 ClassLoader：DriverManager.getCallerClassLoader()  ClassLoader 类常用方法：\n getParent()：返回该类加载器的超类加载器 loadclass(String name)：加载名为 name 的类，返回结果为 Class 类的实例，该方法就是双亲委派模式 findclass(String name)：查找二进制名称为 name 的类，返回结果为 Class 类的实例，该方法会在检查完父类加载器之后被 loadClass() 方法调用 findLoadedClass(String name)：查找名称为 name 的已经被加载过的类，final 修饰无法重写 defineClass(String name, byte[] b, int off, int len)：将字节流解析成 JVM 能够识别的类对象 resolveclass(Class\u0026lt;?\u0026gt; c)：链接指定的 Java 类，可以使类的 Class 对象创建完成的同时也被解析 InputStream getResourceAsStream(String name)：指定资源名称获取输入流  加载模型 加载机制 在 JVM 中，对于类加载模型提供了三种，分别为全盘加载、双亲委派、缓存机制\n  全盘加载： 当一个类加载器负责加载某个 Class 时，该 Class 所依赖和引用的其他 Class 也将由该类加载器负责载入，除非显示指定使用另外一个类加载器来载入\n  双亲委派： 先让父类加载器加载该 Class，在父类加载器无法加载该类时才尝试从自己的类路径中加载该类。简单来说就是，某个特定的类加载器在接到加载类的请求时，首先将加载任务委托给父加载器，依次递归，如果父加载器可以完成类加载任务，就成功返回；只有当父加载器无法完成此加载任务时，才自己去加载\n  缓存机制： 会保证所有加载过的 Class 都会被缓存，当程序中需要使用某个 Class 时，类加载器先从缓存区中搜寻该 Class，只有当缓存区中不存在该 Class 对象时，系统才会读取该类对应的二进制数据，并将其转换成 Class 对象存入缓冲区（方法区）中\n 这就是修改了 Class 后，必须重新启动 JVM，程序所做的修改才会生效的原因    双亲委派 双亲委派模型（Parents Delegation Model）：该模型要求除了顶层的启动类加载器外，其它类加载器都要有父类加载器，这里的父子关系一般通过组合关系（Composition）来实现，而不是继承关系（Inheritance）\n工作过程：一个类加载器首先将类加载请求转发到父类加载器，只有当父类加载器无法完成时才尝试自己加载\n双亲委派机制的优点：\n  可以避免某一个类被重复加载，当父类已经加载后则无需重复加载，保证全局唯一性\n  Java 类随着它的类加载器一起具有一种带有优先级的层次关系，从而使得基础类得到统一\n  保护程序安全，防止类库的核心 API 被随意篡改\n例如：在工程中新建 java.lang 包，接着在该包下新建 String 类，并定义 main 函数\n1 2 3 4 5  public class String { public static void main(String[] args) { System.out.println(\u0026#34;demo info\u0026#34;); } }   此时执行 main 函数，会出现异常，在类 java.lang.String 中找不到 main 方法，防止恶意篡改核心 API 库。出现该信息是因为双亲委派的机制，java.lang.String 的在启动类加载器（Bootstrap）得到加载，启动类加载器优先级更高，在核心 jre 库中有其相同名字的类文件，但该类中并没有 main 方法\n  双亲委派机制的缺点：检查类是否加载的委托过程是单向的，这个方式虽然从结构上看比较清晰，使各个 ClassLoader 的职责非常明确，但顶层的 ClassLoader 无法访问底层的 ClassLoader 所加载的类（可见性）\n源码分析 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  protected Class\u0026lt;?\u0026gt; loadClass(String name, boolean resolve) throws ClassNotFoundException { synchronized (getClassLoadingLock(name)) { // 调用当前类加载器的 findLoadedClass(name)，检查当前类加载器是否已加载过指定 name 的类  Class c = findLoadedClass(name); // 当前类加载器如果没有加载过  if (c == null) { long t0 = System.nanoTime(); try { // 判断当前类加载器是否有父类加载器  if (parent != null) { // 如果当前类加载器有父类加载器，则调用父类加载器的 loadClass(name,false)  // 父类加载器的 loadClass 方法，又会检查自己是否已经加载过  c = parent.loadClass(name, false); } else { // 当前类加载器没有父类加载器，说明当前类加载器是 BootStrapClassLoader  // 则调用 BootStrap ClassLoader 的方法加载类  c = findBootstrapClassOrNull(name); } } catch (ClassNotFoundException e) { } if (c == null) { // 如果调用父类的类加载器无法对类进行加载，则用自己的 findClass() 方法进行加载  // 可以自定义 findClass() 方法  long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats  sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); } } if (resolve) { // 链接指定的 Java 类，可以使类的 Class 对象创建完成的同时也被解析  resolveClass(c); } return c; } }   破坏委派 双亲委派模型并不是一个具有强制性约束的模型，而是 Java 设计者推荐给开发者的类加载器实现方式\n破坏双亲委派模型的方式：\n  自定义 ClassLoader\n 如果不想破坏双亲委派模型，只需要重写 findClass 方法 如果想要去破坏双亲委派模型，需要去**重写 loadClass **方法    引入线程上下文类加载器\nJava 提供了很多服务提供者接口（Service Provider Interface，SPI），允许第三方为这些接口提供实现。常见的 SPI 有 JDBC、JCE、JNDI 等。这些 SPI 接口由 Java 核心库来提供，而 SPI 的实现代码则是作为 Java 应用所依赖的 jar 包被包含进类路径 classpath 里，SPI 接口中的代码需要加载具体的实现类：\n SPI 的接口是 Java 核心库的一部分，是由引导类加载器来加载的 SPI 的实现类是由系统类加载器加载，引导类加载器是无法找到 SPI 的实现类，因为双亲委派模型中 BootstrapClassloader 无法委派 AppClassLoader 来加载类  JDK 开发人员引入了线程上下文类加载器（Thread Context ClassLoader），这种类加载器可以通过 Thread 类的 setContextClassLoader 方法进行设置线程上下文类加载器，在执行线程中抛弃双亲委派加载模式，使程序可以逆向使用类加载器，使 Bootstrap 加载器拿到了 Application 加载器加载的类，破坏了双亲委派模型\n  实现程序的动态性，如代码热替换（Hot Swap）、模块热部署（Hot Deployment）\nIBM 公司主导的 JSR一291（OSGiR4.2）实现模块化热部署的关键是它自定义的类加载器机制的实现，每一个程序模块（OSGi 中称为 Bundle）都有一个自己的类加载器，当更换一个 Bundle 时，就把 Bundle 连同类加载器一起换掉以实现代码的热替换，在 OSGi 环境下，类加载器不再双亲委派模型推荐的树状结构，而是进一步发展为更加复杂的网状结构\n当收到类加载请求时，OSGi 将按照下面的顺序进行类搜索:\n 将以 java.* 开头的类，委派给父类加载器加载 否则，将委派列表名单内的类，委派给父类加载器加载 否则，将 Import 列表中的类，委派给 Export 这个类的 Bundle 的类加载器加载 否则，查找当前 Bundle 的 ClassPath，使用自己的类加载器加载 否则，查找类是否在自己的 Fragment Bundle 中，如果在就委派给 Fragment Bundle 类加载器加载 否则，查找 Dynamic Import 列表的 Bundle，委派给对应 Bundle 的类加载器加载 否则，类查找失败  热替换是指在程序的运行过程中，不停止服务，只通过替换程序文件来修改程序的行为，热替换的关键需求在于服务不能中断，修改必须立即表现正在运行的系统之中\n  对象创建 生命周期 在 Java 中，对象的生命周期包括以下几个阶段：\n   创建阶段 (Created)：\r    应用阶段 (In Use)：对象至少被一个强引用持有着\r    不可见阶段 (Invisible)：程序的执行已经超出了该对象的作用域，不再持有该对象的任何强引用\r    不可达阶段 (Unreachable)：该对象不再被任何强引用所持有，包括 GC Root 的强引用\r    收集阶段 (Collected)：垃圾回收器对该对象的内存空间重新分配做好准备，该对象如果重写了 finalize() 方法，则会去执行该方法\r    终结阶段 (Finalized)：等待垃圾回收器对该对象空间进行回收，当对象执行完 finalize() 方法后仍然处于不可达状态时进入该阶段\r    对象空间重分配阶段 (De-allocated)：垃圾回收器对该对象的所占用的内存空间进行回收或者再分配\r   参考文章：https://blog.csdn.net/sodino/article/details/38387049\n创建时机 类在第一次实例化加载一次，后续实例化不再加载，引用第一次加载的类\nJava 对象创建时机：\n  使用 new 关键字创建对象：由执行类实例创建表达式而引起的对象创建\n  使用 Class 类的 newInstance 方法（反射机制）\n  使用 Constructor 类的 newInstance 方法（反射机制）\n1 2 3 4 5 6 7 8 9 10  public class Student { private int id; public Student(Integer id) { this.id = id; } public static void main(String[] args) throws Exception { Constructor\u0026lt;Student\u0026gt; c = Student.class.getConstructor(Integer.class); Student stu = c.newInstance(123); } }   使用 newInstance 方法的这两种方式创建对象使用的就是 Java 的反射机制，事实上 Class 的 newInstance 方法内部调用的也是 Constructor 的 newInstance 方法\n  使用 Clone 方法创建对象：用 clone 方法创建对象的过程中并不会调用任何构造函数，要想使用 clone 方法，我们就必须先实现 Cloneable 接口并实现其定义的 clone 方法\n  使用（反）序列化机制创建对象：当反序列化一个对象时，JVM 会创建一个单独的对象，在此过程中，JVM 并不会调用任何构造函数，为了反序列化一个对象，需要让类实现 Serializable 接口\n  从 Java 虚拟机层面看，除了使用 new 关键字创建对象的方式外，其他方式全部都是通过转变为 invokevirtual 指令直接创建对象的\n创建过程 创建对象的过程：\n  判断对象对应的类是否加载、链接、初始化\n  为对象分配内存：指针碰撞、空闲链表。当一个对象被创建时，虚拟机就会为其分配内存来存放对象的实例变量及其从父类继承过来的实例变量，即使从隐藏变量也会被分配空间（继承部分解释了为什么会隐藏）\n  处理并发安全问题：\n 采用 CAS 配上自旋保证更新的原子性 每个线程预先分配一块 TLAB    初始化分配的空间：虚拟机将分配到的内存空间都初始化为零值（不包括对象头），保证对象实例字段在不赋值时可以直接使用，程序能访问到这些字段的数据类型所对应的零值\n  设置对象的对象头：将对象的所属类（类的元数据信息）、对象的 HashCode、对象的 GC 信息、锁信息等数据存储在对象头中\n  执行 init 方法进行实例化：实例变量初始化、实例代码块初始化 、构造函数初始化\n  实例变量初始化与实例代码块初始化：\n对实例变量直接赋值或者使用实例代码块赋值，编译器会将其中的代码放到类的构造函数中去，并且这些代码会被放在对超类构造函数的调用语句之后（Java 要求构造函数的第一条语句必须是超类构造函数的调用语句），构造函数本身的代码之前\n  构造函数初始化：\nJava 要求在实例化类之前，必须先实例化其超类，以保证所创建实例的完整性，在准备实例化一个类的对象前，首先准备实例化该类的父类，如果该类的父类还有父类，那么准备实例化该类的父类的父类，依次递归直到递归到 Object 类。然后从 Object 类依次对以下各类进行实例化，初始化父类中的变量和执行构造函数\n    TLAB TLAB：Thread Local Allocation Buffer，为每个线程在堆内单独分配了一个缓冲区，多线程分配内存时，使用 TLAB 可以避免线程安全问题，同时还能够提升内存分配的吞吐量，这种内存分配方式叫做快速分配策略\n 栈上分配使用的是栈来进行对象内存的分配 TLAB 分配使用的是 Eden 区域进行内存分配，属于堆内存  堆区是线程共享区域，任何线程都可以访问到堆区中的共享数据，由于对象实例的创建在 JVM 中非常频繁，因此在并发环境下为避免多个线程操作同一地址，需要使用加锁等机制，进而影响分配速度\n问题：堆空间都是共享的么？ 不一定，因为还有 TLAB，在堆中划分出一块区域，为每个线程所独占\nJVM 是将 TLAB 作为内存分配的首选，但不是所有的对象实例都能够在 TLAB 中成功分配内存，一旦对象在 TLAB 空间分配内存失败时，JVM 就会通过使用加锁机制确保数据操作的原子性，从而直接在堆中分配内存\n栈上分配优先于 TLAB 分配进行，逃逸分析中若可进行栈上分配优化，会优先进行对象栈上直接分配内存\n参数设置：\n  -XX:UseTLAB：设置是否开启 TLAB 空间\n  -XX:TLABWasteTargetPercent：设置 TLAB 空间所占用 Eden 空间的百分比大小，默认情况下 TLAB 空间的内存非常小，仅占有整个 Eden 空间的1%\n  -XX:TLABRefillWasteFraction：指当 TLAB 空间不足，请求分配的对象内存大小超过此阈值时不会进行 TLAB 分配，直接进行堆内存分配，否则还是会优先进行 TLAB 分配\n  承上启下   一个实例变量在对象初始化的过程中会被赋值几次？一个实例变量最多可以被初始化 4 次\nJVM 在为一个对象分配完内存之后，会给每一个实例变量赋予默认值，这个实例变量被第一次赋值；在声明实例变量的同时对其进行了赋值操作，那么这个实例变量就被第二次赋值；在实例代码块中又对变量做了初始化操作，那么这个实例变量就被第三次赋值；；在构造函数中也对变量做了初始化操作，那么这个实例变量就被第四次赋值\n  类的初始化过程与类的实例化过程的异同？\n类的初始化是指类加载过程中的初始化阶段对类变量按照代码进行赋值的过程；类的实例化是指在类完全加载到内存中后创建对象的过程（类的实例化触发了类的初始化，先初始化才能实例化）\n  假如一个类还未加载到内存中，那么在创建一个该类的实例时，具体过程是怎样的？（经典案例）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  public class StaticTest { public static void main(String[] args) { staticFunction();//调用静态方法，触发初始化  } static StaticTest st = new StaticTest(); static { //静态代码块  System.out.println(\u0026#34;1\u0026#34;); } { // 实例代码块  System.out.println(\u0026#34;2\u0026#34;); } StaticTest() { // 实例构造器  System.out.println(\u0026#34;3\u0026#34;); System.out.println(\u0026#34;a=\u0026#34; + a + \u0026#34;,b=\u0026#34; + b); } public static void staticFunction() { // 静态方法  System.out.println(\u0026#34;4\u0026#34;); } int a = 110; // 实例变量  static int b = 112; // 静态变量 }/* Output: 2 3 a=110,b=0 1 4 *///:~   static StaticTest st = new StaticTest();：\n  实例实例化不一定要在类初始化结束之后才开始\n  在同一个类加载器下，一个类型只会被初始化一次。所以一旦开始初始化一个类，无论是否完成后续都不会再重新触发该类型的初始化阶段了（只考虑在同一个类加载器下的情形）。因此在实例化上述程序中的 st 变量时，实际上是把实例化嵌入到了静态初始化流程中，并且在上面的程序中，嵌入到了静态初始化的起始位置，这就导致了实例初始化完全发生在静态初始化之前，这也是导致 a 为 110，b 为 0 的原因\n  代码等价于：\n1 2 3 4 5 6 7 8 9 10 11  public class StaticTest { \u0026lt;clinit\u0026gt;(){ a = 110; // 实例变量  System.out.println(\u0026#34;2\u0026#34;);\t// 实例代码块  System.out.println(\u0026#34;3\u0026#34;);\t// 实例构造器中代码的执行  System.out.println(\u0026#34;a=\u0026#34; + a + \u0026#34;,b=\u0026#34; + b); // 实例构造器中代码的执行  类变量st被初始化 System.out.println(\u0026#34;1\u0026#34;);\t//静态代码块  类变量b被初始化为112 } }     ","date":"2022-07-15T20:17:48+08:00","permalink":"https://isheihei.github.io/posts/java/jvm-%E7%B1%BB%E5%8A%A0%E8%BD%BD/","title":"JVM 类加载"},{"content":"Redis事件 事件模型 Redis 基于 Reactor 模式开发了自己的网络事件处理器。\n  I/O多路复用程序同时监听多个套接字，并向文件事件分派器传送那些产生了事件的套接字。\n  文件事件分派器则接收I/O多路复用程序传来的套接字，并根据套接字产生的事件的类型，调用相应的事件处理器\n  尽管多个文件事件可能会并发地出现，但I/O多路复用程序会将所有产生的套接字都放到一个队列里面，然后通过这个队列向文件事件分派器传送套接字（一个一个顺序进行）。\n  IO模型详解：IO模型分析与对比\n文件事件 Redis事件分为文件事件和时间事件，文件事件就是服务器对套接字操作的抽象，服务器与客户端的通信会产生相应的文件事件，通俗点来说，就是客户端通过命令等方式发送给服务端的请求事件就是文件事件。\n文件事件是以单线程方式运行。\n文件事件处理器主要有：命令请求处理器、命令回复处理器、连接应答处理器\n时间事件 时间时间主要是周期性事件。\nserverCron 函数就是一个时间事件实例，它主要做的工作包括：\n 更新服务器各种统计信息，比如事件、内存占用、数据库占用等 清理数据库中的过期键值对 关闭和清理连接失效的客户端 尝试进行AOF或RDB持久化操作 如果服务器是主服务器，那么对从服务器进行定期同步 如果出于集群模式，对集群进行定期同步和连接测试  事件的调度和执行规则\n 因为文件事件是随机出现的，如果等待并处理完一次文件事件后，仍未有任何时间事件到达，那么服务器将再次等待并处理文件事件。随着文件事件的不断执行，时间会逐渐向时间事件所设置的到达时间逼近，并最终来到到达时间，这时服务器就可以开始处理到达的时间事件了。 文件事件和时间事件的处理都是同步、有序、原子地执行，服务器不会中途中断事件处理，也不会对事件进行抢占。 因为时间事件在文件事件之后执行，并且事件之间不会抢占，所以时间事件的实际处理时间，通常会比时间事件设定的到达事件稍晚一些。  Redis协议详细规范 此章节为转载，原文链接：Redis协议详细规范\nRedis客户端和服务器端通信使用名为 RESP (REdis Serialization Protocol) 的协议。虽然这个协议是专门为Redis设计的，它也可以用在其它 client-server 通信模式的软件上。\nRESP 是下面条件的折中：\n 实现起来简单。 解析速度快。 有可读性。  RESP 能序列化不同的数据类型，例如整型(integers)、字符串(strings)、数组(arrays)。额外还有特殊的错误类型。请求从客户端以字符串数组的形式发送到redis服务器，这些字符串表示要执行的命令的参数。Redis用特定于命令的数据类型回复。\nRESP 是二进制安全的，并且不需要处理从一个进程发到另外一个进程的批量数据，因为它使用前缀长度来传输批量数据。\n注意：这里概述的协议仅用于客户机-服务器通信。Redis集群使用不同的二进制协议在节点之间交换消息。\n网络层 连到Redis服务器的客户端建立了一个到6379端口的TCP连接。\n虽然RESP在技术上不特定于TCP，但是在Redis的上下文中，该协议仅用于TCP连接（或类似的面向流的连接，如unix套接字）。\n请求-响应模型 Redis接受由不同参数组成的命令。一旦收到命令，就会对其进行处理，并将应答发送回客户端。\n这是最简单的模型，但是有两个例外：\n Redis 支持管道pipelining。所以，客户端可以一次发送多个命令，然后再等待应答。 当一个Redis客户端订阅一个频道，那么协议会改变语义并变成pushprotocol, 也就是说，客户客户端不再需要发送命令，因为服务器端会一收到新消息，就会自动发送给客户端。  除了上面两个例外情况，Redis协议是一个简单的请求-响应协议。\nRESP 协议解释 RESP 协议在Redis1.2被引入，直到Redis2.0才成为和Redis服务器通信的标准。这个协议需要在你的Redis客户端实现。\nRESP 是一个支持多种数据类型的序列化协议：简单字符串（Simple Strings）,错误（ Errors）,整型（ Integers）, 大容量字符串（Bulk Strings）和数组（Arrays）。\nRESP在Redis中作为一个请求-响应协议以如下方式使用：\n 客户端以大容量字符串RESP数组的方式发送命令给服务器端。 服务器端根据命令的具体实现返回某一种RESP数据类型。  在 RESP 中，数据的类型依赖于首字节：\n 单行字符串（Simple Strings）： 响应的首字节是 \u0026ldquo;+\u0026rdquo; 错误（Errors）： 响应的首字节是 \u0026ldquo;-\u0026rdquo; 整型（Integers）： 响应的首字节是 \u0026ldquo;:\u0026rdquo; 多行字符串（Bulk Strings）： 响应的首字节是\u0026quot;$\u0026quot; 数组（Arrays）： 响应的首字节是 \u0026ldquo;*\u0026rdquo;  另外，RESP可以使用大容量字符串或者数组类型的特殊变量表示空值，下面会具体解释。RESP协议的不同部分总是以 \u0026ldquo;\\r\\n\u0026rdquo; (CRLF) 结束。\nRESP 单行字符串 单行字符串编码方法: 加号后面跟着一个不包含回车或换行字符的字符串 (不允许出现换行)，以CRLF(\u0026quot;\\r\\n\u0026quot;)结尾。\n单行字符串通常被用来传输非二进制安全字符串并且消耗极小。例如，许多redis命令在成功时回复\u0026quot;OK\u0026quot;，即简单字符串用以下5个字节编码：\n1  \u0026#34;+OK\\r\\n\u0026#34;   为了发送二进制安全的字符串，需要使用RESP的多行字符串（Bulk Strings）替代。\n当Redis返回单行字符串（Simple String）时，客户端lib应该返回去掉首字符加号和结尾CRLF字符的字符串给调用者。\nRESP 错误 RESP 有特殊类型来处理错误。errors类型除了首字符是减号 \u0026lsquo;-\u0026lsquo;不是加号以外，其它跟简单字符串一样。RESP中简单字符和错误的真正区别是：错误被客户端当作异常处理，组成错误类型的字符串是错误消息自身。\n基本格式如下:\n1  \u0026#34;-Error message\\r\\n\u0026#34;   错误应答只在发生异常时发送，例如，要执行命令的参数数据类型不匹配或者命令不存在等。当收到错误返回时，客户端lib应该抛出一个异常。\n错误返回例子:\n1 2  -ERR unknown command \u0026#39;foobar\u0026#39; -WRONGTYPE Operation against a key holding the wrong kind of value   从\u0026quot;-\u0026ldquo;后面第一个单词起，直到第一个空格或者换行，表示返回的错误类型。这是Redis的一种约定，并不是RESP协议的要求。\nERR 是一个通用错误, 而 WRONGTYPE 是表示更具体的错误，意味着客户端在错误的数据类型上执行操作。这被叫做错误前缀（Error Prefix）， 使客户端不用依赖具体错误消息就知道返回的错误类型，错误消息可能会随着时间而变化。\n客户端实现可能会对不同异常返回不同类型的错误，或者可能提供一种通用的方式来捕获错误，通过以字符串的形式直接返回错误名给调用者。\n尽管如此，这种特性不能认为很重要，因为它很少被使用。一小部分客户端的实现可能会返回通用错误条件，例如false。\nRESP 整数 整数类型是由以冒号开头，CRLF结尾，中间是字符串形式表示的数字。 例如 \u0026ldquo;:0\\r\\n\u0026rdquo;, 或 \u0026ldquo;:1000\\r\\n\u0026rdquo; 都是整数回复。\n很多Redis命令返回RESP整数，像 INCR, LLEN 和 LASTSAVE.\n返回的整数并没有特别的意义， INCR 返回的是一个递增的数字， LASTSAVE 返回的是Unix时间戳等。返回的整数有效值需要在有符号64位整数范围内。\n整数返回也被广泛的用来返回 true 或 false。比如 EXISTS 或 SISMEMBER 命令返回1表示true，返回0表示false。\n其它命令像 SADD, SREM 和 SETNX 如果操作被执行则返回1，否则返回0。\n返回整数回复的命令： SETNX, DEL, EXISTS, INCR, INCRBY, DECR, DECRBY, DBSIZE, LASTSAVE, RENAMENX, MOVE, LLEN, SADD, SREM, SISMEMBER, SCARD.\nRESP 多行字符串 多行字符串被用来表示最大512MB长的二进制安全字符串。\n多行字符串编码方式：\n 美元符 \u0026ldquo;$\u0026rdquo; 后面跟着组成字符串的字节数(前缀长度)，并以 CRLF 结尾。 实际的字符串数据。 结尾是 CRLF。  所以，字符串 \u0026ldquo;foobar\u0026rdquo; 编码如下:\n1  \u0026#34;$6\\r\\nfoobar\\r\\n\u0026#34;   空字符串编码格式：\n1  \u0026#34;$0\\r\\n\\r\\n\u0026#34;   RESP 多行字符串（Bulk Strings） 也可以使用一个特殊的用来表示空值的格式表示不存在的值。在这种格式里长度值为-1，数据部分不存在，所以空（Null）用如下方式表示：\n1  \u0026#34;$-1\\r\\n\u0026#34;   叫做空的多行字符串Null Bulk String。\n客户端API库不应该返回空串，当服务器端响应一个空的多行字符串时，API库可以返回一个空对象给调用者。例如，Ruby库应该返回 \u0026rsquo;nil\u0026rsquo; ，而C库应该返回NULL。\nRESP 数组 客户端使用 RESP 数组发送命令到 Redis 服务端。同样地，某些命令的应答使用RESP数组返回元素的集合给Redis客户端。 LRANGE 命令返回元素列表就是一个例子。\nRESP 数组使用如下格式发送：\n 以星号* 为首字符，接着是表示数组中元素个数的十进制数，最后以 CRLF 结尾。 外加数组中每个 RESP 类型的元素。  空数组表示：\n1  \u0026#34;*0\\r\\n\u0026#34;   有两个 RESP 多行字符串\u0026quot;foo\u0026rdquo; 和\u0026quot;bar\u0026quot;元素的 RESP 数组 ：\n1  \u0026#34;*2\\r\\n$3\\r\\nfoo\\r\\n$3\\r\\nbar\\r\\n\u0026#34;   在前缀 *\u0026lt;count\u0026gt;CRLF 的后面，组成数组的其它数据类型一个接在另一个后面。 例如包含三个整数的数组编码方式：\n1  \u0026#34;*3\\r\\n:1\\r\\n:2\\r\\n:3\\r\\n\u0026#34;   数组可以包含混合类型，不一定必须是同一种类型。例如，4个整型和1个多行字符串编码方式：\n1 2 3 4 5 6 7  *5\\r\\n :1\\r\\n :2\\r\\n :3\\r\\n :4\\r\\n $6\\r\\n foobar\\r\\n   (为了方便阅读，应答分成多行来展示)\n第一个行表示 *5\\r\\n 说明后面有5个应答。这些应答组成一个大的应答一起发送。\n空数组的概念也是存在的，另一个表示空值的方式(通常使用多行空字符串，历史遗留导致有这两种格式)。\n例如，当 BLPOP 命令超时，它会返回一个空数组，数组的计数器是-1 :\n1  \u0026#34;*-1\\r\\n\u0026#34;   当 Redis 返回一个空数组的时候，Redis客户端库API应该返回一个空对象而不是返回一个空数组。 这对区分空列表和其它不同情况（像 BLPOP 命令超时情况）是必要的。\n数组的数组也是可行的。例如，一个含有两个数组元素的数组编码方式：\n1 2 3 4 5 6 7 8  *2\\r\\n *3\\r\\n :1\\r\\n :2\\r\\n :3\\r\\n *2\\r\\n +Foo\\r\\n -Bar\\r\\n   (为了方便阅读，分成多行来展示).\n上面的 RESP 数据类型包含两个数组，一个数组包含三个整数1, 2, 3 ，另一个是简单字符串和一个错误类型。\n数组中的空元素 数组中可以有为空的元素。主要使用在Redis应答中，为了表示这个元素丢失并且不是一个空的字符串。当SORT命令使用GET 模式选项，并且特定的key丢失的时会出现这种应答。 含有有空元素的应答数组例子：\n1 2 3 4 5 6  *3\\r\\n $3\\r\\n foo\\r\\n $-1\\r\\n $3\\r\\n bar\\r\\n   第二个元素是空，客户端库应该返回像下面这样的数据：\n1  [\u0026#34;foo\u0026#34;,nil,\u0026#34;bar\u0026#34;]   这不是前面提到的异常情况，这只是说明协议的一个例子。\n发送命令到Redis服务器 至此，我们已经很熟悉RESP序列化格式，写一个Redis客户端库的实现会变得很容易。我们可以进一步说明客户端和服务端如何交互工作：\n 客户端发送包含只有多行字符串的数组给Redis服务器。 Redis 服务器给客户端发送任意有效的 RESP 数据类型作为应答。  下面是一个典型的交互过程例子：\n客户端发送命令 LLEN mylist 来获取存储在 mylist 键中列表的长读，然后服务器端返回整数应答(C: 代表客户端, S: 代表服务器端).\n1 2 3 4 5 6 7  C: *2\\r\\n C: $4\\r\\n C: LLEN\\r\\n C: $6\\r\\n C: mylist\\r\\n S: :48293\\r\\n   为了方便理解我们用换行把协议分成不同部分，实际上客户端发送的是一个整体没有换行：*2\\r\\n$4\\r\\nLLEN\\r\\n$6\\r\\nmylist\\r\\n as a whole.\nRedis 协议的高性能解析器 虽然redis协议是非常容易被人阅读和实现的，但是它可以以类似于二进制协议的性能来实现。\nRESP 使用带前缀的长度来传输批量数据，因此不需要像使用json那样扫描有效负载以查找特殊字符，也不需要引用需要发送到服务器的有效负载。\n批量和多批量长度可以使用代码进行处理，代码对每个字符执行单个操作，同时扫描CR字符，如以下C代码：\nRESP 使用带前缀的长度来传输多行数据，因此不需要像使用json那样扫描有效负载以查找特殊字符，也不需要引用需要发送到服务器的有效负载。\n多行和多个多行长度可以使用代码进行处理，代码对每个字符执行单个操作，同时扫描CR字符，如以下C代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  #include \u0026lt;stdio.h\u0026gt; int main(void) { unsigned char *p = \u0026#34;$123\\r\\n\u0026#34;; int len = 0; p++; while(*p != \u0026#39;\\r\u0026#39;) { len = (len*10)+(*p - \u0026#39;0\u0026#39;); p++; } /* Now p points at \u0026#39;\\r\u0026#39;, and the len is in bulk_len. */ printf(\u0026#34;%d\\n\u0026#34;, len); return 0; }   在识别出第一个CR之后，可以跳过它和下面的LF，而不需要任何处理。然后，可以使用不以任何方式检查有效负载的单个读取操作读取大容量数据。最后，剩余的CR和LF字符将被丢弃，而不进行任何处理。\nRedis协议有着与二进制协议可比的性能，更重要的是易于在大多数高级语言中实现，从而减少了客户端软件中的错误数量。\n实现 事件模型 对于Redis事件模型，java-redis 基于netty实现nio，并使用单线程事件处理器执行文件事件操作。如下图所示\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48  public class RedisNetServer implements RedisServer { private final ServerBootstrap serverBootstrap = new ServerBootstrap(); // 处理 redis 核心操作的线程，是单线程的  private final EventExecutorGroup redisSingleEventExecutor = new NioEventLoopGroup(1); // 处理连接和io操作的线程  private LocalChannelOption channelOption; @Override public void start() { start0(); } private void start0() { serverBootstrap.group(channelOption.boss(), channelOption.selectors()) .channel(channelOption.getChannelClass()) .handler(new LoggingHandler(LogLevel.INFO)) .option(ChannelOption.SO_BACKLOG, 1024) .option(ChannelOption.SO_REUSEADDR, true) .localAddress(new InetSocketAddress(ip, port)) .childHandler(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() { @Override protected void initChannel(SocketChannel socketChannel) { // 初始化客户端  int id = clientId.incrementAndGet(); RedisClient client = new RedisNormalClient(socketChannel.localAddress().toString(), id, dbs); // 初始化 channel  ChannelPipeline channelPipeline = socketChannel.pipeline(); channelPipeline.addLast( new ResponseEncoder(), new CommandDecoder(aof) ); channelPipeline.addLast(redisSingleEventExecutor, new CommandHandler(client, rdb)); } }); try { ChannelFuture sync = serverBootstrap.bind().sync(); LOGGER.info(sync.channel().localAddress().toString()); } catch (InterruptedException e) { LOGGER.warn(\u0026#34;Interrupted!\u0026#34;, e); throw new RuntimeException(e); } } }   nio多路复用模型，实现了单路模型，以及基于Epoll，Kqueue的多路模型。netty默认的nio模型底层是select。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  /** * @ClassName: SingleSelectChannelOption * @Description: 单路模型 * @Date: 2022/6/8 20:56 * @Author: isheihei */ public class SingleSelectChannelOption implements LocalChannelOption { private final NioEventLoopGroup single; public SingleSelectChannelOption(NioEventLoopGroup single) { this.single = single; } public SingleSelectChannelOption() { this.single = new NioEventLoopGroup(1, new ThreadFactory() { private AtomicInteger index = new AtomicInteger(0); @Override public Thread newThread(Runnable r) { return new Thread(r, \u0026#34;Server_boss_\u0026#34; + index.getAndIncrement()); } }); } @Override public EventLoopGroup boss() { return this.single; } @Override public EventLoopGroup selectors() { return this.single; } @Override public Class getChannelClass() { return NioServerSocketChannel.class; } }   协议 共五种消息类型：SimplString、BulkString、RespInt、RespArray、Errors\n协议编解码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177  /** * @ClassName: Resp * @Description: Redis Serialization Protocol协议 * @Date: 2022/6/1 13:15 * @Author: isheihei */ public interface Resp { org.apache.log4j.Logger LOGGER = org.apache.log4j.Logger.getLogger(Resp.class); Charset CHARSET = StandardCharsets.UTF_8; /** * @Description: 回写 * @Param: resp * @Param: buffer * @Return: void * @Author: isheihei */ static void write(Resp resp, ByteBuf buffer) { if (resp instanceof SimpleString) { buffer.writeByte(RespType.STATUS.getCode()); String content = ((SimpleString) resp).getContent(); buffer.writeBytes(content.getBytes(CHARSET)); writeEof(buffer); } else if (resp instanceof Errors) { buffer.writeByte(RespType.ERROR.getCode()); String content = ((Errors) resp).getContent(); buffer.writeBytes(content.getBytes(CHARSET)); writeEof(buffer); } else if (resp instanceof RespInt) { buffer.writeByte(RespType.INTEGER.getCode()); String content = String.valueOf(((RespInt) resp).getValue()); buffer.writeBytes(content.getBytes(CHARSET)); writeEof(buffer); } else if (resp instanceof BulkString) { buffer.writeByte(RespType.BULK.getCode()); BytesWrapper content = ((BulkString) resp).getContent(); if (content == null) { // null: \u0026#34;$-1\\r\\n\u0026#34;  buffer.writeByte(RespType.ERROR.getCode()); buffer.writeByte(RespType.ONE.getCode()); writeEof(buffer); } else if (content.getByteArray().length == 0) { // 空串: \u0026#34;$0\\r\\n\\r\\n\u0026#34;  buffer.writeByte(RespType.ZERO.getCode()); writeEof(buffer); writeEof(buffer); } else { // 正常编码：\u0026#34;foobar\u0026#34; 的编码为 \u0026#34;$6\\r\\nfoobar\\r\\n\u0026#34;，其中 6 是字节数  String length = String.valueOf(content.getByteArray().length); buffer.writeBytes(length.getBytes(CHARSET)); writeEof(buffer); buffer.writeBytes(content.getByteArray()); writeEof(buffer); } } else if (resp instanceof RespArray) { buffer.writeByte(RespType.MULTYBULK.getCode()); Resp[] array = ((RespArray) resp).getArray(); String length = String.valueOf(array.length); buffer.writeBytes(length.getBytes(CHARSET)); writeEof(buffer); for (Resp each : array) { write(each, buffer); } } else { throw new IllegalArgumentException(); } } /** * @Description: 解码为协议对应具体格式 * @Param: buffer * @Return: Resp * @Author: isheihei */ static Resp decode(ByteBuf buffer) { if (buffer.readableBytes() \u0026lt;= 0) { throw new IllegalStateException(\u0026#34;没有读取到完整的命令\u0026#34;); } byte b =buffer.readByte(); if (b == RespType.STATUS.getCode()) { return new SimpleString(getString(buffer)); } else if (b == RespType.ERROR.getCode()) { return new Errors(getString(buffer)); } else if (b == RespType.INTEGER.getCode()) { int value = getNumber(buffer); return new RespInt(value); } else if (b == RespType.BULK.getCode()) { int length = getNumber(buffer); if (buffer.readableBytes() \u0026lt; length + 2) { throw new IllegalStateException(\u0026#34;没有读取到完整的命令\u0026#34;); } byte[] content; if (length == -1) { content = null; } else { content = new byte[length]; buffer.readBytes(content); } if (buffer.readByte() != RespType.R.getCode() || buffer.readByte() != RespType.N.getCode()) { throw new IllegalStateException(\u0026#34;没有读取到完整的命令\u0026#34;); } return new BulkString(new BytesWrapper(content)); } else if (b == RespType.MULTYBULK.getCode()) { int numOfElement = getNumber(buffer); Resp[] array = new Resp[numOfElement]; for (int i = 0; i \u0026lt; numOfElement; i++) { array[i] = decode(buffer); } return new RespArray(array); } else { throw new IllegalStateException(\u0026#34;无法解析命令\u0026#34;); } } /** * @Description: 读取整数类型 * @Param: buffer * @Return: int * @Author: isheihei */ static int getNumber(ByteBuf buffer) { byte b; b = buffer.readByte(); boolean positive = true; int value = 0; // 错误（Errors）： 响应的首字节是 \u0026#34;-\u0026#34;  if (b == RespType.ERROR.getCode()) { positive = false; } else { value = b - RespType.ZERO.getCode(); } while (buffer.readableBytes() \u0026gt; 0 \u0026amp;\u0026amp; (b = buffer.readByte()) != RespType.R.getCode()) { value = value * 10 + (b - RespType.ZERO.getCode()); } if (buffer.readableBytes() == 0 || buffer.readByte() != RespType.N.getCode()) { throw new IllegalStateException(\u0026#34;没有读取到完整的命令\u0026#34;); } if (!positive) { value = -value; } return value; } /** * @Description: 读取一条字符串 * @Param: buffer * @Return: String * @Author: isheihei */ static String getString(ByteBuf buffer) { byte b; ByteBuf byteBuf = PooledByteBufAllocator.DEFAULT.directBuffer(); // 以终止符 /R 为结束标志  while (buffer.readableBytes() \u0026gt; 0 \u0026amp;\u0026amp; (b = buffer.readByte()) != RespType.R.getCode()) { byteBuf.writeByte(b); } // /R 后面必须紧接 /N  if (buffer.readableBytes() == 0 || buffer.readableBytes() != RespType.N.getCode()) { throw new IllegalStateException(\u0026#34;没有读取到完整的命令\u0026#34;); } return byteBuf.toString(CHARSET); } /** * @Description: 写协议终止符：\u0026#34;\\r\\n\u0026#34; (CRLF) * @Param: buffer * @Return: void * @Author: isheihei */ static void writeEof(ByteBuf buffer) { buffer.writeByte(RespType.R.getCode()); buffer.writeByte(RespType.N.getCode()); }   ","date":"2022-06-26T16:32:54+08:00","image":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B001-%E9%80%9A%E4%BF%A1%E4%B8%8E%E5%8D%8F%E8%AE%AE/log_hu0a4ba87b3d81b22780f8a722f1e0fc9b_1722333_120x120_fill_q75_box_smart1.jpg","permalink":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B001-%E9%80%9A%E4%BF%A1%E4%B8%8E%E5%8D%8F%E8%AE%AE/","title":"Redis设计与实现01-通信与协议"},{"content":"数据结构 简单动态字符串（SDS） 1 2 3 4 5 6 7 8 9 10 11  struct sdshdr { //\t记录 buf 数组已使用字节的数量  //\t等于 SDS 所保存字符串的长度  int len; //\t记录 buf 数组中未使用字节的数量  int free; //\t字节数组，用于保存字符串  char buf[]; }    常数复杂度获取字符串长度 杜绝缓冲区溢出，修改前会检查空间是否满足所需要求，不满足会扩展空间 空间预分配，减少修改字符串长度时所需的内存重分配次数。 二进制安全（byte数组） 兼容部分 C 字符串函数  链表（双端列表） 1 2 3 4 5 6 7 8 9 10  typedef struct listNode { //\t前置节点  struct listNode *prev; //\t后置节点  struct listNode *next; //\t节点的值  void *value } listNode;   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  typedef struct list { //\t表头节点  listNode *head; //\t表位节点  listNode *tail; //\t链表所包含的节点数量  unsigned long len; //\t节点值复制函数  void (*free)(void *ptr); //\t节点值对比函数  int (*match)(void *ptr, void *key); } list;    双端 无环，表头结点的 prev 指针和表位节点的 next 指针都指向 NULL，对链表的访问以 NULL 为终点。 带表头和表尾指针，程序获取链表的表头节点和表尾节点的复杂度为O（1） 带链表长度计数器：程序使用 list 结构的 len 属性来对 list 持有的链表节点进行计数，程序获取链表中节点数量的复杂度为 O（1）。 泛型：可以保存不同类型的节点  字典（Map） 哈希表：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  typedef struct dictht { //\t哈希表数组  dictEntry **table; //\t哈希表大小  unsigned long size; //\t哈希表大小掩码，用于计算索引值  //\t总是等于 size - 1  unsigned long sizemask; //\t该哈希表已有节点的数量  unsigned long used; } dictht;   哈希表节点：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  typedef struct dictEntry { //\t键  void *key; //\t值  union{ void *val; uint64_tu64; int64_ts64; } v; //\t指向下个哈希表节点，形成链表  struct dictEntry *next; } dictEntry;   字典：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  typedef struct dict { //\t类型特定函数  dictType *type; //\t私有数据  void *privdata; //\t哈希表，ht[1]用于ht[0]在rehash的时候使用  dictht ht[2]; //\trehash 索引  //\t当 rehash 不在进行时 值为-1  int trehashidx; } dict;   type 属性和 privdata 属性是针对不同类型的键值对，为创建多态字典而设置的\n type 属性是一个指向 dictType 结构的指针，每个 dictType 结构保存了一簇用于操作特定类型键值对的函数，Redis会为用途不同的字典设置不同类型特定函数。 privdata 属性保存了需要传给那些类型特定函数的可选参数。  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  typedef struct dictType { // 计算哈希值的函数  unsigned int (*hashFunction)(const void *key); //\t复制键的函数  void *(*keyDup)(void *privdata, const void *key); //\t复制值的函数  void *(\u0026amp;valDup)(void *privdata, const coid *obj); // 对比键的函数  int (*keyCompare)(void *privdata, const void *key1, const void *key2); //\t销毁键的函数  void (*keyDestructor)(void *privdata, void *key); //\t销毁值的函数  void (*valDestructor)(void *privdata, void *obj); } dictType;   特点\n 拉练法解决哈希冲突,头插（因为拉链没有表位节点），java-HashMap 1.8 后是尾插 扩容和收缩 都是 2^n 双 table 、渐进式 rehash  rehash 步骤\n 为 ht[1]分配空间，让字典同时持有 ht[0] 和ht[1] 两个哈希表 在字典中维持一个索引计数变量rehashidx，并将它的值设置为 0，表示rehash工作正式开始 在rehash 进行期间，每次对字典执行添加、删除、查找或者更新操作时，程序除了执行指定的操作以外，还会顺带将 ht[0] 哈希表在 rehashidx 索引上的所有键值对 rehash 到ht[1]，当rehash 工作完成之后，程序将 rehashidx 属性的值增一。 随着字典操作的不断执行，最终在某个时间点上，ht[0] 的所有键值对都会被 rehash 至 ht[1] , 这时程序将 rehashidx 属性的值设为 -1，表示 rehash操作已完成。  因为在渐进式 rehash 过程中，字典会同时使用 ht[0] 和 ht[1] 两个哈希表，所以在渐进式 rehash 进行期间，字典的删除、查找、更新等操作会在两个哈希表上进行。例如要在字典里面查找一个键的话，程序会先在 ht[0] 里面进行查找，如果没找到的话，就会继续到 ht[1] 里面进行查找。\n另外，在渐进式 rehash 执行期间，新添加到字典的键值对一律会被保存到 ht[1] 里面，而 ht[0] 则不在进行任何添加操作，这一措施保证了 ht[0] 包含的键值对数量会只减不增，并随着 rehash 操作的执行而最终变成空表。\n跳表（SkipList） 跳表详解：Skip List\u0026ndash;跳表（全网最详细的跳表文章没有之一） - 简书 (jianshu.com)\nRedis-zset源码：redis/t_zset.c at unstable · redis/redis (github.com)\n跳跃表节点：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  typedef struct zskiplistNode { //\t层  struct zskiplistLevel { //\t前进指针  struct zskiplistNode *forward; //\t跨度  unsigned int span; } level[]; //\t后退指针  struct zskiplistNode *backward; //\t分值  double score; //\t成员对象  robj *obj; } zskiplistNode;   层\n跳跃表的 level 数组可以包含多个元素，所有包含同层的节点组合构成了跳表该层链表。每次创建一个新的跳跃表节点，程序根据幂次定律（power law， 越大的数出现的概率越小）随机生成一个介于1和32之间的值作为level数组的大小（索引的层数，即该节点要建立几层索引），这个大小就是层的高度。\n前进指针：每个层有一个前进指针，指向该层的下一个节点。\n跨度：跨度记录了两个节点之间的距离，指向NULL的所有前进指针的跨度都为0\n后退指针\n用于从表位向表头方向访问节点，与前进指针不同，每个节点无论高度，都只有一个后退指针，即最底层有后退指针，每次只能后退一个节点。\n跳跃表：\n1 2 3 4 5 6 7 8 9 10  typedef struct zskiplist { // 表头节点和表位节点  struct skiplistNode *header, *tail; //\t表中节点的数量  unsigned long length; //\t表中层数最大的节点的层数  int level; } zskiplist;   整数集合（IntSet） 整数集合（intset）是集合键的底层实现之一，当一个集合只包含整数值元素，并且这个集合的元素数量不多时，Redis 就会使用整数集合作为集合键的底层实现\n1 2 3 4 5 6 7 8 9 10  typedefg struct intset { //\t编码方式  uint32_t encoding; //\t集合包含的元素数量  uint32_t length; //\t保存元素的数组 有序且不重复  int8_t contents[]; } intset;   升级\n当新增的元素编码大于当前集合编码时候，例如当前编码为 INTSET_ENC_INT16 ，新添加一个 INTSET_ENC_INT32 类型元素。那么会引发整数集合的升级，把所有元素扩展为INTSET_ENC_INT32 类型，对应的 contents 字节数组的长度也会相应增加。\n升级的好处：提升灵活性、节约内存。但是不支持降级，一旦升级，编码就会一直保持升级后的状态。\n 升级之后新元素的摆放位置\n因为引发升级的新元素的长度总是比整数集合现有所有元素的长度都打，所以这个新元素值要么就大于所有现有元素，要么就小于所有现有元素。\n怎么理解？\n前一句话是因，后一句话是果。\n当新插入元素的数据类型大小大于已有元素的数据类型大小时，会触发intset的升级操作。\n这个时候 新插入的元素要么大于所有的已有的元素，要么小于所有的已有元素。\n假设现在的元素类型是int16，所有元素的取值范围都在区间[-32768,32767]。\n如果想触发intset的升级，将元素类型升级为int32，新加入元素的范围区间应该是[-2147483648,-32768)和(32767,2147483647)。\n如果新元素在前一个区间，那么它小于-32768，小于所有的int16。\n如果新元素在后一个区间，那么它大于32767，大于所有的int16。\n 压缩列表 压缩列表（ziplist）是列表键和哈希键的底层实现之一。当一个列表键只包含少量列表项，并且每个列表项要么就是小整数值，要么就是长度比较短的字符串，那么 Redis 就会使用压缩列表来做列表键的底层实现。\n压缩列表节点的构成：\n1  previous_entry_length | encoding | content    previous_entry_length：以字节为单位，记录了压缩列表中前一个节点的长度。可以通过指针计算，根据当前节点的起始地址来计算出前一个节点的起始地址。可能为1或者5字节（根据前一个节点的大小），如果前一个节点的长度小于 254 字节，需要1字节；如果前一个节点的长度大于 254 字节，那么需要 5字节。 encoding：节点的 encoding 属性记录了节点的 content 属性所保存数据的类型以及长度 content：节点的 content 属性负责保存节点的值，节点值可以是一个字节数组或者整数，值的类型和长度由节点的 encoding 属性决定  连锁更新\n考虑这样一个情况：在一个压缩列表中，有多个连续的、长度介于 250 字节到 253 字节之间的节点。因为 previous_entry_length 字段只需1字节，那么如果新增一个长度大于254的节点放在列表头，就需要更新之前第一个节点的 previous_entry_length，并且1字节放不下，需要扩展到 5 字节。\n扩展后又出现问题了，因为第二个节点的 previous_entry_length 也放不下第一个节点的长度了，所有就引发后面的一系列连续节点都需要重新分配内存。\n最坏的情况下需要对压缩列表执行 O(N) 次内存重分配操作。\n尽管连锁个更新的复杂度较高，但它真正造成性能问题的几率是很低的：\n 首先压缩列表里要恰好有多个连续的、长度介于 250 字节至 253 字节之间的节点，连锁更新才有可能被引发，实际情况中并不多见 其次，即使出现连锁更新，但只要被更新的节点数量不多，就不会对性能造成任何影响。  对象 对象类型与编码\n类型：数据库键对应的对象类型\n编码：对象具体的底层实现\n字符串对象 编码：int、raw或者 embstr\nembstr编码是专门用于保存短字符串的一种优化编码方式，这种编码和 raw 编码一样，都是用redisObject 和sdshdr 结构来表示字符串对象，但 raw 编码会调用两次分配函数来分别创建 redisObject 结构和 sdshdr 结构，而 embstr 编码通过一次内存分配函数分配一块连续空间，一次包含 redisObject 和 sdshdr两个结构。\n列表对象 编码：ziplist 或者 linkedlist\n哈希对象 编码：ziplist 或者 hashtable\n集合对象 编码：intset 或者 hashtable\n有序集合对象 编码：ziplist 或者 skiplist\n实现 对象和数据结构部分的实现在 java-redis-core模块 org.isheihei.redis.core.obj 和 org.isheihei.redis.core.struct包下。\n由于 java 中的string类型保存的是char数组，且不支持修改。所以新增了一个 BytesWapper 字节包装类以字节数组的形式保存字符串。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64  public class BytesWrapper implements Comparable\u0026lt;BytesWrapper\u0026gt; { static final Charset CHARSET = StandardCharsets.UTF_8; private final byte[] content; public BytesWrapper() { content = new byte[0]; } public BytesWrapper(byte[] content) { this.content = content; } public byte[] getByteArray() { return content; } public int length() { return content == null ? 0 : content.length; } @Override public boolean equals(Object o) { if (this == o) { return true; } if (o == null || getClass() != o.getClass()) { return false; } BytesWrapper that = (BytesWrapper) o; return Arrays.equals(content, that.content); } public String toUtf8String() { return new String(content, CHARSET); } @Override public int hashCode() { return Arrays.hashCode(content); } @Override public int compareTo(BytesWrapper o) { int len1 = content.length; int len2 = o.getByteArray().length; int lim = Math.min(len1, len2); byte v1[] = content; byte v2[] = o.getByteArray(); int k = 0; while (k \u0026lt; lim) { byte c1 = v1[k]; byte c2 = v2[k]; if (c1 != c2) { return c1 - c2; } k++; } return len1 - len2; } }   为了降低系统实现的复杂性，对于五种对象，分别对应了五种数据结构类型，并尽可能复用 Java 已有的数据类和工具。\n五种数据对象分别对应\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84  //\t字符串对象 RedisStringObject{ RedisString.value = BytesWrapper } //\t列表对象 RedisListObject{ RedisDoubleLinkedListextends LinkedList\u0026lt;BytesWrapper\u0026gt; } //\t哈希对象 RedisMapObject{ RedisMap extends HashMap\u0026lt;BytesWrapper, BytesWrapper\u0026gt; } //\t集合对象 RedisSetObject{ RedisSet extends HashSet\u0026lt;BytesWrapper\u0026gt; } //\t有序集合对象 RedisZSetObject{ RedisZSet extends TreeSet\u0026lt;ZNode\u0026gt; } //\tZNode 为有序集合节点： public class ZNode implements Comparable\u0026lt;ZNode\u0026gt; { private BytesWrapper member; private double score; public ZNode(double score, BytesWrapper member) { this.member = member; this.score = score; } public BytesWrapper getMember() { return member; } public double getScore() { return score; } @Override public boolean equals(Object o) { if (this == o) { return true; } if (o == null || getClass() != o.getClass()) { return false; } ZNode zNode = (ZNode) o; return member.equals(zNode.member); } @Override public int hashCode() { return member.hashCode(); } @Override public int compareTo(ZNode o) { int scoreComp = Double.compare(score, o.score); int memberComp = member.compareTo(o.member); if (memberComp == 0) { // member 相等 则相等  return 0; } else if (scoreComp == 0) { // member不相等且 score相等 按照member排序  return memberComp; } else { // member 和 score都不相等 按照score排序  return scoreComp; } } }   其中要单独说一下 TreeSet\nTreeSet 内部封装了一个 TreeMap 成员对象，底层是红黑树实现了有序，并且不允许重复。TreeSet中的元素必须实现Comparable接口并重写compareTo()方法，TreeSet判断元素是否重复 、以及确定元素的顺序 靠的都是这个方法；\n所以 ZNode 的 compare 方法非常关键，因为 ZNode有两个属性，一个 member， 一个 score。按照我们的需求，我们允许 score 重复，但是不允许 member 重复；且排序是优先按照 score 排序，score 相等的情况下再按照 member 字典排序。\n经过一番尝试与不断的思考，给出以下排序代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  @Override public int compareTo(ZNode o) { int scoreComp = Double.compare(score, o.score); int memberComp = member.compareTo(o.member); if (memberComp == 0) { // member 相等 则相等  return 0; } else if (scoreComp == 0) { // member不相等且 score相等 按照member排序  return memberComp; } else { // member 和 score都不相等 按照score排序  return scoreComp; } }   但是这种方案还是有问题，目前已知的有两点：\n add方法不能覆盖旧的节点，如果想对 member 相同但是分数不同的节点进行修改，无法直接add，因为compareTo()的结果虽然是相等，但是add通过比较判断相等则没有添加覆盖的操作，目前的方案是先删除旧节点，再添加。 在使用 TreeSet 方法 subSet() 截取区间时，无法保留右边界元素会失败。例如：this.subSet(new ZNode(min, new BytesWrapper()),true,new ZNode(max, new BytesWrapper()),true); 无法取到保留右边界元素。原因是：在创建ZNode的时候使用了空字符数组创建，当compareTo()比较的时候，如果 score 相等，则会比较 member，因为空串永远是最小的，所以我们想要取到的 score 值相同的 ZNode 永远比我们传入的这个节点大。  ","date":"2022-06-25T16:39:36+08:00","image":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B002-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E5%AF%B9%E8%B1%A1/log_hu0a4ba87b3d81b22780f8a722f1e0fc9b_1722333_120x120_fill_q75_box_smart1.jpg","permalink":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B002-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E5%AF%B9%E8%B1%A1/","title":"Redis设计与实现02-数据结构与对象"},{"content":"命令 继承结构 对于 redis 的众多命令，在设计实现的时候，尽可能的去抽象代码。除了抽象出命令的顶层 interface 之外，对于查询命令和修改命令，又划分出两个抽象类。最终的继承结构如下：\nclassDiagram\rCommand Command接口三个主要方法\n type()：返回命令类型 setContent(RespArray arrays)：设置命令参数 handle(RedisClient redisClient)：执行命令逻辑  AbstractCommand ：抽象了查询命令并实现了setContent(RespArray arrays)方法\nAbstractWriteCommand：\n抽象了更新修改命令并实现了setContent(RespArray arrays)、handle(RedisClient redisClient)方法。并使用了模板方法模式用于写入AOF。提供了一个钩子变量 aofOn，当该变量为 true 时，handle 方法会执行 aof.putAof 操作。\n1 2 3 4 5 6 7 8 9  @Override public Resp handle(RedisClient redisClient) { if (aofOn) { putAof(); } return handleWrite(redisClient); } public abstract Resp handleWrite(RedisClient redisClient);   实现的命令 命令手册：\nCommands | Redis\nredis 命令手册\nCONNECTION 1 2 3  auth(Auth::new), client(Client::new), config(Config::new), echo(Echo::new), ping(Ping::new), quit(Quit::new)   SEVER 1 2 3  select(Select::new), flushall(FlushAll::new), dbsize(DbSize::new), flushdb(FlushDb::new), bgsave(BgSave::new), save(Save::new)   KEY 1 2 3 4  expire(Expire::new), del(Del::new), exists(Exists::new), keys(Keys::new), persist(Persist::new), rename(Rename::new), ttl(Ttl::new), type(Type::new),   TRANSACTION 1 2 3  multi(Multi::new), exec(Exec::new), unwatch(UnWatch::new), watch(Watch::new), discard(Discard::new)   STRING 1 2 3 4  get(Get::new), set(Set::new), mget(MGet::new), mset(MSet::new), append(Append::new), setex(SetEx::new), setnx(SetNx::new)   LIST 1 2 3 4 5  lpush(LPush::new), lrange(LRange::new), lrem(LRem::new), rpush(RPush::new), lpop(LPop::new), rpop(RPop::new), lset(LSet::new), lindex(LIndex::new), llen(LLen::new),   HASH 1 2 3 4 5  hdel(HDel::new), hexists(HExists::new), hget(HGet::new), hgetall(HGetAll::new), hkeys(HKeys::new), hset(HSet::new), hmset(HMSet::new), hvals(HVals::new), hmget(HMGet::new),   SET 1 2 3 4 5 6  sadd(SAdd::new), scard(SCard::new), sdiff(SDiff::new), smembers(SMembers::new), sismember(SIsMember::new), sdiffstore(SDiffStore::new), sinter(SInter::new), sinterstore(SInterStore::new), srem(SRem::new), sunion(SUnion::new), sunionstore(SUnionStore::new),   ZSET 1 2 3 4 5  zadd(ZAdd::new), zcard(ZCard::new), zcount(ZCount::new), zrange(ZRange::new), zrangebyscore(ZRangeByScore::new), zrank(ZRank::new), zrem(ZRem::new), zscore(ZScore::new),   ","date":"2022-06-24T16:40:04+08:00","image":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B003-%E5%91%BD%E4%BB%A4/log_hu0a4ba87b3d81b22780f8a722f1e0fc9b_1722333_120x120_fill_q75_box_smart1.jpg","permalink":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B003-%E5%91%BD%E4%BB%A4/","title":"Redis设计与实现03-命令"},{"content":"参考：\nLinux IO模式及 select、poll、epoll详解 - SegmentFault 思否\n一文搞懂select、poll和epoll区别 - 知乎 (zhihu.com)\n一些前置概念 用户空间与内核空间 现在操作系统都是采用虚拟存储器，那么对32位操作系统而言，它的寻址空间（虚拟存储空间）为4G（2的32次方）。操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。为了保证用户进程不能直接操作内核（kernel），保证内核的安全，操心系统将虚拟空间划分为两部分，一部分为内核空间，一部分为用户空间。\n进程阻塞 正在执行的进程，由于期待的某些事件未发生，如请求系统资源失败、等待某种操作的完成、新数据尚未到达或无新工作做等，则由系统自动执行阻塞原语(Block)，使自己由运行状态变为阻塞状态。可见，进程的阻塞是进程自身的一种主动行为，也因此只有处于运行态的进程（获得CPU），才可能将其转为阻塞状态。当进程进入阻塞状态，是不占用CPU资源的。\n文件描述符 fd 文件描述符（File descriptor）是计算机科学中的一个术语，是一个用于表述指向文件的引用的抽象化概念。\n文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展开。但是文件描述符这一概念往往只适用于UNIX、Linux这样的操作系统。\n缓存 I/O 缓存 I/O 又被称作标准 I/O，大多数文件系统的默认 I/O 操作都是缓存 I/O。在 Linux 的缓存 I/O 机制中，操作系统会将 I/O 的数据缓存在文件系统的页缓存（ page cache ）中，也就是说，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。\n缓存 I/O 的缺点： 数据在传输过程中需要在应用程序地址空间和内核进行多次数据拷贝操作，这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的\nI/O 模式 对于一次IO访问（以read举例），数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。所以说，当一个read操作发生时，它会经历两个阶段：\n 等待数据准备 (Waiting for the data to be ready) 将数据从内核拷贝到进程中 (Copying the data from the kernel to the process)  正是因为这两个阶段，linux系统产生了下面五种网络模式的方案。\n 阻塞 I/O（blocking IO） 非阻塞 I/O（nonblocking IO） I/O 多路复用（ IO multiplexing） 信号驱动 I/O（ signal driven IO） 异步 I/O（asynchronous IO）  阻塞 I/O（blocking IO） 在linux中，默认情况下所有的socket都是blocking，一个典型的读操作流程大概是这样：\n当用户进程调用了recvfrom这个系统调用，kernel就开始了IO的第一个阶段：准备数据（对于网络IO来说，很多时候数据在一开始还没有到达。比如，还没有收到一个完整的UDP包。这个时候kernel就要等待足够的数据到来）。这个过程需要等待，也就是说数据被拷贝到操作系统内核的缓冲区中是需要一个过程的。而在用户进程这边，整个进程会被阻塞（当然，是进程自己选择的阻塞）。当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。\n 所以，blocking IO的特点就是在IO执行的两个阶段都被block了。\n 非阻塞 I/O（nonblocking IO） linux下，可以通过设置socket使其变为non-blocking。当对一个non-blocking socket执行读操作时，流程是这个样子：\n当用户进程发出read操作时，如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error。从用户进程角度讲 ，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的system call，那么它马上就将数据拷贝到了用户内存，然后返回。\n 所以，nonblocking IO的特点是用户进程需要不断的主动询问kernel数据好了没有。\n I/O 多路复用（ IO multiplexing） IO multiplexing就是我们说的select，poll，epoll，有些地方也称这种IO方式为event driven IO。select/epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基本原理就是select，poll，epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。\n当用户进程调用了select，那么整个进程会被block，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。\n 所以，I/O 多路复用的特点是通过一种机制一个进程能同时等待多个文件描述符，而这些文件描述符（套接字描述符）其中的任意一个进入读就绪状态，select()函数就可以返回。\n 这个图和blocking IO的图其实并没有太大的不同，事实上，还更差一些。因为这里需要使用两个system call (select 和 recvfrom)，而blocking IO只调用了一个system call (recvfrom)。但是，用select的优势在于它可以同时处理多个connection。\n所以，如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好，可能延迟还更大。select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。）\n在IO multiplexing Model中，实际中，对于每一个socket，一般都设置成为non-blocking，但是，如上图所示，整个用户的process其实是一直被block的。只不过process是被select这个函数block，而不是被socket IO给block。\n异步 I/O（asynchronous IO） inux下的asynchronous IO其实用得很少。先看一下它的流程：\n用户进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。\n信号驱动 I/O（ signal driven IO） 在信号驱动式I/O模型中，应用程序使用套接口进行信号驱动I/O，并安装一个信号处理函数，进程继续运行并不阻塞。当数据准备好时，进程会收到一个SIGIO信号，可以在信号处理函数中调用I/O操作函数处理数据\n异步 I/O与信号驱动 I/O的主要区别在于：信号驱动I/O是由内核通知应用程序何时启动一个I/O操作，而异步I/O模型是由内核通知应用程序I/O操作何时完成\n优点：线程并没有在等待数据时被阻塞，可以提高资源的利用率\n缺点：信号I/O在大量IO操作时可能会因为信号队列溢出导致没法通知。\n信号驱动I/O尽管对于处理UDP套接字来说有用，即这种信号通知意味着到达一个数据报，或者返回一个异步错误。但是，对于TCP而言，信号驱动的I/O方式近乎无用，因为导致这种通知的条件为数众多，每一个来进行判别会消耗很大资源。\nIO模式总结 blocking和non-blocking的区别 调用blocking IO会一直block住对应的进程直到操作完成，而 non-blocking IO在 kernel 还未准备好数据的情况下会立刻返回。\nsynchronous IO和asynchronous IO的区别 在说明synchronous IO和asynchronous IO的区别之前，需要先给出两者的定义。POSIX的定义是这样子的：\n A synchronous I/O operation causes the requesting process to be blocked until that I/O operation completes; An asynchronous I/O operation does not cause the requesting process to be blocked;  两者的区别就在于synchronous IO做”IO operation”的时候会将process阻塞。按照这个定义，之前所述的blocking IO，non-blocking IO，IO multiplexing都属于synchronous IO。\n这里有个非常“狡猾”的地方，定义中所指的”IO operation”是指真实的IO操作，就是例子中的recvfrom这个system call。non-blocking IO在执行recvfrom这个system call的时候，如果kernel的数据没有准备好，这时候不会block进程。但是，当kernel中数据准备好的时候，recvfrom会将数据从kernel拷贝到用户内存中，这个时候进程是被block了，在这段时间内，进程是被block的。\n而asynchronous IO则不一样，当进程发起IO 操作之后，就直接返回再也不理睬了，直到kernel发送一个信号，告诉进程说IO完成。在这整个过程中，进程完全没有被block。\n同步IO和异步IO的区别就在于：数据拷贝的时候进程是否阻塞！\n阻塞IO和非阻塞IO的区别就在于：应用程序的调用是否立即返回！\n各个IO Model的比较如图所示：\n通过上面的图片，可以发现non-blocking IO和asynchronous IO的区别还是很明显的。在non-blocking IO中，虽然进程大部分时间都不会被block，但是它仍然要求进程去主动的check，并且当数据准备完成以后，也需要进程主动的再次调用recvfrom来将数据拷贝到用户内存。而asynchronous IO则完全不同。它就像是用户进程将整个IO操作交给了他人（kernel）完成，然后他人做完后发信号通知。在此期间，用户进程不需要去检查IO操作的状态，也不需要主动的去拷贝数据。\nI/O 多路复用之select、poll、epoll、kqueue详解 select，poll，epoll，kqueue都是IO多路复用的机制。I/O多路复用就是通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。（这里啰嗦下）\nselect 1 2 3 4  int select (int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout); //\twritefds、readfds、和exceptfds　是三个指针，分别记录了读、写和 except 事件描述符 //\t进程调用select的时候会把这三个指针传递进函数并阻塞直到有就绪事件 //\t如果有就绪的事件对应的描述符，会对其设置就绪，select 返回后进程可以遍历所有的描述符，找到就绪的进行处理。   select 函数监视的文件描述符分3类，分别是writefds、readfds、和exceptfds。调用后select函数会阻塞，直到有描述副就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以 通过遍历fdset，来找到就绪的描述符。\nselect目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点。select的一 个缺点在于单个进程能够监视的文件描述符的数量存在最大限制，在Linux上一般为1024，可以通过修改宏定义甚至重新编译内核的方式提升这一限制，但 是这样也会造成效率的降低。\n调用过程\n 使用copy_from_user从用户空间拷贝fd_set到内核空间 注册回调函数__pollwait 遍历所有fd，调用其对应的poll方法（对于socket，这个poll方法是sock_poll，sock_poll根据情况会调用到tcp_poll，udp_poll或datagram_poll），以tcp_poll为例，核心实现就是__pollwait，即上面注册的回调函数。__pollwait，就是把current（当前进程）挂到设备的等待队列，不同设备有不同等待队列，如tcp_poll的等待队列是sk-\u0026gt;sk_sleep（把进程挂到等待队列中并不代表进程已睡眠）。在设备收到一条消息（网络设备）或填写完文件数据（磁盘设备）后，会唤醒设备等待队列上睡眠的进程，这时current便被唤醒。 poll方法返回时会返回一个描述读写操作是否就绪的mask掩码，根据这个mask掩码给fd_set赋值 若遍历完所有fd，还没返回一个可读写的mask掩码，则调schedule_timeout是调用select的进程（也就是current）进入睡眠。当设备驱动发生自身资源可读写后，会唤醒其等待队列上睡眠的进程。若超过一定超时时间（schedule_timeout指定），还没人唤醒，则调用select的进程会重新被唤醒获得CPU，进而重新遍历fd，判断有无就绪的fd 把fd_set从内核空间拷贝到用户空间  缺点\n内核需要将消息传递到用户空间，都需要内核拷贝动作。需要维护一个用来存放大量fd的数据结构，使得用户空间和内核空间在传递该结构时复制开销大。\n 每次调用select，都需把fd集合从用户态拷贝到内核态，fd很多时开销就很大 同时每次调用select都需在内核遍历传递进来的所有fd，fd很多时开销就很大 select支持的文件描述符数量太小了，默认最大支持1024个 主动轮询效率很低  poll 1  int poll (struct pollfd *fds, unsigned int nfds, int timeout);   不同与select使用三个位图来表示三个fdset的方式，poll使用一个 pollfd的指针实现。\n1 2 3 4 5  struct pollfd { int fd; /* 文件描述符 */ short events; /* 要监视的事件 */ short revents; /* 发生的事件 */ };   pollfd结构包含了要监视的event和发生的event，不再使用select“参数-值”传递的方式。同时，pollfd并没有最大数量限制（但是数量过大后性能也是会下降）。 和select函数一样，poll返回后，需要轮询pollfd来获取就绪的描述符。\npoll和select同样存在一个缺点就是，包含大量文件描述符的数组被整体复制于用户态和内核的地址空间之间，而不论这些文件描述符是否就绪，它的开销随着文件描述符数量的增加而线性增大。\n  它将用户传入的数组拷贝到内核空间\n  然后查询每个fd对应的设备状态：\n   如果设备就绪 在设备等待队列中加入一项继续遍历 若遍历完所有fd后，都没发现就绪的设备 挂起当前进程，直到设备就绪或主动超时，被唤醒后它又再次遍历fd。这个过程经历多次无意义的遍历。     从上面看，select和poll都需要在返回后，通过遍历文件描述符来获取已经就绪的socket。事实上，同时连接的大量客户端在一时刻可能只有很少的处于就绪状态，因此随着监视的描述符数量的增长，其效率也会线性下降。\n epoll epoll是在2.6内核中提出的，是之前的select和poll的增强版本。相对于select和poll来说，epoll更加灵活，没有描述符限制。epoll使用一个文件描述符管理多个描述符，将用户关心的文件描述符的事件存放到内核的一个事件表中，用户每次新增和删除监听事件都通过内核中的这个事件表，这样在用户空间和内核空间的copy只需一次。select 和 poll 都需要把fd表或者数据结构拷贝到内核态再从内核态取出。\nepoll模型修改主动轮询为被动通知，当有事件发生时，被动接收通知。所以epoll模型注册套接字后，主程序可做其他事情，当事件发生时，接收到通知后再去处理。可理解为event poll，epoll会把哪个流发生哪种I/O事件通知我们。所以epoll是事件驱动（每个事件关联fd），此时我们对这些流的操作都是有意义的。复杂度也降到O(1)。\nepoll操作过程 epoll操作过程需要三个接口，分别如下：\n1 2 3  int epoll_create(int size)；//创建一个epoll的句柄（epfd），size用来告诉内核这个监听的数目一共有多大 int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；// 增删改某个fd的某个事件 int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);\t// 等待 epfd 上的事件   1. int epoll_create(int size); 创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大，这个参数不同于select()中的第一个参数，给出最大监听的fd+1的值，参数size并不是限制了epoll所能监听的描述符最大个数，只是对内核初始分配内部数据结构的一个建议。 当创建好epoll句柄后，它就会占用一个fd值，在linux下如果查看/proc/进程id/fd/，是能够看到这个fd的，所以在使用完epoll后，必须调用close()关闭，否则可能导致fd被耗尽。\n2. int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)； 函数是对指定描述符fd执行op操作。 - epfd：是epoll_create()的返回值。 - op：表示op操作，用三个宏来表示：添加EPOLL_CTL_ADD，删除EPOLL_CTL_DEL，修改EPOLL_CTL_MOD。分别添加、删除和修改对fd的监听事件。 - fd：是需要监听的fd（文件描述符） - epoll_event：是告诉内核需要监听什么事，struct epoll_event结构如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13  struct epoll_event { __uint32_t events; /* Epoll events */ epoll_data_t data; /* User data variable */ }; //events可以是以下几个宏的集合： EPOLLIN ：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）； EPOLLOUT：表示对应的文件描述符可以写； EPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）； EPOLLERR：表示对应的文件描述符发生错误； EPOLLHUP：表示对应的文件描述符被挂断； EPOLLET： 将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的。 EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里   3. int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout); 等待epfd上的io事件，最多返回maxevents个事件。 参数events用来从内核得到事件的集合，maxevents告知内核这个events有多大，这个maxevents的值不能大于创建epoll_create()时的size，参数timeout是超时时间（毫秒，0会立即返回，-1将不确定，也有说法说是永久阻塞）。该函数返回需要处理的事件数目，如返回0表示已超时。\n工作模式 epoll对文件描述符的操作有两种模式：LT（level trigger）和ET（edge trigger）。LT模式是默认模式，LT模式与ET模式的区别如下：\nLT模式，默认的模式（水平触发）：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用epoll_wait时，会再次响应应用程序并通知此事件。\nET模式，“高速”模式（边缘触发）：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。\nLT模式\nLT(level triggered)是缺省的工作方式，并且同时支持block和no-block socket.在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你的。\nET模式\nET(edge-triggered)是高速工作方式，只支持no-block socket。在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知，直到你做了某些操作导致那个文件描述符不再为就绪状态了(比如，你在发送，接收或者接收请求，或者发送接收的数据少于一定量时导致了一个EWOULDBLOCK 错误）。但是请注意，如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核不会发送更多的通知(only once)\nET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。epoll工作在ET模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。\n假如有这样一个例子：\n 我们已经把一个用来从管道中读取数据的文件句柄(RFD)添加到epoll描述符 这个时候从管道的另一端被写入了2KB的数据 调用epoll_wait(2)，并且它会返回RFD，说明它已经准备好读取操作 然后我们读取了1KB的数据 调用epoll_wait(2)\u0026hellip;\u0026hellip;  LT模式： 如果是LT模式，那么在第5步调用epoll_wait(2)之后，仍然能受到通知。\nET模式： 如果我们在第1步将RFD添加到epoll描述符的时候使用了EPOLLET标志，那么在第5步调用epoll_wait(2)之后将有可能会挂起，因为剩余的数据还存在于文件的输入缓冲区内，而且数据发出端还在等待一个针对已经发出数据的反馈信息。只有在监视的文件句柄上发生了某个事件的时候 ET 工作模式才会汇报事件。因此在第5步的时候，调用者可能会放弃等待仍在存在于文件输入缓冲区内的剩余数据。\n当使用epoll的ET模型来工作时，当产生了一个EPOLLIN事件后， 读数据的时候需要考虑的是当recv()返回的大小如果等于请求的大小，那么很有可能是缓冲区还有数据未读完，也意味着该次事件还没有处理完，所以还需要再次读取：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  while(rs){ buflen = recv(activeevents[i].data.fd, buf, sizeof(buf), 0); if(buflen \u0026lt; 0){ // 由于是非阻塞的模式,所以当errno为EAGAIN时,表示当前缓冲区已无数据可读  // 在这里就当作是该次事件已处理处.  if(errno == EAGAIN){ break; } else{ return; } } else if(buflen == 0){ // 这里表示对端的socket已正常关闭.  } if(buflen == sizeof(buf){ rs = 1; // 需要再次读取  } else{ rs = 0; } }    Linux中的EAGAIN含义\n Linux环境下开发经常会碰到很多错误(设置errno)，其中EAGAIN是其中比较常见的一个错误(比如用在非阻塞操作中)。 从字面上来看，是提示再试一次。这个错误经常出现在当应用程序进行一些非阻塞(non-blocking)操作(对文件或socket)的时候。\n例如，以 O_NONBLOCK的标志打开文件/socket/FIFO，如果你连续做read操作而没有数据可读。此时程序不会阻塞起来等待数据准备就绪返回，read函数会返回一个错误EAGAIN，提示你的应用程序现在没有数据可读请稍后再试。 又例如，当一个系统调用(比如fork)因为没有足够的资源(比如虚拟内存)而执行失败，返回EAGAIN提示其再调用一次(也许下次就能成功)。\n优点  没有最大并发连接的限制，能打开的FD的上限远大于1024（1G的内存上能监听约10万个端口） 效率提升，不是轮询，不会随着FD数目的增加效率下降。只有活跃可用的FD才会调用callback函数 即Epoll最大的优点就在于它只关心“活跃”的连接，而跟连接总数无关，因此在实际的网络环境中，Epoll的效率就会远远高于select和poll 内存拷贝，利用mmap()文件映射内存加速与内核空间的消息传递；即epoll使用mmap减少复制开销。 epoll通过内核和用户空间共享一块内存来实现的  kqueue kqueue和epoll一样，都是用来替换select和poll的。不同的是kqueue被用在FreeBSD,NetBSD, OpenBSD, DragonFly BSD, 和 macOS中。\nkqueue 不仅能够处理文件描述符事件，还可以用于各种其他通知，例如文件修改监视、信号、异步 I/O 事件 (AIO)、子进程状态更改监视和支持纳秒级分辨率的计时器，此外kqueue提供了一种方式除了内核提供的事件之外，还可以使用用户定义的事件。\nkqueue提供了两个API，第一个是构建kqueue：\n1  int kqueue(void);   第二个是创建kevent:\n1  int kevent(int kq, const struct kevent *changelist, int nchanges, struct kevent *eventlist, int nevents, const struct timespec *timeout);   kevent中的第一个参数是要注册的kqueue，changelist是要监视的事件列表，nchanges表示要监听事件的长度，eventlist是kevent返回的事件列表,nevents表示要返回事件列表的长度，最后一个参数是timeout。\n除此之外，kqueue还有一个用来初始化kevent结构体的EV_SET宏：\n1  EV_SET(\u0026amp;kev, ident, filter, flags, fflags, data, udata);   总结 在 select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，而epoll事先通过epoll_ctl()来注册一 个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait() 时便得到通知。(此处去掉了遍历文件描述符，而是通过监听回调的的机制。这正是epoll的魅力所在。)\nselect，poll，epoll都是IO多路复用机制，即可以监视多个描述符，一旦某个描述符就绪（读或写就绪），能够通知程序进行相应读写操作。 但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。\n select，poll实现需要自己不断轮询所有fd集合，直到设备就绪，期间可能要睡眠和唤醒多次交替。而epoll其实也需要调用epoll_wait不断轮询就绪链表，期间也可能多次睡眠和唤醒交替，但是它是设备就绪时，调用回调函数，把就绪fd放入就绪链表中，并唤醒在epoll_wait中进入睡眠的进程。虽然都要睡眠和交替，但是select和poll在“醒着”的时候要遍历整个fd集合，而epoll在“醒着”的时候只要判断一下就绪链表是否为空就行了，这节省了大量的CPU时间。这就是回调机制带来的性能提升。 select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把current往设备等待队列中挂一次，而epoll只要一次拷贝，而且把current往等待队列上挂也只挂一次（在epoll_wait的开始，注意这里的等待队列并不是设备等待队列，只是一个epoll内部定义的等待队列）。这也能节省不少的开销。   如果没有大量的idle -connection或者dead-connection，epoll的效率并不会比select/poll高很多，但是当遇到大量的idle- connection，就会发现epoll的效率大大高于select/poll。\n ","date":"2022-06-24T13:45:35+08:00","permalink":"https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/io%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90%E4%B8%8E%E5%AF%B9%E6%AF%94/","title":"IO模型分析与对比"},{"content":"过期策略 数据库中有一个过期字典，字典的 key 是被设置过期时间的键，字典的 value 是过期时间（long 类型 以毫秒为单位的 UNXI 时间戳）。\n删除策略 定时删除 在设置键的过期时间的同时，创建一个定时器，让定时器在键的过期时间来临时，立即执行对键的删除操作。\n优点：对内存最友好，通过使用定时器，定时删除策略可以保证过期键会尽可能快地被删除，并释放过期键所占用的内存。\n缺点：对CPU时间最不友好，在过期键比较多的情况下，删除过期键这一行为可能会占用相当一部分CPU时间。在内存不紧张但是CPU时间非常紧张的情况下，拿CPU去做与当前任务无关的过期键上没有意义。\n惰性删除 放任过期键不管，但是每次从键空间中获取键时，都检查取得的键是否过期，如果过期的话，就删除该键；如果没有过期，就返回该键。\n优点：对CPU时间最友好，不会在删除其他无关的过期键上花费任何CPU时间\n缺点：对内存最不友好，如果一个键已经过期，而这个键又仍然保留在数据库中，那么只要这个过期键不被删除，它所占用的内存就不会释放。可以把这种情况视为一种内存泄漏。\n定期删除 每隔一段时间， 程序就对数据库进行一次检查，删除里面的过期键。至于要删除多少过期键，以及要检查多少个数据库，则由算法决定。\n定期策略是前两种策略的一种整合和折中：\n 定期删除策略每隔一段时间执行一次删除过期键操作，并通过限制删除操作执行的时长和频率来减少删除操作对CPU时间的影响。 除此之外，通过定期删除过期键，定期删除策略有效地减少了因为过期键而带来的内存浪费  定期删除策略的难点是确定删除操作执行的时长和频率：\n 如果删除操作执行地太过频繁，或者执行的时间太长，定期删除策略就退化成定时删除策略 如果删除操作执行得太少，或者执行地太短，定期删除策略又会和惰性删除策略一样，出现浪费内存的情况  Redis 的过期键删除策略 Redis 使用了惰性删除策略和定期删除策略结合的方式\n惰性删除策略的实现 所有读写数据库的命令在执行之前都会先判断输入键是否已经过期\n 如果输入键已经过期，那么将输入键删除 如果输入键未过期，那么正常执行  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  public class RedisDBImpl implements RedisDB { // 过期字典  private final Map\u0026lt;BytesWrapper, Long\u0026gt; expires = new HashMap\u0026lt;\u0026gt;(); //\t在获取键的时候先判断是否已经过期，如果过期就删除  public RedisObject get(BytesWrapper key) { RedisObject redisObject = dict.get(key); if (redisObject == null) { return null; } else if (isExpired(key)){ expires.remove(key); dict.remove(key); return null; } else { redisObject.refreshLru(); redisObject.updateLfu(); return redisObject; } } }   定期删除策略的实现 ServerCron 是服务器的时间事件之一，主要执行一些周期性操作。定期策略在 ServerCron 类中被调用：\n1 2 3  private void databasesCron() { expireStrategy.activeExpireCycle(); }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  @Override public void activeExpireCycle() { start = System.currentTimeMillis(); int dbSize = dbs.size(); if (dbSize \u0026lt; dbNumbers) { // 如果数据库当前数量比默认的数量少，取当前数量  dbNumbers = dbSize; } // 当前遍历到的数据库索引  currentDb %= dbSize; int deleteCount = 0; // keyNumbers为每次从数据库过期字典中取出的键的数量，默认为20  for (int i = 0; i \u0026lt; keyNumbers; i++){ RedisDB redisDB = dbs.get(currentDb); int expiresSize = redisDB.expiresSize(); if (expiresSize == 0) return; // 随机取，看是否过期，过期就删除它  BytesWrapper randomKey = redisDB.getRandomExpires(); if (redisDB.isExpired(randomKey)) { LOGGER.info(\u0026#34;过期key: \u0026#34; + randomKey.toUtf8String() + \u0026#34;被删除\u0026#34;); deleteCount++; redisDB.delete(randomKey); } //\t执行事件到达上限则结束 timeLimit = TimeUnit.MICROSECONDS.toMillis(1000)  if (System.currentTimeMillis() - start \u0026gt; timeLimit) { return; } // 如果抽样的 20 个键过期的超过 1/4 则重复该过程  if (deleteCount \u0026gt; keyNumbers / 4) { deleteCount = 0; i = 0; } } }   扩展：从库的过期策略 从库不会进行过期扫描，从库对过期的处理是被动的。主库在 key 到期时，会在 AOF 文件里增加一条 del 指令，同步到所有的从库，从库通过执行这条 del 指令来删除过期的 key。\n因为指令同步是异步进行的，所以主库过期的 key 的 del 指令没有及时同步到从库的话，会出现主从数据的不一致，主库没有的数据在从库里还存在。\n逐出策略 数据淘汰机制 Redis 内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。Redis 提供 6 种数据淘汰策略：\n volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用 的数据淘汰 volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数 据淘汰，ttl （Time To Live）越小越优先被淘汰。 volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据 淘汰 allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰 allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰 no-enviction（驱逐）：禁止驱逐数据  redis5.0新增：\n volatile-lfu：从已设置过期时间的数据集挑选使用频率最低的数据淘汰。 allkeys-lfu：从数据集中挑选使用频率最低的数据淘汰。  volatile-xxx 策略只会针对带过期时间的 key 进行淘汰，allkeys-xxx 策略会对所有的 key 进行淘汰。如果你只是拿 Redis 做缓存，那应该使用 allkeys-xxx，客户端写缓存时不必携带过期时间。如果你还想同时使用 Redis 的持久化功能，那就使用 volatile-xxx 策略，这样可以保留没有设置过期时间的 key，它们是永久的 key 不会被 LRU 算法淘汰。\n实现 何时淘汰？ Redis实例支持通过修改配置参数（maxmemory-policy），修改数据逐出策略。在达到内存上限（maxmemory）时，Redis根据逐出策略进行数据逐出。\n而 Java-Redis 是基于 Java 语言实现，那么内存大小就受限于 JVM内存大小。\n  JVM初始分配的内存由-Xms指定，默认是物理内存的1/64;\n  JVM最大分配的内存由-Xmx指定，默认是物理内存的1/4。\n  默认空余堆内存**小于40%**时，JVM就会增大堆直到-Xmx的最大限制；\n  空余堆内存**大于70%**时，JVM会减少堆直到-Xms的最小限制。因此服务器一般设置-Xms、-Xmx相等以避免在每次GC后调整堆的大小。\n  而且 Java 提供的 Runtime.getRuntime().totalMemory() 、 Runtime.getRuntime().maxMemory() 、Runtime.getRuntime().freeMemory()方法能获取当前 JVM 已分配内存 、 JVM 最大可扩展内存以及 JVM 当前已分配内存中的空闲内存。\n为了适配 JVM 内存，给出以下内存策略：\n建议初始内存和最大内存参数相等，这样可以避免运行过程中的内存重分配过程，也更容易精确计算当前内存的占用情况。\n但是：由于 JVM 的内存的 GC 时间是不固定的，有些已经被淘汰的键不能被虚拟机及时回收，可能会造成获取的内存占用信息实时性不强的问题，这是由于 JVM 内存本身机制决定，能力有限，暂时没有想到更优的解决办法。\n 什么时候触发 GC？\n什么时候触发Young GC\u0026mdash;-针对年轻代\n当Eden区满了的时候，会触发Young GC\n什么时候触发 Full GC\u0026mdash;-针对整个堆\n 在发生Young GC的时候，虚拟机会检测之前每次晋升到老年代的平均大小是否大于年老代的剩余空间，如果大于，则直接进行Full GC； 如果小于，但设置了Handle PromotionFailure，那么也会执行Full GC。  1 2 3  -XX:HandlePromotionFailure：是否设置空间分配担保 JDK7及以后这个参数就失效了. 只要老年代的连续空间大于新生代对象的总大小或者历次晋升到老年代的对象的平均大小就进行MinorGC，否则FullGC    永久代空间不足，会触发Full GC\n  System.gc()也会触发Full GC\n  堆中分配很大的对象\n   1 2 3 4 5 6 7 8 9 10 11 12 13  private void evict() { Runtime runtime = Runtime.getRuntime(); int i = -1; while (runtime.freeMemory() \u0026lt; 0.2 * runtime.totalMemory()) { i = (i + 1) % dbs.size(); if (dbs.get(i).size() != 0) { evictStrategy.setDb(dbs.get(i)); evictStrategy.doEvict(); } else { continue; } } }   Volatile-Random-Evict 1 2 3 4 5 6 7 8 9  public class VolatileRandomEvict extends AbstractEvictStrategy { @Override public void doEvict() { // 从过期字典中随机删除一个  BytesWrapper randomKey = db.getRandomExpires(); db.delete(randomKey); LOGGER.info(\u0026#34;淘汰了key : \u0026#34; + randomKey); } }   AllKeys-Random-Evict 1 2 3 4 5 6 7 8  public class AllKeysRandomEvict extends AbstractEvictStrategy { @Override public void doEvict() { BytesWrapper randomKey = db.getRandomKey(); db.delete(randomKey); LOGGER.info(\u0026#34;淘汰了key : \u0026#34; + randomKey); } }   No-Evict 1 2 3 4 5 6  public class NoEvict extends AbstractEvictStrategy { @Override public void doEvict() { return; } }   Volatile-Lru-Evict 近似 LRU 算法\n严格的 LRU 算法需要单独维护一个访问队列，这对于数据量很大的缓存系统来说是极度影响性能的。\nRedis 使用的是一种近似 LRU 算法，因为 LRU 算法消耗大量的额外的内存。近似 LRU 算法则很简单，在现有数据结构的基础上使用随机采样法来淘汰元素，能达到和 LRU 算法非常近似的效果。\n它给每个 key 增加了一个额外的小字段 lru，也就是最后一次被访问的时间戳。然后从过期字典种随机采样出 samples（默认为20） 个 key，然后淘汰掉最旧的 key，如果淘汰后内存还是超出 maxmemory，那就继续随机采样淘汰，直到内存低于 maxmemory 为止。\n每次访问到key的时候会更调用 refreshLru() 新键对应的数据对象的 lru 记录。\n Redis3.0之后又改善了算法的性能，会提供一个待淘汰候选key的pool，里面默认有16个key，按照空闲时间排好序。更新时从Redis键空间随机选择N个key，分别计算它们的空闲时间idle，key只会在pool不满或者空闲时间大于pool里最小的时，才会进入pool，然后从pool中选择空闲时间最大的key淘汰掉。\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  public class VolatileLruEvict extends AbstractEvictStrategy { @Override public void doEvict() { if (db.expiresSize() == 0) { LOGGER.info(\u0026#34;没有易失键，尝试淘汰失败\u0026#34;); return; } BytesWrapper lruKey = null; long min = Long.MAX_VALUE; for (int i = 0; i \u0026lt; samples; i++) { BytesWrapper randomKey = db.getRandomExpires(); long lru = db.get(randomKey).getLru(); if (lru \u0026lt; min) { lruKey = randomKey; min = lru; } } db.delete(lruKey); LOGGER.info(\u0026#34;淘汰了key : \u0026#34; + lruKey.toUtf8String()); } }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  public abstract class AbstractRedisObject implements RedisObject{ // 最近访问时间  private long lru; @Override public long getLru() { return lru; } @Override public void refreshLru() { lru = System.currentTimeMillis(); } }   AllKeys-Lru-Evict 同 VolatileLruEvict，只不过采样的键的来源从过期字典变为全部键空间。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  public class AllKeysLruEvict extends AbstractEvictStrategy { @Override public void doEvict() { BytesWrapper lruKey = null; long min = Long.MAX_VALUE; for (int i = 0; i \u0026lt; samples; i++) { BytesWrapper randomKey = db.getRandomKey(); long lru = db.get(randomKey).getLru(); if (lru \u0026lt; min) { lruKey = randomKey; min = lru; } } db.delete(lruKey); LOGGER.info(\u0026#34;淘汰了key : \u0026#34; + lruKey.toUtf8String()); } }   Volatile-Lfu-Evict 强烈推荐阅读！👀：Redis中的LFU算法 - 再见紫罗兰 - 博客园 (cnblogs.com)\nLFU 思路：在LFU算法中，可以为每个key维护一个计数器。每次key被访问的时候，计数器增大。计数器越大，可以约等于访问越频繁。\n上述简单算法存在两个问题：\n 在LRU算法中可以维护一个双向链表，然后简单的把被访问的节点移至链表开头，但在LFU中是不可行的，节点要严格按照计数器进行排序，新增节点或者更新节点位置时，时间复杂度可能达到O(N)。 只是简单的增加计数器的方法并不完美。访问模式是会频繁变化的，一段时间内频繁访问的key一段时间之后可能会很少被访问到，只增加计数器并不能体现这种趋势。  第一个问题很好解决，可以借鉴LRU实现的经验，维护一个待淘汰key的pool。\n第二个问题的解决办法是，记录key最后一个被访问的时间，然后随着时间推移，降低计数器。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  public class VolatileLfuEvict extends AbstractEvictStrategy { @Override public void doEvict() { BytesWrapper lfuKey = null; long min = Long.MAX_VALUE; for (int i = 0; i \u0026lt; samples; i++) { BytesWrapper randomKey = db.getRandomExpires(); long lfu = db.get(randomKey).lfuDecrAndReturn(); if (lfu \u0026lt; min) { lfuKey = randomKey; min = lfu; } } db.delete(lfuKey); LOGGER.info(\u0026#34;淘汰了key : \u0026#34; + lfuKey.toUtf8String()); } }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61  public abstract class AbstractRedisObject implements RedisObject{ // 访问计数  private int accessCount; // 最近一次 accessCount 降低的时间  private long ldt; // 65535 分钟为一个周期 每过一个周期降低accessCount  private static final long LFU_DECAY_TIME = 3932100000L; // accessCount 初始值  private static final int LFU_INIT_VAL = 5; // 控制 accessCount 增长的因子 因子越大，增长的概率越小  private static final int LFU_LOG_FACTOR = 10; public AbstractRedisObject() { this.lru = System.currentTimeMillis(); this.accessCount = LFU_INIT_VAL; this.ldt = System.currentTimeMillis(); } /** * redis 源码逻辑 * void updateLFU(robj *val) { * unsigned long counter = LFUDecrAndReturn(val); * counter = LFULogIncr(counter); * val-\u0026gt;lru = (LFUGetTimeInMinutes()\u0026lt;\u0026lt;8) | counter; * } */ @Override public void updateLfu() { lfuDecrAndReturn(); // 最大值为255  if (accessCount == 255) { return; } // 取一个0-1之间的随机数r与p比较，当r\u0026lt;p时，才增加 accessCount，这和比特币中控制产出的策略类似。  // p取决于当前 accessCount 值与 LFU_LOG_FACTOR 因子，  // accessCount 值与 LFU_LOG_FACTOR 因子越大，p越小，r\u0026lt;p 的概率也越小，accessCount 增长的概率也就越小。  // 可见 accessCount 增长与访问次数呈现对数增长的趋势，随着访问次数越来越大，accessCount 增长的越来越慢  double r = new Random().nextDouble(); double baseval = accessCount - LFU_INIT_VAL; if (baseval \u0026lt; 0) baseval = 0; double p = 1.0 / (baseval * LFU_LOG_FACTOR + 1); if (r \u0026lt; p) accessCount++; } //\t距离该key上次被访问，每过去一个周期即LFU_DECAY_TIME，accessCount就要减少1  //\t这样即使以前被经常访问的key，后来不再访问，也会慢慢降低其accessCount  @Override public int lfuDecrAndReturn() { long l = System.currentTimeMillis() - ldt; long decr = l / LFU_DECAY_TIME; if (decr != 0) { accessCount -= decr; ldt = System.currentTimeMillis(); } return accessCount; } }   AllKeys-Lfu-Evict 同 VolatileLfuEvict，只不过采样的键的来源从过期字典变为全部键空间。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  public class AllKeysLfuEvict extends AbstractEvictStrategy { @Override public void doEvict() { BytesWrapper lfuKey = null; long min = Long.MAX_VALUE; for (int i = 0; i \u0026lt; samples; i++) { BytesWrapper randomKey = db.getRandomKey(); long lfu = db.get(randomKey).lfuDecrAndReturn(); if (lfu \u0026lt; min) { lfuKey = randomKey; min = lfu; } } db.delete(lfuKey); LOGGER.info(\u0026#34;淘汰了key : \u0026#34; + lfuKey.toUtf8String()); } }   Volatile-Ttl-Evict 仅限于易失键，即过期字典中的键，随机采样并淘汰其中最早过期的键。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  public class VolatileTtlEvict extends AbstractEvictStrategy { @Override public void doEvict() { BytesWrapper ttlKey = null; long min = Long.MAX_VALUE; for (int i = 0; i \u0026lt; samples; i++) { BytesWrapper randomKey = db.getRandomKey(); Long ttl = db.getTtl(randomKey); if (ttl \u0026lt; min) { ttlKey = randomKey; min = ttl; } } db.delete(ttlKey); LOGGER.info(\u0026#34;淘汰了key : \u0026#34; + ttlKey.toUtf8String()); } }   ","date":"2022-06-23T16:40:14+08:00","image":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B004-%E8%BF%87%E6%9C%9F%E7%AD%96%E7%95%A5%E4%B8%8E%E9%80%90%E5%87%BA%E7%AD%96%E7%95%A5/log_hu0a4ba87b3d81b22780f8a722f1e0fc9b_1722333_120x120_fill_q75_box_smart1.jpg","permalink":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B004-%E8%BF%87%E6%9C%9F%E7%AD%96%E7%95%A5%E4%B8%8E%E9%80%90%E5%87%BA%E7%AD%96%E7%95%A5/","title":"Redis设计与实现04-过期策略与逐出策略"},{"content":"Redis 中的事务 事务 Redis 通过 MULTI、 EXEC、 WATCH等命令来实现事务功能。事务提供了一种将多个命令请求打包，然后一次性、按顺序地执行多个命令机制，并且再事务执行期间，服务器不会中断事务而改去执行其他客户端的命令请求，它会将事务中的所有命令都执行完毕，然后采取处理其他客户端的命令请求。\n事务首先以 MULTI 命令为开始，接着将多个命令放入事务当中，最后由 EXEC 命令将这个事务提交给服务器执行。\n一个事务从卡死hi到结束通常会经历以下三个阶段：\n 事务开始 命令入队 事务执行  当客户端处于非事务状态时，这个客户端发送的命令会立即被服务器执行。\n当一个客户端切换到事务状态之后，服务器会根据这个客户端发来的不同命令执行不同的操作：\n 如果客户端发送的命令为 EXEC DISCARD、 WATCH， MULTI四个命令的其中一个，那么服务器立即执行这个命令 与此相反，如果客户端发送的命令是 EXEC DISCARD、 WATCH， MULTI 四个命令以外的命令，那么服务器并不立即执行这个命令，而是将这个命令放入一个事务队列里面，然后向客户端返回 QUEUED 回复  每个客户端都有自己的事务状态，这个事务状态保存在客户端状态的 mstate 属性里面\n1 2 3 4 5 6 7  typedef struct multiState { //\t事务队列，FIFO顺序  multiCmd *commands; //\t已入队命令计数  int count; } multiState;   WATCH 命令 WATCH 命令是一个乐观锁，它可以在 EXEC 命令执行之前，监视任意熟练高端数据库键，并在 EXEC 命令执行时，检查被监视的键是否至少有一个已经被修改过了，瑞国是的话，服务器将拒绝执行事务，并向客户端返回代表事务失败的空回复。\n每个 Redis 数据库都保存着一个 watched_keys 字典，这个字典的键是某个被 WATCH 命令监视的数据库键，而字典的值则是一个链表，链表中记录了所有监视相应数据库键的客户端\n监视机制的触发\n对数据库进行修改的命令，在执行之后都会调用 touchWatchKey 函数对 watched_keys 字典进行检查，查看是否由客户端正在监视刚刚被命令修改过的数据库键，如果有的话，那么 touchWatchKey 函数会将监视被修改键的客户端 REDIS_DIRTY_CAS 标识打开，表示该客户端的事务安全性已经被破坏。\n1 2 3 4 5 6 7 8 9 10 11 12  def touchWatchKey(db, key){ # 如果键 key 存在于数据库的 watched_keys 字典中  # 那么说明至少有一个客户端在监视这个 key  if key in db.watch_keys: # 遍历所有监视键 key 的客户端 \tfor client in db.watch_keys[key]: # 打开标识  client.flags |= REDIS_DIRTY_CAS }   判断事务是否安全\n当服务器其接收到一个客户端发来的 EXEC 命令时，服务器会根据这个客户端是否打开了 REDIS_DIRTY_CAS 标识来决定是否执行事务：\n 如果客户端的 REDIS_DIRTY_CAS 标识已经被打开，那么说明客户端所监视的键当中，至少一个键已经被修改过了，在这种情况下，客户端提交的事务已经不再安全，所以服务器会拒绝执行客户端提交的事务。 如果客户端的 REDIS_DIRTY_CAS 标识没有被打开，那么说明客户端监视的所有键都没有被修改过（或者客户端没有监视任何键），事务仍然是安全的，服务器将执行客户端提交的事务。  Redis 事务的 ACID 特性 在 Redis 中，事务总具有原子性（Atomicity）、一致性（Consistency）和隔离性（Isolation），并且当 Redis 运行在某种特定的持久化模式下，事务也具有持久性（Durability）。\n原子性\n事务具有原子性是指，数据库将事务中的多个操作当作一个整体来执行，服务器要么就执行事务中的所有操作，要么就一个操作也不执行。Redis是满足原子性的。\n但是 Redis的事务和传统的关系型数据库事务最大的区别在于，Redis 不支持事务回滚机制（rollback），即使事务队列中的某个命令在执行期间出现了错误，整个事务也会继续执行下去，直到事务队列中的所有命令都执行完毕为止。\nRedis 的作者在事务功能的文档中解释说，不支持事务回滚是因为这种复杂的功能和 Redis 追求简单高效的设计主旨不相符，并且它认为，Redis事务的执行时错误通常都是编程错误产生的，这种错误通常只会出现在开发环境中，而很少会在实际的生产环境中出现，所以他认为没有必要为Redis开发事务回滚功能。\n一致性\n事务具有一致性指的是，如果数据库在执行事务之前是一致的，那么在事务执行之后，无论事务是否执行成功，数据库也仍然是一致的。\n”一致“指的是数据符合数据库本身的定义和要求，没有包含非法或者无效的错误数据。\n  入队错误：如果一个事务在入队命令的过程中，出现了命令不存在，或者命令的格式不正确等情况，那么 Redis 将拒绝执行这个事务。\n  执行错误：除了入队时可能发生错误以外，事务还可能在执行的过程中发生错误。\n 执行过程中发生的错误都是一些不能再入队时被服务器发现的错误，这些错误会在命令实际执行时被触发 即使在事务的执行过程中发生了错误，服务器也不会中断事务的执行，它会继续执行事务中余下的其他命令，并且已执行的命令（包括执行命令所产生的结果）不会被出错的命令影响。    服务器停机\n 如果服务器运行在无持久化的内存模式下，那么重启之后的数据库将是空白，因此数据库总是一致 如果服务器运行在 RDB 模式下，那么事务中途停机不会导致不一致性，因为服务器可以根据现有的 RDB 文件来回复数据，从而将数据库还原到一个一致的状态。如果找不到可供使用的 RDB 文件，那么重启之后的数据库将是空白的，而空白数据库总是一致的。 如果服务器运行在 AOF 模式下，那么事务中途停机不会导致不一致性，因为服务器可以根据现有的 AOF文件来回复数据，从而将数据库还原到一个一致的状态。如果找不到可供使用的 AOF文件，那么重启之后的数据库将是空白的，而空白数据库总是一致的。    隔离性\n事务的隔离性指的是，即使数据库中有多个事务并发地执行，各个事务之间也不会互相影响，并在并发状态下执行的事务和串行执行的事务产生的结果完全相同。\n因为 Redis 使用单线程的方式来执行事务（以及事务队列中的命令），并且服务器保证，在执行事务期间不会对事务进行中断，因此，Redis 的事务总是以串行的方式运行的，并且事务也总是具有隔离性的。\n持久性\n事务的持久性指的是，当一个事务执行完毕时，执行这个事务所得的结果已被保存到永久性存储介质（比如硬盘）里面了，即使服务器在事务执行完毕之后停机，执行事务所得的结果也不会丢失。\n因为 Redis 的事务不过是简单地用队列包裹起了一组 Redis 命令，Redis 并没有为事务提供任何额外的持久化功能没所以 Redis 事务的持久性由 Redis 所使用的持久化模式决定。\n 当服务器在无持久化的内存模式下运作时，事务不具有持久性：一旦服务器停机，包括事务数据在内的所有服务器数据都将丢失 当服务器在 RDB 持久化模式下运作时，服务器只会在特定的保存条件被满足时，才会被执行 BGSAVE 命令，对数据库进行保存操作，并且异步执行的 BGSAVE 不能保证事务数据第一时间保存到硬盘里面，因此 RDB 持久化模式下的事务也不具有耐久性。 当服务器运行在 AOF 持久化模式下  appendfsync 选项的值为 always ，程序总会在执行命令之后调用同步函数，将命令数据真正地保存到硬盘里，这种配置下时具有持久性的 appendfsync 选项的值为 everysec 时，程序会每秒同步一次命令数据到硬盘。因为停机可能会恰好发生在等待同步的那一秒钟之内，这可能会造成事务数据丢失，所以这种配置下的事务不具有持久性。 appendfsync 选项的值为 no 时，程序会交由操作系统来决定何时将命令数据同步到硬盘。因为事务数据可能在等待同步的过程中丢失，所以这种配置下的事务不具有持久性    实现 客户端 org.isheihei.redis.core.client.RedisNormalClient 是客户端类，flag 标识当前客户端是否处在事务开启状态，dirtyCas 则标识当前客户端 WATCH 的键是否被更改过。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  public class RedisNormalClient implements RedisClient{ // 事务标志 true表示开启了一个事务  private boolean flag = false; private final Queue\u0026lt;Command\u0026gt; multiCmd = new LinkedList\u0026lt;\u0026gt;(); // 事务安全性标志 false表示安全  private boolean dirtyCas = false; @Override public void setFlag(boolean flag) { this.flag = flag; } @Override public boolean getFlag() { return this.flag; } @Override public void setDirtyCas(boolean dirtyCas) { this.dirtyCas = dirtyCas; } @Override public boolean getDirtyCas() { return dirtyCas; } @Override public void addCommand(Command command) { multiCmd.add(command); } @Override public void unWatchKeys(RedisClient redisClient) { for (RedisDB db : dbs) { db.unWatchKeys(redisClient); } } }   WATCH org.isheihei.redis.server.handler.CommandHandler 中给出了命令的处理逻辑，即\n 如果客户端发送的命令为 EXEC DISCARD、 WATCH， MULTI四个命令的其中一个，那么服务器立即执行这个命令 与此相反，如果客户端发送的命令是 EXEC DISCARD、 WATCH， MULTI 四个命令以外的命令，那么服务器并不立即执行这个命令，而是将这个命令放入一个事务队列里面，然后向客户端返回 QUEUED 回复  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44  protected void channelRead0(ChannelHandlerContext ctx, Command command) { try { if (command instanceof Quit) { ctx.close(); return; } // 如果开启了认证功能，所有命令执行前需要检查认证是否成功  if (ConfigUtil.getRequirePass() != null \u0026amp;\u0026amp; client.getAuth() == 0 \u0026amp;\u0026amp; command.type() != CommandType.auth) { ctx.writeAndFlush(new Errors(ErrorsConst.NO_AUTH)); return; } if (client.getFlag()) { if (command instanceof Exec || command instanceof Watch || command instanceof UnWatch || command instanceof Discard) { ctx.writeAndFlush(command.handle(client)); } else if (command instanceof Multi) { ctx.writeAndFlush(new Errors(ErrorsConst.MULTI_CAN_NOT_NESTED)); } else { client.addCommand(command); ctx.writeAndFlush(new SimpleString(\u0026#34;QUEUED\u0026#34;)); } } else { if (command instanceof Exec) { ctx.writeAndFlush(new Errors(ErrorsConst.EXEC_WITHOUT_MULTI)); } else if (command instanceof Discard) { ctx.writeAndFlush(new Errors(ErrorsConst.DISCARD_WITHOUT_MULTI)); } else if (command instanceof Save) { if (rdb != null) { rdb.save(); } ctx.writeAndFlush(command.handle(client)); } else if (command instanceof BgSave) { if (rdb != null) { rdb.bgSave(); } ctx.writeAndFlush(command.handle(client)); } else { ctx.writeAndFlush(command.handle(client)); } } } catch (Exception e) { LOGGER.error(\u0026#34;执行命令出错\u0026#34;, e); ctx.writeAndFlush(new Errors(ErrorsConst.INTERNEL_ERROR)); } }   WATCH 和 UNWATCH 命令的实现，用了一个 watchKeys 字典，其中字典的 key 是监视的键的 key，字典的 value 是弱引用 WeakHashMap。\n 弱引用（WeakReference）无法阻止GC回收，如果一个对象时弱引用可到达，那么在下一个GC回收执行时，该对象就会被回收掉。\nWeakHashMap如何不阻止对象回收呢\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  //\tWeakHashMap的Entry继承了WeakReference。 private static final class Entry\u0026lt;K, V\u0026gt; extends WeakReference\u0026lt;K\u0026gt; implements Map.Entry\u0026lt;K, V\u0026gt; { int hash; boolean isNull; V value; Entry\u0026lt;K, V\u0026gt; next; interface Type\u0026lt;R, K, V\u0026gt; { R get(Map.Entry\u0026lt;K, V\u0026gt; entry); } Entry(K key, V object, ReferenceQueue\u0026lt;K\u0026gt; queue) { //\tKey作为了WeakReference指向的对象  super(key, queue); isNull = key == null; hash = isNull ? 0 : key.hashCode(); value = object; }   WeakHashMap 通过在get()，size() 等操作前执行，删除掉引用为null的Entry。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  private void expungeStaleEntries() { for (Object x; (x = queue.poll()) != null; ) { synchronized (queue) { @SuppressWarnings(\u0026#34;unchecked\u0026#34;) Entry\u0026lt;K,V\u0026gt; e = (Entry\u0026lt;K,V\u0026gt;) x; int i = indexFor(e.hash, table.length); Entry\u0026lt;K,V\u0026gt; prev = table[i]; Entry\u0026lt;K,V\u0026gt; p = prev; while (p != null) { Entry\u0026lt;K,V\u0026gt; next = p.next; if (p == e) { if (prev == e) table[i] = next; else prev.next = next; // Must not null out e.next;  // stale entries may be in use by a HashIterator  e.value = null; // Help GC  size--; break; } prev = p; p = next; } } } }    这里为什么要用弱引用呢？\n当我们使用客户端连接的时候，服务器会创建一个对应的 RedisClien 对象，该连接的所有信息以及事务队列等都保存在这个客户端对象中。\n想象一个场景：当我们在使用 WATCH 监视了一个key，但是没有调用 EXEC 、UNWATCH 或 DISCARD 清空监视的key，而是直接断开了客户端连接。那么这个客户端对象实际上就是一个应该被回收的对象，但是由于 watchKeys 中还保留了该对象的引用，所以无法对该客户端对象进行 GC 回收，造成了内存泄漏。\n如果使用 WeakHashMap 弱引用，当客户端强行断开连接后， JVM 不会阻止只有一个弱引用对象的 GC 回收。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  public class RedisDBImpl implements RedisDB { // watch_keys 客户端使用弱引用对象 当客户端在事务执行中意外关闭的时候 会自动gc 防止占用内存  private final Map\u0026lt;BytesWrapper, WeakHashMap\u0026lt;RedisClient, Boolean\u0026gt;\u0026gt; watchKeys = new HashMap\u0026lt;\u0026gt;(); // 每对一个键进行修改时，需要进行判断该键是否被某些客户端监视，并修改对应客户端的事务安全性标志  @Override public void touchWatchKey(BytesWrapper key) { WeakHashMap\u0026lt;RedisClient, Boolean\u0026gt; map = watchKeys.get(key); if (map != null) { map.forEach((redisClient, aBoolean) -\u0026gt; redisClient.setDirtyCas(true)); } } @Override public void watchKeys(List\u0026lt;BytesWrapper\u0026gt; keys, RedisClient redisClient) { keys.forEach(key -\u0026gt; { if (watchKeys.containsKey(key)) { watchKeys.get(key).put(redisClient, true); } else { WeakHashMap\u0026lt;RedisClient, Boolean\u0026gt; clients = new WeakHashMap\u0026lt;\u0026gt;(); clients.put(redisClient, true); watchKeys.put(key, clients); } }); } @Override public void unWatchKeys(RedisClient redisClient) { for (Map.Entry\u0026lt;BytesWrapper, WeakHashMap\u0026lt;RedisClient, Boolean\u0026gt;\u0026gt; mapEntry : watchKeys.entrySet()) { mapEntry.getValue().remove(redisClient); } } }   EXEC 事务的执行与 Redis 不同的一点是，如果事务中某条命令存在语法错误，Redis 会在命令入队时就进行报错，并废弃整个事务。\n而我的实现中由于命令的检查过程是在命令实际执行时，所以没有分离出两步检查，无法在入队时进行语法检查。但是实际执行的过程中，只会执行那些语法和实际执行都合法的操作。\n后续也可以进行优化，改为和 Redis 一致的语法检查顺序，但是需要重构所有的命令处理类，工作量比较大，以后有机会的话会慢慢实现。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  public class Exec extends AbstractCommand { @Override public CommandType type() { return CommandType.exec; } @Override public Resp handle(RedisClient redisClient) { // 如果watch key被改动了 则全部拒绝执行  // 如果watch未被改动，则全部执行（执行出错或者语法错误的命令都会失败）  ArrayList\u0026lt;Resp\u0026gt; resps = new ArrayList\u0026lt;\u0026gt;(); if (redisClient.getDirtyCas()) { resps.add(BulkString.NullBulkString); } else { Command cmd; while ((cmd = redisClient.getCommand()) != null) { Resp resp = cmd.handle(redisClient); resps.add(resp); } } redisClient.flushCommand(); redisClient.setDirtyCas(false); redisClient.getDb().unWatchKeys(redisClient); redisClient.setFlag(false); return new RespArray(resps.toArray(new Resp[0])); } }   ","date":"2022-06-22T16:40:21+08:00","image":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B005-%E4%BA%8B%E5%8A%A1/log_hu0a4ba87b3d81b22780f8a722f1e0fc9b_1722333_120x120_fill_q75_box_smart1.jpg","permalink":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B005-%E4%BA%8B%E5%8A%A1/","title":"Redis设计与实现05-事务"},{"content":"持久化分为 RDB 和 AOF 两种。相关实现位于org.isheihei.redis.core.persist\nRDB RDB 文件的创建与载入 RDB 文件创建的条件有两种\n 通过执行 SVAE 和 BGSAVE 命令手动保存。其中 SAVE 会阻塞当前所有命令；而 BGSAVE 是在子进程中执行，服务器在期间仍然可以处理命令。 自动间隔性保存  自动间隔性保存\n在 RDB 中有一些保存条件，他们是一个二元组形式的集合，如果满足其中任何一个条件，就会执行 RDB 文件保存\n1 2 3 4 5  /** * 保存条件 * 900 1 ： 900s内对数据库进行了至少1次修改 */ private Map\u0026lt;Long, Long\u0026gt; saveParams = new HashMap\u0026lt;\u0026gt;();   除了 saveParams 数组之外，还会维护 dirty 计数器，以及一个 lastSave 属性\n dirty 计数器记录距离上一次 RDB 持久化后，数据库的修改次数 lastSave 是一个 UNIX 时间戳，记录了服务器上一次成功执行 RDB 持久化的时间  通过周期事件 ServerCron 调用函数判断是否满足间隔保存条件，如果满足条件，则执行持久化操作：\n1 2 3 4 5 6 7 8  public boolean satisfySaveParams() { long dirtyCount = dbs.stream().mapToLong(RedisDB::getDirty).sum(); long interVal = TimeUnit.MICROSECONDS.toSeconds(System.currentTimeMillis() - lastSave); boolean anyMatch = saveParams.entrySet().stream() .filter(param -\u0026gt; param.getValue() \u0026lt;= dirtyCount) .anyMatch(param -\u0026gt; param.getKey() \u0026gt; interVal); return anyMatch; }   RDB 文件的载入\n会在服务器初始化时进行，如果 RDB 和 AOF 持久化同时开启，会优先使用 AOF 文件进行加载\n1 2 3 4 5 6 7 8 9 10 11 12  // rdb 和 aof 同时开启优先使用aof文件加载 if (dataBase \u0026amp;\u0026amp; appendOnlyFile) { redisSingleEventExecutor.submit(() -\u0026gt; aof.load()); serverCron.aof(aof); serverCron.rdb(rdb); } else if (dataBase) { redisSingleEventExecutor.submit(() -\u0026gt; rdb.load()); serverCron.rdb(rdb); } else if (appendOnlyFile){ redisSingleEventExecutor.submit(() -\u0026gt; aof.load()); serverCron.aof(aof); }   RDB 文件格式 Redis 的 RDB 持久化文件是二进制文件，这里同样参考 Redis 的格式，可能会有些许差异。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  /** * RDB文件结构 * REDIS | db_version | databases | EOF | check_sum * 5B | 4B | | 1B | 8B * * databases部分 * SELECTDB | db_number | key_value_pairs * 1B | 4B | * * key_value_pairs部分 * EXPIRETIME_MS | ms | TYPE | key | value * 1B | 8B | 1B | key_len(4B) + key(ken_len) | value_len(4B) + value(value_len) * * TYPE: * string 0 * map 1 * list 2 * set 3 * zset 4 */   文件读写操作使用的是 MappedByteBuffer\n相对于java io操作中通常采用BufferedReader，BufferedInputStream等带缓冲的IO类处理大文件，java nio中引入了一种基于MappedByteBuffer操作大文件的方式，把文件映射到虚拟内存，其读写性能极高。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161  @Override public synchronized void save() { LOGGER.info(\u0026#34;开始进行rdb持久化...\u0026#34;); try { // 每次持久化需要创建新的文件  deleteFile(); createFile(); long writeIndex = 0L; FileChannel channel = new RandomAccessFile(fileName + suffix, \u0026#34;rw\u0026#34;).getChannel(); MappedByteBuffer mappedByteBuffer = channel.map(FileChannel.MapMode.READ_WRITE, 0, 9); mappedByteBuffer.put(REDIS); //REDIS 5  mappedByteBuffer.putInt(DB_VERSION); // 0001 4  writeIndex += 9; for (int dbIndex = 0; dbIndex \u0026lt; dbs.size(); dbIndex ++) { RedisDB db = dbs.get(dbIndex); if (db.size() == 0) { continue; } mappedByteBuffer = channel.map(FileChannel.MapMode.READ_WRITE, writeIndex, 5); mappedByteBuffer.put(SELECTDB); // X 1  mappedByteBuffer.putInt(dbIndex); // NULL * 4  writeIndex += 5; Map\u0026lt;BytesWrapper, RedisObject\u0026gt; dict = db.dict(); Map\u0026lt;BytesWrapper, Long\u0026gt; expires = db.expires(); Iterator\u0026lt;Map.Entry\u0026lt;BytesWrapper, RedisObject\u0026gt;\u0026gt; entryIterator = dict.entrySet().iterator(); while (entryIterator.hasNext()) { Map.Entry\u0026lt;BytesWrapper, RedisObject\u0026gt; next = entryIterator.next(); BytesWrapper nextKey = next.getKey(); RedisObject value = next.getValue(); mappedByteBuffer = channel.map(FileChannel.MapMode.READ_WRITE, writeIndex, 10); mappedByteBuffer.put(EXPIRETIME_MS); // V  if (db.expires().containsKey(nextKey)) { mappedByteBuffer.putLong(db.getTtl(nextKey)); } else { mappedByteBuffer.putLong(0L); // NULL * 4  } mappedByteBuffer.put(value.getCode()); // 1  writeIndex += 10; int nextLen = nextKey.length(); mappedByteBuffer = channel.map(FileChannel.MapMode.READ_WRITE, writeIndex, 4 + nextLen); mappedByteBuffer.putInt(nextLen); mappedByteBuffer.put(next.getKey().getByteArray()); writeIndex += (nextLen + 4); byte[] objectBytes = next.getValue().objectToBytes(); int objectLen = objectBytes.length; mappedByteBuffer = channel.map(FileChannel.MapMode.READ_WRITE, writeIndex, objectLen + 4); mappedByteBuffer.putInt(objectLen); mappedByteBuffer.put(objectBytes); writeIndex += (objectLen + 4); } mappedByteBuffer = channel.map(FileChannel.MapMode.READ_WRITE, writeIndex, 1); mappedByteBuffer.put(EOF); writeIndex += 1; } mappedByteBuffer = channel.map(FileChannel.MapMode.READ_WRITE, writeIndex, 1); mappedByteBuffer.put(EOF); writeIndex += 1; channel.close(); lastSave = System.currentTimeMillis(); resetDbDirty(); LOGGER.info(\u0026#34;rdb持久化完成\u0026#34;); } catch (FileNotFoundException e) { LOGGER.error(\u0026#34;未找到.rdb文件\u0026#34;); throw new RuntimeException(e); } catch (IOException e) { LOGGER.error(\u0026#34;rdb持久化出错\u0026#34;); throw new RuntimeException(e); } } @Override public void load() { try { long readIndex = 0L; FileChannel channel = new RandomAccessFile(fileName + suffix, \u0026#34;rw\u0026#34;).getChannel(); if (channel.size() == 0) { LOGGER.info(\u0026#34;rdb文件为空\u0026#34;); return; } MappedByteBuffer mappedByteBuffer = channel.map(FileChannel.MapMode.READ_ONLY, 0, 9); for (int i = 0; i \u0026lt; 5; i++) { if (REDIS[i] != mappedByteBuffer.get()) { LOGGER.error(\u0026#34;rdb文件魔数错误\u0026#34;); throw new IOException(); } } if (DB_VERSION != mappedByteBuffer.getInt()) { LOGGER.error(\u0026#34;rdb文件版本错误\u0026#34;); throw new IOException(); } readIndex += 9; while (true){ mappedByteBuffer = channel.map(FileChannel.MapMode.READ_ONLY, readIndex, 1); if (SELECTDB != mappedByteBuffer.get()) { LOGGER.info(\u0026#34;数据库已经加载完成\u0026#34;); break; } readIndex += 1; mappedByteBuffer = channel.map(FileChannel.MapMode.READ_ONLY, readIndex, 4); int dbIndex = mappedByteBuffer.getInt(); RedisDB db = dbs.get(dbIndex); readIndex += 4; while (EOF != channel.map(FileChannel.MapMode.READ_ONLY, readIndex, 1).get(0)) { mappedByteBuffer = channel.map(FileChannel.MapMode.READ_ONLY, readIndex, 14); if (EXPIRETIME_MS != mappedByteBuffer.get()) { LOGGER.error(\u0026#34;rdb文件格式错误\u0026#34;); throw new IOException(); } long ttl = mappedByteBuffer.getLong(); byte type = mappedByteBuffer.get(); RedisObject redisObject; if (type == (byte) 0) { redisObject = new RedisStringObject(); } else if (type == (byte) 1) { redisObject = new RedisMapObject(); } else if (type == (byte) 2) { redisObject = new RedisListObject(); } else if (type == (byte) 3) { redisObject = new RedisSetObject(); } else{ redisObject = new RedisZSetObject(); } int keyLen = mappedByteBuffer.getInt(); readIndex += 14; mappedByteBuffer = channel.map(FileChannel.MapMode.READ_ONLY, readIndex, keyLen); bufferPolled.writeBytes(mappedByteBuffer); readIndex += keyLen; byte[] keyBytes = ByteBufUtil.getBytes(bufferPolled); bufferPolled.clear(); BytesWrapper key = new BytesWrapper(keyBytes); db.put(key, redisObject); db.expire(key, ttl); // ttl 为0即不设置过期  mappedByteBuffer = channel.map(FileChannel.MapMode.READ_ONLY, readIndex, 4); int valueLen = mappedByteBuffer.getInt(); readIndex += 4; mappedByteBuffer = channel.map(FileChannel.MapMode.READ_ONLY, readIndex, valueLen); bufferPolled.writeBytes(mappedByteBuffer); redisObject.loadRdb(bufferPolled); bufferPolled.clear(); readIndex += valueLen; } if (EOF != channel.map(FileChannel.MapMode.READ_ONLY, readIndex, 1).get(0)) { channel.close(); LOGGER.info(\u0026#34;rdb数据全部加载完成\u0026#34;); return; } lastSave = System.currentTimeMillis(); deleteFile(); } } catch (FileNotFoundException e) { e.printStackTrace(); LOGGER.error(\u0026#34;rdb文件加载失败\u0026#34;); } catch (IOException e) { LOGGER.error(\u0026#34;rdb文件加载失败\u0026#34;); e.printStackTrace(); } } public void bgSave() { new Thread(this::save).start(); }   AOF 持久化 AOF 持久化主要通过将修改命令追加到持久化文件中。在Redis设计与实现03-命令 (isheihei.cn)中介绍了写命令的命令执行过程。即：先执行数据库写命令，如果 AOF 开启，则将命令写入 AOF 写队列中。\nAOF 写队列持久化到磁盘的过程还是在周期事件 ServerCron 中被调用。周期是每 100ms 一次。目前只实现了这一种同步方式，所以可能会有极端情况导致数据丢失的情况。\n文件读写操作依然使用的是 MappedByteBuffer\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49  @Override public void save() { if (bufferQueue.isEmpty()) { return; } try (FileChannel channel = new RandomAccessFile(fileName + suffix, \u0026#34;rw\u0026#34;).getChannel()){ LOGGER.info(\u0026#34;开始rdb持久化...\u0026#34;); do { bufferPolled.clear(); long len = channel.size(); Resp resp = bufferQueue.peek(); Resp.write(resp, bufferPolled); int respLen = bufferPolled.readableBytes(); MappedByteBuffer mappedByteBuffer = channel.map(FileChannel.MapMode.READ_WRITE, len, respLen); mappedByteBuffer.put(ByteBufUtil.getBytes(bufferPolled)); bufferQueue.poll(); } while (!bufferQueue.isEmpty()); LOGGER.info(\u0026#34;rdb持久化完成\u0026#34;); } catch (Exception e) { bufferPolled.release(); LOGGER.error(\u0026#34;aof Exception \u0026#34;, e); } } @Override public void load() { try (FileChannel channel = new RandomAccessFile(fileName + suffix, \u0026#34;rw\u0026#34;).getChannel()) { long len = channel.size(); if (len == 0) { LOGGER.info(\u0026#34;aof文件为空\u0026#34;); return; } MappedByteBuffer mappedByteBuffer = channel.map(FileChannel.MapMode.READ_ONLY, 0, len); bufferPolled.writeBytes(mappedByteBuffer); while (bufferPolled.readableBytes() \u0026gt; 0) { Resp resp = Resp.decode(bufferPolled); Command command = CommandFactory.from((RespArray) resp); if (command != null) { AbstractWriteCommand writeCommand = (AbstractWriteCommand) command; writeCommand.handleLoadAof(this.mockClient); } } LOGGER.info(\u0026#34;加载aof文件完成\u0026#34;); } catch (Exception e) { bufferPolled.release(); LOGGER.error(\u0026#34;加载aof文件失败\u0026#34;); LOGGER.error(\u0026#34;aof Exception \u0026#34;, e); } }   ","date":"2022-06-21T16:40:26+08:00","image":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B006-%E6%8C%81%E4%B9%85%E5%8C%96/log_hu0a4ba87b3d81b22780f8a722f1e0fc9b_1722333_120x120_fill_q75_box_smart1.jpg","permalink":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B006-%E6%8C%81%E4%B9%85%E5%8C%96/","title":"Redis设计与实现06-持久化"},{"content":"测试环境 测试环境 CentOS-7，2核2G，网络带宽 4M\n连接并发数 50\n本地测试 请求数量1000000\nRedis 吞吐量：\n set ：96404.12 requests per second get：95392.54 requests per second  延迟：99% 小于 2ms，100 % 小于 3ms\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  [root@ecs bin]# redis-benchmark -h 127.0.0.1 -p 6379 -c 50 -t set,get -n 1000000 ====== SET ====== 1000000 requests completed in 10.37 seconds 50 parallel clients 3 bytes payload keep alive: 1 98.77% \u0026lt;= 1 milliseconds 99.97% \u0026lt;= 2 milliseconds 100.00% \u0026lt;= 3 milliseconds 100.00% \u0026lt;= 3 milliseconds 96404.12 requests per second ====== GET ====== 1000000 requests completed in 10.48 seconds 50 parallel clients 3 bytes payload keep alive: 1 99.98% \u0026lt;= 1 milliseconds 100.00% \u0026lt;= 2 milliseconds 100.00% \u0026lt;= 2 milliseconds 95392.54 requests per second   Java-Redis 吞吐量：\n set ：96852.30 requests per second get：98931.54 requests per second  延迟：99% 以上 小于 1ms，100 % 小于 2ms。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  [root@ecs-215297 ~]# redis-benchmark -h 127.0.0.1 -p 6379 -c 50 -t set,get -n 1000000 ====== SET ====== 1000000 requests completed in 10.32 seconds 50 parallel clients 3 bytes payload keep alive: 1 99.19% \u0026lt;= 1 milliseconds 100.00% \u0026lt;= 2 milliseconds 100.00% \u0026lt;= 2 milliseconds 96852.30 requests per second ====== GET ====== 1000000 requests completed in 10.11 seconds 50 parallel clients 3 bytes payload keep alive: 1 99.99% \u0026lt;= 1 milliseconds 100.00% \u0026lt;= 1 milliseconds 98931.54 requests per second   网络测试结果 请求数量 50000\nRedis 吞吐量：\n set ：1564.46 requests per second get： 1572.67 requests per second  延迟：99% 以上小于 36ms，100% 小于 78ms\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105  D:redis\u0026gt;redis-benchmark -h **** -p 6379 -c 50 -t set,get -n 50000 ====== SET ====== 50000 requests completed in 31.96 seconds 50 parallel clients 3 bytes payload keep alive: 1 0.00% \u0026lt;= 28 milliseconds 0.07% \u0026lt;= 29 milliseconds 6.09% \u0026lt;= 30 milliseconds 30.29% \u0026lt;= 31 milliseconds 52.48% \u0026lt;= 32 milliseconds 82.82% \u0026lt;= 33 milliseconds 95.00% \u0026lt;= 34 milliseconds 98.62% \u0026lt;= 35 milliseconds 99.35% \u0026lt;= 36 milliseconds 99.62% \u0026lt;= 37 milliseconds 99.76% \u0026lt;= 38 milliseconds 99.83% \u0026lt;= 39 milliseconds 99.85% \u0026lt;= 40 milliseconds 99.86% \u0026lt;= 41 milliseconds 99.87% \u0026lt;= 42 milliseconds 99.88% \u0026lt;= 43 milliseconds 99.89% \u0026lt;= 44 milliseconds 99.90% \u0026lt;= 45 milliseconds 99.90% \u0026lt;= 46 milliseconds 99.90% \u0026lt;= 48 milliseconds 99.90% \u0026lt;= 49 milliseconds 99.91% \u0026lt;= 50 milliseconds 99.91% \u0026lt;= 51 milliseconds 99.91% \u0026lt;= 52 milliseconds 99.92% \u0026lt;= 53 milliseconds 99.93% \u0026lt;= 54 milliseconds 99.93% \u0026lt;= 55 milliseconds 99.93% \u0026lt;= 56 milliseconds 99.94% \u0026lt;= 57 milliseconds 99.94% \u0026lt;= 58 milliseconds 99.94% \u0026lt;= 59 milliseconds 99.95% \u0026lt;= 60 milliseconds 99.95% \u0026lt;= 61 milliseconds 99.96% \u0026lt;= 66 milliseconds 99.96% \u0026lt;= 67 milliseconds 99.96% \u0026lt;= 68 milliseconds 99.97% \u0026lt;= 69 milliseconds 99.98% \u0026lt;= 70 milliseconds 99.98% \u0026lt;= 72 milliseconds 99.99% \u0026lt;= 74 milliseconds 99.99% \u0026lt;= 75 milliseconds 99.99% \u0026lt;= 76 milliseconds 99.99% \u0026lt;= 77 milliseconds 100.00% \u0026lt;= 78 milliseconds 100.00% \u0026lt;= 78 milliseconds 1564.46 requests per second ====== GET ====== 50000 requests completed in 31.79 seconds 50 parallel clients 3 bytes payload keep alive: 1 0.00% \u0026lt;= 28 milliseconds 0.65% \u0026lt;= 29 milliseconds 10.31% \u0026lt;= 30 milliseconds 29.60% \u0026lt;= 31 milliseconds 62.84% \u0026lt;= 32 milliseconds 85.18% \u0026lt;= 33 milliseconds 95.62% \u0026lt;= 34 milliseconds 98.32% \u0026lt;= 35 milliseconds 99.14% \u0026lt;= 36 milliseconds 99.49% \u0026lt;= 37 milliseconds 99.66% \u0026lt;= 38 milliseconds 99.77% \u0026lt;= 39 milliseconds 99.81% \u0026lt;= 40 milliseconds 99.84% \u0026lt;= 41 milliseconds 99.86% \u0026lt;= 42 milliseconds 99.87% \u0026lt;= 43 milliseconds 99.88% \u0026lt;= 44 milliseconds 99.90% \u0026lt;= 45 milliseconds 99.90% \u0026lt;= 46 milliseconds 99.90% \u0026lt;= 47 milliseconds 99.90% \u0026lt;= 49 milliseconds 99.91% \u0026lt;= 51 milliseconds 99.91% \u0026lt;= 53 milliseconds 99.91% \u0026lt;= 54 milliseconds 99.92% \u0026lt;= 55 milliseconds 99.92% \u0026lt;= 56 milliseconds 99.93% \u0026lt;= 57 milliseconds 99.93% \u0026lt;= 58 milliseconds 99.94% \u0026lt;= 61 milliseconds 99.94% \u0026lt;= 62 milliseconds 99.95% \u0026lt;= 64 milliseconds 99.95% \u0026lt;= 65 milliseconds 99.96% \u0026lt;= 66 milliseconds 99.96% \u0026lt;= 67 milliseconds 99.96% \u0026lt;= 68 milliseconds 99.96% \u0026lt;= 69 milliseconds 99.97% \u0026lt;= 70 milliseconds 99.97% \u0026lt;= 71 milliseconds 99.98% \u0026lt;= 72 milliseconds 99.98% \u0026lt;= 73 milliseconds 99.99% \u0026lt;= 74 milliseconds 99.99% \u0026lt;= 75 milliseconds 100.00% \u0026lt;= 77 milliseconds 100.00% \u0026lt;= 78 milliseconds 1572.67 requests per second   Java-Redis 吞吐量：\n set ：1552.36 requests per second get： 1558.46 requests per second  延迟：99% 以上小于 42 ms，100% 小于 72 ms。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87  D:redis\u0026gt;redis-benchmark -h 120.46.135.216 -p 6379 -c 50 -t set,get -n 50000 ====== SET ====== 50000 requests completed in 32.21 seconds 50 parallel clients 3 bytes payload keep alive: 1 0.00% \u0026lt;= 27 milliseconds 0.00% \u0026lt;= 28 milliseconds 0.88% \u0026lt;= 29 milliseconds 8.23% \u0026lt;= 30 milliseconds 28.70% \u0026lt;= 31 milliseconds 53.11% \u0026lt;= 32 milliseconds 78.21% \u0026lt;= 33 milliseconds 90.96% \u0026lt;= 34 milliseconds 94.83% \u0026lt;= 35 milliseconds 96.62% \u0026lt;= 36 milliseconds 97.55% \u0026lt;= 37 milliseconds 98.04% \u0026lt;= 38 milliseconds 98.48% \u0026lt;= 39 milliseconds 98.78% \u0026lt;= 40 milliseconds 98.94% \u0026lt;= 41 milliseconds 99.12% \u0026lt;= 42 milliseconds 99.31% \u0026lt;= 43 milliseconds 99.39% \u0026lt;= 44 milliseconds 99.48% \u0026lt;= 45 milliseconds 99.53% \u0026lt;= 46 milliseconds 99.58% \u0026lt;= 47 milliseconds 99.63% \u0026lt;= 48 milliseconds 99.73% \u0026lt;= 49 milliseconds 99.76% \u0026lt;= 50 milliseconds 99.80% \u0026lt;= 51 milliseconds 99.83% \u0026lt;= 52 milliseconds 99.86% \u0026lt;= 53 milliseconds 99.88% \u0026lt;= 54 milliseconds 99.89% \u0026lt;= 55 milliseconds 99.90% \u0026lt;= 56 milliseconds 99.93% \u0026lt;= 57 milliseconds 99.94% \u0026lt;= 58 milliseconds 99.94% \u0026lt;= 59 milliseconds 99.96% \u0026lt;= 60 milliseconds 99.96% \u0026lt;= 61 milliseconds 99.97% \u0026lt;= 62 milliseconds 99.97% \u0026lt;= 63 milliseconds 99.97% \u0026lt;= 64 milliseconds 99.98% \u0026lt;= 65 milliseconds 99.98% \u0026lt;= 67 milliseconds 99.98% \u0026lt;= 68 milliseconds 99.99% \u0026lt;= 69 milliseconds 99.99% \u0026lt;= 70 milliseconds 99.99% \u0026lt;= 71 milliseconds 100.00% \u0026lt;= 72 milliseconds 100.00% \u0026lt;= 75 milliseconds 1552.36 requests per second ====== GET ====== 50000 requests completed in 32.08 seconds 50 parallel clients 3 bytes payload keep alive: 1 0.00% \u0026lt;= 27 milliseconds 0.01% \u0026lt;= 28 milliseconds 0.89% \u0026lt;= 29 milliseconds 4.70% \u0026lt;= 30 milliseconds 27.64% \u0026lt;= 31 milliseconds 49.15% \u0026lt;= 32 milliseconds 76.35% \u0026lt;= 33 milliseconds 93.47% \u0026lt;= 34 milliseconds 97.96% \u0026lt;= 35 milliseconds 99.14% \u0026lt;= 36 milliseconds 99.62% \u0026lt;= 37 milliseconds 99.82% \u0026lt;= 38 milliseconds 99.90% \u0026lt;= 39 milliseconds 99.94% \u0026lt;= 40 milliseconds 99.96% \u0026lt;= 41 milliseconds 99.98% \u0026lt;= 42 milliseconds 99.98% \u0026lt;= 43 milliseconds 99.98% \u0026lt;= 44 milliseconds 99.99% \u0026lt;= 45 milliseconds 99.99% \u0026lt;= 47 milliseconds 99.99% \u0026lt;= 49 milliseconds 99.99% \u0026lt;= 50 milliseconds 99.99% \u0026lt;= 52 milliseconds 100.00% \u0026lt;= 53 milliseconds 100.00% \u0026lt;= 56 milliseconds 1558.46 requests per second   结论 可以看出，无论是本地测试还是网络测试， Java-Redis 的吞吐量和延迟与 Redis 基本相当。\n","date":"2022-06-20T22:34:42+08:00","image":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B007-%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/log_hu0a4ba87b3d81b22780f8a722f1e0fc9b_1722333_120x120_fill_q75_box_smart1.jpg","permalink":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B007-%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/","title":"Redis设计与实现07 性能测试"},{"content":"Arrays.sort(arr) 冒泡排序（超时） 快排 单指针版 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  public int[] MySort(int[] arr) { quickSort(arr, 0, arr.length - 1); return arr; } private void quickSort(int[] array, int start, int end) { if (start \u0026lt; end) { int key = array[start];//用待排数组的第一个作为中枢  int i = start; for (int j = start + 1; j \u0026lt;= end; j++) { if (key \u0026gt; array[j]) { swap(array, j, ++i); } } array[start] = array[i];//先挪，然后再把中枢放到指定位置  array[i] = key; quickSort(array, start, i - 1); quickSort(array, i + 1, end); } } //交换两个数的值  public void swap(int[] A, int i, int j) { if (i != j) { A[i] ^= A[j]; A[j] ^= A[i]; A[i] ^= A[j]; } }   双指针优化 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  public class Solution { public int[] MySort (int[] arr) { quickSort(arr, 0, arr.length - 1); return arr; } public void quickSort(int[] arr, int start, int end){ if(start \u0026gt;= end){ return; } int pivot = arr[start]; int left = start, right = end; while(left \u0026lt; right){ while(left \u0026lt; right \u0026amp;\u0026amp; arr[right] \u0026gt;= pivot){ right--; } swap(arr, left, right); while(left \u0026lt; right \u0026amp;\u0026amp; arr[left] \u0026lt;= pivot){ left++; } swap(arr, left, right); } quickSort(arr, start, left - 1); quickSort(arr, left + 1, end); } private void swap(int[] arr, int i, int j) { int temp = arr[i]; arr[i] = arr[j]; arr[j] = temp; } }   归并 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44  public class Solution { public int[] MySort (int[] arr) { mergeSort(arr, 0, arr.length - 1); return arr; } public void mergeSort(int[] arr, int left, int right){ if(left ==right){ return; } int mid = left + (right - left) / 2; mergeSort(arr, left, mid); mergeSort(arr, mid + 1, right); merge(arr, left, mid, right); } private void merge(int[] arr, int left, int mid, int right){ //辅助数组，先把合并结果放进去，再拷贝回原数组  int[] temp = new int[right - left + 1]; int i = 0; int p1 = left; int p2 = mid + 1; //比较拷贝，直其中一半已经拷贝完成  while(p1 \u0026lt;= mid \u0026amp;\u0026amp; p2 \u0026lt;= right){ temp[i++] = arr[p1] \u0026lt;= arr[p2] ? arr[p1++] : arr[p2++]; } //p2先完成，把p1直接拷贝进去即可  while(p1 \u0026lt;= mid){ temp[i++] = arr[p1++]; } //p1先完成，把p2直接拷贝进去即可  while(p2 \u0026lt;= right){ temp[i++] = arr[p2++]; } for(i = 0; i \u0026lt; temp.length; i++){ arr[left + i] = temp[i]; } } }   堆排序 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78  public class Solution { public int[] MySort (int[] arr) { heapSort(arr); return arr; } /** * 堆是完全二叉树 * 使用数组存储 * 一个节点下标为i： * - 父节点: (i-1)/2 * - 左子节点：2i+1 * - 右子节点: 2i+2 */ public int[] heapSort(int[] nums) { int len = nums.length; // 将数组整理成堆  heapify(nums); // 循环不变量：区间 [0, i] 堆有序  for (int i = len - 1; i \u0026gt;= 1; ) { // 把堆顶元素（当前最大）交换到数组末尾  swap(nums, 0, i); // 把排好的元素剔除堆的范围  i--; // 堆顶元素进行下沉操作，使得区间 [0, i] 堆有序  siftDown(nums, 0, i); } return nums; } /** * 将数组整理成堆（堆有序） * * @param nums */ private void heapify(int[] nums) { int len = nums.length; // 只需要从 i = (len - 1) / 2 这个节点开始，倒序进行逐个下沉调整  // 每个节点调整的过程中可能会对下面已经调整过的产生影响，如果子节点变化需要递归的向下调整  for (int i = (len - 1) / 2; i \u0026gt;= 0; i--) { siftDown(nums, i, len - 1); } } /** * @param nums * @param k 当前进行下沉的元素的下标 * @param end [0, end] 是 nums 的有效部分 */ private void siftDown(int[] nums, int k, int end) { while (2 * k + 1 \u0026lt;= end) { int j = 2 * k + 1; //如果左子节点小于右子节点：将j指向右子节点  if (j + 1 \u0026lt;= end \u0026amp;\u0026amp; nums[j + 1] \u0026gt; nums[j]) { j++; } //如果子节点中较大的与父节点进行比较  if (nums[j] \u0026gt; nums[k]) { swap(nums, j, k); } else { //不需要任何交换，满足堆的条件  break; } //！重要：因为j可能变换，所以继续的向下调整  k = j; } } private void swap(int[] arr, int i, int j){ int temp = arr[i]; arr[i] = arr[j]; arr[j] = temp; } }   ","date":"2022-05-24T18:18:45+08:00","permalink":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E6%8E%92%E5%BA%8F/","title":"排序"},{"content":"可达性分析 GC Roots 可达性分析算法：也可以称为根搜索算法、追踪性垃圾收集\nGC Roots 对象：\n 虚拟机栈中局部变量表中引用的对象：各个线程被调用的方法中使用到的参数、局部变量等 本地方法栈中引用的对象 堆中类静态属性引用的对象 方法区中的常量引用的对象 字符串常量池（string Table）里的引用 同步锁 synchronized 持有的对象  GC Roots 是一组活跃的引用，不是对象，放在 GC Roots Set 集合\n工作原理 可达性分析算法以根对象集合（GCRoots）为起始点，从上至下的方式搜索被根对象集合所连接的目标对象\n分析工作必须在一个保障一致性的快照中进行，否则结果的准确性无法保证，这也是导致 GC 进行时必须 Stop The World 的一个原因\n基本原理：\n  可达性分析算法后，内存中的存活对象都会被根对象集合直接或间接连接着，搜索走过的路径称为引用链\n  如果目标对象没有任何引用链相连，则是不可达的，就意味着该对象己经死亡，可以标记为垃圾对象\n  在可达性分析算法中，只有能够被根对象集合直接或者间接连接的对象才是存活对象\n  三色标记 标记算法 三色标记法把遍历对象图过程中遇到的对象，标记成以下三种颜色：\n 白色：尚未访问过 灰色：本对象已访问过，但是本对象引用到的其他对象尚未全部访问 黑色：本对象已访问过，而且本对象引用到的其他对象也全部访问完成  当 Stop The World (STW) 时，对象间的引用是不会发生变化的，可以轻松完成标记，遍历访问过程为：\n 初始时，所有对象都在白色集合 将 GC Roots 直接引用到的对象挪到灰色集合 从灰色集合中获取对象：  将本对象引用到的其他对象全部挪到灰色集合中 将本对象挪到黑色集合里面   重复步骤 3，直至灰色集合为空时结束 结束后，仍在白色集合的对象即为 GC Roots 不可达，可以进行回收  并发标记 并发标记时，对象间的引用可能发生变化，多标和漏标的情况就有可能发生\n多标情况：当 E 变为灰色或黑色时，其他线程断开的 D 对 E 的引用，导致这部分对象仍会被标记为存活，本轮 GC 不会回收这部分内存，这部分本应该回收但是没有回收到的内存，被称之为浮动垃圾\n 针对并发标记开始后的新对象，通常的做法是直接全部当成黑色，也算浮动垃圾 浮动垃圾并不会影响应用程序的正确性，只是需要等到下一轮垃圾回收中才被清除  漏标情况：\n 条件一：灰色对象断开了对一个白色对象的引用（直接或间接），即灰色对象原成员变量的引用发生了变化 条件二：其他线程中修改了黑色对象，插入了一条或多条对该白色对象的新引用 结果：导致该白色对象当作垃圾被 GC，影响到了程序的正确性  代码角度解释漏标：\n1 2 3  Object G = objE.fieldG; // 读 objE.fieldG = null; // 写 objD.fieldG = G; // 写   为了解决问题，可以操作上面三步，将对象 G 记录起来，然后作为灰色对象再进行遍历，比如放到一个特定的集合，等初始的 GC Roots 遍历完（并发标记），再遍历该集合（重新标记）\n 所以重新标记需要 STW，应用程序一直在运行，该集合可能会一直增加新的对象，导致永远都运行不完\n 解决方法：添加读写屏障，读屏障拦截第一步，写屏障拦截第二三步，在读写前后进行一些后置处理：\n  写屏障 + 增量更新：黑色对象新增引用，会将黑色对象变成灰色对象，最后对该节点重新扫描\n增量更新 (Incremental Update) 破坏了条件二，从而保证了不会漏标\n缺点：对黑色变灰的对象重新扫描所有引用，比较耗费时间\n  写屏障 (Store Barrier) + SATB：当原来成员变量的引用发生变化之前，记录下原来的引用对象\n保留 GC 开始时的对象图，即原始快照 SATB，当 GC Roots 确定后，对象图就已经确定，那后续的标记也应该是按照这个时刻的对象图走，如果期间对白色对象有了新的引用会记录下来，并且将白色对象变灰（说明可达了），重新扫描该对象的引用关系\nSATB (Snapshot At The Beginning) 破坏了条件一，从而保证了不会漏标\n  读屏障 (Load Barrier)：破坏条件二，黑色对象引用白色对象的前提是获取到该对象，此时读屏障发挥作用\n  以 Java HotSpot VM 为例，其并发标记时对漏标的处理方案如下：\n CMS：写屏障 + 增量更新 G1：写屏障 + SATB ZGC：读屏障  垃圾回收器 普通 Serial Serial：串行垃圾收集器，作用于新生代，是指使用单线程进行垃圾回收，采用复制算法，新生代基本都是复制算法，因为分区了\nSTW（Stop-The-World）：垃圾回收时，只有一个线程在工作，并且 Java 应用中的所有线程都要暂停，等待垃圾回收的完成\nSerial old：执行老年代垃圾回收的串行收集器，内存回收算法使用的是标记-整理算法，同样也采用了串行回收和 STW 机制\n Serial old 是 Client 模式下默认的老年代的垃圾回收器 Serial old 在 Server 模式下主要有两个用途：  在 JDK 1.5 以及之前版本（Parallel Old 诞生以前）中与 Parallel Scavenge 收集器搭配使用 作为老年代 CMS 收集器的后备垃圾回收方案，在并发收集发生 Concurrent Mode Failure 时使用    开启参数：-XX:+UseSerialGC 等价于新生代用 Serial GC 且老年代用 Serial old GC\n优点：简单而高效（与其他收集器的单线程比），对于限定单个 CPU 的环境来说，Serial 收集器由于没有线程交互的开销，可以获得最高的单线程收集效率\n缺点：对于交互性较强的应用而言，这种垃圾收集器是不能够接受的，比如 JavaWeb 应用\nParNew Par 是 Parallel 并行的缩写，New 是只能处理的是新生代\n并行垃圾收集器在串行垃圾收集器的基础之上做了改进，采用复制算法，将单线程改为了多线程进行垃圾回收，可以缩短垃圾回收的时间\n对于其他的行为（收集算法、stop the world、对象分配规则、回收策略等）同 Serial 收集器一样，应用在年轻代，除 Serial 外，只有ParNew GC 能与 CMS 收集器配合工作\n相关参数：\n  -XX：+UseParNewGC：表示年轻代使用并行收集器，不影响老年代\n  -XX:ParallelGCThreads：默认开启和 CPU 数量相同的线程数\n  ParNew 是很多 JVM 运行在 Server 模式下新生代的默认垃圾收集器\n 对于新生代，回收次数频繁，使用并行方式高效 对于老年代，回收次数少，使用串行方式节省资源（CPU 并行需要切换线程，串行可以省去切换线程的资源）  Parallel Parallel Scavenge 收集器是应用于新生代的并行垃圾回收器，采用复制算法、并行回收和 Stop the World 机制\n**Parallel Old ** 收集器：是一个应用于老年代的并行垃圾回收器，采用标记-整理算法\n对比其他回收器：\n 其它收集器目标是尽可能缩短垃圾收集时用户线程的停顿时间 Parallel 目标是达到一个可控制的吞吐量，被称为吞吐量优先收集器 Parallel Scavenge 对比 ParNew 拥有自适应调节策略，可以通过一个开关参数打开 GC Ergonomics  应用场景：\n 停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验 高吞吐量可以高效率地利用 CPU 时间，尽快完成程序的运算任务，适合在后台运算而不需要太多交互  停顿时间和吞吐量的关系：新生代空间变小 → 缩短停顿时间 → 垃圾回收变得频繁 → 导致吞吐量下降\n在注重吞吐量及 CPU 资源敏感的场合，都可以优先考虑 Parallel Scavenge + Parallel Old 收集器，在 Server 模式下的内存回收性能很好，Java8 默认是此垃圾收集器组合\n参数配置：\n -XX：+UseParallelGC：手动指定年轻代使用 Paralle 并行收集器执行内存回收任务 -XX：+UseParalleloldcc：手动指定老年代使用并行回收收集器执行内存回收任务  上面两个参数，默认开启一个，另一个也会被开启（互相激活），默认 JDK8 是开启的   -XX:+UseAdaptivesizepplicy：设置 Parallel scavenge 收集器具有自适应调节策略，在这种模式下，年轻代的大小、Eden 和 Survivor 的比例、晋升老年代的对象年龄等参数会被自动调整，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量 -XX:ParallelGcrhreads：设置年轻代并行收集器的线程数，一般与 CPU 数量相等，以避免过多的线程数影响垃圾收集性能  在默认情况下，当 CPU 数量小于 8 个，ParallelGcThreads 的值等于 CPU 数量 当 CPU 数量大于 8 个，ParallelGCThreads 的值等于 3+[5*CPU Count]/8]   -XX:MaxGCPauseMillis：设置垃圾收集器最大停顿时间（即 STW 的时间），单位是毫秒  对于用户来讲，停顿时间越短体验越好；在服务器端，注重高并发，整体的吞吐量 为了把停顿时间控制在 MaxGCPauseMillis 以内，收集器在工作时会调整 Java 堆大小或其他一些参数   -XX:GCTimeRatio：垃圾收集时间占总时间的比例 =1/(N+1)，用于衡量吞吐量的大小  取值范围（0，100）。默认值 99，也就是垃圾回收时间不超过 1 与 -xx:MaxGCPauseMillis 参数有一定矛盾性，暂停时间越长，Radio 参数就容易超过设定的比例    并发 CMS CMS 全称 Concurrent Mark Sweep，是一款并发的、使用标记-清除算法、针对老年代的垃圾回收器，其最大特点是让垃圾收集线程与用户线程同时工作\nCMS 收集器的关注点是尽可能缩短垃圾收集时用户线程的停顿时间，停顿时间越短（低延迟）越适合与用户交互的程序，良好的响应速度能提升用户体验\n分为以下四个流程：\n 初始标记：使用 STW 出现短暂停顿，仅标记一下 GC Roots 能直接关联到的对象，速度很快 并发标记：进行 GC Roots 开始遍历整个对象图，在整个回收过程中耗时最长，不需要 STW，可以与用户线程并发运行 重新标记：修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，比初始标记时间长但远比并发标记时间短，需要 STW（不停顿就会一直变化，采用写屏障 + 增量更新来避免漏标情况） 并发清除：清除标记为可以回收对象，不需要移动存活对象，所以这个阶段可以与用户线程同时并发的  Mark Sweep 会造成内存碎片，不把算法换成 Mark Compact 的原因：Mark Compact 算法会整理内存，导致用户线程使用的对象的地址改变，影响用户线程继续执行\n在整个过程中耗时最长的并发标记和并发清除过程中，收集器线程都可以与用户线程一起工作，不需要进行停顿\n优点：并发收集、低延迟\n缺点：\n  吞吐量降低：在并发阶段虽然不会导致用户停顿，但是会因为占用了一部分线程而导致应用程序变慢，CPU 利用率不够高\n  CMS 收集器无法处理浮动垃圾，可能出现 Concurrent Mode Failure 导致另一次 Full GC 的产生\n浮动垃圾是指并发清除阶段由于用户线程继续运行而产生的垃圾（产生了新对象），这部分垃圾只能到下一次 GC 时才能进行回收。由于浮动垃圾的存在，CMS 收集需要预留出一部分内存，不能等待老年代快满的时候再回收。如果预留的内存不够存放浮动垃圾，就会出现 Concurrent Mode Failure，这时虚拟机将临时启用 Serial Old 来替代 CMS，导致很长的停顿时间\n  标记 - 清除算法导致的空间碎片，往往出现老年代空间无法找到足够大连续空间来分配当前对象，不得不提前触发一次 Full GC；为新对象分配内存空间时，将无法使用指针碰撞（Bump the Pointer）技术，而只能够选择空闲列表（Free List）执行内存分配\n  参数设置：\n  -XX：+UseConcMarkSweepGC：手动指定使用 CMS 收集器执行内存回收任务\n开启该参数后会自动将 -XX:+UseParNewGC 打开，即：ParNew + CMS + Serial old的组合\n  -XX:CMSInitiatingoccupanyFraction：设置堆内存使用率的阈值，一旦达到该阈值，便开始进行回收\n JDK5 及以前版本的默认值为 68，即当老年代的空间使用率达到 68% 时，会执行一次CMS回收 JDK6 及以上版本默认值为 92%    -XX:+UseCMSCompactAtFullCollection：用于指定在执行完 Full GC 后对内存空间进行压缩整理，以此避免内存碎片的产生，由于内存压缩整理过程无法并发执行，所带来的问题就是停顿时间变得更长\n  -XX:CMSFullGCsBeforecompaction：设置在执行多少次 Full GC 后对内存空间进行压缩整理\n  -XX:ParallelCMSThreads：设置 CMS 的线程数量\n CMS 默认启动的线程数是 (ParallelGCThreads+3)/4，ParallelGCThreads 是年轻代并行收集器的线程数 收集线程占用的 CPU 资源多于25%，对用户程序影响可能较大；当 CPU 资源比较紧张时，受到 CMS 收集器线程的影响，应用程序的性能在垃圾回收阶段可能会非常糟糕    G1 收集器 G1 特点 G1（Garbage-First）是一款面向服务端应用的垃圾收集器，应用于新生代和老年代、采用标记-整理算法、软实时、低延迟、可设定目标（最大 STW 停顿时间）的垃圾回收器，用于代替 CMS，适用于较大的堆（\u0026gt;4 ~ 6G），在 JDK9 之后默认使用 G1\nG1 对比其他处理器的优点：\n  并发与并行：\n 并行性：G1 在回收期间，可以有多个 GC 线程同时工作，有效利用多核计算能力，此时用户线程 STW 并发性：G1 拥有与应用程序交替执行的能力，部分工作可以和应用程序同时执行，因此不会在整个回收阶段发生完全阻塞应用程序的情况 其他的垃圾收集器使用内置的 JVM 线程执行 GC 的多线程操作，而 G1 GC 可以采用应用线程承担后台运行的 GC 工作，JVM 的 GC 线程处理速度慢时，系统会调用应用程序线程加速垃圾回收过程    分区算法：\n  从分代上看，G1 属于分代型垃圾回收器，区分年轻代和老年代，年轻代依然有 Eden 区和 Survivor 区。从堆结构上看，新生代和老年代不再物理隔离，不用担心每个代内存是否足够，这种特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一次 GC\n  将整个堆划分成约 2048 个大小相同的独立 Region 块，每个 Region 块大小根据堆空间的实际大小而定，整体被控制在 1MB 到 32 MB之间且为 2 的 N 次幂，所有 Region 大小相同，在 JVM 生命周期内不会被改变。G1 把堆划分成多个大小相等的独立区域，使得每个小空间可以单独进行垃圾回收\n  新的区域 Humongous：本身属于老年代区，当出现了一个巨型对象超出了分区容量的一半，该对象就会进入到该区域。如果一个 H 区装不下一个巨型对象，那么 G1 会寻找连续的 H 分区来存储，为了能找到连续的 H 区，有时候不得不启动 Full GC\n  G1 不会对巨型对象进行拷贝，回收时被优先考虑，G1 会跟踪老年代所有 incoming 引用，这样老年代 incoming 引用为 0 的巨型对象就可以在新生代垃圾回收时处理掉\n  Region 结构图：\n    ​\t  空间整合：\n CMS：标记-清除算法、内存碎片、若干次 GC 后进行一次碎片整理 G1：整体来看是基于标记 - 整理算法实现的收集器，从局部（Region 之间）上来看是基于复制算法实现的，两种算法都可以避免内存碎片    可预测的停顿时间模型（软实时 soft real-time）：可以指定在 M 毫秒的时间片段内，消耗在 GC 上的时间不得超过 N 毫秒\n 由于分块的原因，G1 可以只选取部分区域进行内存回收，这样缩小了回收的范围，对于全局停顿情况也能得到较好的控制 G1 跟踪各个 Region 里面的垃圾堆积的价值大小（回收所获得的空间大小以及回收所需时间，通过过去回收的经验获得），在后台维护一个优先列表，每次根据允许的收集时间优先回收价值最大的 Region，保证了 G1 收集器在有限的时间内可以获取尽可能高的收集效率   相比于 CMS GC，G1 未必能做到 CMS 在最好情况下的延时停顿，但是最差情况要好很多    G1 垃圾收集器的缺点：\n 相较于 CMS，G1 还不具备全方位、压倒性优势。比如在用户程序运行过程中，G1 无论是为了垃圾收集产生的内存占用还是程序运行时的额外执行负载都要比 CMS 要高 从经验上来说，在小内存应用上 CMS 的表现大概率会优于 G1，而 G1 在大内存应用上则发挥其优势，平衡点在 6-8GB 之间  应用场景：\n 面向服务端应用，针对具有大内存、多处理器的机器 需要低 GC 延迟，并具有大堆的应用程序提供解决方案  记忆集 对象不是孤立的，对象之间会存在跨代引用。\n 假如只局限于新生代的收集，那么我们将错误的回收E；若想正确回收，那就需要对老年区同样做一次GC搜索，明显效率低下。\n 假如要现在进行一次只局限于新生代区域内的收集（Minor GC），但新生代中的对象是完全有可能被老年代所引用的，为了找出该区域中的存活对象，不得不在固定的GC Roots之外，再额外遍历整个老年代中所有对象来确保可达性分析结果的正确性，反过来也是一样 。遍历整个老年代所有对象 的方案虽然理论上可行，但无疑会为内存回收带来很大的性能负担。\n记忆集 Remembered Set 在新生代中，每个 Region 都有一个 Remembered Set，用来被哪些其他 Region 里的对象引用（谁引用了我就记录谁）\n 程序对 Reference 类型数据写操作时，产生一个 Write Barrier 暂时中断操作，检查该对象和 Reference 类型数据是否在不同的 Region（跨代引用），不同就将相关引用信息记录到 Reference 类型所属的 Region 的 Remembered Set 之中 进行内存回收时，在 GC 根节点的枚举范围中加入 Remembered Set 即可保证不对全堆扫描也不会有遗漏  垃圾收集器在新生代中建立了记忆集这样的数据结构，可以理解为它是一个抽象类，具体实现记忆集的三种方式：\n 字长精度 对象精度 卡精度(卡表)  卡表（Card Table）在老年代中，是一种对记忆集的具体实现，主要定义了记忆集的记录精度、与堆内存的映射关系等，卡表中的每一个元素都对应着一块特定大小的内存块，这个内存块称之为卡页（card page），当存在跨代引用时，会将卡页标记为 dirty，JVM 对于卡页的维护也是通过写屏障的方式\n收集集合 CSet 代表每次 GC 暂停时回收的一系列目标分区，在任意一次收集暂停中，CSet 所有分区都会被释放，内部存活的对象都会被转移到分配的空闲分区中。年轻代收集 CSet 只容纳年轻代分区，而混合收集会通过启发式算法，在老年代候选回收分区中，筛选出回收收益最高的分区添加到 CSet 中\n CSet of Young Collection CSet of Mix Collection  工作原理 G1 中提供了三种垃圾回收模式：YoungGC、Mixed GC 和 Full GC，在不同的条件下被触发\n 当堆内存使用达到一定值（默认 45%）时，开始老年代并发标记过程 标记完成马上开始混合回收过程  顺时针：Young GC → Young GC + Concurrent Mark → Mixed GC 顺序，进行垃圾回收\n  Young GC：发生在年轻代的 GC 算法，一般对象（除了巨型对象）都是在 eden region 中分配内存，当所有 eden region 被耗尽无法申请内存时，就会触发一次 Young GC，G1 停止应用程序的执行 STW，把活跃对象放入老年代，垃圾对象回收\n回收过程：\n 扫描根：根引用连同 RSet 记录的外部引用作为扫描存活对象的入口 更新 RSet：处理 dirty card queue 更新 RS，此后 RSet 准确的反映对象的引用关系  dirty card queue：类似缓存，产生了引用先记录在这里，然后更新到 RSet 作用：产生引用直接更新 RSet 需要线程同步开销很大，使用队列性能好   处理 RSet：识别被老年代对象指向的 Eden 中的对象，这些被指向的对象被认为是存活的对象，把需要回收的分区放入 Young CSet 中进行回收 复制对象：Eden 区内存段中存活的对象会被复制到 survivor 区，survivor 区内存段中存活的对象如果年龄未达阈值，年龄会加1，达到阀值会被会被复制到 old 区中空的内存分段，如果 survivor 空间不够，Eden 空间的部分数据会直接晋升到老年代空间 处理引用：处理 Soft，Weak，Phantom，JNI Weak 等引用，最终 Eden 空间的数据为空，GC 停止工作    **Concurrent Mark **：\n 初始标记：标记从根节点直接可达的对象，这个阶段是 STW 的，并且会触发一次年轻代 GC 并发标记 (Concurrent Marking)：在整个堆中进行并发标记（应用程序并发执行），可能被 YoungGC 中断。会计算每个区域的对象活性，即区域中存活对象的比例，若区域中的所有对象都是垃圾，则这个区域会被立即回收（实时回收），给浮动垃圾准备出更多的空间，把需要收集的 Region 放入 CSet 当中 最终标记：为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程的 Remembered Set Logs 里面，最终标记阶段需要把 Remembered Set Logs 的数据合并到 Remembered Set 中，这阶段需要停顿线程，但是可并行执行（防止漏标） 筛选回收：并发清理阶段，首先对 CSet 中各个 Region 中的回收价值和成本进行排序，根据用户所期望的 GC 停顿时间来制定回收计划，也需要 STW    Mixed GC：当很多对象晋升到老年代时，为了避免堆内存被耗尽，虚拟机会触发一个混合的垃圾收集器，即 Mixed GC，除了回收整个 young region，还会回收一部分的 old region，过程同 YGC\n注意：是一部分老年代，而不是全部老年代，可以选择哪些老年代 region 收集，对垃圾回收的时间进行控制\n在 G1 中，Mixed GC 可以通过 -XX:InitiatingHeapOccupancyPercent 设置阈值\n  Full GC：对象内存分配速度过快，Mixed GC 来不及回收，导致老年代被填满，就会触发一次 Full GC，G1 的 Full GC 算法就是单线程执行的垃圾回收，会导致异常长时间的暂停时间，需要进行不断的调优，尽可能的避免 Full GC\n产生 Full GC 的原因：\n 晋升时没有足够的空间存放晋升的对象 并发处理过程完成之前空间耗尽，浮动垃圾    相关参数  -XX:+UseG1GC：手动指定使用 G1 垃圾收集器执行内存回收任务 -XX:G1HeapRegionSize：设置每个 Region 的大小。值是 2 的幂，范围是 1MB 到 32MB 之间，目标是根据最小的 Java 堆大小划分出约 2048 个区域，默认是堆内存的 1/2000 -XX:MaxGCPauseMillis：设置期望达到的最大 GC 停顿时间指标，JVM会尽力实现，但不保证达到，默认值是 200ms -XX:+ParallelGcThread：设置 STW 时 GC 线程数的值，最多设置为 8 -XX:ConcGCThreads：设置并发标记线程数，设置为并行垃圾回收线程数 ParallelGcThreads 的1/4左右 -XX:InitiatingHeapoccupancyPercent：设置触发并发 Mixed GC 周期的 Java 堆占用率阈值，超过此值，就触发 GC，默认值是 45 -XX:+ClassUnloadingWithConcurrentMark：并发标记类卸载，默认启用，所有对象都经过并发标记后，就可以知道哪些类不再被使用，当一个类加载器的所有类都不再使用，则卸载它所加载的所有类 -XX:G1NewSizePercent：新生代占用整个堆内存的最小百分比（默认5％） -XX:G1MaxNewSizePercent：新生代占用整个堆内存的最大百分比（默认60％） -XX:G1ReservePercent=10：保留内存区域，防止 to space（Survivor中的 to 区）溢出  G1 (Garbage-First) 是一款面向服务器的垃圾收集器,主要针对配备多颗处理器及大容量内存的机器. 以极高概率满足 GC 停顿时间要求的同时,还具备高吞吐量性能特征.\n被视为 JDK1.7 中 HotSpot 虚拟机的一个重要进化特征。它具备一下特点：\n 并行与并发：G1 能充分利用 CPU、多核环境下的硬件优势，使用多个 CPU（CPU 或者 CPU 核心）来缩短 Stop-The-World 停顿时间。部分其他收集器原本需要停顿 Java 线程执行的 GC 动作，G1 收集器仍然可以通过并发的方式让 java 程序继续执行。 分代收集：虽然 G1 可以不需要其他收集器配合就能独立管理整个 GC 堆，但是还是保留了分代的概念。 空间整合：与 CMS 的“标记-清理”算法不同，G1 从整体来看是基于“标记-整理”算法实现的收集器；从局部上来看是基于“标记-复制”算法实现的。 可预测的停顿：这是 G1 相对于 CMS 的另一个大优势，降低停顿时间是 G1 和 CMS 共同的关注点，但 G1 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为 M 毫秒的时间片段内。  G1 收集器的运作大致分为以下几个步骤：\n  初始标记(Initial Marking)：这阶段仅仅只是标记GC Roots能直接关联到的对象并修改TAMS(Next Top at Mark Start)的值，让下一阶段用户程序并发运行时，能在正确的可用的Region中创建新对象，这阶段需要停顿线程，但是耗时很短。而且是借用进行Minor GC的时候同步完成的，所以G1收集器在这个阶段实际并没有额外的停顿。\n  并发标记(Concurrent Marking)：从GC Roots开始对堆的对象进行可达性分析，递归扫描整个堆里的对象图，找出存活的对象，这阶段耗时较长，但是可以与用户程序并发执行。当对象图扫描完成以后，还要重新处理SATB记录下的在并发时有引用变动的对象。\n  最终标记(Final Marking)：对用户线程做另一个短暂的暂停，用于处理并发阶段结束后仍遗留下来的最后那少量的 SATB 记录。\n  筛选回收(Live Data Counting and Evacuation)：负责更新 Region 的统计数据，对各个 Region 的回收价值和成本进行排序，根据用户所期望的停顿时间来制定回收计划。可以自由选择多个Region来构成回收集，然后把回收的那一部分Region中的存活对象==复制==到空的Region中，在对那些Region进行清空。\n 除了并发标记外，其余过程都要 STW\n   G1 收集器在后台维护了一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的 Region(这也就是它的名字 Garbage-First 的由来) 。这种使用 Region 划分内存空间以及有优先级的区域回收方式，保证了 G1 收集器在有限时间内可以尽可能高的收集效率（把内存化整为零）。\n 不管是G1还是其他分代收集器，JVM都是使用 记忆集(Remembered Set) 来避免全局扫描。 每个Region都有一个对应的记忆集。 每次Reference类型数据写操作时，都会产生一个 写屏障（Write Barrier）暂时去终止操作 然后检查将要写入的引用 指向的对象是否和该Reference类型数据在不同的 Region（其他收集器：检查老年代对象是否引用了新生代对象） 如果不同，通过 卡表（Card Table）把相关引用信息记录到引用指向对象的所在Region对应的记忆集(Remembered Set) 中，被引用对象记录引用自己的对象，这样被引用对象要可达性分析时候，可以找记忆集中的对象 当进行垃圾收集时，在GC Roots枚举范围加上记忆集；就可以保证不进行全局扫描了。  参考  《深入理解 Java 虚拟机：JVM 高级特性与最佳实践（第二版》 https://docs.oracle.com/javase/specs/jvms/se8/html/index.html 参考文章：https://www.jianshu.com/p/12544c0ad5c1  ","date":"2022-05-24T17:24:10+08:00","permalink":"https://isheihei.github.io/posts/java/jvm-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/","title":"JVM 垃圾回收"},{"content":"线程安全与锁优化 线程安全 Java语言中的线程安全 不可变\nJava语言中，如果多线程共享的数据是一个基本数据类型，那么只要在定义时使用final关键字修饰它就可以保证它是不可变的\n只要一个不可变的对象被正确地构建出来（即没有发生this引用逃逸的情况），那其外部的可见状态永远都不会改变，永远都不会看到它在多个线程之中处于不一致的状态。“不可变”带来的安全性是最直接、最纯粹的。\n绝对线程安全\n这个定义其实是很严格的，一个类要达到“不管运行时环境如何，调用者都不需要任何额外的同步措施”可能需要付出非常高昂的，甚至不切实际的代价。\n在Java API中标注自己是线程安全的类，大多数都不是绝对的线程安全。\n相对线程安全\n相对线程安全就是我们通常意义上所讲的线程安全，它需要保证对这个对象单次的操作是线程安全的，我们在调用的时候不需要进行额外的保障措施，但是对于一些特定顺序的连续调用，就可能需要在调用端使用额外的同步手段来保证调用的正确性。\n线程兼容\n线程兼容是指对象本身并不是线程安全的，但是可以通过在调用端正确地使用同步手段来保证对象在并发环境中可以安全地使用。\n线程对立\n线程对立是指不管调用端是否采取了同步措施，都无法在多线程环境中并发使用代码。\n一个线程对立的例子是Thread类的suspend()和resume()方法。如果有两个线程同时持有一个线程对象，一个尝试去中断线程，一个尝试去恢复线程，在并发进行的情况下，无论调用时是否进行了同步，目标线程都存在死锁风险——假如suspend()中断的线程就是即将要执行resume()的那个线程，那就肯定要产生死锁了。\n线程安全的实现方法 互斥同步\n在Java里面，最基本的互斥同步手段就是synchronized关键字，这是一种块结构（Block Structured）的同步语法。synchronized关键字经过Javac编译之后，会在同步块的前后分别形成monitorenter和monitorexit这两个字节码指令。\n这两个字节码指令都需要一个reference类型的参数来指明要锁定和解锁的对象。如果Java源码中的synchronized明确指定了对象参数，那就以这个对象的引用作为reference；如果没有明确指定，那将根据synchronized修饰的方法类型（如实例方法或类方法），来决定是取代码所在的对象实例还是取类型对应的Class对象来作为线程要持有的锁\n从功能上看，根据以上《Java虚拟机规范》对monitorenter和monitorexit的行为描述，我们可以得出两个关于synchronized的直接推论，这是使用它时需特别注意的：\n 被synchronized修饰的同步块对同一条线程来说是可重入的。这意味着同一线程反复进入同步块也不会出现自己把自己锁死的情况。 被synchronized修饰的同步块在持有锁的线程执行完毕并释放锁之前，会无条件地阻塞后面其他线程的进入。这意味着无法像处理某些数据库中的锁那样，强制已获取锁的线程释放锁；也无法强制正在等待锁的线程中断等待或超时退出。  从执行成本的角度看，持有锁是一个重量级（Heavy-Weight）的操作。在主流Java虚拟机实现中，Java的线程是映射到操作系统的原生内核线程之上的，如果要阻塞或唤醒一条线程，则需要操作系统来帮忙完成，这就不可避免地陷入用户态到核心态的转换中，进行这种状态转换需要耗费很多的处理器时间。尤其是对于代码特别简单的同步块（譬如被synchronized修饰的getter()或setter()方法），状态转换消耗的时间甚至会比用户代码本身执行的时间还要长。因此才说，synchronized是Java语言中一个重量级的操作，有经验的程序员都只会在确实必要的情况下才使用这种操作。\n**重入锁（ReentrantLock）**是Lock接口最常见的一种实现，顾名思义，它与synchronized一样是可重入的。在基本用法上，ReentrantLock也与synchronized很相似，只是代码写法上稍有区别而已。不过，ReentrantLock与synchronized相比增加了一些高级功能，主要有以下三项：等待可中断、可实现公平锁及锁可以绑定多个条件。\n 等待可中断：是指当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情。可中断特性对处理执行时间非常长的同步块很有帮助。 公平锁：是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁；而非公平 锁则不保证这一点，在锁被释放时，任何一个等待锁的线程都有机会获得锁。synchronized中的锁是非公平的，ReentrantLock在默认情况下也是非公平的，但可以通过带布尔值的构造函数要求使用公平锁。不过一旦使用了公平锁，将会导致ReentrantLock的性能急剧下降，会明显影响吞吐量。 锁绑定多个条件：是指一个ReentrantLock对象可以同时绑定多个Condition对象。在synchronized中，锁对象的wait()跟它的notify()或者notifyAll()方法配合可以实现一个隐含的条件，如果要和多于一个的条件关联的时候，就不得不额外添加一个锁；而ReentrantLock则无须这样做，多次调用newCondition()方法即可。  ReentrantLock在功能上是synchronized的超集，在性能上又至少不会弱于synchronized，那synchronized修饰符是否应该被直接抛弃，不再使用了呢？当然不是，基于以下理由，笔者仍然推荐在synchronized与ReentrantLock都可满足需要时优先使用synchronized：\n synchronized是在Java语法层面的同步，足够清晰，也足够简单。每个Java程序员都熟悉synchronized，但J.U.C中的Lock接口则并非如此。因此在只需要基础的同步功能时，更推荐synchronized。 Lock应该确保在finally块中释放锁，否则一旦受同步保护的代码块中抛出异常，则有可能永远不会释放持有的锁。这一点必须由程序员自己来保证，而使用synchronized的话则可以由Java虚拟机来确保即使出现异常，锁也能被自动释放。 尽管在JDK 5时代ReentrantLock曾经在性能上领先过synchronized，但这已经是十多年之前的胜利了。从长远来看，Java虚拟机更容易针对synchronized来进行优化，因为Java虚拟机可以在线程和对象的元数据中记录synchronized中锁的相关信息，而使用J.U.C中的Lock的话，Java虚拟机是很难得知具体哪些锁对象是由特定线程锁持有的。  非阻塞同步\n随着硬件指令集的发展，我们已经有了另外一个选择：基于冲突检测的乐观并发策略，通俗地说就是不管风险，先进行操作，如果没有其他线程争用共享数据，那操作就直接成功了；如果共享的数据的确被争用，产生了冲突，那再进行其他的补偿措施，最常用的补偿措施是不断地重试，直到出现没有竞争的共享数据为止。这种乐观并发策略的实现不再需要把线程阻塞挂起，因此这种同步操作被称为非阻塞同步（Non-Blocking Synchronization），使用这种措施的代码也常被称为无锁（Lock-Free）编程。\n硬件保证某些从语义上看起来需要多次操作的行为可以只通过一条处理器指令就能完成，这类指令常用的有：\n 测试并设置（Test-and-Set）； 获取并增加（Fetch-and-Increment）； 交换（Swap）； 比较并交换（Compare-and-Swap，下文称CAS）； 加载链接/条件储存（Load-Linked/Store-Conditional，下文称LL/SC）。  CAS指令需要有三个操作数，分别是内存位置（在Java中可以简单地理解为变量的内存地址，用V表示）、旧的预期值（用A表示）和准备设置的新值（用B表示）。CAS指令执行时，当且仅当V符合A时，处理器才会用B更新V的值，否则它就不执行更新。但是，不管是否更新了V的值，都会返回V的旧值，上述的处理过程是一个原子操作，执行期间不会被其他线程中断。\n无同步方案\n要保证线程安全，也并非一定要进行阻塞或非阻塞同步，同步与线程安全两者没有必然的联系。同步只是保障存在共享数据争用时正确性的手段，如果能让一个方法本来就不涉及共享数据，那它自然就不需要任何同步措施去保证其正确性，因此会有一些代码天生就是线程安全的，简单介绍其中的两类。\n可重入代码（Reentrant Code）：这种代码又称纯代码（Pure Code），是指可以在代码执行的任何时刻中断它，转而去执行另外一段代码（包括递归调用它本身），而在控制权返回后，原来的程序不会出现任何错误，也不会对结果有所影响。在特指多线程的上下文语境里（不涉及信号量等因素），我们可以认为可重入代码是线程安全代码的一个真子集，这意味着相对线程安全来说，可重入性是更为基础的特性，它可以保证代码线程安全，即所有可重入的代码都是线程安全的，但并非所有的线程安全的代码都是可重入的。\n可重入代码有一些共同的特征，例如，不依赖全局变量、存储在堆上的数据和公用的系统资源，用到的状态量都由参数中传入，不调用非可重入的方法等。我们可以通过一个比较简单的原则来判断代码是否具备可重入性：如果一个方法的返回结果是可以预测的，只要输入了相同的数据，就都能返回相同的结果，那它就满足可重入性的要求，当然也就是线程安全的。\n线程本地存储（Thread Local Storage）：如果一段代码中所需要的数据必须与其他代码共享，那就看看这些共享数据的代码是否能保证在同一个线程中执行。如果能保证，我们就可以把共享数据的可见范围限制在同一个线程之内，这样，无须同步也能保证线程之间不出现数据争用的问题。\n锁优化 Java虚拟机中，synchronized支持的同步方法和同步语句都是使用monitor来实现的。每个对象都与一个monitor相关联，当一个线程执行到一个monitor监视下的代码块中的第一个指令时，该线程必须在引用的对象上获得一个锁，这个锁是monitor实现的。在HotSpot虚拟机中，monitor是由ObjectMonitor实现，使用C++编写实现，具体代码在HotSpot虚拟机源码ObjectMonitor.hpp文件中。\n查看源码会发现，主要的属性有_count(记录该线程获取锁的次数)、_recursions(锁的重入次数)、_owner(指向持有ObjectMonitor对象的线程)、_WaitSet(处于wait状态的线程集合)、_EntryList(处于等待锁block状态的线程队列)。\n当并发线程执行synchronized修饰的方法或语句块时，先进入_EntryList中，当某个线程获取到对象的monitor后，把monitor对象中的_owner变量设置为当前线程，同时monitor对象中的计数器_count加1，当前线程获取同步锁成功。\n当synchronized修饰的方法或语句块中的线程调用wait()方法时，当前线程将释放持有的monitor对象，monitor对象中的_owner变量赋值为null，同时，monitor对象中的_count值减1，然后当前线程进入_WaitSet集合中等待被唤醒。\n自旋锁与自适应自旋 如果物理机器有一个以上的处理器或者处理器核心，能让两个或以上的线程同时并行执行，我们就可以让后面请求锁的那个线程“稍等一会”，但不放弃处理器的执行时间，看看持有锁的线程是否很快就会释放锁。为了让线程等待，我们只须让线程执行一个忙循环（自旋），这项技术就是所谓的自旋锁。\n在JDK 6中对自旋锁的优化，引入了自适应的自旋。自适应意味着自旋的时间不再是固定的了，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定的。如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也很有可能再次成功，进而允许自旋等待持续相对更长的时间\n如果对于某个锁，自旋很少成功获得过锁，那在以后要获取这个锁时将有可能直接省略掉自旋过程，以避免浪费处理器资源。\n锁消除 锁消除是指虚拟机即时编译器在运行时，对一些代码要求同步，但是对被检测到不可能存在共享数据竞争的锁进行消除。锁消除的主要判定依据来源于逃逸分析的数据支持（第11章已经讲解过逃逸分析技术），如果判断到一段代码中，在堆上的所有数据都不会逃逸出去被其他线程访问到，那就可以把它们当作栈上数据对待，认为它们是线程私有的，同步加锁自然就无须再进行。\n锁粗化 原则上，我们在编写代码的时候，总是推荐将同步块的作用范围限制得尽量小——只在共享数据的实际作用域中才进行同步，这样是为了使得需要同步的操作数量尽可能变少，即使存在锁竞争，等待锁的线程也能尽可能快地拿到锁。\n大多数情况下，上面的原则都是正确的，但是如果一系列的连续操作都对同一个对象反复加锁和解锁，甚至加锁操作是出现在循环体之中的，那即使没有线程竞争，频繁地进行互斥同步操作也会导致不必要的性能损耗。\n如果虚拟机探测到有这样一串零碎的操作都对同一个对象加锁，将会把加锁同步的范围扩展（粗化）到整个操作序列的外部\n轻量级锁 轻量级锁并不是用来代替重量级锁的，它设计的初衷是在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗。\n32位HotSpot虚拟机对象头Mark Word\n接下来介绍轻量级锁的工作过程：在代码即将进入同步块的时候，如果此同步对象没有被锁定（锁标志位为“01”状态），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝（官方为这份拷贝加了一个Displaced前缀，即Displaced Mark Word），这时候线程堆栈与对象头的状态如图。\n然后，虚拟机将使用CAS操作尝试把对象的Mark Word更新为指向Lock Record的指针。如果这个更新动作成功了，即代表该线程拥有了这个对象的锁，并且对象Mark Word的锁标志位（Mark Word的最后两个比特）将转变为“00”，表示此对象处于轻量级锁定状态。这时候线程堆栈与对象头的状态如图所示。\n如果这个更新操作失败了，那就意味着至少存在一条线程与当前线程竞争获取该对象的锁。虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是，说明当前线程已经拥有了这个对象的锁，那直接进入同步块继续执行就可以了，否则就说明这个锁对象已经被其他线程抢占了。如果出现两条以上的线程争用同一个锁的情况，那轻量级锁就不再有效，必须要膨胀为重量级锁，锁标志的状态值变为“10”，此时Mark Word中存储的就是指向重量级锁（互斥量）的指针，后面等待锁的线程也必须进入阻塞状态。\n上面描述的是轻量级锁的加锁过程，它的解锁过程也同样是通过CAS操作来进行的，如果对象的Mark Word仍然指向线程的锁记录，那就用CAS操作把对象当前的Mark Word和线程中复制DisplacedMark Word替换回来。假如能够成功替换，那整个同步过程就顺利完成了；如果替换失败，则说明有其他线程尝试过获取该锁，就要在释放锁的同时，唤醒被挂起的线程。\n轻量级锁能提升程序同步性能的依据是“对于绝大部分的锁，在整个同步周期内都是不存在竞争的”这一经验法则。如果没有竞争，轻量级锁便通过CAS操作成功避免了使用互斥量的开销；但如果确实存在锁竞争，除了互斥量的本身开销外，还额外发生了CAS操作的开销。因此在有竞争的情况下，轻量级锁反而会比传统的重量级锁更慢。\n偏向锁 偏向锁的思想是偏向于让第一个获取锁对象的线程，这个线程在之后获取该锁就不再需要进行同步操作，甚至连 CAS 操作也不再需要。\n当锁对象第一次被线程获得的时候，进入偏向状态，标记为 |1|01|（前面内存布局图中说明了，这属于偏向锁状态）。同时使用 CAS 操作将线程 ID （ThreadID）记录到 Mark Word 中，如果 CAS 操作成功，这个线程以后每次进入这个锁相关的同步块就不需要再进行任何同步操作。\n当有另外一个线程去尝试获取这个锁对象时，偏向状态就宣告结束，此时撤销偏向（Revoke Bias）后恢复到未锁定状态或者轻量级锁状态。\n偏向锁是为了在资源没有被多线程竞争的情况下尽量减少锁带来的性能开销。\n在锁对象的对象头中有一个ThreadId字段，当第一个线程访问锁时，如果该锁没有被其他线程访问过，即ThreadId字段为空，那么JVM让其持有偏向锁，并将ThreadId字段的值设置为该线程的ID。当下一次获取锁的时候，会判断ThreadId是否相等，如果一致就不会重复获取锁，从而提高了运行率\n如果存在锁的竞争情况，偏向锁就会被撤销并升级为轻量级锁。\n总结 synchronized的执行过程：\n 检测Mark Word里面是不是当前线程的ID，如果是，表示当前线程处于偏向锁 如果不是，则使用CAS将当前线程的ID替换Mark Word，如果成功则表示当前线程获得偏向锁，置偏向标志位1 如果失败，则说明发生竞争，撤销偏向锁，进而升级为轻量级锁。 当前线程使用CAS将对象头的Mark Word替换为锁记录指针，如果成功，当前线程获得锁 如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。 如果自旋成功则依然处于轻量级状态。 如果自旋失败，则升级为重量级锁。  偏向锁、轻量级锁、重量级锁的区别\n偏向锁的优点是加解锁不需要额外消耗，和执行非同步方法比仅存在纳秒级差距，缺点是如果存在锁竞争会带来额外锁撤销的消耗，适用只有一个线程访问同步代码块的场景。\n轻量级锁的优点是竞争线程不阻塞，程序响应速度快，缺点是如果线程始终得不到锁会自旋消耗 CPU，适用追求响应时间、同步代码块执行快的场景。\n重量级锁的优点是线程竞争不使用自旋不消耗CPU，缺点是线程会阻塞，响应时间慢，适应追求吞吐量、同步代码块执行慢的场景。\n","date":"2022-05-24T14:11:07+08:00","permalink":"https://isheihei.github.io/posts/java/jvm-%E9%94%81%E4%BC%98%E5%8C%96/","title":"线程安全与锁优化"},{"content":"  将 zip 包解压到相应的目录，这里我将解压后的文件夹放在D:\\software\\mysql\\mysql-8.0.22-winx64 下。\n  以管理员身份打开cmd命令行工具，切换目录到：D:\\software\\mysql\\mysql-8.0.22-winx64\\bin\n  初始化数据库：\n mysqld \u0026ndash;initialize \u0026ndash;console\n   执行完场后，会输出root默认的随机密码，如：\n 2021-01-18T03:55:52.326932Z 6 [Note] [MY-010454] [Server] A temporary password is generated for root@localhost: =tL5\u0026gt;rI40v_\u0026gt;\n 随机密码就是：=tL5\u0026gt;rI40v_\u0026gt;\n  安装\n 1  mysqld install      启动\n 1  net start mysql      输入以下命令登录数据库\n mysql -u root -p\n 需要输入密码，默认密码就是步骤4中的随机密码\n  登陆后输入命令\n alter user \u0026lsquo;root\u0026rsquo;@\u0026rsquo;localhost\u0026rsquo; identified by \u0026lsquo;想要设置的密码\u0026rsquo;;\ncommit;\n 修改密码\n  将Mysql的bin目录配置到环境变量中\n  属性配置文件\n1 2 3 4  jdbc.driver=com.mysql.cj.jdbc.Driver jdbc.url=jdbc:mysql://localhost:3306/db0?useUnicode=true\u0026amp;characterEncoding=utf-8\u0026amp;useSSL=false\u0026amp;serverTimezone=GMT jdbc.user=root jdbc.password=root    ","date":"2021-01-29T23:28:00+08:00","permalink":"https://isheihei.github.io/posts/tips/mysql%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/","title":"Mysql安装配置"},{"content":"解压maven压缩包 配置环境变量   新建系统变量 MAVEN_HOME 变量值：E:\\Maven\\apache-maven-3.3.9\n  编辑系统变量 Path 添加变量值： %MAVEN_HOME%\\bin\n  打开cmd，输入  mvn \u0026ndash;version\n 查看安装配置是否成功","date":"2021-01-29T23:25:33+08:00","permalink":"https://isheihei.github.io/posts/tips/maven%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/","title":"Maven安装配置"},{"content":"新建JAVA_HOME变量，填写jdk安装路径：bin目录的上一级 PATH变量添加两个：  %JAVA_HOME%\\bin %JAVA_HOME%\\jre\\bin  新建CLASSPATH变量：  .;%JAVA_HOME%\\lib;%JAVA_HOME%\\lib\\tools.jar ","date":"2021-01-29T23:21:58+08:00","permalink":"https://isheihei.github.io/posts/tips/jdk%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE/","title":"Jdk环境变量配置"},{"content":"将rpm 安装包拷贝到usr/local/sql目录下 卸载mariadb 1 2  # rpm -qa | grep mariadb # rpm -e --nodeps mariadb-libs-5.5.68-1.el7.x86_64   解压mysql.tar包,解压后目录下会有一些rpm文件。 1  # tar -xvf MySQL-5.6.25-1.el6.x86_64.rpm-bundle.tar   安装Mysql.server和Mysql.client 1 2 3 4  # rp-ivh MySQL-server-5.6.25-1.el6.x86_64.rpm # 打开/root/.mysql_secret文件，获取随机生成的密码： mAw0cco4dAVG332x # cat /root/.mysql_secret   启动mysql服务 1  # service mysql start   修改密码 1  mysql\u0026gt; set password = password(\u0026#39;root\u0026#39;);   授权远程访问 1 2 3 4 5  mysql\u0026gt; grant all privileges on *.* to \u0026#39;root\u0026#39; @\u0026#39;%\u0026#39; identified by \u0026#39;root\u0026#39;; mysql\u0026gt; flush privileges; # 关闭防火墙 # systemctl stop firewalld   ","date":"2021-01-29T23:17:20+08:00","permalink":"https://isheihei.github.io/posts/tips/centos7%E9%85%8D%E7%BD%AEmysql/","title":"Centos7配置 ysql"}]