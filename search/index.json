[{"content":"hugo 安装 参考官方文档：Hugo Documentation | Hugo (gohugo.io)\ngithub仓库：Releases · gohugoio/hugo (github.com)\n由于我使用的主题是 stack [CaiJimmy/hugo-theme-stack: Card-style Hugo theme designed for bloggers (github.com)]，主题要求下载 hugo-extended 版本\nstack中文文档：介绍 | Hugo 主题 Stack (jimmycai.com)\n下载完成后解压并配置环境变量\nhugo 基本命令 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  # 新建 site-name：quickstart hugo new site \u0026#34;quickstart\u0026#34; # 添加或者修改主题  cd quickstart git init git submodule add https://github.com/CaiJimmy/hugo-theme-stack.git # 方法1： echo theme = \\\u0026#34;stack\\\u0026#34; \u0026gt;\u0026gt; config.toml #方法2（建议）： #使用主题的 \\themes\\hugo-theme-stack\\exampleSite\\config.yaml 文件覆盖 site 的配置文件，这样做是因为主题自带的样例配置已经做了很多默认配置，自己只需要进行简单的定制化即可 # 添加一篇文章 hugo new posts/my-first-post.md # 启动 hugoserver hugo server -D # 访问 http://localhost:1313/   部署 方式1：使用 github 托管  新建仓库：仓库名必须为 {github-username}.github.io 将 hugo 生成的 public 目录作为 git仓库 push 到新建的远程仓库即可  为了避免每次更新都要重新更新仓库，我使用了shell脚本自动化完成，可参考如下脚本：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  #!/bin/sh  # If a command fails then the deploy stops set -e printf \u0026#34;\\033[0;32mDeploying updates to GitHub...\\033[0m\\n\u0026#34; # push meta files git add . msg=\u0026#34;update site $(date)\u0026#34; if [ -n \u0026#34;$*\u0026#34; ]; then msg=\u0026#34;$*\u0026#34; fi git commit -m \u0026#34;$msg\u0026#34; git push -u origin main # Build the project. hugo -D --cleanDestinationDir # if using a theme, replace with `hugo -t \u0026lt;YOURTHEME\u0026gt;` # Go To Public folder cd public # Add changes to git. git add . # Commit changes. msg=\u0026#34;rebuilding site $(date)\u0026#34; if [ -n \u0026#34;$*\u0026#34; ]; then msg=\u0026#34;$*\u0026#34; fi git commit -m \u0026#34;$msg\u0026#34; # Push source and build repos. git push -u origin main   方式2：部署到服务器 服务器安装nginx\n1  yum install nginx -y   配置\n1  vim /etc/nginx/nginx.conf   1 2 3 4 5 6 7 8 9 10 11 12  server { listen 80; listen [::]:80; server_name isheihei.cn; root /root/isheihei.github.io; //网站目录 # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; error_page 404 /404.html; location = /404.html { }   启动\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  // 启动 nginx // 重启 nginx -s reload // 设置开机自启动 systemcel enable nginx.service // 查看nginx状态 systemctl status nginx.service // 杀死nginx重启nginx pkill -9 nginx ps aux | grep nginx systemctl start nginx   遇到的一些问题及解决方案 问题1：插入图片问题 如果需要在博文中插入图片的话，可以使用同图床，但是我自身习惯是所有的博客和资源统一静态管理，那么就需要在生成站点的时候将一些静态图片文件也一起打包。好在 hugo 也提供了这样一种机制。参考：Content Organization | Hugo (gohugo.io)\n遗憾的是我并没有完全搞懂官方的组织管理的方法，这里提供我自己的实现方案供参考\n默认情况下，我们的文章都是在 content/posts/ 目录下，官方提供了一种打包方案：一个文件夹下命名为 index.md 的文档可以访问本文件夹下的静态资源。那么我们只需要给每篇文章使用单独的文件夹目录，该文档包含的图片一并放在该目录下即可。\n为了方便，使用 shell 脚本自动化创建目录和文档\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  #!/bin/sh blog_path=\u0026#34;./content/posts/$2\u0026#34; category_path=\u0026#34;./content/categories/$2\u0026#34; # new blog if [ $1 == \u0026#34;-b\u0026#34; ] then mkdir ${blog_path} hugo new ${blog_path}/index.md # new category elif [ $1 == \u0026#34;-c\u0026#34; ] then mkdir ${category_path} hugo new ${category_path}/_index.md elif [ $1 == \u0026#34;help\u0026#34; -o $1 == \u0026#34;-h\u0026#34; ] then echo \u0026#34;var1\u0026#34; echo \u0026#34;-b:new blog, -c:new category, -h/help:help\u0026#34; echo \u0026#34;var2\u0026#34; echo \u0026#34;path:base is ./content/posts or ./content/categories\u0026#34; # new tag fi   问题2：网页favcoin无法显示 stack 主题提供了配置文件自定义配置 favcoin ，但是我实测后好像一直无法使用静态相对路径访问到。最终的解决方案是修改主题网页模板代码\n文件目录为：\\themes\\hugo-theme-stack\\layouts\\partials\\head.html\n参考作者对于 avator 的处理方法，先对图标进行裁剪，再引入。\n以下是参考对象 \\themes\\hugo-theme-stack\\layouts\\partials\\sidebar\\left.html\n效果：\n","date":"2022-05-19T14:11:07+08:00","image":"https://isheihei.github.io/posts/tips/hugo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E9%83%A8%E7%BD%B2%E4%BB%A5%E5%8F%8A%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/hugo-logo-wide.svg","permalink":"https://isheihei.github.io/posts/tips/hugo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E9%83%A8%E7%BD%B2%E4%BB%A5%E5%8F%8A%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/","title":"Hugo博客搭建部署以及问题解决"},{"content":"Redis事件 事件模型 Redis 基于 Reactor 模式开发了自己的网络事件处理器。\n  I/O多路复用程序同时监听多个套接字，并向文件事件分派器传送那些产生了事件的套接字。\n  文件事件分派器则接收I/O多路复用程序传来的套接字，并根据套接字产生的事件的类型，调用相应的事件处理器\n  尽管多个文件事件可能会并发地出现，但I/O多路复用程序会将所有产生的套接字都放到一个队列里面，然后通过这个队列向文件事件分派器传送套接字（一个一个顺序进行）。\n  IO模型详解：IO模型分析与对比\n文件事件 Redis事件分为文件事件和时间事件，文件事件就是服务器对套接字操作的抽象，服务器与客户端的通信会产生相应的文件事件，通俗点来说，就是客户端通过命令等方式发送给服务端的请求事件就是文件事件。\n文件事件是以单线程方式运行。\n文件事件处理器主要有：命令请求处理器、命令回复处理器、连接应答处理器\n时间事件 时间时间主要是周期性事件。\n时间事件执行器ae.c/processTimeEvents\nserverCron 函数就是一个时间事件实例，它主要做的工作包括：\n 更新服务器各种统计信息，比如事件、内存占用、数据库占用等 清理数据库中的过期键值对 关闭和清理连接失效的客户端 尝试进行AOF或RDB持久化操作 如果服务器是主服务器，那么对从服务器进行定期同步 如果出于集群模式，对集群进行定期同步和连接测试  事件的调度和执行规则\n 因为文件事件是随机出现的，如果等待并处理完一次文件事件后，仍未有任何时间事件到达，那么服务器将再次等待并处理文件事件。随着文件事件的不断执行，时间会逐渐向时间事件所设置的到达时间逼近，并最终来到到达时间，这时服务器就可以开始处理到达的时间事件了。 文件事件和时间事件的处理都是同步、有序、原子地执行，服务器不会中途中断事件处理，也不会对事件进行抢占。 因为时间事件在文件事件之后执行，并且事件之间不会抢占，所以时间事件的实际处理时间，通常会比时间事件设定的到达事件稍晚一些。  Redis协议详细规范 此章节为转载，原文链接：Redis协议详细规范\nRedis客户端和服务器端通信使用名为 RESP (REdis Serialization Protocol) 的协议。虽然这个协议是专门为Redis设计的，它也可以用在其它 client-server 通信模式的软件上。\nRESP 是下面条件的折中：\n 实现起来简单。 解析速度快。 有可读性。  RESP 能序列化不同的数据类型，例如整型(integers)、字符串(strings)、数组(arrays)。额外还有特殊的错误类型。请求从客户端以字符串数组的形式发送到redis服务器，这些字符串表示要执行的命令的参数。Redis用特定于命令的数据类型回复。\nRESP 是二进制安全的，并且不需要处理从一个进程发到另外一个进程的批量数据，因为它使用前缀长度来传输批量数据。\n注意：这里概述的协议仅用于客户机-服务器通信。Redis集群使用不同的二进制协议在节点之间交换消息。\n网络层 连到Redis服务器的客户端建立了一个到6379端口的TCP连接。\n虽然RESP在技术上不特定于TCP，但是在Redis的上下文中，该协议仅用于TCP连接（或类似的面向流的连接，如unix套接字）。\n请求-响应模型 Redis接受由不同参数组成的命令。一旦收到命令，就会对其进行处理，并将应答发送回客户端。\n这是最简单的模型，但是有两个例外：\n Redis 支持管道pipelining。所以，客户端可以一次发送多个命令，然后再等待应答。 当一个Redis客户端订阅一个频道，那么协议会改变语义并变成pushprotocol, 也就是说，客户客户端不再需要发送命令，因为服务器端会一收到新消息，就会自动发送给客户端。  除了上面两个例外情况，Redis协议是一个简单的请求-响应协议。\nRESP 协议解释 RESP 协议在Redis1.2被引入，直到Redis2.0才成为和Redis服务器通信的标准。这个协议需要在你的Redis客户端实现。\nRESP 是一个支持多种数据类型的序列化协议：简单字符串（Simple Strings）,错误（ Errors）,整型（ Integers）, 大容量字符串（Bulk Strings）和数组（Arrays）。\nRESP在Redis中作为一个请求-响应协议以如下方式使用：\n 客户端以大容量字符串RESP数组的方式发送命令给服务器端。 服务器端根据命令的具体实现返回某一种RESP数据类型。  在 RESP 中，数据的类型依赖于首字节：\n 单行字符串（Simple Strings）： 响应的首字节是 \u0026ldquo;+\u0026rdquo; 错误（Errors）： 响应的首字节是 \u0026ldquo;-\u0026rdquo; 整型（Integers）： 响应的首字节是 \u0026ldquo;:\u0026rdquo; 多行字符串（Bulk Strings）： 响应的首字节是\u0026quot;$\u0026quot; 数组（Arrays）： 响应的首字节是 \u0026ldquo;*\u0026rdquo;  另外，RESP可以使用大容量字符串或者数组类型的特殊变量表示空值，下面会具体解释。RESP协议的不同部分总是以 \u0026ldquo;\\r\\n\u0026rdquo; (CRLF) 结束。\nRESP 单行字符串 单行字符串编码方法: 加号后面跟着一个不包含回车或换行字符的字符串 (不允许出现换行)，以CRLF(\u0026quot;\\r\\n\u0026quot;)结尾。\n单行字符串通常被用来传输非二进制安全字符串并且消耗极小。例如，许多redis命令在成功时回复\u0026quot;OK\u0026quot;，即简单字符串用以下5个字节编码：\n1  \u0026#34;+OK\\r\\n\u0026#34;   为了发送二进制安全的字符串，需要使用RESP的多行字符串（Bulk Strings）替代。\n当Redis返回单行字符串（Simple String）时，客户端lib应该返回去掉首字符加号和结尾CRLF字符的字符串给调用者。\nRESP 错误 RESP 有特殊类型来处理错误。errors类型除了首字符是减号 \u0026lsquo;-\u0026lsquo;不是加号以外，其它跟简单字符串一样。RESP中简单字符和错误的真正区别是：错误被客户端当作异常处理，组成错误类型的字符串是错误消息自身。\n基本格式如下:\n1  \u0026#34;-Error message\\r\\n\u0026#34;   错误应答只在发生异常时发送，例如，要执行命令的参数数据类型不匹配或者命令不存在等。当收到错误返回时，客户端lib应该抛出一个异常。\n错误返回例子:\n1 2  -ERR unknown command \u0026#39;foobar\u0026#39; -WRONGTYPE Operation against a key holding the wrong kind of value   从\u0026quot;-\u0026ldquo;后面第一个单词起，直到第一个空格或者换行，表示返回的错误类型。这是Redis的一种约定，并不是RESP协议的要求。\nERR 是一个通用错误, 而 WRONGTYPE 是表示更具体的错误，意味着客户端在错误的数据类型上执行操作。这被叫做错误前缀（Error Prefix）， 使客户端不用依赖具体错误消息就知道返回的错误类型，错误消息可能会随着时间而变化。\n客户端实现可能会对不同异常返回不同类型的错误，或者可能提供一种通用的方式来捕获错误，通过以字符串的形式直接返回错误名给调用者。\n尽管如此，这种特性不能认为很重要，因为它很少被使用。一小部分客户端的实现可能会返回通用错误条件，例如false。\nRESP 整数 整数类型是由以冒号开头，CRLF结尾，中间是字符串形式表示的数字。 例如 \u0026ldquo;:0\\r\\n\u0026rdquo;, 或 \u0026ldquo;:1000\\r\\n\u0026rdquo; 都是整数回复。\n很多Redis命令返回RESP整数，像 INCR, LLEN 和 LASTSAVE.\n返回的整数并没有特别的意义， INCR 返回的是一个递增的数字， LASTSAVE 返回的是Unix时间戳等。返回的整数有效值需要在有符号64位整数范围内。\n整数返回也被广泛的用来返回 true 或 false。比如 EXISTS 或 SISMEMBER 命令返回1表示true，返回0表示false。\n其它命令像 SADD, SREM 和 SETNX 如果操作被执行则返回1，否则返回0。\n返回整数回复的命令： SETNX, DEL, EXISTS, INCR, INCRBY, DECR, DECRBY, DBSIZE, LASTSAVE, RENAMENX, MOVE, LLEN, SADD, SREM, SISMEMBER, SCARD.\nRESP 多行字符串 多行字符串被用来表示最大512MB长的二进制安全字符串。\n多行字符串编码方式：\n 美元符 \u0026ldquo;$\u0026rdquo; 后面跟着组成字符串的字节数(前缀长度)，并以 CRLF 结尾。 实际的字符串数据。 结尾是 CRLF。  所以，字符串 \u0026ldquo;foobar\u0026rdquo; 编码如下:\n1  \u0026#34;$6\\r\\nfoobar\\r\\n\u0026#34;   空字符串编码格式：\n1  \u0026#34;$0\\r\\n\\r\\n\u0026#34;   RESP 多行字符串（Bulk Strings） 也可以使用一个特殊的用来表示空值的格式表示不存在的值。在这种格式里长度值为-1，数据部分不存在，所以空（Null）用如下方式表示：\n1  \u0026#34;$-1\\r\\n\u0026#34;   叫做空的多行字符串Null Bulk String。\n客户端API库不应该返回空串，当服务器端响应一个空的多行字符串时，API库可以返回一个空对象给调用者。例如，Ruby库应该返回 \u0026rsquo;nil\u0026rsquo; ，而C库应该返回NULL。\nRESP 数组 客户端使用 RESP 数组发送命令到 Redis 服务端。同样地，某些命令的应答使用RESP数组返回元素的集合给Redis客户端。 LRANGE 命令返回元素列表就是一个例子。\nRESP 数组使用如下格式发送：\n 以星号* 为首字符，接着是表示数组中元素个数的十进制数，最后以 CRLF 结尾。 外加数组中每个 RESP 类型的元素。  空数组表示：\n1  \u0026#34;*0\\r\\n\u0026#34;   有两个 RESP 多行字符串\u0026quot;foo\u0026rdquo; 和\u0026quot;bar\u0026quot;元素的 RESP 数组 ：\n1  \u0026#34;*2\\r\\n$3\\r\\nfoo\\r\\n$3\\r\\nbar\\r\\n\u0026#34;   在前缀 *\u0026lt;count\u0026gt;CRLF 的后面，组成数组的其它数据类型一个接在另一个后面。 例如包含三个整数的数组编码方式：\n1  \u0026#34;*3\\r\\n:1\\r\\n:2\\r\\n:3\\r\\n\u0026#34;   数组可以包含混合类型，不一定必须是同一种类型。例如，4个整型和1个多行字符串编码方式：\n1 2 3 4 5 6 7  *5\\r\\n :1\\r\\n :2\\r\\n :3\\r\\n :4\\r\\n $6\\r\\n foobar\\r\\n   (为了方便阅读，应答分成多行来展示)\n第一个行表示 *5\\r\\n 说明后面有5个应答。这些应答组成一个大的应答一起发送。\n空数组的概念也是存在的，另一个表示空值的方式(通常使用多行空字符串，历史遗留导致有这两种格式)。\n例如，当 BLPOP 命令超时，它会返回一个空数组，数组的计数器是-1 :\n1  \u0026#34;*-1\\r\\n\u0026#34;   当 Redis 返回一个空数组的时候，Redis客户端库API应该返回一个空对象而不是返回一个空数组。 这对区分空列表和其它不同情况（像 BLPOP 命令超时情况）是必要的。\n数组的数组也是可行的。例如，一个含有两个数组元素的数组编码方式：\n1 2 3 4 5 6 7 8  *2\\r\\n *3\\r\\n :1\\r\\n :2\\r\\n :3\\r\\n *2\\r\\n +Foo\\r\\n -Bar\\r\\n   (为了方便阅读，分成多行来展示).\n上面的 RESP 数据类型包含两个数组，一个数组包含三个整数1, 2, 3 ，另一个是简单字符串和一个错误类型。\n数组中的空元素 数组中可以有为空的元素。主要使用在Redis应答中，为了表示这个元素丢失并且不是一个空的字符串。当SORT命令使用GET 模式选项，并且特定的key丢失的时会出现这种应答。 含有有空元素的应答数组例子：\n1 2 3 4 5 6  *3\\r\\n $3\\r\\n foo\\r\\n $-1\\r\\n $3\\r\\n bar\\r\\n   第二个元素是空，客户端库应该返回像下面这样的数据：\n1  [\u0026#34;foo\u0026#34;,nil,\u0026#34;bar\u0026#34;]   这不是前面提到的异常情况，这只是说明协议的一个例子。\n发送命令到Redis服务器 至此，我们已经很熟悉RESP序列化格式，写一个Redis客户端库的实现会变得很容易。我们可以进一步说明客户端和服务端如何交互工作：\n 客户端发送包含只有多行字符串的数组给Redis服务器。 Redis 服务器给客户端发送任意有效的 RESP 数据类型作为应答。  下面是一个典型的交互过程例子：\n客户端发送命令 LLEN mylist 来获取存储在 mylist 键中列表的长读，然后服务器端返回整数应答(C: 代表客户端, S: 代表服务器端).\n1 2 3 4 5 6 7  C: *2\\r\\n C: $4\\r\\n C: LLEN\\r\\n C: $6\\r\\n C: mylist\\r\\n S: :48293\\r\\n   为了方便理解我们用换行把协议分成不同部分，实际上客户端发送的是一个整体没有换行：*2\\r\\n$4\\r\\nLLEN\\r\\n$6\\r\\nmylist\\r\\n as a whole.\nRedis 协议的高性能解析器 虽然redis协议是非常容易被人阅读和实现的，但是它可以以类似于二进制协议的性能来实现。\nRESP 使用带前缀的长度来传输批量数据，因此不需要像使用json那样扫描有效负载以查找特殊字符，也不需要引用需要发送到服务器的有效负载。\n批量和多批量长度可以使用代码进行处理，代码对每个字符执行单个操作，同时扫描CR字符，如以下C代码：\nRESP 使用带前缀的长度来传输多行数据，因此不需要像使用json那样扫描有效负载以查找特殊字符，也不需要引用需要发送到服务器的有效负载。\n多行和多个多行长度可以使用代码进行处理，代码对每个字符执行单个操作，同时扫描CR字符，如以下C代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  #include \u0026lt;stdio.h\u0026gt; int main(void) { unsigned char *p = \u0026#34;$123\\r\\n\u0026#34;; int len = 0; p++; while(*p != \u0026#39;\\r\u0026#39;) { len = (len*10)+(*p - \u0026#39;0\u0026#39;); p++; } /* Now p points at \u0026#39;\\r\u0026#39;, and the len is in bulk_len. */ printf(\u0026#34;%d\\n\u0026#34;, len); return 0; }   在识别出第一个CR之后，可以跳过它和下面的LF，而不需要任何处理。然后，可以使用不以任何方式检查有效负载的单个读取操作读取大容量数据。最后，剩余的CR和LF字符将被丢弃，而不进行任何处理。\nRedis协议有着与二进制协议可比的性能，更重要的是易于在大多数高级语言中实现，从而减少了客户端软件中的错误数量。\n实现 事件模型 对于Redis事件模型，java-redis 基于netty实现nio，并使用单线程事件处理器执行文件事件操作。如下图所示\nnio多路复用模型，实现了单路模型，以及基于Epoll，Kqueue的多路模型。netty默认的nio模型底层是select。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  /** * @ClassName: SingleSelectChannelOption * @Description: 单路模型 * @Date: 2022/6/8 20:56 * @Author: isheihei */ public class SingleSelectChannelOption implements LocalChannelOption { private final NioEventLoopGroup single; public SingleSelectChannelOption(NioEventLoopGroup single) { this.single = single; } public SingleSelectChannelOption() { this.single = new NioEventLoopGroup(1, new ThreadFactory() { private AtomicInteger index = new AtomicInteger(0); @Override public Thread newThread(Runnable r) { return new Thread(r, \u0026#34;Server_boss_\u0026#34; + index.getAndIncrement()); } }); } @Override public EventLoopGroup boss() { return this.single; } @Override public EventLoopGroup selectors() { return this.single; } @Override public Class getChannelClass() { return NioServerSocketChannel.class; } }   协议 共五种消息类型：SimplString、BulkString、RespInt、RespArray、Errors\n协议编解码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177  /** * @ClassName: Resp * @Description: Redis Serialization Protocol协议 * @Date: 2022/6/1 13:15 * @Author: isheihei */ public interface Resp { org.apache.log4j.Logger LOGGER = org.apache.log4j.Logger.getLogger(Resp.class); Charset CHARSET = StandardCharsets.UTF_8; /** * @Description: 回写 * @Param: resp * @Param: buffer * @Return: void * @Author: isheihei */ static void write(Resp resp, ByteBuf buffer) { if (resp instanceof SimpleString) { buffer.writeByte(RespType.STATUS.getCode()); String content = ((SimpleString) resp).getContent(); buffer.writeBytes(content.getBytes(CHARSET)); writeEof(buffer); } else if (resp instanceof Errors) { buffer.writeByte(RespType.ERROR.getCode()); String content = ((Errors) resp).getContent(); buffer.writeBytes(content.getBytes(CHARSET)); writeEof(buffer); } else if (resp instanceof RespInt) { buffer.writeByte(RespType.INTEGER.getCode()); String content = String.valueOf(((RespInt) resp).getValue()); buffer.writeBytes(content.getBytes(CHARSET)); writeEof(buffer); } else if (resp instanceof BulkString) { buffer.writeByte(RespType.BULK.getCode()); BytesWrapper content = ((BulkString) resp).getContent(); if (content == null) { // null: \u0026#34;$-1\\r\\n\u0026#34;  buffer.writeByte(RespType.ERROR.getCode()); buffer.writeByte(RespType.ONE.getCode()); writeEof(buffer); } else if (content.getByteArray().length == 0) { // 空串: \u0026#34;$0\\r\\n\\r\\n\u0026#34;  buffer.writeByte(RespType.ZERO.getCode()); writeEof(buffer); writeEof(buffer); } else { // 正常编码：\u0026#34;foobar\u0026#34; 的编码为 \u0026#34;$6\\r\\nfoobar\\r\\n\u0026#34;，其中 6 是字节数  String length = String.valueOf(content.getByteArray().length); buffer.writeBytes(length.getBytes(CHARSET)); writeEof(buffer); buffer.writeBytes(content.getByteArray()); writeEof(buffer); } } else if (resp instanceof RespArray) { buffer.writeByte(RespType.MULTYBULK.getCode()); Resp[] array = ((RespArray) resp).getArray(); String length = String.valueOf(array.length); buffer.writeBytes(length.getBytes(CHARSET)); writeEof(buffer); for (Resp each : array) { write(each, buffer); } } else { throw new IllegalArgumentException(); } } /** * @Description: 解码为协议对应具体格式 * @Param: buffer * @Return: Resp * @Author: isheihei */ static Resp decode(ByteBuf buffer) { if (buffer.readableBytes() \u0026lt;= 0) { throw new IllegalStateException(\u0026#34;没有读取到完整的命令\u0026#34;); } byte b =buffer.readByte(); if (b == RespType.STATUS.getCode()) { return new SimpleString(getString(buffer)); } else if (b == RespType.ERROR.getCode()) { return new Errors(getString(buffer)); } else if (b == RespType.INTEGER.getCode()) { int value = getNumber(buffer); return new RespInt(value); } else if (b == RespType.BULK.getCode()) { int length = getNumber(buffer); if (buffer.readableBytes() \u0026lt; length + 2) { throw new IllegalStateException(\u0026#34;没有读取到完整的命令\u0026#34;); } byte[] content; if (length == -1) { content = null; } else { content = new byte[length]; buffer.readBytes(content); } if (buffer.readByte() != RespType.R.getCode() || buffer.readByte() != RespType.N.getCode()) { throw new IllegalStateException(\u0026#34;没有读取到完整的命令\u0026#34;); } return new BulkString(new BytesWrapper(content)); } else if (b == RespType.MULTYBULK.getCode()) { int numOfElement = getNumber(buffer); Resp[] array = new Resp[numOfElement]; for (int i = 0; i \u0026lt; numOfElement; i++) { array[i] = decode(buffer); } return new RespArray(array); } else { throw new IllegalStateException(\u0026#34;无法解析命令\u0026#34;); } } /** * @Description: 读取整数类型 * @Param: buffer * @Return: int * @Author: isheihei */ static int getNumber(ByteBuf buffer) { byte b; b = buffer.readByte(); boolean positive = true; int value = 0; // 错误（Errors）： 响应的首字节是 \u0026#34;-\u0026#34;  if (b == RespType.ERROR.getCode()) { positive = false; } else { value = b - RespType.ZERO.getCode(); } while (buffer.readableBytes() \u0026gt; 0 \u0026amp;\u0026amp; (b = buffer.readByte()) != RespType.R.getCode()) { value = value * 10 + (b - RespType.ZERO.getCode()); } if (buffer.readableBytes() == 0 || buffer.readByte() != RespType.N.getCode()) { throw new IllegalStateException(\u0026#34;没有读取到完整的命令\u0026#34;); } if (!positive) { value = -value; } return value; } /** * @Description: 读取一条字符串 * @Param: buffer * @Return: String * @Author: isheihei */ static String getString(ByteBuf buffer) { byte b; ByteBuf byteBuf = PooledByteBufAllocator.DEFAULT.directBuffer(); // 以终止符 /R 为结束标志  while (buffer.readableBytes() \u0026gt; 0 \u0026amp;\u0026amp; (b = buffer.readByte()) != RespType.R.getCode()) { byteBuf.writeByte(b); } // /R 后面必须紧接 /N  if (buffer.readableBytes() == 0 || buffer.readableBytes() != RespType.N.getCode()) { throw new IllegalStateException(\u0026#34;没有读取到完整的命令\u0026#34;); } return byteBuf.toString(CHARSET); } /** * @Description: 写协议终止符：\u0026#34;\\r\\n\u0026#34; (CRLF) * @Param: buffer * @Return: void * @Author: isheihei */ static void writeEof(ByteBuf buffer) { buffer.writeByte(RespType.R.getCode()); buffer.writeByte(RespType.N.getCode()); }   ","date":"2022-06-26T16:32:54+08:00","image":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B001-%E9%80%9A%E4%BF%A1%E4%B8%8E%E5%8D%8F%E8%AE%AE/log_hu0a4ba87b3d81b22780f8a722f1e0fc9b_1722333_120x120_fill_q75_box_smart1.jpg","permalink":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B001-%E9%80%9A%E4%BF%A1%E4%B8%8E%E5%8D%8F%E8%AE%AE/","title":"Redis设计与实现01-通信与协议"},{"content":"数据结构 简单动态字符串（SDS） 1 2 3 4 5 6 7 8 9 10 11  struct sdshdr { //\t记录 buf 数组已使用字节的数量  //\t等于 SDS 所保存字符串的长度  int len; //\t记录 buf 数组中未使用字节的数量  int free; //\t字节数组，用于保存字符串  char buf[]; }    常数复杂度获取字符串长度 杜绝缓冲区溢出，修改前会检查空间是否满足所需要求，不满足会扩展空间 空间预分配，减少修改字符串长度时所需的内存重分配次数。 二进制安全（byte数组） 兼容部分 C 字符串函数  链表（双端列表） 1 2 3 4 5 6 7 8 9 10  typedef struct listNode { //\t前置节点  struct listNode *prev; //\t后置节点  struct listNode *next; //\t节点的值  void *value } listNode;   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  typedef struct list { //\t表头节点  listNode *head; //\t表位节点  listNode *tail; //\t链表所包含的节点数量  unsigned long len; //\t节点值复制函数  void (*free)(void *ptr); //\t节点值对比函数  int (*match)(void *ptr, void *key); } list;    双端 无环，表头结点的 prev 指针和表位节点的 next 指针都指向 NULL，对链表的访问以 NULL 为终点。 带表头和表尾指针，程序获取链表的表头节点和表尾节点的复杂度为O（1） 带链表长度计数器：程序使用 list 结构的 len 属性来对 list 持有的链表节点进行计数，程序获取链表中节点数量的复杂度为 O（1）。 泛型：可以保存不同类型的节点  字典（Map） 哈希表：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  typedef struct dictht { //\t哈希表数组  dictEntry **table; //\t哈希表大小  unsigned long size; //\t哈希表大小掩码，用于计算索引值  //\t总是等于 size - 1  unsigned long sizemask; //\t该哈希表已有节点的数量  unsigned long used; } dictht;   哈希表节点：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  typedef struct dictEntry { //\t键  void *key; //\t值  union{ void *val; uint64_tu64; int64_ts64; } v; //\t指向下个哈希表节点，形成链表  struct dictEntry *next; } dictEntry;   字典：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  typedef struct dict { //\t类型特定函数  dictType *type; //\t私有数据  void *privdata; //\t哈希表，ht[1]用于ht[0]在rehash的时候使用  dictht ht[2]; //\trehash 索引  //\t当 rehash 不在进行时 值为-1  int trehashidx; } dict;   type 属性和 privdata 属性是针对不同类型的键值对，为创建多态字典而设置的\n type 属性是一个指向 dictType 结构的指针，每个 dictType 结构保存了一簇用于操作特定类型键值对的函数，Redis会为用途不同的字典设置不同类型特定函数。 privdata 属性保存了需要传给那些类型特定函数的可选参数。  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  typedef struct dictType { // 计算哈希值的函数  unsigned int (*hashFunction)(const void *key); //\t复制键的函数  void *(*keyDup)(void *privdata, const void *key); //\t复制值的函数  void *(\u0026amp;valDup)(void *privdata, const coid *obj); // 对比键的函数  int (*keyCompare)(void *privdata, const void *key1, const void *key2); //\t销毁键的函数  void (*keyDestructor)(void *privdata, void *key); //\t销毁值的函数  void (*valDestructor)(void *privdata, void *obj); } dictType;   特点\n 拉练法解决哈希冲突,头插（因为拉链没有表位节点），java-HashMap 1.8 后是尾插 扩容和收缩 都是 2^n 双 table 、渐进式 rehash  rehash 步骤\n 为 ht[1]分配空间，让字典同时持有 ht[0] 和ht[1] 两个哈希表 在字典中维持一个索引计数变量rehashidx，并将它的值设置为 0，表示rehash工作正式开始 在rehash 进行期间，每次对字典执行添加、删除、查找或者更新操作时，程序除了执行指定的操作以外，还会顺带将 ht[0] 哈希表在 rehashidx 索引上的所有键值对 rehash 到ht[1]，当rehash 工作完成之后，程序将 rehashidx 属性的值增一。 随着字典操作的不断执行，最终在某个时间点上，ht[0] 的所有键值对都会被 rehash 至 ht[1] , 这时程序将 rehashidx 属性的值设为 -1，表示 rehash操作已完成。  因为在渐进式 rehash 过程中，字典会同时使用 ht[0] 和 ht[1] 两个哈希表，所以在渐进式 rehash 进行期间，字典的删除、查找、更新等操作会在两个哈希表上进行。例如要在字典里面查找一个键的话，程序会先在 ht[0] 里面进行查找，如果没找到的话，就会继续到 ht[1] 里面进行查找。\n另外，在渐进式 rehash 执行期间，新添加到字典的键值对一律会被保存到 ht[1] 里面，而 ht[0] 则不在进行任何添加操作，这一措施保证了 ht[0] 包含的键值对数量会只减不增，并随着 rehash 操作的执行而最终变成空表。\n跳表（SkipList） 跳表详解：Skip List\u0026ndash;跳表（全网最详细的跳表文章没有之一） - 简书 (jianshu.com)\nRedis-zset源码：redis/t_zset.c at unstable · redis/redis (github.com)\n跳跃表节点：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  typedef struct zskiplistNode { //\t层  struct zskiplistLevel { //\t前进指针  struct zskiplistNode *forward; //\t跨度  unsigned int span; } level[]; //\t后退指针  struct zskiplistNode *backward; //\t分值  double score; //\t成员对象  robj *obj; } zskiplistNode;   层\n跳跃表的 level 数组可以包含多个元素，所有包含同层的节点组合构成了跳表该层链表。每次创建一个新的跳跃表节点，程序根据幂次定律（power law， 越大的数出现的概率越小）随机生成一个介于1和32之间的值作为level数组的大小（索引的层数，即该节点要建立几层索引），这个大小就是层的高度。\n前进指针：每个层有一个前进指针，指向该层的下一个节点。\n跨度：跨度记录了两个节点之间的距离，指向NULL的所有前进指针的跨度都为0\n后退指针\n用于从表位向表头方向访问节点，与前进指针不同，每个节点无论高度，都只有一个后退指针，即最底层有后退指针，每次只能后退一个节点。\n跳跃表：\n1 2 3 4 5 6 7 8 9 10  typedef struct zskiplist { // 表头节点和表位节点  struct skiplistNode *header, *tail; //\t表中节点的数量  unsigned long length; //\t表中层数最大的节点的层数  int level; } zskiplist;   整数集合（IntSet） 整数集合（intset）是集合键的底层实现之一，当一个集合只包含整数值元素，并且这个集合的元素数量不多时，Redis 就会使用整数集合作为集合键的底层实现\n1 2 3 4 5 6 7 8 9 10  typedefg struct intset { //\t编码方式  uint32_t encoding; //\t集合包含的元素数量  uint32_t length; //\t保存元素的数组 有序且不重复  int8_t contents[]; } intset;   升级\n当新增的元素编码大于当前集合编码时候，例如当前编码为 INTSET_ENC_INT16 ，新添加一个 INTSET_ENC_INT32 类型元素。那么会引发整数集合的升级，把所有元素扩展为INTSET_ENC_INT32 类型，对应的 contents 字节数组的长度也会相应增加。\n升级的好处：提升灵活性、节约内存。但是不支持降级，一旦升级，编码就会一直保持升级后的状态。\n 升级之后新元素的摆放位置\n因为引发升级的新元素的长度总是比整数集合现有所有元素的长度都打，所以这个新元素值要么就大于所有现有元素，要么就小于所有现有元素。\n怎么理解？\n前一句话是因，后一句话是果。\n当新插入元素的数据类型大小大于已有元素的数据类型大小时，会触发intset的升级操作。\n这个时候 新插入的元素要么大于所有的已有的元素，要么小于所有的已有元素。\n假设现在的元素类型是int16，所有元素的取值范围都在区间[-32768,32767]。\n如果想触发intset的升级，将元素类型升级为int32，新加入元素的范围区间应该是[-2147483648,-32768)和(32767,2147483647)。\n如果新元素在前一个区间，那么它小于-32768，小于所有的int16。\n如果新元素在后一个区间，那么它大于32767，大于所有的int16。\n 压缩列表 压缩列表（ziplist）是列表键和哈希键的底层实现之一。当一个列表键只包含少量列表项，并且每个列表项要么就是小整数值，要么就是长度比较短的字符串，那么 Redis 就会使用压缩列表来做列表键的底层实现。\n压缩列表节点的构成：\n1  previous_entry_length | encoding | content    previous_entry_length：以字节为单位，记录了压缩列表中前一个节点的长度。可以通过指针计算，根据当前节点的起始地址来计算出前一个节点的起始地址。可能为1或者5字节（根据前一个节点的大小），如果前一个节点的长度小于 254 字节，需要1字节；如果前一个节点的长度大于 254 字节，那么需要 5字节。 encoding：节点的 encoding 属性记录了节点的 content 属性所保存数据的类型以及长度 content：节点的 content 属性负责保存节点的值，节点值可以是一个字节数组或者整数，值的类型和长度由节点的 encoding 属性决定  连锁更新\n考虑这样一个情况：在一个压缩列表中，有多个连续的、长度介于 250 字节到 253 字节之间的节点。因为 previous_entry_length 字段只需1字节，那么如果新增一个长度大于254的节点放在列表头，就需要更新之前第一个节点的 previous_entry_length，并且1字节放不下，需要扩展到 5 字节。\n扩展后又出现问题了，因为第二个节点的 previous_entry_length 也放不下第一个节点的长度了，所有就引发后面的一系列连续节点都需要重新分配内存。\n最坏的情况下需要对压缩列表执行 O(N) 次内存重分配操作。\n尽管连锁个更新的复杂度较高，但它真正造成性能问题的几率是很低的：\n 首先压缩列表里要恰好有多个连续的、长度介于 250 字节至 253 字节之间的节点，连锁更新才有可能被引发，实际情况中并不多见 其次，即使出现连锁更新，但只要被更新的节点数量不多，就不会对性能造成任何影响。  对象 对象类型与编码\n类型：数据库键对应的对象类型\n编码：对象具体的底层实现\n字符串对象 编码：int、raw或者 embstr\nembstr编码是专门用于保存短字符串的一种优化编码方式，这种编码和 raw 编码一样，都是用redisObject 和sdshdr 结构来表示字符串对象，但 raw 编码会调用两次分配函数来分别创建 redisObject 结构和 sdshdr 结构，而 embstr 编码通过一次内存分配函数分配一块连续空间，一次包含 redisObject 和 sdshdr两个结构。\n列表对象 编码：ziplist 或者 linkedlist\n哈希对象 编码：ziplist 或者 hashtable\n集合对象 编码：intset 或者 hashtable\n有序集合对象 编码：ziplist 或者 skiplist\n实现 对象和数据结构部分的实现在 java-redis-core模块 org.isheihei.redis.core.obj 和 org.isheihei.redis.core.struct包下。\n由于 java 中的string类型保存的是char数组，且不支持修改。所以新增了一个 BytesWapper 字节包装类以字节数组的形式保存字符串。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64  public class BytesWrapper implements Comparable\u0026lt;BytesWrapper\u0026gt; { static final Charset CHARSET = StandardCharsets.UTF_8; private final byte[] content; public BytesWrapper() { content = new byte[0]; } public BytesWrapper(byte[] content) { this.content = content; } public byte[] getByteArray() { return content; } public int length() { return content == null ? 0 : content.length; } @Override public boolean equals(Object o) { if (this == o) { return true; } if (o == null || getClass() != o.getClass()) { return false; } BytesWrapper that = (BytesWrapper) o; return Arrays.equals(content, that.content); } public String toUtf8String() { return new String(content, CHARSET); } @Override public int hashCode() { return Arrays.hashCode(content); } @Override public int compareTo(BytesWrapper o) { int len1 = content.length; int len2 = o.getByteArray().length; int lim = Math.min(len1, len2); byte v1[] = content; byte v2[] = o.getByteArray(); int k = 0; while (k \u0026lt; lim) { byte c1 = v1[k]; byte c2 = v2[k]; if (c1 != c2) { return c1 - c2; } k++; } return len1 - len2; } }   为了降低系统实现的复杂性，对于五种对象，分别对应了五种数据结构类型，并尽可能复用 Java 已有的数据类和工具。\n五种数据对象分别对应\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84  //\t字符串对象 RedisStringObject{ RedisString.value = BytesWrapper } //\t列表对象 RedisListObject{ RedisDoubleLinkedListextends LinkedList\u0026lt;BytesWrapper\u0026gt; } //\t哈希对象 RedisMapObject{ RedisMap extends HashMap\u0026lt;BytesWrapper, BytesWrapper\u0026gt; } //\t集合对象 RedisSetObject{ RedisSet extends HashSet\u0026lt;BytesWrapper\u0026gt; } //\t有序集合对象 RedisZSetObject{ RedisZSet extends TreeSet\u0026lt;ZNode\u0026gt; } //\tZNode 为有序集合节点： public class ZNode implements Comparable\u0026lt;ZNode\u0026gt; { private BytesWrapper member; private double score; public ZNode(double score, BytesWrapper member) { this.member = member; this.score = score; } public BytesWrapper getMember() { return member; } public double getScore() { return score; } @Override public boolean equals(Object o) { if (this == o) { return true; } if (o == null || getClass() != o.getClass()) { return false; } ZNode zNode = (ZNode) o; return member.equals(zNode.member); } @Override public int hashCode() { return member.hashCode(); } @Override public int compareTo(ZNode o) { int scoreComp = Double.compare(score, o.score); int memberComp = member.compareTo(o.member); if (memberComp == 0) { // member 相等 则相等  return 0; } else if (scoreComp == 0) { // member不相等且 score相等 按照member排序  return memberComp; } else { // member 和 score都不相等 按照score排序  return scoreComp; } } }   其中要单独说一下 TreeSet\nTreeSet 内部封装了一个 TreeMap 成员对象，底层是红黑树实现了有序，并且不允许重复。TreeSet中的元素必须实现Comparable接口并重写compareTo()方法，TreeSet判断元素是否重复 、以及确定元素的顺序 靠的都是这个方法；\n所以 ZNode 的 compare 方法非常关键，因为 ZNode有两个属性，一个 member， 一个 score。按照我们的需求，我们允许 score 重复，但是不允许 member 重复；且排序是优先按照 score 排序，score 相等的情况下再按照 member 字典排序。\n经过一番尝试与不断的思考，给出以下排序代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  @Override public int compareTo(ZNode o) { int scoreComp = Double.compare(score, o.score); int memberComp = member.compareTo(o.member); if (memberComp == 0) { // member 相等 则相等  return 0; } else if (scoreComp == 0) { // member不相等且 score相等 按照member排序  return memberComp; } else { // member 和 score都不相等 按照score排序  return scoreComp; } }   但是这种方案还是有问题，目前已知的有两点：\n add方法不能覆盖旧的节点，如果想对 member 相同但是分数不同的节点进行修改，无法直接add，因为compareTo()的结果虽然是相等，但是add通过比较判断相等则没有添加覆盖的操作，目前的方案是先删除旧节点，再添加。 在使用 TreeSet 方法 subSet() 截取区间时，无法保留右边界元素会失败。例如：this.subSet(new ZNode(min, new BytesWrapper()),true,new ZNode(max, new BytesWrapper()),true); 无法取到保留右边界元素。原因是：在创建ZNode的时候使用了空字符数组创建，当compareTo()比较的时候，如果 score 相等，则会比较 member，因为空串永远是最小的，所以我们想要取到的 score 值相同的 ZNode 永远比我们传入的这个节点大。  ","date":"2022-06-26T16:39:36+08:00","image":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B002-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E5%AF%B9%E8%B1%A1/log_hu0a4ba87b3d81b22780f8a722f1e0fc9b_1722333_120x120_fill_q75_box_smart1.jpg","permalink":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B002-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E5%AF%B9%E8%B1%A1/","title":"Redis设计与实现02-数据结构与对象"},{"content":"命令 继承结构 对于 redis 的众多命令，在设计实现的时候，尽可能的去抽象代码。除了抽象出命令的顶层 interface 之外，对于查询命令和修改命令，又划分出两个抽象类。最终的继承结构如下：\nclassDiagram\rCommand Command接口三个主要方法\n type()：返回命令类型 setContent(RespArray arrays)：设置命令参数 handle(RedisClient redisClient)：执行命令逻辑  AbstractCommand ：抽象了查询命令并实现了setContent(RespArray arrays)方法\nAbstractWriteCommand：\n抽象了更新修改命令并实现了setContent(RespArray arrays)、handle(RedisClient redisClient)方法。并使用了模板方法模式用于写入AOF。提供了一个钩子变量 aofOn，当该变量为 true 时，handle 方法会执行 aof.putAof 操作。\n1 2 3 4 5 6 7 8 9  @Override public Resp handle(RedisClient redisClient) { if (aofOn) { putAof(); } return handleWrite(redisClient); } public abstract Resp handleWrite(RedisClient redisClient);   实现的命令 命令手册：\nCommands | Redis\nredis 命令手册\nCONNECTION 1  auth(Auth::new), client(Client::new), config(Config::new), echo(Echo::new), ping(Ping::new), quit(Quit::new)   SEVER 1  select(Select::new), flushall(FlushAll::new), dbsize(DbSize::new), flushdb(FlushDb::new), bgsave(BgSave::new), save(Save::new)   KEY 1  expire(Expire::new), del(Del::new), exists(Exists::new), keys(Keys::new), persist(Persist::new), rename(Rename::new), ttl(Ttl::new), type(Type::new),   TRANSACTION 1  multi(Multi::new), exec(Exec::new), unwatch(UnWatch::new), watch(Watch::new), discard(Discard::new)   STRING 1  get(Get::new), set(Set::new), mget(MGet::new), mset(MSet::new), append(Append::new), setex(SetEx::new), setnx(SetNx::new)   LIST 1  lpush(LPush::new), lrange(LRange::new), lrem(LRem::new), rpush(RPush::new), lpop(LPop::new), rpop(RPop::new), lset(LSet::new), lindex(LIndex::new), llen(LLen::new),   HASH 1 2  hdel(HDel::new), hexists(HExists::new), hget(HGet::new), hgetall(HGetAll::new), hkeys(HKeys::new), hset(HSet::new), hmset(HMSet::new), hvals(HVals::new), hmget(HMGet::new),   SET 1  sadd(SAdd::new), scard(SCard::new), sdiff(SDiff::new), smembers(SMembers::new), sismember(SIsMember::new), sdiffstore(SDiffStore::new), sinter(SInter::new), sinterstore(SInterStore::new), srem(SRem::new), sunion(SUnion::new), sunionstore(SUnionStore::new),   ZSET 1 2  zadd(ZAdd::new), zcard(ZCard::new), zcount(ZCount::new), zrange(ZRange::new), zrangebyscore(ZRangeByScore::new), zrank(ZRank::new), zrem(ZRem::new), zscore(ZScore::new),   ","date":"2022-06-26T16:40:04+08:00","image":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B003-%E5%91%BD%E4%BB%A4/log_hu0a4ba87b3d81b22780f8a722f1e0fc9b_1722333_120x120_fill_q75_box_smart1.jpg","permalink":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B003-%E5%91%BD%E4%BB%A4/","title":"Redis设计与实现03-命令"},{"content":"过期策略 数据库中有一个过期字典，字典的 key 是被设置过期时间的键，字典的 value 是过期时间（long 类型 以毫秒为单位的 UNXI 时间戳）。\n删除策略 定时删除 在设置键的过期时间的同时，创建一个定时器，让定时器在键的过期时间来临时，立即执行对键的删除操作。\n优点：对内存最友好，通过使用定时器，定时删除策略可以保证过期键会尽可能快地被删除，并释放过期键所占用的内存。\n缺点：对CPU时间最不友好，在过期键比较多的情况下，删除过期键这一行为可能会占用相当一部分CPU时间。在内存不紧张但是CPU时间非常紧张的情况下，拿CPU去做与当前任务无关的过期键上没有意义。\n惰性删除 放任过期键不管，但是每次从键空间中获取键时，都检查取得的键是否过期，如果过期的话，就删除该键；如果没有过期，就返回该键。\n优点：对CPU时间最友好，不会在删除其他无关的过期键上花费任何CPU时间\n缺点：对内存最不友好，如果一个键已经过期，而这个键又仍然保留在数据库中，那么只要这个过期键不被删除，它所占用的内存就不会释放。可以把这种情况视为一种内存泄漏。\n定期删除 每隔一段时间， 程序就对数据库进行一次检查，删除里面的过期键。至于要删除多少过期键，以及要检查多少个数据库，则由算法决定。\n定期策略是前两种策略的一种整合和折中：\n 定期删除策略每隔一段时间执行一次删除过期键操作，并通过限制删除操作执行的时长和频率来减少删除操作对CPU时间的影响。 除此之外，通过定期删除过期键，定期删除策略有效地减少了因为过期键而带来的内存浪费  定期删除策略的难点是确定删除操作执行的时长和频率：\n 如果删除操作执行地太过频繁，或者执行的时间太长，定期删除策略就退化成定时删除策略 如果删除操作执行得太少，或者执行地太短，定期删除策略又会和惰性删除策略一样，出现浪费内存的情况  Redis 的过期键删除策略 Redis 使用了惰性删除策略和定期删除策略结合的方式\n惰性删除策略的实现 所有读写数据库的命令在执行之前都会先判断输入键是否已经过期\n 如果输入键已经过期，那么将输入键删除 如果输入键未过期，那么正常执行  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  public class RedisDBImpl implements RedisDB { // 过期字典  private final Map\u0026lt;BytesWrapper, Long\u0026gt; expires = new HashMap\u0026lt;\u0026gt;(); //\t在获取键的时候先判断是否已经过期，如果过期就删除  public RedisObject get(BytesWrapper key) { RedisObject redisObject = dict.get(key); if (redisObject == null) { return null; } else if (isExpired(key)){ expires.remove(key); dict.remove(key); return null; } else { redisObject.refreshLru(); redisObject.updateLfu(); return redisObject; } } }   定期删除策略的实现 ServerCron 是服务器的时间事件之一，主要执行一些周期性操作。定期策略在 ServerCron 类中被调用：\n1 2 3  private void databasesCron() { expireStrategy.activeExpireCycle(); }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  @Override public void activeExpireCycle() { start = System.currentTimeMillis(); int dbSize = dbs.size(); if (dbSize \u0026lt; dbNumbers) { // 如果数据库当前数量比默认的数量少，取当前数量  dbNumbers = dbSize; } // 当前遍历到的数据库索引  currentDb %= dbSize; int deleteCount = 0; // keyNumbers为每次从数据库过期字典中取出的键的数量，默认为20  for (int i = 0; i \u0026lt; keyNumbers; i++){ RedisDB redisDB = dbs.get(currentDb); int expiresSize = redisDB.expiresSize(); if (expiresSize == 0) return; // 随机取，看是否过期，过期就删除它  BytesWrapper randomKey = redisDB.getRandomExpires(); if (redisDB.isExpired(randomKey)) { LOGGER.info(\u0026#34;过期key: \u0026#34; + randomKey.toUtf8String() + \u0026#34;被删除\u0026#34;); deleteCount++; redisDB.delete(randomKey); } //\t执行事件到达上限则结束 timeLimit = TimeUnit.MICROSECONDS.toMillis(1000)  if (System.currentTimeMillis() - start \u0026gt; timeLimit) { return; } // 如果抽样的 20 个键过期的超过 1/4 则重复该过程  if (deleteCount \u0026gt; keyNumbers / 4) { deleteCount = 0; i = 0; } } }   扩展：从库的过期策略 从库不会进行过期扫描，从库对过期的处理是被动的。主库在 key 到期时，会在 AOF 文件里增加一条 del 指令，同步到所有的从库，从库通过执行这条 del 指令来删除过期的 key。\n因为指令同步是异步进行的，所以主库过期的 key 的 del 指令没有及时同步到从库的话，会出现主从数据的不一致，主库没有的数据在从库里还存在。\n逐出策略 数据淘汰机制 Redis 内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。Redis 提供 6 种数据淘汰策略：\n volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用 的数据淘汰 volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数 据淘汰，ttl （Time To Live）越小越优先被淘汰。 volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据 淘汰 allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰 allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰 no-enviction（驱逐）：禁止驱逐数据  redis5.0新增：\n volatile-lfu：从已设置过期时间的数据集挑选使用频率最低的数据淘汰。 allkeys-lfu：从数据集中挑选使用频率最低的数据淘汰。  volatile-xxx 策略只会针对带过期时间的 key 进行淘汰，allkeys-xxx 策略会对所有的 key 进行淘汰。如果你只是拿 Redis 做缓存，那应该使用 allkeys-xxx，客户端写缓存时不必携带过期时间。如果你还想同时使用 Redis 的持久化功能，那就使用 volatile-xxx 策略，这样可以保留没有设置过期时间的 key，它们是永久的 key 不会被 LRU 算法淘汰。\n实现 何时淘汰？ Redis实例支持通过修改配置参数（maxmemory-policy），修改数据逐出策略。在达到内存上限（maxmemory）时，Redis根据逐出策略进行数据逐出。\n而 Java-Redis 是基于 Java 语言实现，那么内存大小就受限于 JVM内存大小。\n  JVM初始分配的内存由-Xms指定，默认是物理内存的1/64;\n  JVM最大分配的内存由-Xmx指定，默认是物理内存的1/4。\n  默认空余堆内存**小于40%**时，JVM就会增大堆直到-Xmx的最大限制；\n  空余堆内存**大于70%**时，JVM会减少堆直到-Xms的最小限制。因此服务器一般设置-Xms、-Xmx相等以避免在每次GC后调整堆的大小。\n  而且 Java 提供的 Runtime.getRuntime().totalMemory() 、 Runtime.getRuntime().maxMemory() 、Runtime.getRuntime().freeMemory()方法能获取当前 JVM 已分配内存 、 JVM 最大可扩展内存以及 JVM 当前已分配内存中的空闲内存。\n为了适配 JVM 内存，给出以下内存策略：\n建议初始内存和最大内存参数相等，这样可以避免运行过程中的内存重分配过程，也更容易精确计算当前内存的占用情况。\n但是：由于 JVM 的内存的 GC 时间是不固定的，有些已经被淘汰的键不能被虚拟机及时回收，可能会造成获取的内存占用信息实时性不强的问题，这是由于 JVM 内存本身机制决定，能力有限，暂时没有想到更优的解决办法。\n 什么时候触发 GC？\n什么时候触发Young GC\u0026mdash;-针对年轻代\n当Eden区满了的时候，会触发Young GC\n什么时候触发 Full GC\u0026mdash;-针对整个堆\n 在发生Young GC的时候，虚拟机会检测之前每次晋升到老年代的平均大小是否大于年老代的剩余空间，如果大于，则直接进行Full GC； 如果小于，但设置了Handle PromotionFailure，那么也会执行Full GC。  1 2 3  -XX:HandlePromotionFailure：是否设置空间分配担保 JDK7及以后这个参数就失效了. 只要老年代的连续空间大于新生代对象的总大小或者历次晋升到老年代的对象的平均大小就进行MinorGC，否则FullGC    永久代空间不足，会触发Full GC\n  System.gc()也会触发Full GC\n  堆中分配很大的对象\n   1 2 3 4 5 6 7 8 9 10 11 12 13  private void evict() { Runtime runtime = Runtime.getRuntime(); int i = -1; while (runtime.freeMemory() \u0026lt; 0.2 * runtime.totalMemory()) { i = (i + 1) % dbs.size(); if (dbs.get(i).size() != 0) { evictStrategy.setDb(dbs.get(i)); evictStrategy.doEvict(); } else { continue; } } }   Volatile-Random-Evict 1 2 3 4 5 6 7 8 9  public class VolatileRandomEvict extends AbstractEvictStrategy { @Override public void doEvict() { // 从过期字典中随机删除一个  BytesWrapper randomKey = db.getRandomExpires(); db.delete(randomKey); LOGGER.info(\u0026#34;淘汰了key : \u0026#34; + randomKey); } }   AllKeys-Random-Evict 1 2 3 4 5 6 7 8  public class AllKeysRandomEvict extends AbstractEvictStrategy { @Override public void doEvict() { BytesWrapper randomKey = db.getRandomKey(); db.delete(randomKey); LOGGER.info(\u0026#34;淘汰了key : \u0026#34; + randomKey); } }   No-Evict 1 2 3 4 5 6  public class NoEvict extends AbstractEvictStrategy { @Override public void doEvict() { return; } }   Volatile-Lru-Evict 近似 LRU 算法\n严格的 LRU 算法需要单独维护一个访问队列，这对于数据量很大的缓存系统来说是极度影响性能的。\nRedis 使用的是一种近似 LRU 算法，因为 LRU 算法消耗大量的额外的内存。近似 LRU 算法则很简单，在现有数据结构的基础上使用随机采样法来淘汰元素，能达到和 LRU 算法非常近似的效果。\n它给每个 key 增加了一个额外的小字段 lru，也就是最后一次被访问的时间戳。然后从过期字典种随机采样出 samples（默认为20） 个 key，然后淘汰掉最旧的 key，如果淘汰后内存还是超出 maxmemory，那就继续随机采样淘汰，直到内存低于 maxmemory 为止。\n每次访问到key的时候会更调用 refreshLru() 新键对应的数据对象的 lru 记录。\n Redis3.0之后又改善了算法的性能，会提供一个待淘汰候选key的pool，里面默认有16个key，按照空闲时间排好序。更新时从Redis键空间随机选择N个key，分别计算它们的空闲时间idle，key只会在pool不满或者空闲时间大于pool里最小的时，才会进入pool，然后从pool中选择空闲时间最大的key淘汰掉。\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  public class VolatileLruEvict extends AbstractEvictStrategy { @Override public void doEvict() { if (db.expiresSize() == 0) { LOGGER.info(\u0026#34;没有易失键，尝试淘汰失败\u0026#34;); return; } BytesWrapper lruKey = null; long min = Long.MAX_VALUE; for (int i = 0; i \u0026lt; samples; i++) { BytesWrapper randomKey = db.getRandomExpires(); long lru = db.get(randomKey).getLru(); if (lru \u0026lt; min) { lruKey = randomKey; min = lru; } } db.delete(lruKey); LOGGER.info(\u0026#34;淘汰了key : \u0026#34; + lruKey.toUtf8String()); } }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  public abstract class AbstractRedisObject implements RedisObject{ // 最近访问时间  private long lru; @Override public long getLru() { return lru; } @Override public void refreshLru() { lru = System.currentTimeMillis(); } }   AllKeys-Lru-Evict 同 VolatileLruEvict，只不过采样的键的来源从过期字典变为全部键空间。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  public class AllKeysLruEvict extends AbstractEvictStrategy { @Override public void doEvict() { BytesWrapper lruKey = null; long min = Long.MAX_VALUE; for (int i = 0; i \u0026lt; samples; i++) { BytesWrapper randomKey = db.getRandomKey(); long lru = db.get(randomKey).getLru(); if (lru \u0026lt; min) { lruKey = randomKey; min = lru; } } db.delete(lruKey); LOGGER.info(\u0026#34;淘汰了key : \u0026#34; + lruKey.toUtf8String()); } }   Volatile-Lfu-Evict 强烈推荐阅读！👀：Redis中的LFU算法 - 再见紫罗兰 - 博客园 (cnblogs.com)\nLFU 思路：在LFU算法中，可以为每个key维护一个计数器。每次key被访问的时候，计数器增大。计数器越大，可以约等于访问越频繁。\n上述简单算法存在两个问题：\n 在LRU算法中可以维护一个双向链表，然后简单的把被访问的节点移至链表开头，但在LFU中是不可行的，节点要严格按照计数器进行排序，新增节点或者更新节点位置时，时间复杂度可能达到O(N)。 只是简单的增加计数器的方法并不完美。访问模式是会频繁变化的，一段时间内频繁访问的key一段时间之后可能会很少被访问到，只增加计数器并不能体现这种趋势。  第一个问题很好解决，可以借鉴LRU实现的经验，维护一个待淘汰key的pool。\n第二个问题的解决办法是，记录key最后一个被访问的时间，然后随着时间推移，降低计数器。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  public class VolatileLfuEvict extends AbstractEvictStrategy { @Override public void doEvict() { BytesWrapper lfuKey = null; long min = Long.MAX_VALUE; for (int i = 0; i \u0026lt; samples; i++) { BytesWrapper randomKey = db.getRandomExpires(); long lfu = db.get(randomKey).lfuDecrAndReturn(); if (lfu \u0026lt; min) { lfuKey = randomKey; min = lfu; } } db.delete(lfuKey); LOGGER.info(\u0026#34;淘汰了key : \u0026#34; + lfuKey.toUtf8String()); } }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61  public abstract class AbstractRedisObject implements RedisObject{ // 访问计数  private int accessCount; // 最近一次 accessCount 降低的时间  private long ldt; // 65535 分钟为一个周期 每过一个周期降低accessCount  private static final long LFU_DECAY_TIME = 3932100000L; // accessCount 初始值  private static final int LFU_INIT_VAL = 5; // 控制 accessCount 增长的因子 因子越大，增长的概率越小  private static final int LFU_LOG_FACTOR = 10; public AbstractRedisObject() { this.lru = System.currentTimeMillis(); this.accessCount = LFU_INIT_VAL; this.ldt = System.currentTimeMillis(); } /** * redis 源码逻辑 * void updateLFU(robj *val) { * unsigned long counter = LFUDecrAndReturn(val); * counter = LFULogIncr(counter); * val-\u0026gt;lru = (LFUGetTimeInMinutes()\u0026lt;\u0026lt;8) | counter; * } */ @Override public void updateLfu() { lfuDecrAndReturn(); // 最大值为255  if (accessCount == 255) { return; } // 取一个0-1之间的随机数r与p比较，当r\u0026lt;p时，才增加 accessCount，这和比特币中控制产出的策略类似。  // p取决于当前 accessCount 值与 LFU_LOG_FACTOR 因子，  // accessCount 值与 LFU_LOG_FACTOR 因子越大，p越小，r\u0026lt;p 的概率也越小，accessCount 增长的概率也就越小。  // 可见 accessCount 增长与访问次数呈现对数增长的趋势，随着访问次数越来越大，accessCount 增长的越来越慢  double r = new Random().nextDouble(); double baseval = accessCount - LFU_INIT_VAL; if (baseval \u0026lt; 0) baseval = 0; double p = 1.0 / (baseval * LFU_LOG_FACTOR + 1); if (r \u0026lt; p) accessCount++; } //\t距离该key上次被访问，每过去一个周期即LFU_DECAY_TIME，accessCount就要减少1  //\t这样即使以前被经常访问的key，后来不再访问，也会慢慢降低其accessCount  @Override public int lfuDecrAndReturn() { long l = System.currentTimeMillis() - ldt; long decr = l / LFU_DECAY_TIME; if (decr != 0) { accessCount -= decr; ldt = System.currentTimeMillis(); } return accessCount; } }   AllKeys-Lfu-Evict 同 VolatileLfuEvict，只不过采样的键的来源从过期字典变为全部键空间。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  public class AllKeysLfuEvict extends AbstractEvictStrategy { @Override public void doEvict() { BytesWrapper lfuKey = null; long min = Long.MAX_VALUE; for (int i = 0; i \u0026lt; samples; i++) { BytesWrapper randomKey = db.getRandomKey(); long lfu = db.get(randomKey).lfuDecrAndReturn(); if (lfu \u0026lt; min) { lfuKey = randomKey; min = lfu; } } db.delete(lfuKey); LOGGER.info(\u0026#34;淘汰了key : \u0026#34; + lfuKey.toUtf8String()); } }   Volatile-Ttl-Evict 仅限于易失键，即过期字典中的键，随机采样并淘汰其中最早过期的键。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  public class VolatileTtlEvict extends AbstractEvictStrategy { @Override public void doEvict() { BytesWrapper ttlKey = null; long min = Long.MAX_VALUE; for (int i = 0; i \u0026lt; samples; i++) { BytesWrapper randomKey = db.getRandomKey(); Long ttl = db.getTtl(randomKey); if (ttl \u0026lt; min) { ttlKey = randomKey; min = ttl; } } db.delete(ttlKey); LOGGER.info(\u0026#34;淘汰了key : \u0026#34; + ttlKey.toUtf8String()); } }   ","date":"2022-06-26T16:40:14+08:00","image":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B004-%E8%BF%87%E6%9C%9F%E7%AD%96%E7%95%A5%E4%B8%8E%E9%80%90%E5%87%BA%E7%AD%96%E7%95%A5/log_hu0a4ba87b3d81b22780f8a722f1e0fc9b_1722333_120x120_fill_q75_box_smart1.jpg","permalink":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B004-%E8%BF%87%E6%9C%9F%E7%AD%96%E7%95%A5%E4%B8%8E%E9%80%90%E5%87%BA%E7%AD%96%E7%95%A5/","title":"Redis设计与实现04-过期策略与逐出策略"},{"content":"Redis 中的事务 ","date":"2022-06-26T16:40:21+08:00","image":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B005-%E4%BA%8B%E5%8A%A1/log_hu0a4ba87b3d81b22780f8a722f1e0fc9b_1722333_120x120_fill_q75_box_smart1.jpg","permalink":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B005-%E4%BA%8B%E5%8A%A1/","title":"Redis设计与实现05-事务"},{"content":"","date":"2022-06-26T16:40:26+08:00","image":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B006-%E6%8C%81%E4%B9%85%E5%8C%96/log_hu0a4ba87b3d81b22780f8a722f1e0fc9b_1722333_120x120_fill_q75_box_smart1.jpg","permalink":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B006-%E6%8C%81%E4%B9%85%E5%8C%96/","title":"Redis设计与实现06-持久化"},{"content":"参考：\nLinux IO模式及 select、poll、epoll详解 - SegmentFault 思否\n一文搞懂select、poll和epoll区别 - 知乎 (zhihu.com)\n一些前置概念 用户空间与内核空间 现在操作系统都是采用虚拟存储器，那么对32位操作系统而言，它的寻址空间（虚拟存储空间）为4G（2的32次方）。操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。为了保证用户进程不能直接操作内核（kernel），保证内核的安全，操心系统将虚拟空间划分为两部分，一部分为内核空间，一部分为用户空间。\n进程阻塞 正在执行的进程，由于期待的某些事件未发生，如请求系统资源失败、等待某种操作的完成、新数据尚未到达或无新工作做等，则由系统自动执行阻塞原语(Block)，使自己由运行状态变为阻塞状态。可见，进程的阻塞是进程自身的一种主动行为，也因此只有处于运行态的进程（获得CPU），才可能将其转为阻塞状态。当进程进入阻塞状态，是不占用CPU资源的。\n文件描述符 fd 文件描述符（File descriptor）是计算机科学中的一个术语，是一个用于表述指向文件的引用的抽象化概念。\n文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展开。但是文件描述符这一概念往往只适用于UNIX、Linux这样的操作系统。\n缓存 I/O 缓存 I/O 又被称作标准 I/O，大多数文件系统的默认 I/O 操作都是缓存 I/O。在 Linux 的缓存 I/O 机制中，操作系统会将 I/O 的数据缓存在文件系统的页缓存（ page cache ）中，也就是说，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。\n缓存 I/O 的缺点： 数据在传输过程中需要在应用程序地址空间和内核进行多次数据拷贝操作，这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的\nI/O 模式 对于一次IO访问（以read举例），数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。所以说，当一个read操作发生时，它会经历两个阶段：\n 等待数据准备 (Waiting for the data to be ready) 将数据从内核拷贝到进程中 (Copying the data from the kernel to the process)  正式因为这两个阶段，linux系统产生了下面五种网络模式的方案。\n 阻塞 I/O（blocking IO） 非阻塞 I/O（nonblocking IO） I/O 多路复用（ IO multiplexing） 信号驱动 I/O（ signal driven IO） 异步 I/O（asynchronous IO）  阻塞 I/O（blocking IO） 在linux中，默认情况下所有的socket都是blocking，一个典型的读操作流程大概是这样：\n当用户进程调用了recvfrom这个系统调用，kernel就开始了IO的第一个阶段：准备数据（对于网络IO来说，很多时候数据在一开始还没有到达。比如，还没有收到一个完整的UDP包。这个时候kernel就要等待足够的数据到来）。这个过程需要等待，也就是说数据被拷贝到操作系统内核的缓冲区中是需要一个过程的。而在用户进程这边，整个进程会被阻塞（当然，是进程自己选择的阻塞）。当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。\n 所以，blocking IO的特点就是在IO执行的两个阶段都被block了。\n 非阻塞 I/O（nonblocking IO） linux下，可以通过设置socket使其变为non-blocking。当对一个non-blocking socket执行读操作时，流程是这个样子：\n当用户进程发出read操作时，如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error。从用户进程角度讲 ，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的system call，那么它马上就将数据拷贝到了用户内存，然后返回。\n 所以，nonblocking IO的特点是用户进程需要不断的主动询问kernel数据好了没有。\n I/O 多路复用（ IO multiplexing） IO multiplexing就是我们说的select，poll，epoll，有些地方也称这种IO方式为event driven IO。select/epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基本原理就是select，poll，epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。\n当用户进程调用了select，那么整个进程会被block，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。\n 所以，I/O 多路复用的特点是通过一种机制一个进程能同时等待多个文件描述符，而这些文件描述符（套接字描述符）其中的任意一个进入读就绪状态，select()函数就可以返回。\n 这个图和blocking IO的图其实并没有太大的不同，事实上，还更差一些。因为这里需要使用两个system call (select 和 recvfrom)，而blocking IO只调用了一个system call (recvfrom)。但是，用select的优势在于它可以同时处理多个connection。\n所以，如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好，可能延迟还更大。select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。）\n在IO multiplexing Model中，实际中，对于每一个socket，一般都设置成为non-blocking，但是，如上图所示，整个用户的process其实是一直被block的。只不过process是被select这个函数block，而不是被socket IO给block。\n异步 I/O（asynchronous IO） inux下的asynchronous IO其实用得很少。先看一下它的流程：\n用户进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。\n信号驱动 I/O（ signal driven IO） 在信号驱动式I/O模型中，应用程序使用套接口进行信号驱动I/O，并安装一个信号处理函数，进程继续运行并不阻塞。当数据准备好时，进程会收到一个SIGIO信号，可以在信号处理函数中调用I/O操作函数处理数据\n异步 I/O与信号驱动 I/O的主要区别在于：信号驱动I/O是由内核通知应用程序何时启动一个I/O操作，而异步I/O模型是由内核通知应用程序I/O操作何时完成\n优点：线程并没有在等待数据时被阻塞，可以提高资源的利用率\n缺点：信号I/O在大量IO操作时可能会因为信号队列溢出导致没法通知。\n信号驱动I/O尽管对于处理UDP套接字来说有用，即这种信号通知意味着到达一个数据报，或者返回一个异步错误。但是，对于TCP而言，信号驱动的I/O方式近乎无用，因为导致这种通知的条件为数众多，每一个来进行判别会消耗很大资源。\nIO模式总结 blocking和non-blocking的区别 调用blocking IO会一直block住对应的进程直到操作完成，而non-blocking IO在kernel还准备数据的情况下会立刻返回。\nsynchronous IO和asynchronous IO的区别 在说明synchronous IO和asynchronous IO的区别之前，需要先给出两者的定义。POSIX的定义是这样子的：\n A synchronous I/O operation causes the requesting process to be blocked until that I/O operation completes; An asynchronous I/O operation does not cause the requesting process to be blocked;  两者的区别就在于synchronous IO做”IO operation”的时候会将process阻塞。按照这个定义，之前所述的blocking IO，non-blocking IO，IO multiplexing都属于synchronous IO。\n这里有个非常“狡猾”的地方，定义中所指的”IO operation”是指真实的IO操作，就是例子中的recvfrom这个system call。non-blocking IO在执行recvfrom这个system call的时候，如果kernel的数据没有准备好，这时候不会block进程。但是，当kernel中数据准备好的时候，recvfrom会将数据从kernel拷贝到用户内存中，这个时候进程是被block了，在这段时间内，进程是被block的。\n而asynchronous IO则不一样，当进程发起IO 操作之后，就直接返回再也不理睬了，直到kernel发送一个信号，告诉进程说IO完成。在这整个过程中，进程完全没有被block。\n各个IO Model的比较如图所示：\n通过上面的图片，可以发现non-blocking IO和asynchronous IO的区别还是很明显的。在non-blocking IO中，虽然进程大部分时间都不会被block，但是它仍然要求进程去主动的check，并且当数据准备完成以后，也需要进程主动的再次调用recvfrom来将数据拷贝到用户内存。而asynchronous IO则完全不同。它就像是用户进程将整个IO操作交给了他人（kernel）完成，然后他人做完后发信号通知。在此期间，用户进程不需要去检查IO操作的状态，也不需要主动的去拷贝数据。\nI/O 多路复用之select、poll、epoll、kqueue详解 select，poll，epoll，kqueue都是IO多路复用的机制。I/O多路复用就是通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。（这里啰嗦下）\nselect 1 2 3 4  int select (int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout); //\twritefds、readfds、和exceptfds　是三个指针，分别记录了读、写和 except 事件描述符 //\t进程调用select的时候会把这三个指针传递进函数并阻塞直到有就绪事件 //\t如果有就绪的事件对应的描述符，会对其设置就绪，select 返回后进程可以遍历所有的描述符，找到就绪的进行处理。   select 函数监视的文件描述符分3类，分别是writefds、readfds、和exceptfds。调用后select函数会阻塞，直到有描述副就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以 通过遍历fdset，来找到就绪的描述符。\nselect目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点。select的一 个缺点在于单个进程能够监视的文件描述符的数量存在最大限制，在Linux上一般为1024，可以通过修改宏定义甚至重新编译内核的方式提升这一限制，但 是这样也会造成效率的降低。\n调用过程\n 使用copy_from_user从用户空间拷贝fd_set到内核空间 注册回调函数__pollwait 遍历所有fd，调用其对应的poll方法（对于socket，这个poll方法是sock_poll，sock_poll根据情况会调用到tcp_poll，udp_poll或datagram_poll），以tcp_poll为例，核心实现就是__pollwait，即上面注册的回调函数。__pollwait，就是把current（当前进程）挂到设备的等待队列，不同设备有不同等待队列，如tcp_poll的等待队列是sk-\u0026gt;sk_sleep（把进程挂到等待队列中并不代表进程已睡眠）。在设备收到一条消息（网络设备）或填写完文件数据（磁盘设备）后，会唤醒设备等待队列上睡眠的进程，这时current便被唤醒。 poll方法返回时会返回一个描述读写操作是否就绪的mask掩码，根据这个mask掩码给fd_set赋值 若遍历完所有fd，还没返回一个可读写的mask掩码，则调schedule_timeout是调用select的进程（也就是current）进入睡眠。当设备驱动发生自身资源可读写后，会唤醒其等待队列上睡眠的进程。若超过一定超时时间（schedule_timeout指定），还没人唤醒，则调用select的进程会重新被唤醒获得CPU，进而重新遍历fd，判断有无就绪的fd 把fd_set从内核空间拷贝到用户空间  缺点\n内核需要将消息传递到用户空间，都需要内核拷贝动作。需要维护一个用来存放大量fd的数据结构，使得用户空间和内核空间在传递该结构时复制开销大。\n 每次调用select，都需把fd集合从用户态拷贝到内核态，fd很多时开销就很大 同时每次调用select都需在内核遍历传递进来的所有fd，fd很多时开销就很大 select支持的文件描述符数量太小了，默认最大支持1024个 主动轮询效率很低  poll 1  int poll (struct pollfd *fds, unsigned int nfds, int timeout);   不同与select使用三个位图来表示三个fdset的方式，poll使用一个 pollfd的指针实现。\n1 2 3 4 5  struct pollfd { int fd; /* 文件描述符 */ short events; /* 要监视的事件 */ short revents; /* 发生的事件 */ };   pollfd结构包含了要监视的event和发生的event，不再使用select“参数-值”传递的方式。同时，pollfd并没有最大数量限制（但是数量过大后性能也是会下降）。 和select函数一样，poll返回后，需要轮询pollfd来获取就绪的描述符。\npoll和select同样存在一个缺点就是，包含大量文件描述符的数组被整体复制于用户态和内核的地址空间之间，而不论这些文件描述符是否就绪，它的开销随着文件描述符数量的增加而线性增大。\n  它将用户传入的数组拷贝到内核空间\n  然后查询每个fd对应的设备状态：\n   如果设备就绪 在设备等待队列中加入一项继续遍历 若遍历完所有fd后，都没发现就绪的设备 挂起当前进程，直到设备就绪或主动超时，被唤醒后它又再次遍历fd。这个过程经历多次无意义的遍历。     从上面看，select和poll都需要在返回后，通过遍历文件描述符来获取已经就绪的socket。事实上，同时连接的大量客户端在一时刻可能只有很少的处于就绪状态，因此随着监视的描述符数量的增长，其效率也会线性下降。\n epoll epoll是在2.6内核中提出的，是之前的select和poll的增强版本。相对于select和poll来说，epoll更加灵活，没有描述符限制。epoll使用一个文件描述符管理多个描述符，将用户关心的文件描述符的事件存放到内核的一个事件表中，用户每次新增和删除监听事件都通过内核中的这个事件表，这样在用户空间和内核空间的copy只需一次。select 和 poll 都需要把fd表或者数据结构拷贝到内核态再从内核态取出。\nepoll模型修改主动轮询为被动通知，当有事件发生时，被动接收通知。所以epoll模型注册套接字后，主程序可做其他事情，当事件发生时，接收到通知后再去处理。可理解为event poll，epoll会把哪个流发生哪种I/O事件通知我们。所以epoll是事件驱动（每个事件关联fd），此时我们对这些流的操作都是有意义的。复杂度也降到O(1)。\nepoll操作过程 epoll操作过程需要三个接口，分别如下：\n1 2 3  int epoll_create(int size)；//创建一个epoll的句柄（epfd），size用来告诉内核这个监听的数目一共有多大 int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；// 增删改某个fd的某个事件 int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);\t// 等待 epfd 上的事件   1. int epoll_create(int size); 创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大，这个参数不同于select()中的第一个参数，给出最大监听的fd+1的值，参数size并不是限制了epoll所能监听的描述符最大个数，只是对内核初始分配内部数据结构的一个建议。 当创建好epoll句柄后，它就会占用一个fd值，在linux下如果查看/proc/进程id/fd/，是能够看到这个fd的，所以在使用完epoll后，必须调用close()关闭，否则可能导致fd被耗尽。\n2. int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)； 函数是对指定描述符fd执行op操作。 - epfd：是epoll_create()的返回值。 - op：表示op操作，用三个宏来表示：添加EPOLL_CTL_ADD，删除EPOLL_CTL_DEL，修改EPOLL_CTL_MOD。分别添加、删除和修改对fd的监听事件。 - fd：是需要监听的fd（文件描述符） - epoll_event：是告诉内核需要监听什么事，struct epoll_event结构如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13  struct epoll_event { __uint32_t events; /* Epoll events */ epoll_data_t data; /* User data variable */ }; //events可以是以下几个宏的集合： EPOLLIN ：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）； EPOLLOUT：表示对应的文件描述符可以写； EPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）； EPOLLERR：表示对应的文件描述符发生错误； EPOLLHUP：表示对应的文件描述符被挂断； EPOLLET： 将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的。 EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里   3. int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout); 等待epfd上的io事件，最多返回maxevents个事件。 参数events用来从内核得到事件的集合，maxevents告之内核这个events有多大，这个maxevents的值不能大于创建epoll_create()时的size，参数timeout是超时时间（毫秒，0会立即返回，-1将不确定，也有说法说是永久阻塞）。该函数返回需要处理的事件数目，如返回0表示已超时。\n工作模式 epoll对文件描述符的操作有两种模式：LT（level trigger）和ET（edge trigger）。LT模式是默认模式，LT模式与ET模式的区别如下：\nLT模式，默认的模式（水平触发：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用epoll_wait时，会再次响应应用程序并通知此事件。\nET模式，“高速”模式（边缘触发）：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。\nLT模式\nLT(level triggered)是缺省的工作方式，并且同时支持block和no-block socket.在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你的。\nET模式\nET(edge-triggered)是高速工作方式，只支持no-block socket。在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知，直到你做了某些操作导致那个文件描述符不再为就绪状态了(比如，你在发送，接收或者接收请求，或者发送接收的数据少于一定量时导致了一个EWOULDBLOCK 错误）。但是请注意，如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核不会发送更多的通知(only once)\nET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。epoll工作在ET模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。\n假如有这样一个例子：\n 我们已经把一个用来从管道中读取数据的文件句柄(RFD)添加到epoll描述符 这个时候从管道的另一端被写入了2KB的数据 调用epoll_wait(2)，并且它会返回RFD，说明它已经准备好读取操作 然后我们读取了1KB的数据 调用epoll_wait(2)\u0026hellip;\u0026hellip;  LT模式： 如果是LT模式，那么在第5步调用epoll_wait(2)之后，仍然能受到通知。\nET模式： 如果我们在第1步将RFD添加到epoll描述符的时候使用了EPOLLET标志，那么在第5步调用epoll_wait(2)之后将有可能会挂起，因为剩余的数据还存在于文件的输入缓冲区内，而且数据发出端还在等待一个针对已经发出数据的反馈信息。只有在监视的文件句柄上发生了某个事件的时候 ET 工作模式才会汇报事件。因此在第5步的时候，调用者可能会放弃等待仍在存在于文件输入缓冲区内的剩余数据。\n当使用epoll的ET模型来工作时，当产生了一个EPOLLIN事件后， 读数据的时候需要考虑的是当recv()返回的大小如果等于请求的大小，那么很有可能是缓冲区还有数据未读完，也意味着该次事件还没有处理完，所以还需要再次读取：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  while(rs){ buflen = recv(activeevents[i].data.fd, buf, sizeof(buf), 0); if(buflen \u0026lt; 0){ // 由于是非阻塞的模式,所以当errno为EAGAIN时,表示当前缓冲区已无数据可读  // 在这里就当作是该次事件已处理处.  if(errno == EAGAIN){ break; } else{ return; } } else if(buflen == 0){ // 这里表示对端的socket已正常关闭.  } if(buflen == sizeof(buf){ rs = 1; // 需要再次读取  } else{ rs = 0; } }    Linux中的EAGAIN含义\n Linux环境下开发经常会碰到很多错误(设置errno)，其中EAGAIN是其中比较常见的一个错误(比如用在非阻塞操作中)。 从字面上来看，是提示再试一次。这个错误经常出现在当应用程序进行一些非阻塞(non-blocking)操作(对文件或socket)的时候。\n例如，以 O_NONBLOCK的标志打开文件/socket/FIFO，如果你连续做read操作而没有数据可读。此时程序不会阻塞起来等待数据准备就绪返回，read函数会返回一个错误EAGAIN，提示你的应用程序现在没有数据可读请稍后再试。 又例如，当一个系统调用(比如fork)因为没有足够的资源(比如虚拟内存)而执行失败，返回EAGAIN提示其再调用一次(也许下次就能成功)。\n优点  没有最大并发连接的限制，能打开的FD的上限远大于1024（1G的内存上能监听约10万个端口） 效率提升，不是轮询，不会随着FD数目的增加效率下降。只有活跃可用的FD才会调用callback函数 即Epoll最大的优点就在于它只关心“活跃”的连接，而跟连接总数无关，因此在实际的网络环境中，Epoll的效率就会远远高于select和poll 内存拷贝，利用mmap()文件映射内存加速与内核空间的消息传递；即epoll使用mmap减少复制开销。 epoll通过内核和用户空间共享一块内存来实现的  kqueue kqueue和epoll一样，都是用来替换select和poll的。不同的是kqueue被用在FreeBSD,NetBSD, OpenBSD, DragonFly BSD, 和 macOS中。\nkqueue 不仅能够处理文件描述符事件，还可以用于各种其他通知，例如文件修改监视、信号、异步 I/O 事件 (AIO)、子进程状态更改监视和支持纳秒级分辨率的计时器，此外kqueue提供了一种方式除了内核提供的事件之外，还可以使用用户定义的事件。\nkqueue提供了两个API，第一个是构建kqueue：\n1  int kqueue(void);   第二个是创建kevent:\n1  int kevent(int kq, const struct kevent *changelist, int nchanges, struct kevent *eventlist, int nevents, const struct timespec *timeout);   kevent中的第一个参数是要注册的kqueue，changelist是要监视的事件列表，nchanges表示要监听事件的长度，eventlist是kevent返回的事件列表,nevents表示要返回事件列表的长度，最后一个参数是timeout。\n除此之外，kqueue还有一个用来初始化kevent结构体的EV_SET宏：\n1  EV_SET(\u0026amp;kev, ident, filter, flags, fflags, data, udata);   总结 在 select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，而epoll事先通过epoll_ctl()来注册一 个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait() 时便得到通知。(此处去掉了遍历文件描述符，而是通过监听回调的的机制。这正是epoll的魅力所在。)\nselect，poll，epoll都是IO多路复用机制，即可以监视多个描述符，一旦某个描述符就绪（读或写就绪），能够通知程序进行相应读写操作。 但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。\n select，poll实现需要自己不断轮询所有fd集合，直到设备就绪，期间可能要睡眠和唤醒多次交替。而epoll其实也需要调用epoll_wait不断轮询就绪链表，期间也可能多次睡眠和唤醒交替，但是它是设备就绪时，调用回调函数，把就绪fd放入就绪链表中，并唤醒在epoll_wait中进入睡眠的进程。虽然都要睡眠和交替，但是select和poll在“醒着”的时候要遍历整个fd集合，而epoll在“醒着”的时候只要判断一下就绪链表是否为空就行了，这节省了大量的CPU时间。这就是回调机制带来的性能提升。 select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把current往设备等待队列中挂一次，而epoll只要一次拷贝，而且把current往等待队列上挂也只挂一次（在epoll_wait的开始，注意这里的等待队列并不是设备等待队列，只是一个epoll内部定义的等待队列）。这也能节省不少的开销。   如果没有大量的idle -connection或者dead-connection，epoll的效率并不会比select/poll高很多，但是当遇到大量的idle- connection，就会发现epoll的效率大大高于select/poll。\n ","date":"2022-06-24T13:45:35+08:00","permalink":"https://isheihei.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/io%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90%E4%B8%8E%E5%AF%B9%E6%AF%94/","title":"IO模型分析与对比"},{"content":"Arrays.sort(arr) 冒泡排序（超时） 快排 单指针版 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  public int[] MySort(int[] arr) { quickSort(arr, 0, arr.length - 1); return arr; } private void quickSort(int[] array, int start, int end) { if (start \u0026lt; end) { int key = array[start];//用待排数组的第一个作为中枢  int i = start; for (int j = start + 1; j \u0026lt;= end; j++) { if (key \u0026gt; array[j]) { swap(array, j, ++i); } } array[start] = array[i];//先挪，然后再把中枢放到指定位置  array[i] = key; quickSort(array, start, i - 1); quickSort(array, i + 1, end); } } //交换两个数的值  public void swap(int[] A, int i, int j) { if (i != j) { A[i] ^= A[j]; A[j] ^= A[i]; A[i] ^= A[j]; } }   双指针优化 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  public class Solution { public int[] MySort (int[] arr) { quickSort(arr, 0, arr.length - 1); return arr; } public void quickSort(int[] arr, int start, int end){ if(start \u0026gt;= end){ return; } int pivot = arr[start]; int left = start, right = end; while(left \u0026lt; right){ while(left \u0026lt; right \u0026amp;\u0026amp; arr[right] \u0026gt;= pivot){ right--; } swap(arr, left, right); while(left \u0026lt; right \u0026amp;\u0026amp; arr[left] \u0026lt;= pivot){ left++; } swap(arr, left, right); } quickSort(arr, start, left - 1); quickSort(arr, left + 1, end); } private void swap(int[] arr, int i, int j) { int temp = arr[i]; arr[i] = arr[j]; arr[j] = temp; } }   归并 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44  public class Solution { public int[] MySort (int[] arr) { mergeSort(arr, 0, arr.length - 1); return arr; } public void mergeSort(int[] arr, int left, int right){ if(left ==right){ return; } int mid = left + (right - left) / 2; mergeSort(arr, left, mid); mergeSort(arr, mid + 1, right); merge(arr, left, mid, right); } private void merge(int[] arr, int left, int mid, int right){ //辅助数组，先把合并结果放进去，再拷贝回原数组  int[] temp = new int[right - left + 1]; int i = 0; int p1 = left; int p2 = mid + 1; //比较拷贝，直其中一半已经拷贝完成  while(p1 \u0026lt;= mid \u0026amp;\u0026amp; p2 \u0026lt;= right){ temp[i++] = arr[p1] \u0026lt;= arr[p2] ? arr[p1++] : arr[p2++]; } //p2先完成，把p1直接拷贝进去即可  while(p1 \u0026lt;= mid){ temp[i++] = arr[p1++]; } //p1先完成，把p2直接拷贝进去即可  while(p2 \u0026lt;= right){ temp[i++] = arr[p2++]; } for(i = 0; i \u0026lt; temp.length; i++){ arr[left + i] = temp[i]; } } }   堆排序 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78  public class Solution { public int[] MySort (int[] arr) { heapSort(arr); return arr; } /** * 堆是完全二叉树 * 使用数组存储 * 一个节点下标为i： * - 父节点: (i-1)/2 * - 左子节点：2i+1 * - 右子节点: 2i+2 */ public int[] heapSort(int[] nums) { int len = nums.length; // 将数组整理成堆  heapify(nums); // 循环不变量：区间 [0, i] 堆有序  for (int i = len - 1; i \u0026gt;= 1; ) { // 把堆顶元素（当前最大）交换到数组末尾  swap(nums, 0, i); // 把排好的元素剔除堆的范围  i--; // 堆顶元素进行下沉操作，使得区间 [0, i] 堆有序  siftDown(nums, 0, i); } return nums; } /** * 将数组整理成堆（堆有序） * * @param nums */ private void heapify(int[] nums) { int len = nums.length; // 只需要从 i = (len - 1) / 2 这个节点开始，倒序进行逐个下沉调整  // 每个节点调整的过程中可能会对下面已经调整过的产生影响，如果子节点变化需要递归的向下调整  for (int i = (len - 1) / 2; i \u0026gt;= 0; i--) { siftDown(nums, i, len - 1); } } /** * @param nums * @param k 当前进行下沉的元素的下标 * @param end [0, end] 是 nums 的有效部分 */ private void siftDown(int[] nums, int k, int end) { while (2 * k + 1 \u0026lt;= end) { int j = 2 * k + 1; //如果左子节点小于右子节点：将j指向右子节点  if (j + 1 \u0026lt;= end \u0026amp;\u0026amp; nums[j + 1] \u0026gt; nums[j]) { j++; } //如果子节点中较大的与父节点进行比较  if (nums[j] \u0026gt; nums[k]) { swap(nums, j, k); } else { //不需要任何交换，满足堆的条件  break; } //！重要：因为j可能变换，所以继续的向下调整  k = j; } } private void swap(int[] arr, int i, int j){ int temp = arr[i]; arr[i] = arr[j]; arr[j] = temp; } }   ","date":"2022-05-24T18:18:45+08:00","permalink":"https://isheihei.github.io/posts/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E6%8E%92%E5%BA%8F/","title":"排序"},{"content":" 普通 Serial：单线程，新生代标记-复制，老年代标记-整理\nParNew：Serial的多线程版本，新生代标记-复制，老年代标记-整理\nParallel Scavenge ：收集器关注点是吞吐量（高效率的利用 CPU）。CMS 等垃圾收集器的关注点更多的是用户线程的停顿时间（提高用户体验）。所谓吞吐量就是 CPU 中用于运行用户代码的时间与 CPU 总消耗时间的比值。 Parallel Scavenge 收集器提供了很多参数供用户找到最合适的停顿时间或最大吞吐量，如果对于收集器运作不太了解，手工优化存在困难的时候，使用 Parallel Scavenge 收集器配合自适应调节策略，把内存管理优化交给虚拟机去完成也是一个不错的选择。 新生代采用标记-复制算法，老年代采用标记-整理算法。这是 JDK1.8 默认收集器 JDK1.8 默认使用的是 Parallel Scavenge + Parallel Old\nSerial Old ：Serial的老年代版本\nParallel Old ：Parallel Scavenge 的老年代版本\n并发 CMS （Concurrent Mark Sweep）收集器： CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。它非常符合在注重用户体验的应用上使用。\nCMS（Concurrent Mark Sweep）收集器是 HotSpot 虚拟机第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作。\n基于标记-清除算法\n 初始标记： 暂停所有的其他线程，并记录下直接与 root 相连的对象，速度很快 ； 并发标记： 同时开启 GC 和用户线程，用一个闭包结构去记录可达对象。但在这个阶段结束，这个闭包结构并不能保证包含当前所有的可达对象。因为用户线程可能会不断的更新引用域，所以 GC 线程无法保证可达性分析的实时性。所以这个算法里会跟踪记录这些发生引用更新的地方。 重新标记： 重新标记阶段就是为了修正并发标记期间因为用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短 并发清除： 开启用户线程，同时 GC 线程开始对未标记的区域做清扫。  主要优点：并发收集、低停顿。但是它有下面三个明显的缺点：\n 对 CPU 资源敏感； 无法处理浮动垃圾； 它使用的回收算法-“标记-清除”算法会导致收集结束时会有大量空间碎片产生。  G1 收集器 G1 (Garbage-First) 是一款面向服务器的垃圾收集器,主要针对配备多颗处理器及大容量内存的机器. 以极高概率满足 GC 停顿时间要求的同时,还具备高吞吐量性能特征.\n被视为 JDK1.7 中 HotSpot 虚拟机的一个重要进化特征。它具备一下特点：\n 并行与并发：G1 能充分利用 CPU、多核环境下的硬件优势，使用多个 CPU（CPU 或者 CPU 核心）来缩短 Stop-The-World 停顿时间。部分其他收集器原本需要停顿 Java 线程执行的 GC 动作，G1 收集器仍然可以通过并发的方式让 java 程序继续执行。 分代收集：虽然 G1 可以不需要其他收集器配合就能独立管理整个 GC 堆，但是还是保留了分代的概念。 空间整合：与 CMS 的“标记-清理”算法不同，G1 从整体来看是基于“标记-整理”算法实现的收集器；从局部上来看是基于“标记-复制”算法实现的。 可预测的停顿：这是 G1 相对于 CMS 的另一个大优势，降低停顿时间是 G1 和 CMS 共同的关注点，但 G1 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为 M 毫秒的时间片段内。  G1 收集器的运作大致分为以下几个步骤：\n  初始标记(Initial Marking)：这阶段仅仅只是标记GC Roots能直接关联到的对象并修改TAMS(Next Top at Mark Start)的值，让下一阶段用户程序并发运行时，能在正确的可用的Region中创建新对象，这阶段需要停顿线程，但是耗时很短。而且是借用进行Minor GC的时候同步完成的，所以G1收集器在这个阶段实际并没有额外的停顿。\n  并发标记(Concurrent Marking)：从GC Roots开始对堆的对象进行可达性分析，递归扫描整个堆里的对象图，找出存活的对象，这阶段耗时较长，但是可以与用户程序并发执行。当对象图扫描完成以后，还要重新处理SATB记录下的在并发时有引用变动的对象。\n  最终标记(Final Marking)：对用户线程做另一个短暂的暂停，用于处理并发阶段结束后仍遗留下来的最后那少量的 SATB 记录。\n  筛选回收(Live Data Counting and Evacuation)：负责更新 Region 的统计数据，对各个 Region 的回收价值和成本进行排序，根据用户所期望的停顿时间来制定回收计划。可以自由选择多个Region来构成回收集，然后把回收的那一部分Region中的存活对象==复制==到空的Region中，在对那些Region进行清空。\n 除了并发标记外，其余过程都要 STW\n   G1 收集器在后台维护了一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的 Region(这也就是它的名字 Garbage-First 的由来) 。这种使用 Region 划分内存空间以及有优先级的区域回收方式，保证了 G1 收集器在有限时间内可以尽可能高的收集效率（把内存化整为零）。\n 不管是G1还是其他分代收集器，JVM都是使用 记忆集(Remembered Set) 来避免全局扫描。 每个Region都有一个对应的记忆集。 每次Reference类型数据写操作时，都会产生一个 写屏障（Write Barrier）暂时去终止操作 然后检查将要写入的引用 指向的对象是否和该Reference类型数据在不同的 Region（其他收集器：检查老年代对象是否引用了新生代对象） 如果不同，通过 卡表（Card Table）把相关引用信息记录到引用指向对象的所在Region对应的记忆集(Remembered Set) 中，被引用对象记录引用自己的对象，这样被引用对象要可达性分析时候，可以找记忆集中的对象 当进行垃圾收集时，在GC Roots枚举范围加上记忆集；就可以保证不进行全局扫描了。  参考  《深入理解 Java 虚拟机：JVM 高级特性与最佳实践（第二版》 https://docs.oracle.com/javase/specs/jvms/se8/html/index.html  ","date":"2022-05-24T17:24:10+08:00","permalink":"https://isheihei.github.io/posts/java/jvm-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/","title":"JVM 垃圾回收器"},{"content":"线程安全与锁优化 线程安全 Java语言中的线程安全 不可变\nJava语言中，如果多线程共享的数据是一个基本数据类型，那么只要在定义时使用final关键字修饰它就可以保证它是不可变的\n只要一个不可变的对象被正确地构建出来（即没有发生this引用逃逸的情况），那其外部的可见状态永远都不会改变，永远都不会看到它在多个线程之中处于不一致的状态。“不可变”带来的安全性是最直接、最纯粹的。\n绝对线程安全\n这个定义其实是很严格的，一个类要达到“不管运行时环境如何，调用者都不需要任何额外的同步措施”可能需要付出非常高昂的，甚至不切实际的代价。\n在Java API中标注自己是线程安全的类，大多数都不是绝对的线程安全。\n相对线程安全\n相对线程安全就是我们通常意义上所讲的线程安全，它需要保证对这个对象单次的操作是线程安全的，我们在调用的时候不需要进行额外的保障措施，但是对于一些特定顺序的连续调用，就可能需要在调用端使用额外的同步手段来保证调用的正确性。\n线程兼容\n线程兼容是指对象本身并不是线程安全的，但是可以通过在调用端正确地使用同步手段来保证对象在并发环境中可以安全地使用。\n线程对立\n线程对立是指不管调用端是否采取了同步措施，都无法在多线程环境中并发使用代码。\n一个线程对立的例子是Thread类的suspend()和resume()方法。如果有两个线程同时持有一个线程对象，一个尝试去中断线程，一个尝试去恢复线程，在并发进行的情况下，无论调用时是否进行了同步，目标线程都存在死锁风险——假如suspend()中断的线程就是即将要执行resume()的那个线程，那就肯定要产生死锁了。\n线程安全的实现方法 互斥同步\n在Java里面，最基本的互斥同步手段就是synchronized关键字，这是一种块结构（Block Structured）的同步语法。synchronized关键字经过Javac编译之后，会在同步块的前后分别形成monitorenter和monitorexit这两个字节码指令。\n这两个字节码指令都需要一个reference类型的参数来指明要锁定和解锁的对象。如果Java源码中的synchronized明确指定了对象参数，那就以这个对象的引用作为reference；如果没有明确指定，那将根据synchronized修饰的方法类型（如实例方法或类方法），来决定是取代码所在的对象实例还是取类型对应的Class对象来作为线程要持有的锁\n从功能上看，根据以上《Java虚拟机规范》对monitorenter和monitorexit的行为描述，我们可以得出两个关于synchronized的直接推论，这是使用它时需特别注意的：\n 被synchronized修饰的同步块对同一条线程来说是可重入的。这意味着同一线程反复进入同步块也不会出现自己把自己锁死的情况。 被synchronized修饰的同步块在持有锁的线程执行完毕并释放锁之前，会无条件地阻塞后面其他线程的进入。这意味着无法像处理某些数据库中的锁那样，强制已获取锁的线程释放锁；也无法强制正在等待锁的线程中断等待或超时退出。  从执行成本的角度看，持有锁是一个重量级（Heavy-Weight）的操作。在主流Java虚拟机实现中，Java的线程是映射到操作系统的原生内核线程之上的，如果要阻塞或唤醒一条线程，则需要操作系统来帮忙完成，这就不可避免地陷入用户态到核心态的转换中，进行这种状态转换需要耗费很多的处理器时间。尤其是对于代码特别简单的同步块（譬如被synchronized修饰的getter()或setter()方法），状态转换消耗的时间甚至会比用户代码本身执行的时间还要长。因此才说，synchronized是Java语言中一个重量级的操作，有经验的程序员都只会在确实必要的情况下才使用这种操作。\n**重入锁（ReentrantLock）**是Lock接口最常见的一种实现，顾名思义，它与synchronized一样是可重入的。在基本用法上，ReentrantLock也与synchronized很相似，只是代码写法上稍有区别而已。不过，ReentrantLock与synchronized相比增加了一些高级功能，主要有以下三项：等待可中断、可实现公平锁及锁可以绑定多个条件。\n 等待可中断：是指当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情。可中断特性对处理执行时间非常长的同步块很有帮助。 公平锁：是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁；而非公平 锁则不保证这一点，在锁被释放时，任何一个等待锁的线程都有机会获得锁。synchronized中的锁是非公平的，ReentrantLock在默认情况下也是非公平的，但可以通过带布尔值的构造函数要求使用公平锁。不过一旦使用了公平锁，将会导致ReentrantLock的性能急剧下降，会明显影响吞吐量。 锁绑定多个条件：是指一个ReentrantLock对象可以同时绑定多个Condition对象。在synchronized中，锁对象的wait()跟它的notify()或者notifyAll()方法配合可以实现一个隐含的条件，如果要和多于一个的条件关联的时候，就不得不额外添加一个锁；而ReentrantLock则无须这样做，多次调用newCondition()方法即可。  ReentrantLock在功能上是synchronized的超集，在性能上又至少不会弱于synchronized，那synchronized修饰符是否应该被直接抛弃，不再使用了呢？当然不是，基于以下理由，笔者仍然推荐在synchronized与ReentrantLock都可满足需要时优先使用synchronized：\n synchronized是在Java语法层面的同步，足够清晰，也足够简单。每个Java程序员都熟悉synchronized，但J.U.C中的Lock接口则并非如此。因此在只需要基础的同步功能时，更推荐synchronized。 Lock应该确保在finally块中释放锁，否则一旦受同步保护的代码块中抛出异常，则有可能永远不会释放持有的锁。这一点必须由程序员自己来保证，而使用synchronized的话则可以由Java虚拟机来确保即使出现异常，锁也能被自动释放。 尽管在JDK 5时代ReentrantLock曾经在性能上领先过synchronized，但这已经是十多年之前的胜利了。从长远来看，Java虚拟机更容易针对synchronized来进行优化，因为Java虚拟机可以在线程和对象的元数据中记录synchronized中锁的相关信息，而使用J.U.C中的Lock的话，Java虚拟机是很难得知具体哪些锁对象是由特定线程锁持有的。  非阻塞同步\n随着硬件指令集的发展，我们已经有了另外一个选择：基于冲突检测的乐观并发策略，通俗地说就是不管风险，先进行操作，如果没有其他线程争用共享数据，那操作就直接成功了；如果共享的数据的确被争用，产生了冲突，那再进行其他的补偿措施，最常用的补偿措施是不断地重试，直到出现没有竞争的共享数据为止。这种乐观并发策略的实现不再需要把线程阻塞挂起，因此这种同步操作被称为非阻塞同步（Non-Blocking Synchronization），使用这种措施的代码也常被称为无锁（Lock-Free）编程。\n硬件保证某些从语义上看起来需要多次操作的行为可以只通过一条处理器指令就能完成，这类指令常用的有：\n 测试并设置（Test-and-Set）； 获取并增加（Fetch-and-Increment）； 交换（Swap）； 比较并交换（Compare-and-Swap，下文称CAS）； 加载链接/条件储存（Load-Linked/Store-Conditional，下文称LL/SC）。  CAS指令需要有三个操作数，分别是内存位置（在Java中可以简单地理解为变量的内存地址，用V表示）、旧的预期值（用A表示）和准备设置的新值（用B表示）。CAS指令执行时，当且仅当V符合A时，处理器才会用B更新V的值，否则它就不执行更新。但是，不管是否更新了V的值，都会返回V的旧值，上述的处理过程是一个原子操作，执行期间不会被其他线程中断。\n无同步方案\n要保证线程安全，也并非一定要进行阻塞或非阻塞同步，同步与线程安全两者没有必然的联系。同步只是保障存在共享数据争用时正确性的手段，如果能让一个方法本来就不涉及共享数据，那它自然就不需要任何同步措施去保证其正确性，因此会有一些代码天生就是线程安全的，简单介绍其中的两类。\n可重入代码（Reentrant Code）：这种代码又称纯代码（Pure Code），是指可以在代码执行的任何时刻中断它，转而去执行另外一段代码（包括递归调用它本身），而在控制权返回后，原来的程序不会出现任何错误，也不会对结果有所影响。在特指多线程的上下文语境里（不涉及信号量等因素），我们可以认为可重入代码是线程安全代码的一个真子集，这意味着相对线程安全来说，可重入性是更为基础的特性，它可以保证代码线程安全，即所有可重入的代码都是线程安全的，但并非所有的线程安全的代码都是可重入的。\n可重入代码有一些共同的特征，例如，不依赖全局变量、存储在堆上的数据和公用的系统资源，用到的状态量都由参数中传入，不调用非可重入的方法等。我们可以通过一个比较简单的原则来判断代码是否具备可重入性：如果一个方法的返回结果是可以预测的，只要输入了相同的数据，就都能返回相同的结果，那它就满足可重入性的要求，当然也就是线程安全的。\n线程本地存储（Thread Local Storage）：如果一段代码中所需要的数据必须与其他代码共享，那就看看这些共享数据的代码是否能保证在同一个线程中执行。如果能保证，我们就可以把共享数据的可见范围限制在同一个线程之内，这样，无须同步也能保证线程之间不出现数据争用的问题。\n锁优化 Java虚拟机中，synchronized支持的同步方法和同步语句都是使用monitor来实现的。每个对象都与一个monitor相关联，当一个线程执行到一个monitor监视下的代码块中的第一个指令时，该线程必须在引用的对象上获得一个锁，这个锁是monitor实现的。在HotSpot虚拟机中，monitor是由ObjectMonitor实现，使用C++编写实现，具体代码在HotSpot虚拟机源码ObjectMonitor.hpp文件中。\n查看源码会发现，主要的属性有_count(记录该线程获取锁的次数)、_recursions(锁的重入次数)、_owner(指向持有ObjectMonitor对象的线程)、_WaitSet(处于wait状态的线程集合)、_EntryList(处于等待锁block状态的线程队列)。\n当并发线程执行synchronized修饰的方法或语句块时，先进入_EntryList中，当某个线程获取到对象的monitor后，把monitor对象中的_owner变量设置为当前线程，同时monitor对象中的计数器_count加1，当前线程获取同步锁成功。\n当synchronized修饰的方法或语句块中的线程调用wait()方法时，当前线程将释放持有的monitor对象，monitor对象中的_owner变量赋值为null，同时，monitor对象中的_count值减1，然后当前线程进入_WaitSet集合中等待被唤醒。\n自旋锁与自适应自旋 如果物理机器有一个以上的处理器或者处理器核心，能让两个或以上的线程同时并行执行，我们就可以让后面请求锁的那个线程“稍等一会”，但不放弃处理器的执行时间，看看持有锁的线程是否很快就会释放锁。为了让线程等待，我们只须让线程执行一个忙循环（自旋），这项技术就是所谓的自旋锁。\n在JDK 6中对自旋锁的优化，引入了自适应的自旋。自适应意味着自旋的时间不再是固定的了，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定的。如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也很有可能再次成功，进而允许自旋等待持续相对更长的时间\n如果对于某个锁，自旋很少成功获得过锁，那在以后要获取这个锁时将有可能直接省略掉自旋过程，以避免浪费处理器资源。\n锁消除 锁消除是指虚拟机即时编译器在运行时，对一些代码要求同步，但是对被检测到不可能存在共享数据竞争的锁进行消除。锁消除的主要判定依据来源于逃逸分析的数据支持（第11章已经讲解过逃逸分析技术），如果判断到一段代码中，在堆上的所有数据都不会逃逸出去被其他线程访问到，那就可以把它们当作栈上数据对待，认为它们是线程私有的，同步加锁自然就无须再进行。\n锁粗化 原则上，我们在编写代码的时候，总是推荐将同步块的作用范围限制得尽量小——只在共享数据的实际作用域中才进行同步，这样是为了使得需要同步的操作数量尽可能变少，即使存在锁竞争，等待锁的线程也能尽可能快地拿到锁。\n大多数情况下，上面的原则都是正确的，但是如果一系列的连续操作都对同一个对象反复加锁和解锁，甚至加锁操作是出现在循环体之中的，那即使没有线程竞争，频繁地进行互斥同步操作也会导致不必要的性能损耗。\n如果虚拟机探测到有这样一串零碎的操作都对同一个对象加锁，将会把加锁同步的范围扩展（粗化）到整个操作序列的外部\n轻量级锁 轻量级锁并不是用来代替重量级锁的，它设计的初衷是在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗。\n32位HotSpot虚拟机对象头Mark Word\n接下来介绍轻量级锁的工作过程：在代码即将进入同步块的时候，如果此同步对象没有被锁定（锁标志位为“01”状态），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝（官方为这份拷贝加了一个Displaced前缀，即Displaced Mark Word），这时候线程堆栈与对象头的状态如图。\n然后，虚拟机将使用CAS操作尝试把对象的Mark Word更新为指向Lock Record的指针。如果这个更新动作成功了，即代表该线程拥有了这个对象的锁，并且对象Mark Word的锁标志位（Mark Word的最后两个比特）将转变为“00”，表示此对象处于轻量级锁定状态。这时候线程堆栈与对象头的状态如图所示。\n如果这个更新操作失败了，那就意味着至少存在一条线程与当前线程竞争获取该对象的锁。虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是，说明当前线程已经拥有了这个对象的锁，那直接进入同步块继续执行就可以了，否则就说明这个锁对象已经被其他线程抢占了。如果出现两条以上的线程争用同一个锁的情况，那轻量级锁就不再有效，必须要膨胀为重量级锁，锁标志的状态值变为“10”，此时Mark Word中存储的就是指向重量级锁（互斥量）的指针，后面等待锁的线程也必须进入阻塞状态。\n上面描述的是轻量级锁的加锁过程，它的解锁过程也同样是通过CAS操作来进行的，如果对象的Mark Word仍然指向线程的锁记录，那就用CAS操作把对象当前的Mark Word和线程中复制DisplacedMark Word替换回来。假如能够成功替换，那整个同步过程就顺利完成了；如果替换失败，则说明有其他线程尝试过获取该锁，就要在释放锁的同时，唤醒被挂起的线程。\n轻量级锁能提升程序同步性能的依据是“对于绝大部分的锁，在整个同步周期内都是不存在竞争的”这一经验法则。如果没有竞争，轻量级锁便通过CAS操作成功避免了使用互斥量的开销；但如果确实存在锁竞争，除了互斥量的本身开销外，还额外发生了CAS操作的开销。因此在有竞争的情况下，轻量级锁反而会比传统的重量级锁更慢。\n偏向锁 偏向锁的思想是偏向于让第一个获取锁对象的线程，这个线程在之后获取该锁就不再需要进行同步操作，甚至连 CAS 操作也不再需要。\n当锁对象第一次被线程获得的时候，进入偏向状态，标记为 |1|01|（前面内存布局图中说明了，这属于偏向锁状态）。同时使用 CAS 操作将线程 ID （ThreadID）记录到 Mark Word 中，如果 CAS 操作成功，这个线程以后每次进入这个锁相关的同步块就不需要再进行任何同步操作。\n当有另外一个线程去尝试获取这个锁对象时，偏向状态就宣告结束，此时撤销偏向（Revoke Bias）后恢复到未锁定状态或者轻量级锁状态。\n偏向锁是为了在资源没有被多线程竞争的情况下尽量减少锁带来的性能开销。\n在锁对象的对象头中有一个ThreadId字段，当第一个线程访问锁时，如果该锁没有被其他线程访问过，即ThreadId字段为空，那么JVM让其持有偏向锁，并将ThreadId字段的值设置为该线程的ID。当下一次获取锁的时候，会判断ThreadId是否相等，如果一致就不会重复获取锁，从而提高了运行率\n如果存在锁的竞争情况，偏向锁就会被撤销并升级为轻量级锁。\n总结 synchronized的执行过程：\n 检测Mark Word里面是不是当前线程的ID，如果是，表示当前线程处于偏向锁 如果不是，则使用CAS将当前线程的ID替换Mark Word，如果成功则表示当前线程获得偏向锁，置偏向标志位1 如果失败，则说明发生竞争，撤销偏向锁，进而升级为轻量级锁。 当前线程使用CAS将对象头的Mark Word替换为锁记录指针，如果成功，当前线程获得锁 如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。 如果自旋成功则依然处于轻量级状态。 如果自旋失败，则升级为重量级锁。  偏向锁、轻量级锁、重量级锁的区别\n偏向锁的优点是加解锁不需要额外消耗，和执行非同步方法比仅存在纳秒级差距，缺点是如果存在锁竞争会带来额外锁撤销的消耗，适用只有一个线程访问同步代码块的场景。\n轻量级锁的优点是竞争线程不阻塞，程序响应速度快，缺点是如果线程始终得不到锁会自旋消耗 CPU，适用追求响应时间、同步代码块执行快的场景。\n重量级锁的优点是线程竞争不使用自旋不消耗CPU，缺点是线程会阻塞，响应时间慢，适应追求吞吐量、同步代码块执行慢的场景。\n","date":"2022-05-24T14:11:07+08:00","permalink":"https://isheihei.github.io/posts/java/jvm-%E9%94%81%E4%BC%98%E5%8C%96/","title":"线程安全与锁优化"},{"content":"  将 zip 包解压到相应的目录，这里我将解压后的文件夹放在D:\\software\\mysql\\mysql-8.0.22-winx64 下。\n  以管理员身份打开cmd命令行工具，切换目录到：D:\\software\\mysql\\mysql-8.0.22-winx64\\bin\n  初始化数据库：\n mysqld \u0026ndash;initialize \u0026ndash;console\n   执行完场后，会输出root默认的随机密码，如：\n 2021-01-18T03:55:52.326932Z 6 [Note] [MY-010454] [Server] A temporary password is generated for root@localhost: =tL5\u0026gt;rI40v_\u0026gt;\n 随机密码就是：=tL5\u0026gt;rI40v_\u0026gt;\n  安装\n 1  mysqld install      启动\n 1  net start mysql      输入以下命令登录数据库\n mysql -u root -p\n 需要输入密码，默认密码就是步骤4中的随机密码\n  登陆后输入命令\n alter user \u0026lsquo;root\u0026rsquo;@\u0026rsquo;localhost\u0026rsquo; identified by \u0026lsquo;想要设置的密码\u0026rsquo;;\ncommit;\n 修改密码\n  将Mysql的bin目录配置到环境变量中\n  属性配置文件\n1 2 3 4  jdbc.driver=com.mysql.cj.jdbc.Driver jdbc.url=jdbc:mysql://localhost:3306/db0?useUnicode=true\u0026amp;characterEncoding=utf-8\u0026amp;useSSL=false\u0026amp;serverTimezone=GMT jdbc.user=root jdbc.password=root    ","date":"2021-01-29T23:28:00+08:00","permalink":"https://isheihei.github.io/posts/tips/mysql%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/","title":"Mysql安装配置"},{"content":"解压maven压缩包 配置环境变量   新建系统变量 MAVEN_HOME 变量值：E:\\Maven\\apache-maven-3.3.9\n  编辑系统变量 Path 添加变量值： %MAVEN_HOME%\\bin\n  打开cmd，输入  mvn \u0026ndash;version\n 查看安装配置是否成功","date":"2021-01-29T23:25:33+08:00","permalink":"https://isheihei.github.io/posts/tips/maven%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/","title":"Maven安装配置"},{"content":"新建JAVA_HOME变量，填写jdk安装路径：bin目录的上一级 PATH变量添加两个：  %JAVA_HOME%\\bin %JAVA_HOME%\\jre\\bin  新建CLASSPATH变量：  .;%JAVA_HOME%\\lib;%JAVA_HOME%\\lib\\tools.jar ","date":"2021-01-29T23:21:58+08:00","permalink":"https://isheihei.github.io/posts/tips/jdk%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE/","title":"Jdk环境变量配置"},{"content":"将rpm 安装包拷贝到usr/local/sql目录下 卸载mariadb 1 2  # rpm -qa | grep mariadb # rpm -e --nodeps mariadb-libs-5.5.68-1.el7.x86_64   解压mysql.tar包,解压后目录下会有一些rpm文件。 1  # tar -xvf MySQL-5.6.25-1.el6.x86_64.rpm-bundle.tar   安装Mysql.server和Mysql.client 1 2 3 4  # rp-ivh MySQL-server-5.6.25-1.el6.x86_64.rpm # 打开/root/.mysql_secret文件，获取随机生成的密码： mAw0cco4dAVG332x # cat /root/.mysql_secret   启动mysql服务 1  # service mysql start   修改密码 1  mysql\u0026gt; set password = password(\u0026#39;root\u0026#39;);   授权远程访问 1 2 3 4 5  mysql\u0026gt; grant all privileges on *.* to \u0026#39;root\u0026#39; @\u0026#39;%\u0026#39; identified by \u0026#39;root\u0026#39;; mysql\u0026gt; flush privileges; # 关闭防火墙 # systemctl stop firewalld   ","date":"2021-01-29T23:17:20+08:00","permalink":"https://isheihei.github.io/posts/tips/centos7%E9%85%8D%E7%BD%AEmysql/","title":"Centos7配置 ysql"}]